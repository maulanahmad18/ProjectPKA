title,authors,published_date,summary,categories,main_category,link
AI-generated Image Detection: Passive or Watermark?,"Moyang Guo, Yuepeng Hu, Zhengyuan Jiang, Zeyu Li, Amir Sadovnik, Arka Daw, Neil Gong",2024-11-20T18:59:58Z,"While text-to-image models offer numerous benefits, they also pose
significant societal risks. Detecting AI-generated images is crucial for
mitigating these risks. Detection methods can be broadly categorized into
passive and watermark-based approaches: passive detectors rely on artifacts
present in AI-generated images, whereas watermark-based detectors proactively
embed watermarks into such images. A key question is which type of detector
performs better in terms of effectiveness, robustness, and efficiency. However,
the current literature lacks a comprehensive understanding of this issue. In
this work, we aim to bridge that gap by developing ImageDetectBench, the first
comprehensive benchmark to compare the effectiveness, robustness, and
efficiency of passive and watermark-based detectors. Our benchmark includes
four datasets, each containing a mix of AI-generated and non-AI-generated
images. We evaluate five passive detectors and four watermark-based detectors
against eight types of common perturbations and three types of adversarial
perturbations. Our benchmark results reveal several interesting findings. For
instance, watermark-based detectors consistently outperform passive detectors,
both in the presence and absence of perturbations. Based on these insights, we
provide recommendations for detecting AI-generated images, e.g., when both
types of detectors are applicable, watermark-based detectors should be the
preferred choice.","cs.CR, cs.CV, cs.LG",cs.CR,http://arxiv.org/abs/2411.13553v1
Generating 3D-Consistent Videos from Unposed Internet Photos,"Gene Chou, Kai Zhang, Sai Bi, Hao Tan, Zexiang Xu, Fujun Luan, Bharath Hariharan, Noah Snavely",2024-11-20T18:58:31Z,"We address the problem of generating videos from unposed internet photos. A
handful of input images serve as keyframes, and our model interpolates between
them to simulate a path moving between the cameras. Given random images, a
model's ability to capture underlying geometry, recognize scene identity, and
relate frames in terms of camera position and orientation reflects a
fundamental understanding of 3D structure and scene layout. However, existing
video models such as Luma Dream Machine fail at this task. We design a
self-supervised method that takes advantage of the consistency of videos and
variability of multiview internet photos to train a scalable, 3D-aware video
model without any 3D annotations such as camera parameters. We validate that
our method outperforms all baselines in terms of geometric and appearance
consistency. We also show our model benefits applications that enable camera
control, such as 3D Gaussian Splatting. Our results suggest that we can scale
up scene-level 3D learning using only 2D data such as videos and multiview
internet photos.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13549v1
"HF-Diff: High-Frequency Perceptual Loss and Distribution Matching for
  One-Step Diffusion-Based Image Super-Resolution","Shoaib Meraj Sami, Md Mahedi Hasan, Jeremy Dawson, Nasser Nasrabadi",2024-11-20T18:56:24Z,"Although recent diffusion-based single-step super-resolution methods achieve
better performance as compared to SinSR, they are computationally complex. To
improve the performance of SinSR, we investigate preserving the high-frequency
detail features during super-resolution (SR) because the downgraded images lack
detailed information. For this purpose, we introduce a high-frequency
perceptual loss by utilizing an invertible neural network (INN) pretrained on
the ImageNet dataset. Different feature maps of pretrained INN produce
different high-frequency aspects of an image. During the training phase, we
impose to preserve the high-frequency features of super-resolved and ground
truth (GT) images that improve the SR image quality during inference.
Furthermore, we also utilize the Jenson-Shannon divergence between GT and SR
images in the pretrained DINO-v2 embedding space to match their distribution.
By introducing the $\textbf{h}igh$- $\textbf{f}requency$ preserving loss and
distribution matching constraint in the single-step $\textbf{diff}usion-based$
SR ($\textbf{HF-Diff}$), we achieve a state-of-the-art CLIPIQA score in the
benchmark RealSR, RealSet65, DIV2K-Val, and ImageNet datasets. Furthermore, the
experimental results in several datasets demonstrate that our high-frequency
perceptual loss yields better SR image quality than LPIPS and VGG-based
perceptual losses. Our code will be released at
https://github.com/shoaib-sami/HF-Diff.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.13548v1
"Promoting User Data Autonomy During the Dissolution of a Monopolistic
  Firm","Rushabh Solanki, Elliot Creager",2024-11-20T18:55:51Z,"The deployment of AI in consumer products is currently focused on the use of
so-called foundation models, large neural networks pre-trained on massive
corpora of digital records. This emphasis on scaling up datasets and
pre-training computation raises the risk of further consolidating the industry,
and enabling monopolistic (or oligopolistic) behavior. Judges and regulators
seeking to improve market competition may employ various remedies. This paper
explores dissolution -- the breaking up of a monopolistic entity into smaller
firms -- as one such remedy, focusing in particular on the technical challenges
and opportunities involved in the breaking up of large models and datasets. We
show how the framework of Conscious Data Contribution can enable user autonomy
during under dissolution. Through a simulation study, we explore how
fine-tuning and the phenomenon of ""catastrophic forgetting"" could actually
prove beneficial as a type of machine unlearning that allows users to specify
which data they want used for what purposes.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13546v1
Pushing the Limits of Sparsity: A Bag of Tricks for Extreme Pruning,"Andy Li, Aiden Durrant, Milan Markovic, Lu Yin, Georgios Leontidis",2024-11-20T18:54:53Z,"Pruning of deep neural networks has been an effective technique for reducing
model size while preserving most of the performance of dense networks, crucial
for deploying models on memory and power-constrained devices. While recent
sparse learning methods have shown promising performance up to moderate
sparsity levels such as 95% and 98%, accuracy quickly deteriorates when pushing
sparsities to extreme levels. Obtaining sparse networks at such extreme
sparsity levels presents unique challenges, such as fragile gradient flow and
heightened risk of layer collapse. In this work, we explore network performance
beyond the commonly studied sparsities, and propose a collection of techniques
that enable the continuous learning of networks without accuracy collapse even
at extreme sparsities, including 99.90%, 99.95% and 99.99% on ResNet
architectures. Our approach combines 1) Dynamic ReLU phasing, where DyReLU
initially allows for richer parameter exploration before being gradually
replaced by standard ReLU, 2) weight sharing which reuses parameters within a
residual layer while maintaining the same number of learnable parameters, and
3) cyclic sparsity, where both sparsity levels and sparsity patterns evolve
dynamically throughout training to better encourage parameter exploration. We
evaluate our method, which we term Extreme Adaptive Sparse Training (EAST) at
extreme sparsities using ResNet-34 and ResNet-50 on CIFAR-10, CIFAR-100, and
ImageNet, achieving significant performance improvements over state-of-the-art
methods we compared with.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13545v1
BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games,"Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel",2024-11-20T18:54:32Z,"Large Language Models (LLMs) and Vision Language Models (VLMs) possess
extensive knowledge and exhibit promising reasoning abilities; however, they
still struggle to perform well in complex, dynamic environments. Real-world
tasks require handling intricate interactions, advanced spatial reasoning,
long-term planning, and continuous exploration of new strategies-areas in which
we lack effective methodologies for comprehensively evaluating these
capabilities. To address this gap, we introduce BALROG, a novel benchmark
designed to assess the agentic capabilities of LLMs and VLMs through a diverse
set of challenging games. Our benchmark incorporates a range of existing
reinforcement learning environments with varying levels of difficulty,
including tasks that are solvable by non-expert humans in seconds to extremely
challenging ones that may take years to master (e.g., the NetHack Learning
Environment). We devise fine-grained metrics to measure performance and conduct
an extensive evaluation of several popular open-source and closed-source LLMs
and VLMs. Our findings indicate that while current models achieve partial
success in the easier games, they struggle significantly with more challenging
tasks. Notably, we observe severe deficiencies in vision-based decision-making,
as models perform worse when visual representations of the environments are
provided. We release BALROG as an open and user-friendly benchmark to
facilitate future research and development in the agentic community.",cs.AI,cs.AI,http://arxiv.org/abs/2411.13543v1
Metacognition for Unknown Situations and Environments (MUSE),"Rodolfo Valiente, Praveen K. Pilly",2024-11-20T18:41:03Z,"Metacognition--the awareness and regulation of one's cognitive processes--is
central to human adaptability in unknown situations. In contrast, current
autonomous agents often struggle in novel environments due to their limited
capacity for adaptation. We hypothesize that metacognition is a critical
missing ingredient in adaptive autonomous systems, equipping them with the
cognitive flexibility needed to tackle unfamiliar challenges. Given the broad
scope of metacognitive abilities, we focus on two key aspects: competence
awareness and strategy selection for novel tasks. To this end, we propose the
Metacognition for Unknown Situations and Environments (MUSE) framework, which
integrates metacognitive processes--specifically self-awareness and
self-regulation--into autonomous agents. We present two initial implementations
of MUSE: one based on world modeling and another leveraging large language
models (LLMs), both instantiating the metacognitive cycle. Our system
continuously learns to assess its competence on a given task and uses this
self-awareness to guide iterative cycles of strategy selection. MUSE agents
show significant improvements in self-awareness and self-regulation, enabling
them to solve novel, out-of-distribution tasks more effectively compared to
Dreamer-v3-based reinforcement learning and purely prompt-based LLM agent
approaches. This work highlights the promise of approaches inspired by
cognitive and neural systems in enabling autonomous systems to adapt to new
environments, overcoming the limitations of current methods that rely heavily
on extensive training data.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13537v1
"Identity Preserving 3D Head Stylization with Multiview Score
  Distillation","Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar",2024-11-20T18:37:58Z,"3D head stylization transforms realistic facial features into artistic
representations, enhancing user engagement across gaming and virtual reality
applications. While 3D-aware generators have made significant advancements,
many 3D stylization methods primarily provide near-frontal views and struggle
to preserve the unique identities of original subjects, often resulting in
outputs that lack diversity and individuality. This paper addresses these
challenges by leveraging the PanoHead model, synthesizing images from a
comprehensive 360-degree perspective. We propose a novel framework that employs
negative log-likelihood distillation (LD) to enhance identity preservation and
improve stylization quality. By integrating multi-view grid score and mirror
gradients within the 3D GAN architecture and introducing a score rank weighing
technique, our approach achieves substantial qualitative and quantitative
improvements. Our findings not only advance the state of 3D head stylization
but also provide valuable insights into effective distillation processes
between diffusion models and GANs, focusing on the critical issue of identity
preservation. Please visit the https://three-bee.github.io/head_stylization for
more visuals.","cs.CV, cs.AI, cs.GR, cs.LG, cs.MM",cs.CV,http://arxiv.org/abs/2411.13536v1
"Predictive Insights into LGBTQ+ Minority Stress: A Transductive
  Exploration of Social Media Discourse","S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira",2024-11-20T18:35:41Z,"Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13534v1
Geometric Algebra Planes: Convex Implicit Neural Volumes,"Irmak Sivgin, Sara Fridovich-Keil, Gordon Wetzstein, Mert Pilanci",2024-11-20T18:21:58Z,"Volume parameterizations abound in recent literature, from the classic voxel
grid to the implicit neural representation and everything in between. While
implicit representations have shown impressive capacity and better memory
efficiency compared to voxel grids, to date they require training via nonconvex
optimization. This nonconvex training process can be slow to converge and
sensitive to initialization and hyperparameter choices that affect the final
converged result. We introduce a family of models, GA-Planes, that is the first
class of implicit neural volume representations that can be trained by convex
optimization. GA-Planes models include any combination of features stored in
tensor basis elements, followed by a neural feature decoder. They generalize
many existing representations and can be adapted for convex, semiconvex, or
nonconvex training as needed for different inverse problems. In the 2D setting,
we prove that GA-Planes is equivalent to a low-rank plus low-resolution matrix
factorization; we show that this approximation outperforms the classic low-rank
plus sparse decomposition for fitting a natural image. In 3D, we demonstrate
GA-Planes' competitive performance in terms of expressiveness, model size, and
optimizability across three volume fitting tasks: radiance field
reconstruction, 3D segmentation, and video segmentation.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13525v1
"Understanding the Personal Networks of People Experiencing Homelessness
  in King County, WA with aggregate Relational Data","Zack Almquist, Ihsan Kahveci, Owen Kajfasz, Janelle Rothfolk, Amy Hagopian",2024-11-20T18:09:14Z,"The social networks of people experiencing homelessness are an understudied
but vital aspect of their lives, offering access to information, support, and
safety. In 2023, the U.S. Department of Housing and Urban Development reported
653,100 people experiencing homelessness on any given night -- a 23% rise since
2022, though likely an undercount. This paper examines a unique three-year
dataset (2022-2024) of survey responses from over 3,000 unhoused individuals in
King County, WA, collected via network-based sampling methods to estimate the
unsheltered population. Our study analyzes the networks of the unsheltered
population, focusing on acquaintance, close friendship, kinship, and peer
referral networks. Findings reveal a decline in social connectivity over time.
The average number of acquaintances dropped from 80 in 2023 to 40 in 2024.
Close friendship levels remained stable at 2.5, but given the growth in the
homeless population, this suggests decreased network connectivity. Kinship
networks expanded, indicating that more family members of unhoused individuals
are also experiencing homelessness. These trends suggest increasing social
disconnection, possibly driven by displacement and a rise in newly homeless
individuals. The growing isolation may reduce opportunities for information
sharing and mutual support. However, the increased reliance on family networks
highlights the shifting dynamics of social support within this community. This
research underscores the need for policies fostering social connections and
community building, such as reducing displacement and providing spaces for
congregation, to counter the growing anomie among unhoused populations.","cs.SI, physics.soc-ph",cs.SI,http://arxiv.org/abs/2411.13517v1
Procurement Auctions via Approximately Optimal Submodular Optimization,"Yuan Deng, Amin Karbasi, Vahab Mirrokni, Renato Paes Leme, Grigoris Velegkas, Song Zuo",2024-11-20T18:06:55Z,"We study procurement auctions, where an auctioneer seeks to acquire services
from strategic sellers with private costs. The quality of services is measured
by a submodular function known to the auctioneer. Our goal is to design
computationally efficient procurement auctions that (approximately) maximize
the difference between the quality of the acquired services and the total cost
of the sellers, while ensuring incentive compatibility (IC), individual
rationality (IR) for sellers, and non-negative surplus (NAS) for the
auctioneer.
  Our contributions are twofold: (i) we provide an improved analysis of
existing algorithms for non-positive submodular function maximization, and (ii)
we design efficient frameworks that transform submodular optimization
algorithms into mechanisms that are IC, IR, NAS, and approximation-preserving.
These frameworks apply to both the offline setting, where all sellers' bids and
services are available simultaneously, and the online setting, where sellers
arrive in an adversarial order, requiring the auctioneer to make irrevocable
decisions.
  We also explore whether state-of-the-art submodular optimization algorithms
can be converted into descending auctions in adversarial settings, where the
schedule of descending prices is determined by an adversary. We show that a
submodular optimization algorithm satisfying bi-criteria $(1/2,
1)$-approximation in welfare can be effectively adapted to a descending
auction. Additionally, we establish a connection between descending auctions
and online submodular optimization.
  Finally, we demonstrate the practical applications of our frameworks by
instantiating them with state-of-the-art submodular optimization algorithms and
empirically comparing their welfare performance on publicly available datasets
with thousands of sellers.","cs.GT, cs.DS, cs.LG",cs.GT,http://arxiv.org/abs/2411.13513v1
"Advancing Heatwave Forecasting via Distribution Informed-Graph Neural
  Networks (DI-GNNs): Integrating Extreme Value Theory with GNNs","Farrukh A. Chishtie, Dominique Brunet, Rachel H. White, Daniel Michelson, Jing Jiang, Vicky Lucas, Emily Ruboonga, Sayana Imaash, Melissa Westland, Timothy Chui, Rana Usman Ali, Mujtaba Hassan, Roland Stull, David Hudak",2024-11-20T17:45:03Z,"Heatwaves, prolonged periods of extreme heat, have intensified in frequency
and severity due to climate change, posing substantial risks to public health,
ecosystems, and infrastructure. Despite advancements in Machine Learning (ML)
modeling, accurate heatwave forecasting at weather scales (1--15 days) remains
challenging due to the non-linear interactions between atmospheric drivers and
the rarity of these extreme events. Traditional models relying on heuristic
feature engineering often fail to generalize across diverse climates and
capture the complexities of heatwave dynamics. This study introduces the
Distribution-Informed Graph Neural Network (DI-GNN), a novel framework that
integrates principles from Extreme Value Theory (EVT) into the graph neural
network architecture. DI-GNN incorporates Generalized Pareto Distribution
(GPD)-derived descriptors into the feature space, adjacency matrix, and loss
function to enhance its sensitivity to rare heatwave occurrences. By
prioritizing the tails of climatic distributions, DI-GNN addresses the
limitations of existing methods, particularly in imbalanced datasets where
traditional metrics like accuracy are misleading. Empirical evaluations using
weather station data from British Columbia, Canada, demonstrate the superior
performance of DI-GNN compared to baseline models. DI-GNN achieved significant
improvements in balanced accuracy, recall, and precision, with high AUC and
average precision scores, reflecting its robustness in distinguishing heatwave
events.","cs.LG, physics.ao-ph, physics.soc-ph",cs.LG,http://arxiv.org/abs/2411.13496v1
"Utilizing Large Language Models to Synthesize Product Desirability
  Datasets","John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary L. Myers, Warren Thompson",2024-11-20T17:35:21Z,"This research explores the application of large language models (LLMs) to
generate synthetic datasets for Product Desirability Toolkit (PDT) testing, a
key component in evaluating user sentiment and product experience. Utilizing
gpt-4o-mini, a cost-effective alternative to larger commercial LLMs, three
methods, Word+Review, Review+Word, and Supply-Word, were each used to
synthesize 1000 product reviews. The generated datasets were assessed for
sentiment alignment, textual diversity, and data generation cost. Results
demonstrated high sentiment alignment across all methods, with Pearson
correlations ranging from 0.93 to 0.97. Supply-Word exhibited the highest
diversity and coverage of PDT terms, although with increased generation costs.
Despite minor biases toward positive sentiments, in situations with limited
test data, LLM-generated synthetic data offers significant advantages,
including scalability, cost savings, and flexibility in dataset production.","cs.CL, cs.AI, cs.LG, I.2.7; H.3.3; I.2.6; H.5.2",cs.CL,http://arxiv.org/abs/2411.13485v1
Packet Steering Mechanisms for MLO in Wi-Fi 7,"Gianluca Cena, Matteo Rosani, Stefano Scanzio",2024-11-20T17:18:56Z,"Besides extremely high throughput, Wi-Fi 7 is also aimed at providing users a
more deterministic behavior, characterized by shorter average latency and
smaller jitters. A key mechanism to achieve this is multi-link operation, which
brings simultaneous multi-band communication to client stations as well. In
this paper, traffic steering policies are briefly reviewed and grouped into
general classes, each one with its advantages and limitations. A basic
mechanism for supporting dynamic steering is then described, which is simple
enough to allow implementation in real Wi-Fi chipsets but highly flexible at
the same time. Its operation can be driven by the host on a per-packet basis,
and this permits to optimize spectrum usage depending on the requirements of
applications and the traffic pattern they generate.",cs.NI,cs.NI,http://arxiv.org/abs/2411.13470v1
"Sampling and Integration of Logconcave Functions by Algorithmic
  Diffusion","Yunbum Kook, Santosh S. Vempala",2024-11-20T17:10:24Z,"We study the complexity of sampling, rounding, and integrating arbitrary
logconcave functions. Our new approach provides the first complexity
improvements in nearly two decades for general logconcave functions for all
three problems, and matches the best-known complexities for the special case of
uniform distributions on convex bodies. For the sampling problem, our output
guarantees are significantly stronger than previously known, and lead to a
streamlined analysis of statistical estimation based on dependent random
samples.","cs.DS, cs.LG, math.ST, stat.ML, stat.TH",cs.DS,http://arxiv.org/abs/2411.13462v1
SoK: A Systems Perspective on Compound AI Threats and Countermeasures,"Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari",2024-11-20T17:08:38Z,"Large language models (LLMs) used across enterprises often use proprietary
models and operate on sensitive inputs and data. The wide range of attack
vectors identified in prior research - targeting various software and hardware
components used in training and inference - makes it extremely challenging to
enforce confidentiality and integrity policies.
  As we advance towards constructing compound AI inference pipelines that
integrate multiple large language models (LLMs), the attack surfaces expand
significantly. Attackers now focus on the AI algorithms as well as the software
and hardware components associated with these systems. While current research
often examines these elements in isolation, we find that combining cross-layer
attack observations can enable powerful end-to-end attacks with minimal
assumptions about the threat model. Given, the sheer number of existing attacks
at each layer, we need a holistic and systemized understanding of different
attack vectors at each layer.
  This SoK discusses different software and hardware attacks applicable to
compound AI systems and demonstrates how combining multiple attack mechanisms
can reduce the threat model assumptions required for an isolated attack. Next,
we systematize the ML attacks in lines with the Mitre Att&ck framework to
better position each attack based on the threat model. Finally, we outline the
existing countermeasures for both software and hardware layers and discuss the
necessity of a comprehensive defense strategy to enable the secure and
high-performance deployment of compound AI systems.","cs.CR, cs.AI, cs.LG",cs.CR,http://arxiv.org/abs/2411.13459v1
"AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from
  Human Demonstrations","Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso",2024-11-20T16:54:15Z,"State-of-the-art multimodal web agents, powered by Multimodal Large Language
Models (MLLMs), can autonomously execute many web tasks by processing user
instructions and interacting with graphical user interfaces (GUIs). Current
strategies for building web agents rely on (i) the generalizability of
underlying MLLMs and their steerability via prompting, and (ii) large-scale
fine-tuning of MLLMs on web-related tasks. However, web agents still struggle
to automate tasks on unseen websites and domains, limiting their applicability
to enterprise-specific and proprietary platforms. Beyond generalization from
large-scale pre-training and fine-tuning, we propose building agents for
few-shot adaptability using human demonstrations. We introduce the AdaptAgent
framework that enables both proprietary and open-weights multimodal web agents
to adapt to new websites and domains using few human demonstrations (up to 2).
Our experiments on two popular benchmarks -- Mind2Web & VisualWebArena -- show
that using in-context demonstrations (for proprietary models) or
meta-adaptation demonstrations (for meta-learned open-weights models) boosts
task success rate by 3.36% to 7.21% over non-adapted state-of-the-art models,
corresponding to a relative increase of 21.03% to 65.75%. Furthermore, our
additional analyses (a) show the effectiveness of multimodal demonstrations
over text-only ones, (b) shed light on the influence of different data
selection strategies during meta-learning on the generalization of the agent,
and (c) demonstrate the effect of number of few-shot examples on the web
agent's success rate. Overall, our results unlock a complementary axis for
developing widely applicable multimodal web agents beyond large-scale
pre-training and fine-tuning, emphasizing few-shot adaptability.","cs.AI, cs.CL, cs.LG",cs.AI,http://arxiv.org/abs/2411.13451v1
"Eco-Friendly 0G Networks: Unlocking the Power of Backscatter
  Communications for a Greener Future","Shumaila Javaid, Hamza Fahim, Bin He, Nasir Saeed",2024-11-20T16:29:40Z,"Backscatter Communication (BackCom) technology has emerged as a promising
paradigm for the Green Internet of Things (IoT) ecosystem, offering advantages
such as low power consumption, cost-effectiveness, and ease of deployment.
While traditional BackCom systems, such as RFID technology, have found
widespread applications, the advent of ambient backscatter presents new
opportunities for expanding applications and enhancing capabilities. Moreover,
ongoing standardization efforts are actively focusing on BackCom technologies,
positioning them as a potential solution to meet the near-zero power
consumption and massive connectivity requirements of next-generation wireless
systems. 0G networks have the potential to provide advanced solutions by
leveraging BackCom technology to deliver ultra-low-power, ubiquitous
connectivity for the expanding IoT ecosystem, supporting billions of devices
with minimal energy consumption. This paper investigates the integration of
BackCom and 0G networks to enhance the capabilities of traditional BackCom
systems and enable Green IoT. We conduct an in-depth analysis of
BackCom-enabled 0G networks, exploring their architecture and operational
objectives, and also explore the Waste Factor (WF) metric for evaluating energy
efficiency and minimizing energy waste within integrated systems. By examining
both structural and operational aspects, we demonstrate how this synergy
enhances the performance, scalability, and sustainability of next-generation
wireless networks. Moreover, we highlight possible applications, open
challenges, and future directions, offering valuable insights for guiding
future research and practical implementations aimed at achieving large-scale,
sustainable IoT deployments.","cs.NI, cs.ET, eess.SP",cs.NI,http://arxiv.org/abs/2411.13440v1
Robust Monocular Visual Odometry using Curriculum Learning,"Assaf Lahiany, Oren Gal",2024-11-20T16:26:51Z,"Curriculum Learning (CL), drawing inspiration from natural learning patterns
observed in humans and animals, employs a systematic approach of gradually
introducing increasingly complex training data during model development. Our
work applies innovative CL methodologies to address the challenging geometric
problem of monocular Visual Odometry (VO) estimation, which is essential for
robot navigation in constrained environments. The primary objective of our
research is to push the boundaries of current state-of-the-art (SOTA)
benchmarks in monocular VO by investigating various curriculum learning
strategies. We enhance the end-to-end Deep-Patch-Visual Odometry (DPVO)
framework through the integration of novel CL approaches, with the goal of
developing more resilient models capable of maintaining high performance across
challenging environments and complex motion scenarios. Our research encompasses
several distinctive CL strategies. We develop methods to evaluate sample
difficulty based on trajectory motion characteristics, implement sophisticated
adaptive scheduling through self-paced weighted loss mechanisms, and utilize
reinforcement learning agents for dynamic adjustment of training emphasis.
Through comprehensive evaluation on the real-world TartanAir dataset, our
Curriculum Learning-based Deep-Patch-Visual Odometry (CL-DPVO) demonstrates
superior performance compared to existing SOTA methods, including both
feature-based and learning-based VO approaches. The results validate the
effectiveness of integrating curriculum learning principles into visual
odometry systems.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.13438v1
"SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records
  using Decoder-Only Transformers","Hojjat Karami, David Atienza, Anisoara Ionescu",2024-11-20T16:11:20Z,"Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13428v1
WaterPark: A Robustness Assessment of Language Model Watermarking,"Jiacheng Liang, Zian Wang, Lauren Hong, Shouling Ji, Ting Wang",2024-11-20T16:09:22Z,"To mitigate the misuse of large language models (LLMs), such as
disinformation, automated phishing, and academic cheating, there is a pressing
need for the capability of identifying LLM-generated texts. Watermarking
emerges as one promising solution: it plants statistical signals into LLMs'
generative processes and subsequently verifies whether LLMs produce given
texts. Various watermarking methods (``watermarkers'') have been proposed; yet,
due to the lack of unified evaluation platforms, many critical questions remain
under-explored: i) What are the strengths/limitations of various watermarkers,
especially their attack robustness? ii) How do various design choices impact
their robustness? iii) How to optimally operate watermarkers in adversarial
environments?
  To fill this gap, we systematize existing LLM watermarkers and watermark
removal attacks, mapping out their design spaces. We then develop WaterPark, a
unified platform that integrates 10 state-of-the-art watermarkers and 12
representative attacks. More importantly, leveraging WaterPark, we conduct a
comprehensive assessment of existing watermarkers, unveiling the impact of
various design choices on their attack robustness. For instance, a
watermarker's resilience to increasingly intensive attacks hinges on its
context dependency. We further explore the best practices to operate
watermarkers in adversarial environments. For instance, using a generic
detector alongside a watermark-specific detector improves the security of
vulnerable watermarkers. We believe our study sheds light on current LLM
watermarking techniques while WaterPark serves as a valuable testbed to
facilitate future research.","cs.CR, cs.CL, cs.LG",cs.CR,http://arxiv.org/abs/2411.13425v1
Heuristically Adaptive Diffusion-Model Evolutionary Strategy,"Benedikt Hartl, Yanbo Zhang, Hananel Hazan, Michael Levin",2024-11-20T16:06:28Z,"Diffusion Models represent a significant advancement in generative modeling,
employing a dual-phase process that first degrades domain-specific information
via Gaussian noise and restores it through a trainable model. This framework
enables pure noise-to-data generation and modular reconstruction of, images or
videos. Concurrently, evolutionary algorithms employ optimization methods
inspired by biological principles to refine sets of numerical parameters
encoding potential solutions to rugged objective functions. Our research
reveals a fundamental connection between diffusion models and evolutionary
algorithms through their shared underlying generative mechanisms: both methods
generate high-quality samples via iterative refinement on random initial
distributions. By employing deep learning-based diffusion models as generative
models across diverse evolutionary tasks and iteratively refining diffusion
models with heuristically acquired databases, we can iteratively sample
potentially better-adapted offspring parameters, integrating them into
successive generations of the diffusion model. This approach achieves efficient
convergence toward high-fitness parameters while maintaining explorative
diversity. Diffusion models introduce enhanced memory capabilities into
evolutionary algorithms, retaining historical information across generations
and leveraging subtle data correlations to generate refined samples. We elevate
evolutionary algorithms from procedures with shallow heuristics to frameworks
with deep memory. By deploying classifier-free guidance for conditional
sampling at the parameter level, we achieve precise control over evolutionary
search dynamics to further specific genotypical, phenotypical, or
population-wide traits. Our framework marks a major heuristic and algorithmic
transition, offering increased flexibility, precision, and control in
evolutionary optimization processes.","cs.NE, cs.AI, cs.LG",cs.NE,http://arxiv.org/abs/2411.13420v1
"Unleashing the Power of Large Language Models for Group POI
  Recommendations","Jing Long, Liang Qu, Guanhua Ye, Tong Chen, Quoc Viet Hung Nguyen, Hongzhi Yin",2024-11-20T16:02:14Z,"Group Point-of-Interest (POI) recommendations aim to predict the next POI
that satisfies the diverse preferences of a group of users. This task is more
challenging than traditional individual POI recommendations due to complex
group decision-making and extremely sparse group-level check-in data. Existing
methods for group POI recommendations primarily rely on single ID-based
features from check-in data, capturing only statistical correlations and
failing to fully utilize the rich semantic information contained in the
check-ins, resulting in suboptimal performance. To this end, we propose a
framework that unleashes the power of the Large Language Model (LLM) for
context-aware group POI recommendations (LLMGPR). Our approach first introduces
POI tokens alongside the original word tokens of the LLM, which are initialized
by applying the LLM to the rich information of each POI. We then propose a
novel sequencing adapter guided by Quantized Low-Rank Adaptation (QLORA) to
modify the LLM. The enhanced LLM can learn sequence representations by
combining semantic-enhanced POI tokens and rich contextual information
including positional encodings and spatio-temporal differences. This approach
can be adapted for learning either group or user representations depending on
the sequence type. Furthermore, we enhance group representations by aggregating
individual member representations with another QLORA-based aggregation adapter
and introducing a self-supervised learning task that predicts the purpose of
check-in sequences, alleviating the data sparsity issue. Our experimental
results demonstrate that LLMGPR outperforms existing methods, effectively
addressing group-level data sparsity and providing superior recommendations.",cs.IR,cs.IR,http://arxiv.org/abs/2411.13415v1
"A Survey On Enhancing Reinforcement Learning in Complex Environments:
  Insights from Human and LLM Feedback","Alireza Rashidi Laleh, Majid Nili Ahmadabadi",2024-11-20T15:52:03Z,"Reinforcement learning (RL) is one of the active fields in machine learning,
demonstrating remarkable potential in tackling real-world challenges. Despite
its promising prospects, this methodology has encountered with issues and
challenges, hindering it from achieving the best performance. In particular,
these approaches lack decent performance when navigating environments and
solving tasks with large observation space, often resulting in
sample-inefficiency and prolonged learning times. This issue, commonly referred
to as the curse of dimensionality, complicates decision-making for RL agents,
necessitating a careful balance between attention and decision-making. RL
agents, when augmented with human or large language models' (LLMs) feedback,
may exhibit resilience and adaptability, leading to enhanced performance and
accelerated learning. Such feedback, conveyed through various modalities or
granularities including natural language, serves as a guide for RL agents,
aiding them in discerning relevant environmental cues and optimizing
decision-making processes. In this survey paper, we mainly focus on problems of
two-folds: firstly, we focus on humans or an LLMs assistance, investigating the
ways in which these entities may collaborate with the RL agent in order to
foster optimal behavior and expedite learning; secondly, we delve into the
research papers dedicated to addressing the intricacies of environments
characterized by large observation space.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13410v1
"Transformer-Based Contextualized Language Models Joint with Neural
  Networks for Natural Language Inference in Vietnamese","Dat Van-Thanh Nguyen, Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen",2024-11-20T15:46:48Z,"Natural Language Inference (NLI) is a task within Natural Language Processing
(NLP) that holds value for various AI applications. However, there have been
limited studies on Natural Language Inference in Vietnamese that explore the
concept of joint models. Therefore, we conducted experiments using various
combinations of contextualized language models (CLM) and neural networks. We
use CLM to create contextualized work presentations and use Neural Networks for
classification. Furthermore, we have evaluated the strengths and weaknesses of
each joint model and identified the model failure points in the Vietnamese
context. The highest F1 score in this experiment, up to 82.78\% in the
benchmark dataset (ViNLI). By conducting experiments with various models, the
most considerable size of the CLM is XLM-R (355M). That combination has
consistently demonstrated superior performance compared to fine-tuning strong
pre-trained language models like PhoBERT (+6.58\%), mBERT (+19.08\%), and XLM-R
(+0.94\%) in terms of F1-score. This article aims to introduce a novel approach
or model that attains improved performance for Vietnamese NLI. Overall, we find
that the joint approach of CLM and neural networks is simple yet capable of
achieving high-quality performance, which makes it suitable for applications
that require efficient resource utilization.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13407v1
"On the Way to LLM Personalization: Learning to Remember User
  Conversations","Lucie Charlotte Magister, Katherine Metcalf, Yizhe Zhang, Maartje ter Hoeve",2024-11-20T15:45:08Z,"Large Language Models (LLMs) have quickly become an invaluable assistant for
a variety of tasks. However, their effectiveness is constrained by their
ability to tailor responses to human preferences and behaviors via
personalization. Prior work in LLM personalization has largely focused on style
transfer or incorporating small factoids about the user, as knowledge injection
remains an open challenge. In this paper, we explore injecting knowledge of
prior conversations into LLMs to enable future work on less redundant,
personalized conversations. We identify two real-world constraints: (1)
conversations are sequential in time and must be treated as such during
training, and (2) per-user personalization is only viable in
parameter-efficient settings. To this aim, we propose PLUM, a pipeline
performing data augmentation for up-sampling conversations as question-answer
pairs, that are then used to finetune a low-rank adaptation adapter with a
weighted cross entropy loss. Even in this first exploration of the problem, we
perform competitively with baselines such as RAG, attaining an accuracy of
81.5% across 100 conversations.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.13405v1
Executable QR codes with Machine Learning for Industrial Applications,"Stefano Scanzio, Francesco Velluto, Matteo Rosani, Lukasz Wisniewski, Gianluca Cena",2024-11-20T15:38:33Z,"Executable QR codes, also known as eQR codes or just sQRy, are a special kind
of QR codes that embed programs conceived to run on mobile devices like
smartphones. Since the program is directly encoded in binary form within the QR
code, it can be executed even when the reading device is not provided with
Internet access. The applications of this technology are manifold, and range
from smart user guides to advisory systems. The first programming language made
available for eQR is QRtree, which enables the implementation of decision trees
aimed, for example, at guiding the user in operating/maintaining a complex
machinery or for reaching a specific location.
  In this work, an additional language is proposed, we term QRind, which was
specifically devised for Industry. It permits to integrate distinct
computational blocks into the QR code, e.g., machine learning models to enable
predictive maintenance and algorithms to ease machinery usage. QRind permits
the Industry 4.0/5.0 paradigms to be implemented, in part, also in those cases
where Internet is unavailable.","cs.NI, cs.CL, cs.FL",cs.NI,http://arxiv.org/abs/2411.13400v1
UKFin+: A Research Agenda for Financial Services,"Jing Chen, Karen Elliott, William Knottenbelt, Aad van Moorsel, Helen Orpin, Sheena Robertson, John Vines, Katinka Wolter",2024-11-20T15:23:40Z,"This document presents a research agenda for financial services as a
deliverable of UKFin+, a Network Plus grant funded by the Engineering and
Physical Sciences Research Council. UKFin+ fosters research collaborations
between academic and non-academic partners directed at tackling complex
long-term challenges relevant to the UK's financial services sector.
Confronting these challenges is crucial to promote the long-term health and
international competitiveness of the UK's financial services industry. As one
route to impact, UKFin+ includes dedicated funding streams for research
collaborations between academic researchers and non-academic organisations.
  The intended audience of this document includes researchers based in
academia, academic funders, as well as practitioners based in industry,
regulators, charities or NGOs. It is not intended to be comprehensive or
exhaustive in scope but may provide applicants to UKFin+ funding streams and
other funding bodies with inspiration for their proposals or at least an
understanding of how their proposals align with the broader needs of the UK
financial services industry.",cs.CE,cs.CE,http://arxiv.org/abs/2411.13389v1
"Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain
  Understanding","Hoang-Quan Nguyen, Xuan-Bac Nguyen, Hugh Churchill, Arabinda Kumar Choudhary, Pawan Sinha, Samee U. Khan, Khoa Luu",2024-11-20T14:59:47Z,"Vision-brain understanding aims to extract semantic information about brain
signals from human perceptions. Existing deep learning methods for vision-brain
understanding are usually introduced in a traditional learning paradigm missing
the ability to learn the connectivities between brain regions. Meanwhile, the
quantum computing theory offers a new paradigm for designing deep learning
models. Motivated by the connectivities in the brain signals and the
entanglement properties in quantum computing, we propose a novel Quantum-Brain
approach, a quantum-inspired neural network, to tackle the vision-brain
understanding problem. To compute the connectivity between areas in brain
signals, we introduce a new Quantum-Inspired Voxel-Controlling module to learn
the impact of a brain voxel on others represented in the Hilbert space. To
effectively learn connectivity, a novel Phase-Shifting module is presented to
calibrate the value of the brain signals. Finally, we introduce a new
Measurement-like Projection module to present the connectivity information from
the Hilbert space into the feature space. The proposed approach can learn to
find the connectivities between fMRI voxels and enhance the semantic
information obtained from human perceptions. Our experimental results on the
Natural Scene Dataset benchmarks illustrate the effectiveness of the proposed
method with Top-1 accuracies of 95.1% and 95.6% on image and brain retrieval
tasks and an Inception score of 95.3% on fMRI-to-image reconstruction task. Our
proposed quantum-inspired network brings a potential paradigm to solving the
vision-brain problems via the quantum computing theory.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13378v1
Distributed weak independent sets in hypergraphs: Upper and lower bounds,"Duncan Adamson, Will Rosenbaum, Paul G. Spirakis",2024-11-20T14:58:47Z,"In this paper, we consider the problem of finding weak independent sets in a
distributed network represented by a hypergraph. In this setting, each edge
contains a set of r vertices rather than simply a pair, as in a standard graph.
A k-weak independent set in a hypergraph is a set where no edge contains more
than k vertices in the independent set. We focus two variations of this
problem. First, we study the problem of finding k-weak maximal independent
sets, k-weak independent sets where each vertex belongs to at least one edge
with k vertices in the independent set. Second we introduce a weaker variant
that we call (\alpha, \beta)-independent sets where the independent set is
\beta-weak, and each vertex belongs to at least one edge with at least \alpha
vertices in the independent set. Finally, we consider the problem of finding a
(2, k)-ruling set on hypergraphs, i.e. independent sets where no vertex is a
distance of more than k from the nearest member of the set.
  Given a hypergraph H of rank r and maximum degree \Delta, we provide a LLL
formulation for finding an (\alpha, \beta)-independent set when (\beta -
\alpha)^2 / (\beta + \alpha) \geq 6 \log(16 r \Delta), an O(\Delta r / (\beta -
\alpha + 1) + \log^* n) round deterministic algorithm finding an (\alpha,
\beta)-independent set, and a O(\Delta^2(r - k) \log r + \Delta \log r \log^* r
+ \log^* n) round algorithm for finding a k-weak maximal independent set.
Additionally, we provide zero round randomized algorithms for finding (\alpha,
\beta) independent sets, when (\beta - \alpha)^2 / (\beta + \alpha) \geq 6 c
\log n + 6 for some constant c, and finding an m-weak independent set for some
m \geq r / 2k where k is a given parameter. Finally, we provide lower bounds of
\Omega(\Delta + \log^* n) and \Omega(r + \log^* n) on the problems of finding a
k-weak maximal independent sets for some values of k.",cs.DC,cs.DC,http://arxiv.org/abs/2411.13377v1
ODTE -- An ensemble of multi-class SVM-based oblique decision trees,"Ricardo Montañana, José A. Gámez, José M. Puerta",2024-11-20T14:58:32Z,"We propose ODTE, a new ensemble that uses oblique decision trees as base
classifiers. Additionally, we introduce STree, the base algorithm for growing
oblique decision trees, which leverages support vector machines to define
hyperplanes within the decision nodes. We embed a multiclass strategy --
one-vs-one or one-vs-rest -- at the decision nodes, allowing the model to
directly handle non-binary classification tasks without the need to cluster
instances into two groups, as is common in other approaches from the
literature. In each decision node, only the best-performing model SVM -- the
one that minimizes an impurity measure for the n-ary classification -- is
retained, even if the learned SVM addresses a binary classification subtask. An
extensive experimental study involving 49 datasets and various state-of-the-art
algorithms for oblique decision tree ensembles has been conducted. Our results
show that ODTE ranks consistently above its competitors, achieving significant
performance gains when hyperparameters are carefully tuned. Moreover, the
oblique decision trees learned through STree are more compact than those
produced by other algorithms evaluated in our experiments.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13376v1
"Predicting Wall Thickness Changes in Cold Forging Processes: An
  Integrated FEM and Neural Network approach","Sasa Ilic, Abdulkerim Karaman, Johannes Pöppelbaum, Jan Niclas Reimann, Michael Marré, Andreas Schwung",2024-11-20T14:42:53Z,"This study presents a novel approach for predicting wall thickness changes in
tubes during the nosing process. Specifically, we first provide a thorough
analysis of nosing processes and the influencing parameters. We further set-up
a Finite Element Method (FEM) simulation to better analyse the effects of
varying process parameters. As however traditional FEM simulations, while
accurate, are time-consuming and computationally intensive, which renders them
inapplicable for real-time application, we present a novel modeling framework
based on specifically designed graph neural networks as surrogate models. To
this end, we extend the neural network architecture by directly incorporating
information about the nosing process by adding different types of edges and
their corresponding encoders to model object interactions. This augmentation
enhances model accuracy and opens the possibility for employing precise
surrogate models within closed-loop production processes. The proposed approach
is evaluated using a new evaluation metric termed area between thickness curves
(ABTC). The results demonstrate promising performance and highlight the
potential of neural networks as surrogate models in predicting wall thickness
changes during nosing forging processes.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13366v1
"Explainable Finite-Memory Policies for Partially Observable Markov
  Decision Processes","Muqsit Azeem, Debraj Chakraborty, Sudeep Kanav, Jan Kretinsky",2024-11-20T14:42:23Z,"Partially Observable Markov Decision Processes (POMDPs) are a fundamental
framework for decision-making under uncertainty and partial observability.
Since in general optimal policies may require infinite memory, they are hard to
implement and often render most problems undecidable. Consequently,
finite-memory policies are mostly considered instead. However, the algorithms
for computing them are typically very complex, and so are the resulting
policies. Facing the need for their explainability, we provide a representation
of such policies, both (i) in an interpretable formalism and (ii) typically of
smaller size, together yielding higher explainability. To that end, we combine
models of Mealy machines and decision trees; the latter describing simple,
stationary parts of the policies and the former describing how to switch among
them. We design a translation for policies of the finite-state-controller (FSC)
form from standard literature and show how our method smoothly generalizes to
other variants of finite-memory policies. Further, we identify specific
properties of recently used ""attractor-based"" policies, which allow us to
construct yet simpler and smaller representations. Finally, we illustrate the
higher explainability in a few case studies.","cs.AI, cs.LG, cs.RO, cs.SY, eess.SY",cs.AI,http://arxiv.org/abs/2411.13365v1
"Vertical Validation: Evaluating Implicit Generative Models for Graphs on
  Thin Support Regions","Mai Elkady, Thu Bui, Bruno Ribeiro, David I. Inouye",2024-11-20T14:29:59Z,"There has been a growing excitement that implicit graph generative models
could be used to design or discover new molecules for medicine or material
design. Because these molecules have not been discovered, they naturally lie in
unexplored or scarcely supported regions of the distribution of known
molecules. However, prior evaluation methods for implicit graph generative
models have focused on validating statistics computed from the thick support
(e.g., mean and variance of a graph property). Therefore, there is a mismatch
between the goal of generating novel graphs and the evaluation methods. To
address this evaluation gap, we design a novel evaluation method called
Vertical Validation (VV) that systematically creates thin support regions
during the train-test splitting procedure and then reweights generated samples
so that they can be compared to the held-out test data. This procedure can be
seen as a generalization of the standard train-test procedure except that the
splits are dependent on sample features. We demonstrate that our method can be
used to perform model selection if performance on thin support regions is the
desired goal. As a side benefit, we also show that our approach can better
detect overfitting as exemplified by memorization.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13358v1
Learning based Ge'ez character handwritten recognition,"Hailemicael Lulseged Yimer, Hailegabriel Dereje Degefa, Marco Cristani, Federico Cunico",2024-11-20T14:22:15Z,"Ge'ez, an ancient Ethiopic script of cultural and historical significance,
has been largely neglected in handwriting recognition research, hindering the
digitization of valuable manuscripts. Our study addresses this gap by
developing a state-of-the-art Ge'ez handwriting recognition system using
Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM)
networks. Our approach uses a two-stage recognition process. First, a CNN is
trained to recognize individual characters, which then acts as a feature
extractor for an LSTM-based system for word recognition. Our dual-stage
recognition approach achieves new top scores in Ge'ez handwriting recognition,
outperforming eight state-of-the-art methods, which are SVTR, ASTER, and others
as well as human performance, as measured in the HHD-Ethiopic dataset work.
This research significantly advances the preservation and accessibility of
Ge'ez cultural heritage, with implications for historical document
digitization, educational tools, and cultural preservation. The code will be
released upon acceptance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13350v1
"Gaze2AOI: Open Source Deep-learning Based System for Automatic Area of
  Interest Annotation with Eye Tracking Data","Karolina Trajkovska, Matjaž Kljun, Klen Čopič Pucihar",2024-11-20T14:17:23Z,"Eye gaze is considered an important indicator for understanding and
predicting user behaviour, as well as directing their attention across various
domains including advertisement design, human-computer interaction and film
viewing. In this paper, we present a novel method to enhance the analysis of
user behaviour and attention by (i) augmenting video streams with automatically
annotating and labelling areas of interest (AOIs), and (ii) integrating AOIs
with collected eye gaze and fixation data. The tool provides key features such
as time to first fixation, dwell time, and frequency of AOI revisits. By
incorporating the YOLOv8 object tracking algorithm, the tool supports over 600
different object classes, providing a comprehensive set for a variety of video
streams. This tool will be made available as open-source software, thereby
contributing to broader research and development efforts in the field.",cs.SE,cs.SE,http://arxiv.org/abs/2411.13346v1
Verifying Machine Unlearning with Explainable AI,"Àlex Pujol Vidal, Anders S. Johansen, Mohammad N. S. Jahromi, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund",2024-11-20T13:57:32Z,"We investigate the effectiveness of Explainable AI (XAI) in verifying Machine
Unlearning (MU) within the context of harbor front monitoring, focusing on data
privacy and regulatory compliance. With the increasing need to adhere to
privacy legislation such as the General Data Protection Regulation (GDPR),
traditional methods of retraining ML models for data deletions prove
impractical due to their complexity and resource demands. MU offers a solution
by enabling models to selectively forget specific learned patterns without full
retraining. We explore various removal techniques, including data relabeling,
and model perturbation. Then, we leverage attribution-based XAI to discuss the
effects of unlearning on model performance. Our proof-of-concept introduces
feature importance as an innovative verification step for MU, expanding beyond
traditional metrics and demonstrating techniques' ability to reduce reliance on
undesired patterns. Additionally, we propose two novel XAI-based metrics,
Heatmap Coverage (HC) and Attention Shift (AS), to evaluate the effectiveness
of these methods. This approach not only highlights how XAI can complement MU
by providing effective verification, but also sets the stage for future
research to enhance their joint integration.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13332v1
"Fine-tuning Myoelectric Control through Reinforcement Learning in a Game
  Environment","Kilian Freitag, Yiannis Karayiannidis, Jan Zbinden, Rita Laezza",2024-11-20T13:49:06Z,"Objective: Enhancing the reliability of myoelectric controllers that decode
motor intent is a pressing challenge in the field of bionic prosthetics.
State-of-the-art research has mostly focused on Supervised Learning (SL)
techniques to tackle this problem. However, obtaining high-quality labeled data
that accurately represents muscle activity during daily usage remains
difficult. We investigate the potential of Reinforcement Learning (RL) to
further improve the decoding of human motion intent by incorporating
usage-based data. Methods: The starting point of our method is a SL control
policy, pretrained on a static recording of electromyographic (EMG) ground
truth data. We then apply RL to fine-tune the pretrained classifier with
dynamic EMG data obtained during interaction with a game environment developed
for this work. We conducted real-time experiments to evaluate our approach and
achieved significant improvements in human-in-the-loop performance. Results:
The method effectively predicts simultaneous finger movements, leading to a
two-fold increase in decoding accuracy during gameplay and a 39\% improvement
in a separate motion test. Conclusion: By employing RL and incorporating
usage-based EMG data during fine-tuning, our method achieves significant
improvements in accuracy and robustness. Significance: These results showcase
the potential of RL for enhancing the reliability of myoelectric controllers,
of particular importance for advanced bionic limbs. See our project page for
visual demonstrations: https://sites.google.com/view/bionic-limb-rl",cs.HC,cs.HC,http://arxiv.org/abs/2411.13327v1
"An Evolutional Neural Network Framework for Classification of Microarray
  Data","Maryam Eshraghi Evari, Md Nasir Sulaiman, Amir Rajabi Behjat",2024-11-20T13:48:40Z,"DNA microarray gene-expression data has been widely used to identify
cancerous gene signatures. Microarray can increase the accuracy of cancer
diagnosis and prognosis. However, analyzing the large amount of gene expression
data from microarray chips pose a challenge for current machine learning
researches. One of the challenges lie within classification of healthy and
cancerous tissues is high dimensionality of gene expressions. High
dimensionality decreases the accuracy of the classification. This research aims
to apply a hybrid model of Genetic Algorithm and Neural Network to overcome the
problem during subset selection of informative genes. Whereby, a Genetic
Algorithm (GA) reduced dimensionality during feature selection and then a
Multi-Layer perceptron Neural Network (MLP) is applied to classify selected
genes. The performance evaluated by considering to the accuracy and the number
of selected genes. Experimental results show the proposed method suggested high
accuracy and minimum number of selected genes in comparison with other machine
learning algorithms.","cs.NE, cs.AI, q-bio.GN",cs.NE,http://arxiv.org/abs/2411.13326v1
Are Large Language Models Memorizing Bug Benchmarks?,"Daniel Ramos, Claudia Mamede, Kush Jain, Paulo Canelas, Catarina Gamboa, Claire Le Goues",2024-11-20T13:46:04Z,"Large Language Models (LLMs) have become integral to various software
engineering tasks, including code generation, bug detection, and repair. To
evaluate model performance in these domains, numerous bug benchmarks containing
real-world bugs from software projects have been developed. However, a growing
concern within the software engineering community is that these benchmarks may
not reliably reflect true LLM performance due to the risk of data leakage.
Despite this concern, limited research has been conducted to quantify the
impact of potential leakage.
  In this paper, we systematically evaluate popular LLMs to assess their
susceptibility to data leakage from widely used bug benchmarks. To identify
potential leakage, we use multiple metrics, including a study of benchmark
membership within commonly used training datasets, as well as analyses of
negative log-likelihood and n-gram accuracy. Our findings show that certain
models, in particular codegen-multi, exhibit significant evidence of
memorization in widely used benchmarks like Defects4J, while newer models
trained on larger datasets like LLaMa 3.1 exhibit limited signs of leakage.
These results highlight the need for careful benchmark selection and the
adoption of robust metrics to adequately assess models capabilities.","cs.SE, cs.AI, cs.LG",cs.SE,http://arxiv.org/abs/2411.13323v1
Scaling Laws for Online Advertisement Retrieval,"Yunli Wang, Zixuan Yang, Zhen Zhang, Zhiqiang Wang, Jian Yang, Shiyang Wen, Peng Jiang, Kun Gai",2024-11-20T13:44:59Z,"The scaling law is a notable property of neural network models and has
significantly propelled the development of large language models. Scaling laws
hold great promise in guiding model design and resource allocation. Recent
research increasingly shows that scaling laws are not limited to NLP tasks or
Transformer architectures; they also apply to domains such as recommendation.
However, there is still a lack of literature on scaling law research in online
advertisement retrieval systems. This may be because 1) identifying the scaling
law for resource cost and online revenue is often expensive in both time and
training resources for large-scale industrial applications, and 2) varying
settings for different systems prevent the scaling law from being applied
across various scenarios. To address these issues, we propose a lightweight
paradigm to identify the scaling law of online revenue and machine cost for a
certain online advertisement retrieval scenario with a low experimental cost.
Specifically, we focus on a sole factor (FLOPs) and propose an offline metric
named R/R* that exhibits a high linear correlation with online revenue for
retrieval models. We estimate the machine cost offline via a simulation
algorithm. Thus, we can transform most online experiments into low-cost offline
experiments. We conduct comprehensive experiments to verify the effectiveness
of our proposed metric R/R* and to identify the scaling law in the online
advertisement retrieval system of Kuaishou. With the scaling law, we
demonstrate practical applications for ROI-constrained model designing and
multi-scenario resource allocation in Kuaishou advertising system. To the best
of our knowledge, this is the first work to study the scaling laws for online
advertisement retrieval of real-world systems, showing great potential for
scaling law in advertising system optimization.","cs.IR, cs.AI, cs.LG",cs.IR,http://arxiv.org/abs/2411.13322v1
Teaching VLMs to Localize Specific Objects from In-context Examples,"Sivan Doveh, Nimrod Shabtay, Wei Lin, Eli Schwartz, Hilde Kuehne, Raja Giryes, Rogerio Feris, Leonid Karlinsky, James Glass, Assaf Arbelle, Shimon Ullman, M. Jehanzeb Mirza",2024-11-20T13:34:22Z,"Vision-Language Models (VLMs) have shown remarkable capabilities across
diverse visual tasks, including image recognition, video understanding, and
Visual Question Answering (VQA) when explicitly trained for these tasks.
Despite these advances, we find that current VLMs lack a fundamental cognitive
ability: learning to localize objects in a scene by taking into account the
context. In this work, we focus on the task of few-shot personalized
localization, where a model is given a small set of annotated images
(in-context examples) -- each with a category label and bounding box -- and is
tasked with localizing the same object type in a query image. To provoke
personalized localization abilities in models, we present a data-centric
solution that fine-tunes them using carefully curated data from video object
tracking datasets. By leveraging sequences of frames tracking the same object
across multiple shots, we simulate instruction-tuning dialogues that promote
context awareness. To reinforce this, we introduce a novel regularization
technique that replaces object labels with pseudo-names, ensuring the model
relies on visual context rather than prior knowledge. Our method significantly
enhances few-shot localization performance without sacrificing generalization,
as demonstrated on several benchmarks tailored to personalized localization.
This work is the first to explore and benchmark personalized few-shot
localization for VLMs, laying a foundation for future research in
context-driven vision-language applications. The code for our project is
available at https://github.com/SivanDoveh/IPLoc",cs.CV,cs.CV,http://arxiv.org/abs/2411.13317v1
"A Resource Efficient Fusion Network for Object Detection in Bird's-Eye
  View using Camera and Raw Radar Data","Kavin Chandrasekaran, Sorin Grigorescu, Gijs Dubbelman, Pavol Jancura",2024-11-20T13:26:13Z,"Cameras can be used to perceive the environment around the vehicle, while
affordable radar sensors are popular in autonomous driving systems as they can
withstand adverse weather conditions unlike cameras. However, radar point
clouds are sparser with low azimuth and elevation resolution that lack semantic
and structural information of the scenes, resulting in generally lower radar
detection performance. In this work, we directly use the raw range-Doppler (RD)
spectrum of radar data, thus avoiding radar signal processing. We independently
process camera images within the proposed comprehensive image processing
pipeline. Specifically, first, we transform the camera images to Bird's-Eye
View (BEV) Polar domain and extract the corresponding features with our camera
encoder-decoder architecture. The resultant feature maps are fused with
Range-Azimuth (RA) features, recovered from the RD spectrum input from the
radar decoder to perform object detection. We evaluate our fusion strategy with
other existing methods not only in terms of accuracy but also on computational
complexity metrics on RADIal dataset.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13311v1
"Can Reasons Help Improve Pedestrian Intent Estimation? A Cross-Modal
  Approach","Vaishnavi Khindkar, Vineeth Balasubramanian, Chetan Arora, Anbumani Subramanian, C. V. Jawahar",2024-11-20T13:15:04Z,"With the increased importance of autonomous navigation systems has come an
increasing need to protect the safety of Vulnerable Road Users (VRUs) such as
pedestrians. Predicting pedestrian intent is one such challenging task, where
prior work predicts the binary cross/no-cross intention with a fusion of visual
and motion features. However, there has been no effort so far to hedge such
predictions with human-understandable reasons. We address this issue by
introducing a novel problem setting of exploring the intuitive reasoning behind
a pedestrian's intent. In particular, we show that predicting the 'WHY' can be
very useful in understanding the 'WHAT'. To this end, we propose a novel,
reason-enriched PIE++ dataset consisting of multi-label textual
explanations/reasons for pedestrian intent. We also introduce a novel
multi-task learning framework called MINDREAD, which leverages a cross-modal
representation learning framework for predicting pedestrian intent as well as
the reason behind the intent. Our comprehensive experiments show significant
improvement of 5.6% and 7% in accuracy and F1-score for the task of intent
prediction on the PIE++ dataset using MINDREAD. We also achieved a 4.4%
improvement in accuracy on a commonly used JAAD dataset. Extensive evaluation
using quantitative/qualitative metrics and user studies shows the effectiveness
of our approach.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13302v1
"DATTA: Domain-Adversarial Test-Time Adaptation for Cross-Domain
  WiFi-Based Human Activity Recognition","Julian Strohmayer, Rafael Sterzinger, Matthias Wödlinger, Martin Kampel",2024-11-20T12:52:36Z,"Cross-domain generalization is an open problem in WiFi-based sensing due to
variations in environments, devices, and subjects, causing domain shifts in
channel state information. To address this, we propose Domain-Adversarial
Test-Time Adaptation (DATTA), a novel framework combining domain-adversarial
training (DAT), test-time adaptation (TTA), and weight resetting to facilitate
adaptation to unseen target domains and to prevent catastrophic forgetting.
DATTA is integrated into a lightweight, flexible architecture optimized for
speed. We conduct a comprehensive evaluation of DATTA, including an ablation
study on all key components using publicly available data, and verify its
suitability for real-time applications such as human activity recognition. When
combining a SotA video-based variant of TTA with WiFi-based DAT and comparing
it to DATTA, our method achieves an 8.1% higher F1-Score. The PyTorch
implementation of DATTA is publicly available at:
https://github.com/StrohmayerJ/DATTA.","cs.CV, cs.AI, cs.ET, cs.LG",cs.CV,http://arxiv.org/abs/2411.13284v1
Transformers with Sparse Attention for Granger Causality,"Riya Mahesh, Rahul Vashisht, Chandrashekar Lakshminarayanan",2024-11-20T12:34:06Z,"Temporal causal analysis means understanding the underlying causes behind
observed variables over time. Deep learning based methods such as transformers
are increasingly used to capture temporal dynamics and causal relationships
beyond mere correlations. Recent works suggest self-attention weights of
transformers as a useful indicator of causal links. We leverage this to propose
a novel modification to the self-attention module to establish causal links
between the variables of multivariate time-series data with varying lag
dependencies. Our Sparse Attention Transformer captures causal relationships
using a two-fold approach - performing temporal attention first followed by
attention between the variables across the time steps masking them individually
to compute Granger Causality indices. The key novelty in our approach is the
ability of the model to assert importance and pick the most significant past
time instances for its prediction task against manually feeding a fixed time
lag value. We demonstrate the effectiveness of our approach via extensive
experimentation on several synthetic benchmark datasets. Furthermore, we
compare the performance of our model with the traditional Vector Autoregression
based Granger Causality method that assumes fixed lag length.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13264v1
"FASTNav: Fine-tuned Adaptive Small-language-models Trained for
  Multi-point Robot Navigation","Yuxuan Chen, Yixin Han, Xiao Li",2024-11-20T12:28:13Z,"With the rapid development of large language models (LLM), robots are
starting to enjoy the benefits of new interaction methods that large language
models bring. Because edge computing fulfills the needs for rapid response,
privacy, and network autonomy, we believe it facilitates the extensive
deployment of large models for robot navigation across various industries. To
enable local deployment of language models on edge devices, we adopt some model
boosting methods. In this paper, we propose FASTNav - a method for boosting
lightweight LLMs, also known as small language models (SLMs), for robot
navigation. The proposed method contains three modules: fine-tuning,
teacher-student iteration, and language-based multi-point robot navigation. We
train and evaluate models with FASTNav in both simulation and real robots,
proving that we can deploy them with low cost, high accuracy and low response
time. Compared to other model compression methods, FASTNav shows potential in
the local deployment of language models and tends to be a promising solution
for language-guided robot navigation on edge devices.","cs.RO, cs.AI, cs.HC",cs.RO,http://arxiv.org/abs/2411.13262v1
"Paying more attention to local contrast: improving infrared small target
  detection performance via prior knowledge","Peichao Wang, Jiabao Wang, Yao Chen, Rui Zhang, Yang Li, Zhuang Miao",2024-11-20T12:21:30Z,"The data-driven method for infrared small target detection (IRSTD) has
achieved promising results. However, due to the small scale of infrared small
target datasets and the limited number of pixels occupied by the targets
themselves, it is a challenging task for deep learning methods to directly
learn from these samples. Utilizing human expert knowledge to assist deep
learning methods in better learning is worthy of exploration. To effectively
guide the model to focus on targets' spatial features, this paper proposes the
Local Contrast Attention Enhanced infrared small target detection Network
(LCAE-Net), combining prior knowledge with data-driven deep learning methods.
LCAE-Net is a U-shaped neural network model which consists of two developed
modules: a Local Contrast Enhancement (LCE) module and a Channel Attention
Enhancement (CAE) module. The LCE module takes advantages of prior knowledge,
leveraging handcrafted convolution operator to acquire Local Contrast Attention
(LCA), which could realize background suppression while enhance the potential
target region, thus guiding the neural network to pay more attention to
potential infrared small targets' location information. To effectively utilize
the response information throughout downsampling progresses, the CAE module is
proposed to achieve the information fusion among feature maps' different
channels. Experimental results indicate that our LCAE-Net outperforms existing
state-of-the-art methods on the three public datasets NUDT-SIRST, NUAA-SIRST,
and IRSTD-1K, and its detection speed could reach up to 70 fps. Meanwhile, our
model has a parameter count and Floating-Point Operations (FLOPs) of 1.945M and
4.862G respectively, which is suitable for deployment on edge devices.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13260v1
"BelHouse3D: A Benchmark Dataset for Assessing Occlusion Robustness in 3D
  Point Cloud Semantic Segmentation","Umamaheswaran Raman Kumar, Abdur Razzaq Fayjie, Jurgen Hannaert, Patrick Vandewalle",2024-11-20T12:09:43Z,"Large-scale 2D datasets have been instrumental in advancing machine learning;
however, progress in 3D vision tasks has been relatively slow. This disparity
is largely due to the limited availability of 3D benchmarking datasets. In
particular, creating real-world point cloud datasets for indoor scene semantic
segmentation presents considerable challenges, including data collection within
confined spaces and the costly, often inaccurate process of per-point labeling
to generate ground truths. While synthetic datasets address some of these
challenges, they often fail to replicate real-world conditions, particularly
the occlusions that occur in point clouds collected from real environments.
Existing 3D benchmarking datasets typically evaluate deep learning models under
the assumption that training and test data are independently and identically
distributed (IID), which affects the models' usability for real-world point
cloud segmentation. To address these challenges, we introduce the BelHouse3D
dataset, a new synthetic point cloud dataset designed for 3D indoor scene
semantic segmentation. This dataset is constructed using real-world references
from 32 houses in Belgium, ensuring that the synthetic data closely aligns with
real-world conditions. Additionally, we include a test set with data occlusion
to simulate out-of-distribution (OOD) scenarios, reflecting the occlusions
commonly encountered in real-world point clouds. We evaluate popular
point-based semantic segmentation methods using our OOD setting and present a
benchmark. We believe that BelHouse3D and its OOD setting will advance research
in 3D point cloud semantic segmentation for indoor scenes, providing valuable
insights for the development of more generalizable models.","cs.CV, cs.AI, cs.LG, cs.RO",cs.CV,http://arxiv.org/abs/2411.13251v1
"Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for
  Text-to-SQL","Zhibo Chu, Zichong Wang, Qitao Qin",2024-11-20T12:03:17Z,"Large Language Models (LLMs) exhibit impressive problem-solving skills across
many tasks, but they still underperform compared to humans in various
downstream applications, such as text-to-SQL. On the BIRD benchmark
leaderboard, human performance achieves an accuracy of 92.96\%, whereas the
top-performing method reaches only 72.39\%. Notably, these state-of-the-art
(SoTA) methods predominantly rely on in-context learning to simulate human-like
reasoning. However, they overlook a critical human skill: continual learning.
Inspired by the educational practice of maintaining mistake notebooks during
our formative years, we propose LPE-SQL (Leveraging Prior Experience: An
Expandable Auxiliary Knowledge Base for Text-to-SQL), a novel framework
designed to augment LLMs by enabling continual learning without requiring
parameter fine-tuning. LPE-SQL consists of four modules that \textbf{i)}
retrieve relevant entries, \textbf{ii)} efficient sql generation, \textbf{iii)}
generate the final result through a cross-consistency mechanism and
\textbf{iv)} log successful and failed tasks along with their reasoning
processes or reflection-generated tips. Importantly, the core module of LPE-SQL
is the fourth one, while the other modules employ foundational methods,
allowing LPE-SQL to be easily integrated with SoTA technologies to further
enhance performance. Our experimental results demonstrate that this continual
learning approach yields substantial performance gains, with the smaller
Llama-3.1-70B model with surpassing the performance of the larger
Llama-3.1-405B model using SoTA methods.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13244v1
"Advanced Plaque Modeling for Atherosclerosis Detection Using Molecular
  Communication","Alexander Wietfeld, Pit Hofmann, Jonas Fuchtmann, Pengjie Zhou, Ruifeng Zheng, Juan A. Cabrera, Frank H. P. Fitzek, Wolfgang Kellerer",2024-11-20T11:59:44Z,"As one of the most prevalent diseases worldwide, plaque formation in human
arteries, known as atherosclerosis, is the focus of many research efforts.
Previously, molecular communication (MC) models have been proposed to capture
and analyze the natural processes inside the human body and to support the
development of diagnosis and treatment methods. In the future, synthetic MC
networks are envisioned to span the human body as part of the Internet of
Bio-Nano Things (IoBNT), turning blood vessels into physical communication
channels. By observing and characterizing changes in these channels, MC
networks could play an active role in detecting diseases like atherosclerosis.
In this paper, building on previous preliminary work for simulating an MC
scenario in a plaque-obstructed blood vessel, we evaluate different analytical
models for non-Newtonian flow and derive associated channel impulse responses
(CIRs). Additionally, we add the crucial factor of flow pulsatility to our
simulation model and investigate the effect of the systole-diastole cycle on
the received particles across the plaque channel. We observe a significant
influence of the plaque on the channel in terms of the flow profile and CIR
across different emission times in the cycle. These metrics could act as
crucial indicators for early non-invasive plaque detection in advanced future
MC methods.","cs.ET, physics.med-ph",cs.ET,http://arxiv.org/abs/2411.13241v1
"Probabilistic Trust-Based Enhancement for simultaneous transmission in
  AOMDV Routing Protocol",Nikhil Mishra,2024-11-20T11:41:21Z,"This work addresses a trust-based enhancement to the Multipath Ad hoc
On-Demand Distance Vector (AOMDV) routing protocol. While AODV and its
multipath variant AOMDV have been fundamental in mobile ad hoc networks, they
lack mechanisms to account for node reliability. A probabilistic link-trust
model is proposed that incorporates factors such as past behavior, battery
levels, and node coupling to distribute data optimally to reduce delay while
simultaneously transmitting through multiple paths.",cs.NI,cs.NI,http://arxiv.org/abs/2411.13227v1
Building music with Lego bricks and Raspberry Pi,"Ana M. Barbancho, Lorenzo J. Tardon, Isabel Barbancho",2024-11-20T11:37:05Z,"In this paper, a system to build music in an intuitive and accessible way,
with Lego bricks, is presented. The system makes use of the new powerful and
cheap possibilities that technology offers for making old things in a new way.
The Raspberry Pi is used to control the system and run the necessary
algorithms, customized Lego bricks are used for building melodies, custom
electronic designs, software pieces and 3D printed parts complete the items
employed. The system designed is modular, it allows creating melodies with
chords and percussion or just melodies or perform as a beatbox or a melody box.
The main interaction with the system is made using Lego-type building blocks.
Tests have demonstrated its versatility and ease of use, as well as its
usefulness in music learning for both children and adults.","cs.HC, cs.SD, eess.AS, 68, B.m; J.m",cs.HC,http://arxiv.org/abs/2411.13224v1
"Existential Conversations with Large Language Models: Content,
  Community, and Culture","Murray Shanahan, Beth Singler",2024-11-20T11:35:22Z,"Contemporary conversational AI systems based on large language models (LLMs)
can engage users on a wide variety of topics, including philosophy,
spirituality, and religion. Suitably prompted, LLMs can be coaxed into
discussing such existentially significant matters as their own putative
consciousness and the role of artificial intelligence in the fate of the
Cosmos. Here we examine two lengthy conversations of this type. We trace likely
sources, both ancient and modern, for the extensive repertoire of images,
myths, metaphors, and conceptual esoterica that the language model draws on
during these conversations, and foreground the contemporary communities and
cultural movements that deploy related motifs, especially in their online
activity. Finally, we consider the larger societal impacts of such engagements
with LLMs.","cs.CY, cs.AI, cs.LG",cs.CY,http://arxiv.org/abs/2411.13223v1
ViSTa Dataset: Do vision-language models understand sequential tasks?,"Evžen Wybitul, Evan Ryan Gunter, Mikhail Seleznyov",2024-11-20T11:19:22Z,"Using vision-language models (VLMs) as reward models in reinforcement
learning holds promise for reducing costs and improving safety. So far, VLM
reward models have only been used for goal-oriented tasks, where the agent must
reach a particular final outcome. We explore VLMs' potential to supervise tasks
that cannot be scored by the final state alone. To this end, we introduce
ViSTa, a dataset for evaluating Vision-based understanding of Sequential Tasks.
ViSTa comprises over 4,000 videos with step-by-step descriptions in virtual
home, Minecraft, and real-world environments. Its novel hierarchical structure
-- basic single-step tasks composed into more and more complex sequential tasks
-- allows a fine-grained understanding of how well VLMs can judge tasks with
varying complexity. To illustrate this, we use ViSTa to evaluate
state-of-the-art VLMs, including CLIP, ViCLIP, and GPT-4o. We find that, while
they are all good at object recognition, they fail to understand sequential
tasks, with only GPT-4o achieving non-trivial performance.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.13211v1
The Information Security Awareness of Large Language Models,"Ofir Cohen, Gil Ari Agmon, Asaf Shabtai, Rami Puzis",2024-11-20T11:09:55Z,"The popularity of large language models (LLMs) continues to increase, and
LLM-based assistants have become ubiquitous, assisting people of diverse
backgrounds in many aspects of life. Significant resources have been invested
in the safety of LLMs and their alignment with social norms. However, research
examining their behavior from the information security awareness (ISA)
perspective is lacking. Chatbots and LLM-based assistants may put unwitting
users in harm's way by facilitating unsafe behavior. We observe that the ISA
inherent in some of today's most popular LLMs varies significantly, with most
models requiring user prompts with a clear security context to utilize their
security knowledge and provide safe responses to users. Based on this
observation, we created a comprehensive set of 30 scenarios to assess the ISA
of LLMs. These scenarios benchmark the evaluated models with respect to all
focus areas defined in a mobile ISA taxonomy. Among our findings is that ISA is
mildly affected by changing the model's temperature, whereas adjusting the
system prompt can substantially impact it. This underscores the necessity of
setting the right system prompt to mitigate ISA weaknesses. Our findings also
highlight the importance of ISA assessment for the development of future
LLM-based assistants.","cs.CR, cs.AI, cs.LG",cs.CR,http://arxiv.org/abs/2411.13207v1
Engagement-Driven Content Generation with Large Language Models,"Erica Coppolillo, Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco",2024-11-20T10:40:08Z,"Large Language Models (LLMs) exhibit significant persuasion capabilities in
one-on-one interactions, but their influence within social networks remains
underexplored. This study investigates the potential social impact of LLMs in
these environments, where interconnected users and complex opinion dynamics
pose unique challenges. In particular, we address the following research
question: can LLMs learn to generate meaningful content that maximizes user
engagement on social networks?
  To answer this question, we define a pipeline to guide the LLM-based content
generation which employs reinforcement learning with simulated feedback. In our
framework, the reward is based on an engagement model borrowed from the
literature on opinion dynamics and information propagation. Moreover, we force
the text generated by the LLM to be aligned with a given topic and to satisfy a
minimum fluency requirement.
  Using our framework, we analyze the capabilities and limitations of LLMs in
tackling the given task, specifically considering the relative positions of the
LLM as an agent within the social network and the distribution of opinions in
the network on the given topic. Our findings show the full potential of LLMs in
creating social engagement. Notable properties of our approach are that the
learning procedure is adaptive to the opinion distribution of the underlying
network and agnostic to the specifics of the engagement model, which is
embedded as a plug-and-play component. In this regard, our approach can be
easily refined for more complex engagement tasks and interventions in
computational social science.
  The code used for the experiments is publicly available at
https://anonymous.4open.science/r/EDCG/.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13187v1
"Cross-Camera Distracted Driver Classification through Feature
  Disentanglement and Contrastive Learning","Simone Bianco, Luigi Celona, Paolo Napoletano",2024-11-20T10:27:12Z,"The classification of distracted drivers is pivotal for ensuring safe
driving. Previous studies demonstrated the effectiveness of neural networks in
automatically predicting driver distraction, fatigue, and potential hazards.
However, recent research has uncovered a significant loss of accuracy in these
models when applied to samples acquired under conditions that differ from the
training data. In this paper, we introduce a robust model designed to withstand
changes in camera position within the vehicle. Our Driver Behavior Monitoring
Network (DBMNet) relies on a lightweight backbone and integrates a
disentanglement module to discard camera view information from features,
coupled with contrastive learning to enhance the encoding of various driver
actions. Experiments conducted on the daytime and nighttime subsets of the
100-Driver dataset validate the effectiveness of our approach with an increment
on average of 9\% in Top-1 accuracy in comparison with the state of the art. In
addition, cross-dataset and cross-camera experiments conducted on three
benchmark datasets, namely AUCDD-V1, EZZ2021 and SFD, demonstrate the superior
generalization capability of the proposed method.","cs.CV, cs.AI, cs.CY",cs.CV,http://arxiv.org/abs/2411.13181v1
SONNET: Enhancing Time Delay Estimation by Leveraging Simulated Audio,"Erik Tegler, Magnus Oskarsson, Kalle Åström",2024-11-20T10:23:21Z,"Time delay estimation or Time-Difference-Of-Arrival estimates is a critical
component for multiple localization applications such as multilateration,
direction of arrival, and self-calibration. The task is to estimate the time
difference between a signal arriving at two different sensors. For the audio
sensor modality, most current systems are based on classical methods such as
the Generalized Cross-Correlation Phase Transform (GCC-PHAT) method. In this
paper we demonstrate that learning based methods can, even based on synthetic
data, significantly outperform GCC-PHAT on novel real world data. To overcome
the lack of data with ground truth for the task, we train our model on a
simulated dataset which is sufficiently large and varied, and that captures the
relevant characteristics of the real world problem. We provide our trained
model, SONNET (Simulation Optimized Neural Network Estimator of Timeshifts),
which is runnable in real-time and works on novel data out of the box for many
real data applications, i.e. without re-training. We further demonstrate
greatly improved performance on the downstream task of self-calibration when
using our model compared to classical methods.","cs.SD, cs.CV, eess.AS",cs.SD,http://arxiv.org/abs/2411.13179v1
A Unified Analysis for Finite Weight Averaging,"Peng Wang, Li Shen, Zerui Tao, Yan Sun, Guodong Zheng, Dacheng Tao",2024-11-20T10:08:22Z,"Averaging iterations of Stochastic Gradient Descent (SGD) have achieved
empirical success in training deep learning models, such as Stochastic Weight
Averaging (SWA), Exponential Moving Average (EMA), and LAtest Weight Averaging
(LAWA). Especially, with a finite weight averaging method, LAWA can attain
faster convergence and better generalization. However, its theoretical
explanation is still less explored since there are fundamental differences
between finite and infinite settings. In this work, we first generalize SGD and
LAWA as Finite Weight Averaging (FWA) and explain their advantages compared to
SGD from the perspective of optimization and generalization. A key challenge is
the inapplicability of traditional methods in the sense of expectation or
optimal values for infinite-dimensional settings in analyzing FWA's
convergence. Second, the cumulative gradients introduced by FWA introduce
additional confusion to the generalization analysis, especially making it more
difficult to discuss them under different assumptions. Extending the final
iteration convergence analysis to the FWA, this paper, under a convexity
assumption, establishes a convergence bound
$\mathcal{O}(\log\left(\frac{T}{k}\right)/\sqrt{T})$, where $k\in[1, T/2]$ is a
constant representing the last $k$ iterations. Compared to SGD with
$\mathcal{O}(\log(T)/\sqrt{T})$, we prove theoretically that FWA has a faster
convergence rate and explain the effect of the number of average points. In the
generalization analysis, we find a recursive representation for bounding the
cumulative gradient using mathematical induction. We provide bounds for
constant and decay learning rates and the convex and non-convex cases to show
the good generalization performance of FWA. Finally, experimental results on
several benchmarks verify our theoretical results.","cs.LG, math.OC, stat.ML",cs.LG,http://arxiv.org/abs/2411.13169v1
"Cyborg Insect Factory: Automatic Assembly System to Build up
  Insect-computer Hybrid Robot Based on Vision-guided Robotic Arm Manipulation
  of Custom Bipolar Electrodes","Qifeng Lin, Nghia Vuong, Kewei Song, Phuoc Thanh Tran-Ngoc, Greg Angelo Gonzales Nonato, Hirotaka Sato",2024-11-20T10:00:10Z,"The advancement of insect-computer hybrid robots holds significant promise
for navigating complex terrains and enhancing robotics applications. This study
introduced an automatic assembly method for insect-computer hybrid robots,
which was accomplished by mounting backpack with precise implantation of
custom-designed bipolar electrodes. We developed a stimulation protocol for the
intersegmental membrane between pronotum and mesothorax of the Madagascar
hissing cockroach, allowing for bipolar electrodes' automatic implantation
using a robotic arm. The assembly process was integrated with a deep
learning-based vision system to accurately identify the implantation site, and
a dedicated structure to fix the insect (68 s for the whole assembly process).
The automatically assembled hybrid robots demonstrated steering control (over
70 degrees for 0.4 s stimulation) and deceleration control (68.2% speed
reduction for 0.4 s stimulation), matching the performance of manually
assembled systems. Furthermore, a multi-agent system consisting of 4 hybrid
robots successfully covered obstructed outdoor terrain (80.25% for 10 minutes
31 seconds), highlighting the feasibility of mass-producing these systems for
practical applications. The proposed automatic assembly strategy reduced
preparation time for the insect-computer hybrid robots while maintaining their
precise control, laying a foundation for scalable production and deployment in
real-world applications.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13164v1
"Unlocking Historical Clinical Trial Data with ALIGN: A Compositional
  Large Language Model System for Medical Coding","Nabeel Seedat, Caterina Tozzi, Andrea Hita Ardiaca, Mihaela van der Schaar, James Weatherall, Adam Taylor",2024-11-20T09:59:12Z,"The reuse of historical clinical trial data has significant potential to
accelerate medical research and drug development. However, interoperability
challenges, particularly with missing medical codes, hinders effective data
integration across studies. While Large Language Models (LLMs) offer a
promising solution for automated coding without labeled data, current
approaches face challenges on complex coding tasks. We introduce ALIGN, a novel
compositional LLM-based system for automated, zero-shot medical coding. ALIGN
follows a three-step process: (1) diverse candidate code generation; (2)
self-evaluation of codes and (3) confidence scoring and uncertainty estimation
enabling human deferral to ensure reliability. We evaluate ALIGN on harmonizing
medication terms into Anatomical Therapeutic Chemical (ATC) and medical history
terms into Medical Dictionary for Regulatory Activities (MedDRA) codes
extracted from 22 immunology trials. ALIGN outperformed the LLM baselines,
while also providing capabilities for trustworthy deployment. For MedDRA
coding, ALIGN achieved high accuracy across all levels, matching RAG and
excelling at the most specific levels (87-90% for HLGT). For ATC coding, ALIGN
demonstrated superior performance, particularly at lower hierarchy levels (ATC
Level 4), with 72-73% overall accuracy and 86-89% accuracy for common
medications, outperforming baselines by 7-22%. ALIGN's uncertainty-based
deferral improved accuracy by 17% to 90% accuracy with 30% deferral, notably
enhancing performance on uncommon medications. ALIGN achieves this
cost-efficiently at \$0.0007 and \$0.02 per code for GPT-4o-mini and GPT-4o,
reducing barriers to clinical adoption. ALIGN advances automated medical coding
for clinical trial data, contributing to enhanced data interoperability and
reusability, positioning it as a promising tool to improve clinical research
and accelerate drug development.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13163v1
"Closer Look at Efficient Inference Methods: A Survey of Speculative
  Decoding","Hyun Ryu, Eric Kim",2024-11-20T09:46:30Z,"Efficient inference in large language models (LLMs) has become a critical
focus as their scale and complexity grow. Traditional autoregressive decoding,
while effective, suffers from computational inefficiencies due to its
sequential token generation process. Speculative decoding addresses this
bottleneck by introducing a two-stage framework: drafting and verification. A
smaller, efficient model generates a preliminary draft, which is then refined
by a larger, more sophisticated model. This paper provides a comprehensive
survey of speculative decoding methods, categorizing them into draft-centric
and model-centric approaches. We discuss key ideas associated with each method,
highlighting their potential for scaling LLM inference. This survey aims to
guide future research in optimizing speculative decoding and its integration
into real-world LLM applications.","cs.CL, cs.AI, cs.LG",cs.CL,http://arxiv.org/abs/2411.13157v1
"MecQaBot: A Modular Robot Sensing and Wireless Mechatronics Framework
  for Education and Research","Alice James, Avishkar Seth, Subhas Mukhopadhyay",2024-11-20T09:45:14Z,"We introduce MecQaBot, an open-source, affordable, and modular autonomous
mobile robotics framework developed for education and research at Macquarie
University, School of Engineering, since 2019. This platform aims to provide
students and researchers with an accessible means for exploring autonomous
robotics and fostering hands-on learning and innovation. Over the five years,
the platform has engaged more than 240 undergraduate and postgraduate students
across various engineering disciplines. The framework addresses the growing
need for practical robotics training in response to the expanding robotics
field and its increasing relevance in industry and academia. The platform
facilitates teaching critical concepts in sensing, programming,
hardware-software integration, and autonomy within real-world contexts,
igniting student interest and engagement. We describe the design and evolution
of the MecQaBot framework and the underlying principles of scalability and
flexibility, which are keys to its success. Complete documentation:
https://github.com/AliceJames-1/MecQaBot",cs.RO,cs.RO,http://arxiv.org/abs/2411.13156v1
"Long-term Detection System for Six Kinds of Abnormal Behavior of the
  Elderly Living Alone","Kai Tanaka, Mineichi Kudo, Keigo Kimura, Atsuyoshi Nakamura",2024-11-20T09:42:08Z,"The proportion of elderly people is increasing worldwide, particularly those
living alone in Japan. As elderly people get older, their risks of physical
disabilities and health issues increase. To automatically discover these issues
at a low cost in daily life, sensor-based detection in a smart home is
promising. As part of the effort towards early detection of abnormal behaviors,
we propose a simulator-based detection systems for six typical anomalies: being
semi-bedridden, being housebound, forgetting, wandering, fall while walking and
fall while standing. Our detection system can be customized for various room
layout, sensor arrangement and resident's characteristics by training detection
classifiers using the simulator with the parameters fitted to individual cases.
Considering that the six anomalies that our system detects have various
occurrence durations, such as being housebound for weeks or lying still for
seconds after a fall, the detection classifiers of our system produce anomaly
labels depending on each anomaly's occurrence duration, e.g., housebound per
day and falls per second. We propose a method that standardizes the processing
of sensor data, and uses a simple detection approach. Although the validity
depends on the realism of the simulation, numerical evaluations using sensor
data that includes a variety of resident behavior patterns over nine years as
test data show that (1) the methods for detecting wandering and falls are
comparable to previous methods, and (2) the methods for detecting being
semi-bedridden, being housebound, and forgetting achieve a sensitivity of over
0.9 with fewer than one false alarm every 50 days.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13153v1
AGLP: A Graph Learning Perspective for Semi-supervised Domain Adaptation,"Houcheng Su, Mengzhu Wang, Jiao Li, Nan Yin, Li Shen",2024-11-20T09:41:41Z,"In semi-supervised domain adaptation (SSDA), the model aims to leverage
partially labeled target domain data along with a large amount of labeled
source domain data to enhance its generalization capability for the target
domain. A key advantage of SSDA is its ability to significantly reduce reliance
on labeled data, thereby lowering the costs and time associated with data
preparation. Most existing SSDA methods utilize information from domain labels
and class labels but overlook the structural information of the data. To
address this issue, this paper proposes a graph learning perspective (AGLP) for
semi-supervised domain adaptation. We apply the graph convolutional network to
the instance graph which allows structural information to propagate along the
weighted graph edges. The proposed AGLP model has several advantages. First, to
the best of our knowledge, this is the first work to model structural
information in SSDA. Second, the proposed model can effectively learn
domain-invariant and semantic representations, reducing domain discrepancies in
SSDA. Extensive experimental results on multiple standard benchmarks
demonstrate that the proposed AGLP algorithm outperforms state-of-the-art
semi-supervised domain adaptation methods.","cs.CV, cs.AI, 68T07, 92C55, 62H35, I.2.6; I.4.10; J.3",cs.CV,http://arxiv.org/abs/2411.13152v1
"RAW-Diffusion: RGB-Guided Diffusion Models for High-Fidelity RAW Image
  Generation","Christoph Reinders, Radu Berdan, Beril Besbinar, Junji Otsuka, Daisuke Iso",2024-11-20T09:40:12Z,"Current deep learning approaches in computer vision primarily focus on RGB
data sacrificing information. In contrast, RAW images offer richer
representation, which is crucial for precise recognition, particularly in
challenging conditions like low-light environments. The resultant demand for
comprehensive RAW image datasets contrasts with the labor-intensive process of
creating specific datasets for individual sensors. To address this, we propose
a novel diffusion-based method for generating RAW images guided by RGB images.
Our approach integrates an RGB-guidance module for feature extraction from RGB
inputs, then incorporates these features into the reverse diffusion process
with RGB-guided residual blocks across various resolutions. This approach
yields high-fidelity RAW images, enabling the creation of camera-specific RAW
datasets. Our RGB2RAW experiments on four DSLR datasets demonstrate
state-of-the-art performance. Moreover, RAW-Diffusion demonstrates exceptional
data efficiency, achieving remarkable performance with as few as 25 training
samples or even fewer. We extend our method to create BDD100K-RAW and
Cityscapes-RAW datasets, revealing its effectiveness for object detection in
RAW imagery, significantly reducing the amount of required RAW images.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13150v1
"YCB-LUMA: YCB Object Dataset with Luminance Keying for Object
  Localization",Thomas Pöllabauer,2024-11-20T09:32:22Z,"Localizing target objects in images is an important task in computer vision.
Often it is the first step towards solving a variety of applications in
autonomous driving, maintenance, quality insurance, robotics, and augmented
reality. Best in class solutions for this task rely on deep neural networks,
which require a set of representative training data for best performance.
Creating sets of sufficient quality, variety, and size is often difficult,
error prone, and expensive. This is where the method of luminance keying can
help: it provides a simple yet effective solution to record high quality data
for training object detection and segmentation. We extend previous work that
presented luminance keying on the common YCB-V set of household objects by
recording the remaining objects of the YCB superset. The additional variety of
objects - addition of transparency, multiple color variations, non-rigid
objects - further demonstrates the usefulness of luminance keying and might be
used to test the applicability of the approach on new 2D object detection and
segmentation algorithms.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13149v1
Learning Time-Optimal and Speed-Adjustable Tactile In-Hand Manipulation,"Johannes Pitz, Lennart Röstel, Leon Sievers, Berthold Bäuml",2024-11-20T09:25:02Z,"In-hand manipulation with multi-fingered hands is a challenging problem that
recently became feasible with the advent of deep reinforcement learning
methods. While most contributions to the task brought improvements in
robustness and generalization, this paper addresses the critical performance
measure of the speed at which an in-hand manipulation can be performed. We
present reinforcement learning policies that can perform in-hand reorientation
significantly faster than previous approaches for the complex setting of
goal-conditioned reorientation in SO(3) with permanent force closure and
tactile feedback only (i.e., using the hand's torque and position sensors).
Moreover, we show how policies can be trained to be speed-adjustable, allowing
for setting the average orientation speed of the manipulated object during
deployment. To this end, we present suitable and minimalistic reinforcement
learning objectives for time-optimal and speed-adjustable in-hand manipulation,
as well as an analysis based on extensive experiments in simulation. We also
demonstrate the zero-shot transfer of the learned policies to the real DLR-Hand
II with a wide range of target speeds and the fastest dextrous in-hand
manipulation without visual inputs.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13148v1
"GraphCL: Graph-based Clustering for Semi-Supervised Medical Image
  Segmentation","Mengzhu Wang, Jiao Li, Houcheng Su, Nan Yin, Shen Li",2024-11-20T09:24:46Z,"Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.","cs.CV, cs.AI, 68T07, 92C55, 62H35, I.2.6; I.4.10; J.3",cs.CV,http://arxiv.org/abs/2411.13147v1
Globally Correlation-Aware Hard Negative Generation,"Wenjie Peng, Hongxiang Huang, Tianshui Chen, Quhui Ke, Gang Dai, Shuangping Huang",2024-11-20T09:19:12Z,"Hard negative generation aims to generate informative negative samples that
help to determine the decision boundaries and thus facilitate advancing deep
metric learning. Current works select pair/triplet samples, learn their
correlations, and fuse them to generate hard negatives. However, these works
merely consider the local correlations of selected samples, ignoring global
sample correlations that would provide more significant information to generate
more informative negatives. In this work, we propose a Globally
Correlation-Aware Hard Negative Generation (GCA-HNG) framework, which first
learns sample correlations from a global perspective and exploits these
correlations to guide generating hardness-adaptive and diverse negatives.
Specifically, this approach begins by constructing a structured graph to model
sample correlations, where each node represents a specific sample and each edge
represents the correlations between corresponding samples. Then, we introduce
an iterative graph message propagation to propagate the messages of node and
edge through the whole graph and thus learn the sample correlations globally.
Finally, with the guidance of the learned global correlations, we propose a
channel-adaptive manner to combine an anchor and multiple negatives for HNG.
Compared to current methods, GCA-HNG allows perceiving sample correlations with
numerous negatives from a global and comprehensive perspective and generates
the negatives with better hardness and diversity. Extensive experiment results
demonstrate that the proposed GCA-HNG is superior to related methods on four
image retrieval benchmark datasets. Codes and trained models are available at
\url{https://github.com/PWenJay/GCA-HNG}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13145v1
SAGA: Synthetic Audit Log Generation for APT Campaigns,"Yi-Ting Huang, Ying-Ren Guo, Yu-Sheng Yang, Guo-Wei Wong, Yu-Zih Jheng, Yeali Sun, Jessemyn Modini, Timothy Lynar, Meng Chang Chen",2024-11-20T09:06:46Z,"With the increasing sophistication of Advanced Persistent Threats (APTs), the
demand for effective detection and mitigation strategies and methods has
escalated. Program execution leaves traces in the system audit log, which can
be analyzed to detect malicious activities. However, collecting and analyzing
large volumes of audit logs over extended periods is challenging, further
compounded by insufficient labeling that hinders their usability. Addressing
these challenges, this paper introduces SAGA (Synthetic Audit log Generation
for APT campaigns), a novel approach for generating find-grained labeled
synthetic audit logs that mimic real-world system logs while embedding stealthy
APT attacks. SAGA generates configurable audit logs for arbitrary duration,
blending benign logs from normal operations with malicious logs based on the
definitions the MITRE ATT\&CK framework. Malicious audit logs follow an APT
lifecycle, incorporating various attack techniques at each stage. These
synthetic logs can serve as benchmark datasets for training machine learning
models and assessing diverse APT detection methods. To demonstrate the
usefulness of synthetic audit logs, we ran established baselines of event-based
technique hunting and APT campaign detection using various synthetic audit
logs. In addition, we show that a deep learning model trained on synthetic
audit logs can detect previously unseen techniques within audit logs.",cs.CR,cs.CR,http://arxiv.org/abs/2411.13138v1
Domain Adaptive Unfolded Graph Neural Networks,"Zepeng Zhang, Olga Fink",2024-11-20T09:05:36Z,"Over the last decade, graph neural networks (GNNs) have made significant
progress in numerous graph machine learning tasks. In real-world applications,
where domain shifts occur and labels are often unavailable for a new target
domain, graph domain adaptation (GDA) approaches have been proposed to
facilitate knowledge transfer from the source domain to the target domain.
Previous efforts in tackling distribution shifts across domains have mainly
focused on aligning the node embedding distributions generated by the GNNs in
the source and target domains. However, as the core part of GDA approaches, the
impact of the underlying GNN architecture has received limited attention. In
this work, we explore this orthogonal direction, i.e., how to facilitate GDA
with architectural enhancement. In particular, we consider a class of GNNs that
are designed explicitly based on optimization problems, namely unfolded GNNs
(UGNNs), whose training process can be represented as bi-level optimization.
Empirical and theoretical analyses demonstrate that when transferring from the
source domain to the target domain, the lower-level objective value generated
by the UGNNs significantly increases, resulting in an increase in the
upper-level objective as well. Motivated by this observation, we propose a
simple yet effective strategy called cascaded propagation (CP), which is
guaranteed to decrease the lower-level objective value. The CP strategy is
widely applicable to general UGNNs, and we evaluate its efficacy with three
representative UGNN architectures. Extensive experiments on five real-world
datasets demonstrate that the UGNNs integrated with CP outperform
state-of-the-art GDA baselines.","cs.LG, eess.SP",cs.LG,http://arxiv.org/abs/2411.13137v1
"TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in
  Vision-Language Models","Xin Wang, Kai Chen, Jiaming Zhang, Jingjing Chen, Xingjun Ma",2024-11-20T08:58:59Z,"Large pre-trained Vision-Language Models (VLMs) such as CLIP have
demonstrated excellent zero-shot generalizability across various downstream
tasks. However, recent studies have shown that the inference performance of
CLIP can be greatly degraded by small adversarial perturbations, especially its
visual modality, posing significant safety threats. To mitigate this
vulnerability, in this paper, we propose a novel defense method called
Test-Time Adversarial Prompt Tuning (TAPT) to enhance the inference robustness
of CLIP against visual adversarial attacks. TAPT is a test-time defense method
that learns defensive bimodal (textual and visual) prompts to robustify the
inference process of CLIP. Specifically, it is an unsupervised method that
optimizes the defensive prompts for each test sample by minimizing a multi-view
entropy and aligning adversarial-clean distributions. We evaluate the
effectiveness of TAPT on 11 benchmark datasets, including ImageNet and 10 other
zero-shot datasets, demonstrating that it enhances the zero-shot adversarial
robustness of the original CLIP by at least 48.9% against AutoAttack (AA),
while largely maintaining performance on clean examples. Moreover, TAPT
outperforms existing adversarial prompt tuning methods across various
backbones, achieving an average robustness improvement of at least 36.6%.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13136v1
"Approximating Spatial Distance Through Confront Networks: Application to
  the Segmentation of Medieval Avignon","Margot Ferrand, Vincent Labatut",2024-11-20T08:57:10Z,"In historical studies, the older the sources, the more common it is to have
access to data that are only partial, and/or unreliable or imprecise. This can
make it difficult, or even impossible, to perform certain tasks of interest,
such as the segmentation of some urban space based on the location of its
constituting elements. Indeed, traditional approaches to tackle this specific
task require knowing the position of all these elements before clustering them.
Yet, alternative information is sometimes available, which can be leveraged to
address this challenge. For instance, in the Middle Ages, land registries
typically do not provide exact addresses, but rather locate spatial objects
relative to each other, e.g. x being to the North of y. Spatial graphs are
particularly adapted to model such spatial relationships, called confronts,
which is why we propose their use over standard tabular databases. However,
historical data are rich and allow extracting confront networks in many ways,
making the process non-trivial. In this article, we propose several extraction
methods and compare them to identify the most appropriate. We postulate that
the best candidate must constitute an optimal trade-off between covering as
much of the original data as possible, and providing the best graph-based
approximation of spatial distance. Leveraging a dataset that describes Avignon
during its papal period, we show empirically that the best results require
ignoring some of the information present in the original historical sources,
and that including additional information from secondary sources significantly
improves the confront network. We illustrate the relevance of our method by
partitioning the best graph that we extracted, and discussing its community
structure in terms of urban space organization, from a historical perspective.
Our data and source code are both publicly available online.",cs.SI,cs.SI,http://arxiv.org/abs/2411.13134v1
"Adapting Vision Foundation Models for Robust Cloud Segmentation in
  Remote Sensing Images","Xuechao Zou, Shun Zhang, Kai Li, Shiying Wang, Junliang Xing, Lei Jin, Congyan Lang, Pin Tao",2024-11-20T08:37:39Z,"Cloud segmentation is a critical challenge in remote sensing image
interpretation, as its accuracy directly impacts the effectiveness of
subsequent data processing and analysis. Recently, vision foundation models
(VFM) have demonstrated powerful generalization capabilities across various
visual tasks. In this paper, we present a parameter-efficient adaptive
approach, termed Cloud-Adapter, designed to enhance the accuracy and robustness
of cloud segmentation. Our method leverages a VFM pretrained on general domain
data, which remains frozen, eliminating the need for additional training.
Cloud-Adapter incorporates a lightweight spatial perception module that
initially utilizes a convolutional neural network (ConvNet) to extract dense
spatial representations. These multi-scale features are then aggregated and
serve as contextual inputs to an adapting module, which modulates the frozen
transformer layers within the VFM. Experimental results demonstrate that the
Cloud-Adapter approach, utilizing only 0.6% of the trainable parameters of the
frozen backbone, achieves substantial performance gains. Cloud-Adapter
consistently attains state-of-the-art (SOTA) performance across a wide variety
of cloud segmentation datasets from multiple satellite sources, sensor series,
data processing levels, land cover scenarios, and annotation granularities. We
have released the source code and pretrained models at
https://github.com/XavierJiezou/Cloud-Adapter to support further research.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13127v1
"ReinFog: A DRL Empowered Framework for Resource Management in Edge and
  Cloud Computing Environments","Zhiyu Wang, Mohammad Goudarzi, Rajkumar Buyya",2024-11-20T08:31:43Z,"The growing IoT landscape requires effective server deployment strategies to
meet demands including real-time processing and energy efficiency. This is
complicated by heterogeneous, dynamic applications and servers. To address
these challenges, we propose ReinFog, a modular distributed software empowered
with Deep Reinforcement Learning (DRL) for adaptive resource management across
edge/fog and cloud environments. ReinFog enables the practical
development/deployment of various centralized and distributed DRL techniques
for resource management in edge/fog and cloud computing environments. It also
supports integrating native and library-based DRL techniques for diverse IoT
application scheduling objectives. Additionally, ReinFog allows for customizing
deployment configurations for different DRL techniques, including the number
and placement of DRL Learners and DRL Workers in large-scale distributed
systems. Besides, we propose a novel Memetic Algorithm for DRL Component (e.g.,
DRL Learners and DRL Workers) Placement in ReinFog named MADCP, which combines
the strengths of Genetic Algorithm, Firefly Algorithm, and Particle Swarm
Optimization. Experiments reveal that the DRL mechanisms developed within
ReinFog have significantly enhanced both centralized and distributed DRL
techniques implementation. These advancements have resulted in notable
improvements in IoT application performance, reducing response time by 45%,
energy consumption by 39%, and weighted cost by 37%, while maintaining minimal
scheduling overhead. Additionally, ReinFog exhibits remarkable scalability,
with a rise in DRL Workers from 1 to 30 causing only a 0.3-second increase in
startup time and around 2 MB more RAM per Worker. The proposed MADCP for DRL
component placement further accelerates the convergence rate of DRL techniques
by up to 38%.",cs.DC,cs.DC,http://arxiv.org/abs/2411.13121v1
Virtual Staining of Label-Free Tissue in Imaging Mass Spectrometry,"Yijie Zhang, Luzhe Huang, Nir Pillar, Yuzhu Li, Lukasz G. Migas, Raf Van de Plas, Jeffrey M. Spraggins, Aydogan Ozcan",2024-11-20T08:30:11Z,"Imaging mass spectrometry (IMS) is a powerful tool for untargeted, highly
multiplexed molecular mapping of tissue in biomedical research. IMS offers a
means of mapping the spatial distributions of molecular species in biological
tissue with unparalleled chemical specificity and sensitivity. However, most
IMS platforms are not able to achieve microscopy-level spatial resolution and
lack cellular morphological contrast, necessitating subsequent histochemical
staining, microscopic imaging and advanced image registration steps to enable
molecular distributions to be linked to specific tissue features and cell
types. Here, we present a virtual histological staining approach that enhances
spatial resolution and digitally introduces cellular morphological contrast
into mass spectrometry images of label-free human tissue using a diffusion
model. Blind testing on human kidney tissue demonstrated that the virtually
stained images of label-free samples closely match their histochemically
stained counterparts (with Periodic Acid-Schiff staining), showing high
concordance in identifying key renal pathology structures despite utilizing IMS
data with 10-fold larger pixel size. Additionally, our approach employs an
optimized noise sampling technique during the diffusion model's inference
process to reduce variance in the generated images, yielding reliable and
repeatable virtual staining. We believe this virtual staining method will
significantly expand the applicability of IMS in life sciences and open new
avenues for mass spectrometry-based biomedical research.","cs.CV, cs.LG, physics.med-ph, physics.optics",cs.CV,http://arxiv.org/abs/2411.13120v1
"Compute Optimal Inference and Provable Amortisation Gap in Sparse
  Autoencoders","Charles O'Neill, David Klindt",2024-11-20T08:21:53Z,"A recent line of work has shown promise in using sparse autoencoders (SAEs)
to uncover interpretable features in neural network representations. However,
the simple linear-nonlinear encoding mechanism in SAEs limits their ability to
perform accurate sparse inference. In this paper, we investigate sparse
inference and learning in SAEs through the lens of sparse coding. Specifically,
we show that SAEs perform amortised sparse inference with a computationally
restricted encoder and, using compressed sensing theory, we prove that this
mapping is inherently insufficient for accurate sparse inference, even in
solvable cases. Building on this theory, we empirically explore conditions
where more sophisticated sparse inference methods outperform traditional SAE
encoders. Our key contribution is the decoupling of the encoding and decoding
processes, which allows for a comparison of various sparse encoding strategies.
We evaluate these strategies on two dimensions: alignment with true underlying
sparse features and correct inference of sparse codes, while also accounting
for computational costs during training and inference. Our results reveal that
substantial performance gains can be achieved with minimal increases in compute
cost. We demonstrate that this generalises to SAEs applied to large language
models (LLMs), where advanced encoders achieve similar interpretability. This
work opens new avenues for understanding neural network representations and
offers important implications for improving the tools we use to analyse the
activations of large language models.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13117v1
"Provably Efficient Action-Manipulation Attack Against Continuous
  Reinforcement Learning","Zhi Luo, Xiyuan Yang, Pan Zhou, Di Wang",2024-11-20T08:20:29Z,"Manipulating the interaction trajectories between the intelligent agent and
the environment can control the agent's training and behavior, exposing the
potential vulnerabilities of reinforcement learning (RL). For example, in
Cyber-Physical Systems (CPS) controlled by RL, the attacker can manipulate the
actions of the adopted RL to other actions during the training phase, which
will lead to bad consequences. Existing work has studied action-manipulation
attacks in tabular settings, where the states and actions are discrete. As seen
in many up-and-coming RL applications, such as autonomous driving, continuous
action space is widely accepted, however, its action-manipulation attacks have
not been thoroughly investigated yet. In this paper, we consider this crucial
problem in both white-box and black-box scenarios. Specifically, utilizing the
knowledge derived exclusively from trajectories, we propose a black-box attack
algorithm named LCBT, which uses the Monte Carlo tree search method for
efficient action searching and manipulation. Additionally, we demonstrate that
for an agent whose dynamic regret is sub-linearly related to the total number
of steps, LCBT can teach the agent to converge to target policies with only
sublinear attack cost, i.e., $O\left(\mathcal{R}(T) + MH^3K^E\log
(MT)\right)(0<E<1)$, where $H$ is the number of steps per episode, $K$ is the
total number of episodes, $T=KH$ is the total number of steps, $M$ is the
number of subspaces divided in the state space, and $\mathcal{R}(T)$ is the
bound of the RL algorithm's regret. We conduct our proposed attack methods on
three aggressive algorithms: DDPG, PPO, and TD3 in continuous settings, which
show a promising attack performance.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13116v1
Special Unitary Parameterized Estimators of Rotation,Akshay Chandrasekhar,2024-11-20T08:07:11Z,"This paper explores rotation estimation from the perspective of special
unitary matrices. First, multiple solutions to Wahba's problem are derived
through special unitary matrices, providing linear constraints on quaternion
rotation parameters. Next, from these constraints, closed-form solutions to the
problem are presented for minimal cases. Finally, motivated by these results,
we investigate new representations for learning rotations in neural networks.
Numerous experiments validate the proposed methods.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13109v1
Superpixel Cost Volume Excitation for Stereo Matching,"Shanglong Liu, Lin Qi, Junyu Dong, Wenxiang Gu, Liyi Xu",2024-11-20T07:59:55Z,"In this work, we concentrate on exciting the intrinsic local consistency of
stereo matching through the incorporation of superpixel soft constraints, with
the objective of mitigating inaccuracies at the boundaries of predicted
disparity maps. Our approach capitalizes on the observation that neighboring
pixels are predisposed to belong to the same object and exhibit closely similar
intensities within the probability volume of superpixels. By incorporating this
insight, our method encourages the network to generate consistent probability
distributions of disparity within each superpixel, aiming to improve the
overall accuracy and coherence of predicted disparity maps. Experimental evalua
tions on widely-used datasets validate the efficacy of our proposed approach,
demonstrating its ability to assist cost volume-based matching networks in
restoring competitive performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13105v1
"DRL-Based Optimization for AoI and Energy Consumption in C-V2X Enabled
  IoV","Zheng Zhang, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief",2024-11-20T07:59:35Z,"To address communication latency issues, the Third Generation Partnership
Project (3GPP) has defined Cellular-Vehicle to Everything (C-V2X) technology,
which includes Vehicle-to-Vehicle (V2V) communication for direct
vehicle-to-vehicle communication. However, this method requires vehicles to
autonomously select communication resources based on the Semi-Persistent
Scheduling (SPS) protocol, which may lead to collisions due to different
vehicles sharing the same communication resources, thereby affecting
communication effectiveness. Non-Orthogonal Multiple Access (NOMA) is
considered a potential solution for handling large-scale vehicle communication,
as it can enhance the Signal-to-Interference-plus-Noise Ratio (SINR) by
employing Successive Interference Cancellation (SIC), thereby reducing the
negative impact of communication collisions. When evaluating vehicle
communication performance, traditional metrics such as reliability and
transmission delay present certain contradictions. Introducing the new metric
Age of Information (AoI) provides a more comprehensive evaluation of
communication system. Additionally, to ensure service quality, user terminals
need to possess high computational capabilities, which may lead to increased
energy consumption, necessitating a trade-off between communication energy
consumption and effectiveness. Given the complexity and dynamics of
communication systems, Deep Reinforcement Learning (DRL) serves as an
intelligent learning method capable of learning optimal strategies in dynamic
environments. Therefore, this paper analyzes the effects of multi-priority
queues and NOMA on AoI in the C-V2X vehicular communication system and proposes
an energy consumption and AoI optimization method based on DRL. Finally,
through comparative simulations with baseline methods, the proposed approach
demonstrates its advances in terms of energy consumption and AoI.","cs.LG, cs.NI",cs.LG,http://arxiv.org/abs/2411.13104v1
"Incremental Label Distribution Learning with Scalable Graph
  Convolutional Networks","Ziqi Jia, Xiaoyang Qu, Chenghao Liu, Jianzong Wang",2024-11-20T07:49:51Z,"Label Distribution Learning (LDL) is an effective approach for handling label
ambiguity, as it can analyze all labels at once and indicate the extent to
which each label describes a given sample. Most existing LDL methods consider
the number of labels to be static. However, in various LDL-specific contexts
(e.g., disease diagnosis), the label count grows over time (such as the
discovery of new diseases), a factor that existing methods overlook. Learning
samples with new labels directly means learning all labels at once, thus
wasting more time on the old labels and even risking overfitting the old
labels. At the same time, learning new labels by the LDL model means
reconstructing the inter-label relationships. How to make use of constructed
relationships is also a crucial challenge. To tackle these challenges, we
introduce Incremental Label Distribution Learning (ILDL), analyze its key
issues regarding training samples and inter-label relationships, and propose
Scalable Graph Label Distribution Learning (SGLDL) as a practical framework for
implementing ILDL. Specifically, in SGLDL, we develop a New-label-aware
Gradient Compensation Loss to speed up the learning of new labels and represent
inter-label relationships as a graph to reduce the time required to reconstruct
inter-label relationships. Experimental results on the classical LDL dataset
show the clear advantages of unique algorithms and illustrate the importance of
a dedicated design for the ILDL problem.","cs.LG, cs.IT, math.IT",cs.LG,http://arxiv.org/abs/2411.13097v1
"ESARM: 3D Emotional Speech-to-Animation via Reward Model from
  Automatically-Ranked Demonstrations","Xulong Zhang, Xiaoyang Qu, Haoxiang Shi, Chunguang Xiao, Jianzong Wang",2024-11-20T07:37:37Z,"This paper proposes a novel 3D speech-to-animation (STA) generation framework
designed to address the shortcomings of existing models in producing diverse
and emotionally resonant animations. Current STA models often generate
animations that lack emotional depth and variety, failing to align with human
expectations. To overcome these limitations, we introduce a novel STA model
coupled with a reward model. This combination enables the decoupling of emotion
and content under audio conditions through a cross-coupling training approach.
Additionally, we develop a training methodology that leverages automatic
quality evaluation of generated facial animations to guide the reinforcement
learning process. This methodology encourages the STA model to explore a
broader range of possibilities, resulting in the generation of diverse and
emotionally expressive facial animations of superior quality. We conduct
extensive empirical experiments on a benchmark dataset, and the results
validate the effectiveness of our proposed framework in generating
high-quality, emotionally rich 3D animations that are better aligned with human
preferences.","cs.CV, cs.SD, eess.AS",cs.CV,http://arxiv.org/abs/2411.13089v1
Omnipredicting Single-Index Models with Multi-Index Models,"Lunjia Hu, Kevin Tian, Chutong Yang",2024-11-20T07:20:49Z,"Recent work on supervised learning [GKR+22] defined the notion of
omnipredictors, i.e., predictor functions $p$ over features that are
simultaneously competitive for minimizing a family of loss functions
$\mathcal{L}$ against a comparator class $\mathcal{C}$. Omniprediction requires
approximating the Bayes-optimal predictor beyond the loss minimization
paradigm, and has generated significant interest in the learning theory
community. However, even for basic settings such as agnostically learning
single-index models (SIMs), existing omnipredictor constructions require
impractically-large sample complexities and runtimes, and output complex,
highly-improper hypotheses.
  Our main contribution is a new, simple construction of omnipredictors for
SIMs. We give a learner outputting an omnipredictor that is
$\varepsilon$-competitive on any matching loss induced by a monotone, Lipschitz
link function, when the comparator class is bounded linear predictors. Our
algorithm requires $\approx \varepsilon^{-4}$ samples and runs in nearly-linear
time, and its sample complexity improves to $\approx \varepsilon^{-2}$ if link
functions are bi-Lipschitz. This significantly improves upon the only prior
known construction, due to [HJKRR18, GHK+23], which used $\gtrsim
\varepsilon^{-10}$ samples.
  We achieve our construction via a new, sharp analysis of the classical
Isotron algorithm [KS09, KKKS11] in the challenging agnostic learning setting,
of potential independent interest. Previously, Isotron was known to properly
learn SIMs in the realizable setting, as well as constant-factor competitive
hypotheses under the squared loss [ZWDD24]. As they are based on Isotron, our
omnipredictors are multi-index models with $\approx \varepsilon^{-2}$
prediction heads, bringing us closer to the tantalizing goal of proper
omniprediction for general loss families and comparators.","cs.LG, cs.DS, math.OC, stat.ML",cs.LG,http://arxiv.org/abs/2411.13083v1
Patience Is The Key to Large Language Model Reasoning,Yijiong Yu,2024-11-20T07:20:48Z,"Recent advancements in the field of large language models, particularly
through the Chain of Thought (CoT) approach, have demonstrated significant
improvements in solving complex problems. However, existing models either tend
to sacrifice detailed reasoning for brevity due to user preferences, or require
extensive and expensive training data to learn complicated reasoning ability,
limiting their potential in solving complex tasks. To bridge this gap,
following the concept of scaling test-time, we propose a simple method by
encouraging models to adopt a more patient reasoning style without the need of
introducing new knowledge or skills. To employ a preference optimization
approach, we generate detailed reasoning processes as positive examples and
simple answers as negative examples, thereby training the model to favor
thoroughness in its responses. Our results demonstrate a performance increase
of up to 6.7% on GSM8k with training just on a lightweight dataset.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13082v1
Practical Compact Deep Compressed Sensing,"Bin Chen, Jian Zhang",2024-11-20T07:17:16Z,"Recent years have witnessed the success of deep networks in compressed
sensing (CS), which allows for a significant reduction in sampling cost and has
gained growing attention since its inception. In this paper, we propose a new
practical and compact network dubbed PCNet for general image CS. Specifically,
in PCNet, a novel collaborative sampling operator is designed, which consists
of a deep conditional filtering step and a dual-branch fast sampling step. The
former learns an implicit representation of a linear transformation matrix into
a few convolutions and first performs adaptive local filtering on the input
image, while the latter then uses a discrete cosine transform and a scrambled
block-diagonal Gaussian matrix to generate under-sampled measurements. Our
PCNet is equipped with an enhanced proximal gradient descent algorithm-unrolled
network for reconstruction. It offers flexibility, interpretability, and strong
recovery performance for arbitrary sampling rates once trained. Additionally,
we provide a deployment-oriented extraction scheme for single-pixel CS imaging
systems, which allows for the convenient conversion of any linear sampling
operator to its matrix form to be loaded onto hardware like digital
micro-mirror devices. Extensive experiments on natural image CS, quantized CS,
and self-supervised CS demonstrate the superior reconstruction accuracy and
generalization ability of PCNet compared to existing state-of-the-art methods,
particularly for high-resolution images. Code is available at
https://github.com/Guaishou74851/PCNet.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.13081v1
"Neural Internal Model Control: Learning a Robust Control Policy via
  Predictive Error Feedback","Feng Gao, Chao Yu, Yu Wang, Yi Wu",2024-11-20T07:07:42Z,"Accurate motion control in the face of disturbances within complex
environments remains a major challenge in robotics. Classical model-based
approaches often struggle with nonlinearities and unstructured disturbances,
while RL-based methods can be fragile when encountering unseen scenarios. In
this paper, we propose a novel framework, Neural Internal Model Control, which
integrates model-based control with RL-based control to enhance robustness. Our
framework streamlines the predictive model by applying Newton-Euler equations
for rigid-body dynamics, eliminating the need to capture complex
high-dimensional nonlinearities. This internal model combines model-free RL
algorithms with predictive error feedback. Such a design enables a closed-loop
control structure to enhance the robustness and generalizability of the control
system. We demonstrate the effectiveness of our framework on both quadrotors
and quadrupedal robots, achieving superior performance compared to
state-of-the-art methods. Furthermore, real-world deployment on a quadrotor
with rope-suspended payloads highlights the framework's robustness in
sim-to-real transfer. Our code is released at
https://github.com/thu-uav/NeuralIMC.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.13079v1
"Improving OOD Generalization of Pre-trained Encoders via Aligned
  Embedding-Space Ensembles","Shuman Peng, Arash Khoeini, Sharan Vaswani, Martin Ester",2024-11-20T06:50:50Z,"The quality of self-supervised pre-trained embeddings on out-of-distribution
(OOD) data is poor without fine-tuning. A straightforward and simple approach
to improving the generalization of pre-trained representation to OOD data is
the use of deep ensembles. However, obtaining an effective ensemble in the
embedding space with only unlabeled data remains an unsolved problem. We first
perform a theoretical analysis that reveals the relationship between individual
hyperspherical embedding spaces in an ensemble. We then design a principled
method to align these embedding spaces in an unsupervised manner. Experimental
results on the MNIST dataset show that our embedding-space ensemble method
improves pre-trained embedding quality on in-distribution and OOD data compared
to single encoders.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.13073v1
picoRing: battery-free rings for subtle thumb-to-index input,"Ryo Takahashi, Eric Whitmire, Roger Boldu, Shiu Ng, Wolf Kienzle, Hrvoje Benko",2024-11-20T06:27:33Z,"Smart rings for subtle, reliable finger input offer an attractive path for
ubiquitous interaction with wearable computing platforms. However, compared to
ordinary rings worn for cultural or fashion reasons, smart rings are much
bulkier and less comfortable, largely due to the space required for a battery,
which also limits the space available for sensors. This paper presents
picoRing, a flexible sensing architecture that enables a variety of
\textit{battery-free} smart rings paired with a wristband. By inductively
connecting a wristband-based sensitive reader coil with a ring-based
fully-passive sensor coil, picoRing enables the wristband to stably detect the
passive response from the ring via a weak inductive coupling. We demonstrate
four different rings that support thumb-to-finger interactions like pressing,
sliding, or scrolling. When users perform these interactions, the corresponding
ring converts each input into a unique passive response through a network of
passive switches. Combining the coil-based sensitive readout with the
fully-passive ring design enables a tiny ring that weighs as little as 1.5 g
and achieves a 13 cm stable readout despite finger bending, and proximity to
metal.",cs.HC,cs.HC,http://arxiv.org/abs/2411.13065v1
"Towards Unbiased and Robust Spatio-Temporal Scene Graph Generation and
  Anticipation","Rohith Peddi, Saurabh, Ayush Abhay Shrivastava, Parag Singla, Vibhav Gogate",2024-11-20T06:15:28Z,"Spatio-Temporal Scene Graphs (STSGs) provide a concise and expressive
representation of dynamic scenes by modelling objects and their evolving
relationships over time. However, real-world visual relationships often exhibit
a long-tailed distribution, causing existing methods for tasks like Video Scene
Graph Generation (VidSGG) and Scene Graph Anticipation (SGA) to produce biased
scene graphs. To this end, we propose ImparTail, a novel training framework
that leverages curriculum learning and loss masking to mitigate bias in the
generation and anticipation of spatio-temporal scene graphs. Our approach
gradually decreases the dominance of the head relationship classes during
training and focuses more on tail classes, leading to more balanced training.
Furthermore, we introduce two new tasks, Robust Spatio-Temporal Scene Graph
Generation and Robust Scene Graph Anticipation, designed to evaluate the
robustness of STSG models against distribution shifts. Extensive experiments on
the Action Genome dataset demonstrate that our framework significantly enhances
the unbiased performance and robustness of STSG models compared to existing
methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13059v1
"Branches, Assemble! Multi-Branch Cooperation Network for Large-Scale
  Click-Through Rate Prediction at Taobao","Xu Chen, Zida Cheng, Yuangang Pan, Shuai Xiao, Xiaoming Liu, Jinsong Lan, Qingwen Liu, Ivor W. Tsang",2024-11-20T06:10:06Z,"Existing click-through rate (CTR) prediction works have studied the role of
feature interaction through a variety of techniques. Each interaction technique
exhibits its own strength, and solely using one type could constrain the
model's capability to capture the complex feature relationships, especially for
industrial large-scale data with enormous users and items. Recent research
shows that effective CTR models often combine an MLP network with a dedicated
feature interaction network in a two-parallel structure. However, the interplay
and cooperative dynamics between different streams or branches remain
under-researched. In this work, we introduce a novel Multi-Branch Cooperation
Network (MBCnet) which enables multiple branch networks to collaborate with
each other for better complex feature interaction modeling. Specifically,
MBCnet consists of three branches: the Expert-based Feature Grouping and
Crossing (EFGC) branch that promotes the model's memorization ability of
specific feature fields, the low rank Cross Net branch and Deep branch to
enhance both explicit and implicit feature crossing for improved
generalization. Among branches, a novel cooperation scheme is proposed based on
two principles: branch co-teaching and moderate differentiation. Branch
co-teaching encourages well-learned branches to support poorly-learned ones on
specific training samples. Moderate differentiation advocates branches to
maintain a reasonable level of difference in their feature representations. The
cooperation strategy improves learning through mutual knowledge sharing via
co-teaching and boosts the discovery of diverse feature interactions across
branches. Extensive experiments on large-scale industrial datasets and online
A/B test demonstrate MBCnet's superior performance, delivering a 0.09 point
increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes will
be released soon.","cs.IR, cs.AI",cs.IR,http://arxiv.org/abs/2411.13057v1
"Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale
  Benchmark","Bing Cao, Quanhao Lu, Jiekang Feng, Pengfei Zhu, Qinghua Hu, Qilong Wang",2024-11-20T06:08:21Z,"The dynamic imbalance of the fore-background is a major challenge in video
object counting, which is usually caused by the sparsity of foreground objects.
This often leads to severe under- and over-prediction problems and has been
less studied in existing works. To tackle this issue in video object counting,
we propose a density-embedded Efficient Masked Autoencoder Counting (E-MAC)
framework in this paper. To effectively capture the dynamic variations across
frames, we utilize an optical flow-based temporal collaborative fusion that
aligns features to derive multi-frame density residuals. The counting accuracy
of the current frame is boosted by harnessing the information from adjacent
frames. More importantly, to empower the representation ability of dynamic
foreground objects for intra-frame, we first take the density map as an
auxiliary modality to perform $\mathtt{D}$ensity-$\mathtt{E}$mbedded
$\mathtt{M}$asked m$\mathtt{O}$deling ($\mathtt{DEMO}$) for multimodal
self-representation learning to regress density map. However, as
$\mathtt{DEMO}$ contributes effective cross-modal regression guidance, it also
brings in redundant background information and hard to focus on foreground
regions. To handle this dilemma, we further propose an efficient spatial
adaptive masking derived from density maps to boost efficiency. In addition,
considering most existing datasets are limited to human-centric scenarios, we
first propose a large video bird counting dataset $\textit{DroneBird}$, in
natural scenarios for migratory bird protection. Extensive experiments on three
crowd datasets and our $\textit{DroneBird}$ validate our superiority against
the counterparts.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13056v1
"Hardware Scaling Trends and Diminishing Returns in Large-Scale
  Distributed Training","Jared Fernandez, Luca Wehrstedt, Leonid Shamis, Mostafa Elhoushi, Kalyan Saladi, Yonatan Bisk, Emma Strubell, Jacob Kahn",2024-11-20T06:05:11Z,"Dramatic increases in the capabilities of neural network models in recent
years are driven by scaling model size, training data, and corresponding
computational resources. To develop the exceedingly large networks required in
modern applications, such as large language models (LLMs), model training is
distributed across tens of thousands of hardware accelerators (e.g. GPUs),
requiring orchestration of computation and communication across large computing
clusters. In this work, we demonstrate that careful consideration of hardware
configuration and parallelization strategy is critical for effective (i.e.
compute- and cost-efficient) scaling of model size, training data, and total
computation. We conduct an extensive empirical study of the performance of
large-scale LLM training workloads across model size, hardware configurations,
and distributed parallelization strategies. We demonstrate that: (1) beyond
certain scales, overhead incurred from certain distributed communication
strategies leads parallelization strategies previously thought to be
sub-optimal in fact become preferable; and (2) scaling the total number of
accelerators for large model training quickly yields diminishing returns even
when hardware and parallelization strategies are properly optimized, implying
poor marginal performance per additional unit of power or GPU-hour.","cs.LG, cs.DC",cs.LG,http://arxiv.org/abs/2411.13055v1
"Generalized Ping-Pong: Off-Chip Memory Bandwidth Centric Pipelining
  Strategy for Processing-In-Memory Accelerators","Ruibao Wang, Bonan Yan",2024-11-20T06:03:56Z,"Processing-in-memory (PIM) is a promising choice for accelerating deep neural
networks (DNNs) featuring high efficiency and low power. However, the rapid
upscaling of neural network model sizes poses a crucial challenge for the
limited on-chip PIM capacity. When the PIM presumption of ""pre-loading DNN
weights/parameters only once before repetitive computing"" is no longer
practical, concurrent writing and computing techniques become necessary for
PIM. Conventional methods of naive ping-pong or in~situ concurrent
write/compute scheduling for PIM cause low utilization of off-chip memory
bandwidth, subsequently offsetting the efficiency gain brought by PIM
technology. To address this challenge, we propose an off-chip memory bandwidth
centric pipelining strategy, named ""generalized ping-pong"", to maximize the
utilization and performance of PIM accelerators toward large DNN models. The
core idea of the proposed generalized ping-pong strategy is to evenly
distribute the active time and fully utilize the off-chip memory bandwidth.
Based on a programmable and scalable SRAM PIM architecture, we quantitatively
analyze and compare the generalized ping-pong with the conventional scheduling
strategies of naive ping-pong and in-situ write/compute for PIM. Experiments
show that the generalized ping-pong strategy achieves acceleration of over 1.67
times when fully utilizing the off-chip memory bandwidth. When further limiting
the off-chip memory bandwidth ranging in 8~256 bytes per clock cycle, the
proposed generalized ping-pong strategy accelerates 1.22~7.71 times versus
naive ping-pong. The developed PIM accelerator design with the generalized
ping-poing strategy is open-sourced at https://github.com/rw999creator/gpp-pim.",cs.AR,cs.AR,http://arxiv.org/abs/2411.13054v1
MEGL: Multimodal Explanation-Guided Learning,"Yifei Zhang, Tianxu Jiang, Bo Pan, Jingyu Wang, Guangji Bai, Liang Zhao",2024-11-20T05:57:00Z,"Explaining the decision-making processes of Artificial Intelligence (AI)
models is crucial for addressing their ""black box"" nature, particularly in
tasks like image classification. Traditional eXplainable AI (XAI) methods
typically rely on unimodal explanations, either visual or textual, each with
inherent limitations. Visual explanations highlight key regions but often lack
rationale, while textual explanations provide context without spatial
grounding. Further, both explanation types can be inconsistent or incomplete,
limiting their reliability. To address these challenges, we propose a novel
Multimodal Explanation-Guided Learning (MEGL) framework that leverages both
visual and textual explanations to enhance model interpretability and improve
classification performance. Our Saliency-Driven Textual Grounding (SDTG)
approach integrates spatial information from visual explanations into textual
rationales, providing spatially grounded and contextually rich explanations.
Additionally, we introduce Textual Supervision on Visual Explanations to align
visual explanations with textual rationales, even in cases where ground truth
visual annotations are missing. A Visual Explanation Distribution Consistency
loss further reinforces visual coherence by aligning the generated visual
explanations with dataset-level patterns, enabling the model to effectively
learn from incomplete multimodal supervision. We validate MEGL on two new
datasets, Object-ME and Action-ME, for image classification with multimodal
explanations. Experimental results demonstrate that MEGL outperforms previous
approaches in prediction accuracy and explanation quality across both visual
and textual domains. Our code will be made available upon the acceptance of the
paper.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.13053v1
"On-device Content-based Recommendation with Single-shot Embedding
  Pruning: A Cooperative Game Perspective","Hung Vinh Tran, Tong Chen, Guanhua Ye, Quoc Viet Hung Nguyen, Kai Zheng, Hongzhi Yin",2024-11-20T05:56:31Z,"Content-based Recommender Systems (CRSs) play a crucial role in shaping user
experiences in e-commerce, online advertising, and personalized
recommendations. However, due to the vast amount of categorical features, the
embedding tables used in CRS models pose a significant storage bottleneck for
real-world deployment, especially on resource-constrained devices. To address
this problem, various embedding pruning methods have been proposed, but most
existing ones require expensive retraining steps for each target parameter
budget, leading to enormous computation costs. In reality, this computation
cost is a major hurdle in real-world applications with diverse storage
requirements, such as federated learning and streaming settings. In this paper,
we propose Shapley Value-guided Embedding Reduction (Shaver) as our response.
With Shaver, we view the problem from a cooperative game perspective, and
quantify each embedding parameter's contribution with Shapley values to
facilitate contribution-based parameter pruning. To address the inherently high
computation costs of Shapley values, we propose an efficient and unbiased
method to estimate Shapley values of a CRS's embedding parameters. Moreover, in
the pruning stage, we put forward a field-aware codebook to mitigate the
information loss in the traditional zero-out treatment. Through extensive
experiments on three real-world datasets, Shaver has demonstrated competitive
performance with lightweight recommendation models across various parameter
budgets. The source code is available at
https://anonymous.4open.science/r/shaver-E808","cs.IR, cs.LG",cs.IR,http://arxiv.org/abs/2411.13052v1
"Topkima-Former: Low-energy, Low-Latency Inference for Transformers using
  top-k In-memory ADC","Shuai Dong, Junyi Yang, Xiaoqi Peng, Hongyang Shang, Ye Ke, Xiaofeng Yang, Hongjie Liu, Arindam Basu",2024-11-20T05:51:35Z,"Transformer model has gained prominence as a popular deep neural network
architecture for neural language processing (NLP) and computer vision (CV)
applications. However, the extensive use of nonlinear operations, like softmax,
poses a performance bottleneck during transformer inference and comprises up to
40% of the total latency. Hence, we propose innovations at the circuit,
architecture, and algorithm levels to accelerate the transformer. At the
circuit level, we propose topkima-combining top-k activation selection with
in-memory ADC (IMA) to implement a low-energy and low-latency softmax without
any sorting latency. Only the k largest activations are sent to the softmax
calculation block, reducing the huge computational cost of softmax. Using a
modified training scheme with top-k only in the forward pass, experimental
results demonstrate only a 0.4% to 1.2% reduction in accuracy across ViT,
distilBERT, and BERT-base models when evaluated on CIFAR-10, CIFAR-100, and
SQuAD datasets with k=5. At the architecture level, an improved scale-free
technique is introduced to reduce the computational cost of attention. The
combined system, dubbed Topkima-Former, enhances 1.8x-84x speedup and 1.3x-35x
energy efficiency (EE) over prior In-memory computing (IMC) accelerators.
Compared to a conventional softmax macro and a digital top-k (Dtopk) softmax
macro, our proposed tokima softmax macro achieves about 15x and 8x faster speed
respectively.",cs.AR,cs.AR,http://arxiv.org/abs/2411.13050v1
"Bounding-box Watermarking: Defense against Model Extraction Attacks on
  Object Detectors","Satoru Koda, Ikuya Morikawa",2024-11-20T05:40:20Z,"Deep neural networks (DNNs) deployed in a cloud often allow users to query
models via the APIs. However, these APIs expose the models to model extraction
attacks (MEAs). In this attack, the attacker attempts to duplicate the target
model by abusing the responses from the API. Backdoor-based DNN watermarking is
known as a promising defense against MEAs, wherein the defender injects a
backdoor into extracted models via API responses. The backdoor is used as a
watermark of the model; if a suspicious model has the watermark (i.e.,
backdoor), it is verified as an extracted model. This work focuses on object
detection (OD) models. Existing backdoor attacks on OD models are not
applicable for model watermarking as the defense against MEAs on a realistic
threat model. Our proposed approach involves inserting a backdoor into
extracted models via APIs by stealthily modifying the bounding-boxes (BBs) of
objects detected in queries while keeping the OD capability. In our experiments
on three OD datasets, the proposed approach succeeded in identifying the
extracted models with 100% accuracy in a wide variety of experimental
scenarios.","cs.CR, cs.CV",cs.CR,http://arxiv.org/abs/2411.13047v1
"Explainable LLM-driven Multi-dimensional Distillation for E-Commerce
  Relevance Learning","Gang Zhao, Ximing Zhang, Chenji Lu, Hui Zhao, Tianshu Wu, Pengjie Wang, Jian Xu, Bo Zheng",2024-11-20T05:30:15Z,"Effective query-item relevance modeling is pivotal for enhancing user
experience and safeguarding user satisfaction in e-commerce search systems.
Recently, benefiting from the vast inherent knowledge, Large Language Model
(LLM) approach demonstrates strong performance and long-tail generalization
ability compared with previous neural-based specialized relevance learning
methods. Though promising, current LLM-based methods encounter the following
inadequacies in practice: First, the massive parameters and computational
demands make it difficult to be deployed online. Second, distilling LLM models
to online models is a feasible direction, but the LLM relevance modeling is a
black box, and its rich intrinsic knowledge is difficult to extract and apply
online. To improve the interpretability of LLM and boost the performance of
online relevance models via LLM, we propose an Explainable LLM-driven
Multi-dimensional Distillation framework for e-commerce relevance learning,
which comprises two core components: (1) An Explainable LLM for relevance
modeling (ELLM-rele), which decomposes the relevance learning into intermediate
steps and models relevance learning as a Chain-of-Thought (CoT) reasoning,
thereby enhancing both interpretability and performance of LLM. (2) A
Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the
knowledge of ELLM-rele to current deployable interaction-based and
representation-based student models from both the relevance score distribution
and CoT reasoning aspects. Through distilling the probabilistic and CoT
reasoning knowledge, MKD improves both the semantic interaction and long-tail
generalization abilities of student models. Extensive offline evaluations and
online experiments on Taobao search ad scene demonstrate that our proposed
framework significantly enhances e-commerce relevance learning performance and
user experience.","cs.IR, cs.AI, cs.CL",cs.IR,http://arxiv.org/abs/2411.13045v1
Attentive Contextual Attention for Cloud Removal,"Wenli Huang, Ye Deng, Yang Wu, Jinjun Wang",2024-11-20T05:16:31Z,"Cloud cover can significantly hinder the use of remote sensing images for
Earth observation, prompting urgent advancements in cloud removal technology.
Recently, deep learning strategies have shown strong potential in restoring
cloud-obscured areas. These methods utilize convolution to extract intricate
local features and attention mechanisms to gather long-range information,
improving the overall comprehension of the scene. However, a common drawback of
these approaches is that the resulting images often suffer from blurriness,
artifacts, and inconsistencies. This is partly because attention mechanisms
apply weights to all features based on generalized similarity scores, which can
inadvertently introduce noise and irrelevant details from cloud-covered areas.
To overcome this limitation and better capture relevant distant context, we
introduce a novel approach named Attentive Contextual Attention (AC-Attention).
This method enhances conventional attention mechanisms by dynamically learning
data-driven attentive selection scores, enabling it to filter out noise and
irrelevant features effectively. By integrating the AC-Attention module into
the DSen2-CR cloud removal framework, we significantly improve the model's
ability to capture essential distant information, leading to more effective
cloud removal. Our extensive evaluation of various datasets shows that our
method outperforms existing ones regarding image reconstruction quality.
Additionally, we conducted ablation studies by integrating AC-Attention into
multiple existing methods and widely used network architectures. These studies
demonstrate the effectiveness and adaptability of AC-Attention and reveal its
ability to focus on relevant features, thereby improving the overall
performance of the networks. The code is available at
\url{https://github.com/huangwenwenlili/ACA-CRNet}.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.13042v1
"TrustMesh: A Blockchain-Enabled Trusted Distributed Computing Framework
  for Open Heterogeneous IoT Environments","Murtaza Rangwala, Rajkumar Buyya",2024-11-20T05:10:48Z,"The rapid evolution of Internet of Things (IoT) environments has created an
urgent need for secure and trustworthy distributed computing systems,
particularly when dealing with heterogeneous devices and applications where
centralized trust cannot be assumed. This paper proposes TrustMesh, a novel
blockchain-enabled framework that addresses these challenges through a unique
three-layer architecture combining permissioned blockchain technology with a
novel multi-phase Practical Byzantine Fault Tolerance (PBFT) consensus
protocol. The key innovation lies in TrustMesh's ability to support
non-deterministic scheduling algorithms while maintaining Byzantine fault
tolerance - features traditionally considered mutually exclusive in blockchain
systems. The framework supports a sophisticated resource management approach
that enables flexible scheduling decisions while preserving the security
guarantees of blockchain-based verification. Our experimental evaluation using
a real-world cold chain monitoring scenario demonstrates that TrustMesh
successfully maintains Byzantine fault tolerance with fault detection latencies
under 150 milliseconds, while maintaining consistent framework overhead across
varying computational workloads even with network scaling. These results
establish TrustMesh's effectiveness in balancing security, performance, and
flexibility requirements in trustless IoT environments, advancing the
state-of-the-art in secure distributed computing frameworks.",cs.DC,cs.DC,http://arxiv.org/abs/2411.13039v1
RobustFormer: Noise-Robust Pre-training for images and videos,"Ashish Bastola, Nishant Luitel, Hao Wang, Danda Pani Paudel, Roshani Poudel, Abolfazl Razi",2024-11-20T05:10:48Z,"While deep learning models are powerful tools that revolutionized many areas,
they are also vulnerable to noise as they rely heavily on learning patterns and
features from the exact details of the clean data. Transformers, which have
become the backbone of modern vision models, are no exception. Current Discrete
Wavelet Transforms (DWT) based methods do not benefit from masked autoencoder
(MAE) pre-training since the inverse DWT (iDWT) introduced in these approaches
is computationally inefficient and lacks compatibility with video inputs in
transformer architectures.
  In this work, we present RobustFormer, a method that overcomes these
limitations by enabling noise-robust pre-training for both images and videos;
improving the efficiency of DWT-based methods by removing the need for
computationally iDWT steps and simplifying the attention mechanism. To our
knowledge, the proposed method is the first DWT-based method compatible with
video inputs and masked pre-training. Our experiments show that MAE-based
pre-training allows us to bypass the iDWT step, greatly reducing computation.
Through extensive tests on benchmark datasets, RobustFormer achieves
state-of-the-art results for both image and video tasks.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13040v1
"Unsupervised Homography Estimation on Multimodal Image Pair via
  Alternating Optimization","Sanghyeob Song, Jaihyun Lew, Hyemi Jang, Sungroh Yoon",2024-11-20T04:56:19Z,"Estimating the homography between two images is crucial for mid- or
high-level vision tasks, such as image stitching and fusion. However, using
supervised learning methods is often challenging or costly due to the
difficulty of collecting ground-truth data. In response, unsupervised learning
approaches have emerged. Most early methods, though, assume that the given
image pairs are from the same camera or have minor lighting differences.
Consequently, while these methods perform effectively under such conditions,
they generally fail when input image pairs come from different domains,
referred to as multimodal image pairs. To address these limitations, we propose
AltO, an unsupervised learning framework for estimating homography in
multimodal image pairs. Our method employs a two-phase alternating optimization
framework, similar to Expectation-Maximization (EM), where one phase reduces
the geometry gap and the other addresses the modality gap. To handle these
gaps, we use Barlow Twins loss for the modality gap and propose an extended
version, Geometry Barlow Twins, for the geometry gap. As a result, we
demonstrate that our method, AltO, can be trained on multimodal datasets
without any ground-truth data. It not only outperforms other unsupervised
methods but is also compatible with various architectures of homography
estimators. The source code can be found
at:~\url{https://github.com/songsang7/AltO}","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13036v1
Probably Approximately Precision and Recall Learning,"Lee Cohen, Yishay Mansour, Shay Moran, Han Shao",2024-11-20T04:21:07Z,"Precision and Recall are foundational metrics in machine learning where both
accurate predictions and comprehensive coverage are essential, such as in
recommender systems and multi-label learning. In these tasks, balancing
precision (the proportion of relevant items among those predicted) and recall
(the proportion of relevant items successfully predicted) is crucial. A key
challenge is that one-sided feedback--where only positive examples are observed
during training--is inherent in many practical problems. For instance, in
recommender systems like YouTube, training data only consists of videos that a
user has actively selected, while unselected items remain unseen. Despite this
lack of negative feedback in training, avoiding undesirable recommendations at
test time is essential.
  We introduce a PAC learning framework where each hypothesis is represented by
a graph, with edges indicating positive interactions, such as between users and
items. This framework subsumes the classical binary and multi-class PAC
learning models as well as multi-label learning with partial feedback, where
only a single random correct label per example is observed, rather than all
correct labels.
  Our work uncovers a rich statistical and algorithmic landscape, with nuanced
boundaries on what can and cannot be learned. Notably, classical methods like
Empirical Risk Minimization fail in this setting, even for simple hypothesis
classes with only two hypotheses. To address these challenges, we develop novel
algorithms that learn exclusively from positive data, effectively minimizing
both precision and recall losses. Specifically, in the realizable setting, we
design algorithms that achieve optimal sample complexity guarantees. In the
agnostic case, we show that it is impossible to achieve additive error
guarantees--as is standard in PAC learning--and instead obtain meaningful
multiplicative approximations.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.13029v1
"A Theory for Compressibility of Graph Transformers for Transductive
  Learning","Hamed Shirzad, Honghao Lin, Ameya Velingker, Balaji Venkatachalam, David Woodruff, Danica Sutherland",2024-11-20T04:20:17Z,"Transductive tasks on graphs differ fundamentally from typical supervised
machine learning tasks, as the independent and identically distributed (i.i.d.)
assumption does not hold among samples. Instead, all train/test/validation
samples are present during training, making them more akin to a semi-supervised
task. These differences make the analysis of the models substantially different
from other models. Recently, Graph Transformers have significantly improved
results on these datasets by overcoming long-range dependency problems.
However, the quadratic complexity of full Transformers has driven the community
to explore more efficient variants, such as those with sparser attention
patterns. While the attention matrix has been extensively discussed, the hidden
dimension or width of the network has received less attention. In this work, we
establish some theoretical bounds on how and under what conditions the hidden
dimension of these networks can be compressed. Our results apply to both sparse
and dense variants of Graph Transformers.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.13028v1
"X as Supervision: Contending with Depth Ambiguity in Unsupervised
  Monocular 3D Pose Estimation","Yuchen Yang, Xuanyi Liu, Xing Gao, Zhihang Zhong, Xiao Sun",2024-11-20T04:18:11Z,"Recent unsupervised methods for monocular 3D pose estimation have endeavored
to reduce dependence on limited annotated 3D data, but most are solely
formulated in 2D space, overlooking the inherent depth ambiguity issue. Due to
the information loss in 3D-to-2D projection, multiple potential depths may
exist, yet only some of them are plausible in human structure. To tackle depth
ambiguity, we propose a novel unsupervised framework featuring a
multi-hypothesis detector and multiple tailored pretext tasks. The detector
extracts multiple hypotheses from a heatmap within a local window, effectively
managing the multi-solution problem. Furthermore, the pretext tasks harness 3D
human priors from the SMPL model to regularize the solution space of pose
estimation, aligning it with the empirical distribution of 3D human structures.
This regularization is partially achieved through a GCN-based discriminator
within the discriminative learning, and is further complemented with synthetic
images through rendering, ensuring plausible estimations. Consequently, our
approach demonstrates state-of-the-art unsupervised 3D pose estimation
performance on various human datasets. Further evaluations on data scale-up and
one animal dataset highlight its generalization capabilities. Code will be
available at https://github.com/Charrrrrlie/X-as-Supervision.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13026v1
"ORID: Organ-Regional Information Driven Framework for Radiology Report
  Generation","Tiancheng Gu, Kaicheng Yang, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai",2024-11-20T04:13:43Z,"The objective of Radiology Report Generation (RRG) is to automatically
generate coherent textual analyses of diseases based on radiological images,
thereby alleviating the workload of radiologists. Current AI-based methods for
RRG primarily focus on modifications to the encoder-decoder model architecture.
To advance these approaches, this paper introduces an Organ-Regional
Information Driven (ORID) framework which can effectively integrate multi-modal
information and reduce the influence of noise from unrelated organs.
Specifically, based on the LLaVA-Med, we first construct an RRG-related
instruction dataset to improve organ-regional diagnosis description ability and
get the LLaVA-Med-RRG. After that, we propose an organ-based cross-modal fusion
module to effectively combine the information from the organ-regional diagnosis
description and radiology image. To further reduce the influence of noise from
unrelated organs on the radiology report generation, we introduce an organ
importance coefficient analysis module, which leverages Graph Neural Network
(GNN) to examine the interconnections of the cross-modal information of each
organ region. Extensive experiments an1d comparisons with state-of-the-art
methods across various evaluation metrics demonstrate the superior performance
of our proposed method.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13025v1
"Prior-based Objective Inference Mining Potential Uncertainty for Facial
  Expression Recognition","Hanwei Liu, Huiling Cai, Qingcheng Lin, Xuefeng Li, Hui Xiao",2024-11-20T04:13:05Z,"Annotation ambiguity caused by the inherent subjectivity of visual judgment
has always been a major challenge for Facial Expression Recognition (FER)
tasks, particularly for largescale datasets from in-the-wild scenarios. A
potential solution is the evaluation of relatively objective emotional
distributions to help mitigate the ambiguity of subjective annotations. To this
end, this paper proposes a novel Prior-based Objective Inference (POI) network.
This network employs prior knowledge to derive a more objective and varied
emotional distribution and tackles the issue of subjective annotation ambiguity
through dynamic knowledge transfer. POI comprises two key networks: Firstly,
the Prior Inference Network (PIN) utilizes the prior knowledge of AUs and
emotions to capture intricate motion details. To reduce over-reliance on priors
and facilitate objective emotional inference, PIN aggregates inferential
knowledge from various key facial subregions, encouraging mutual learning.
Secondly, the Target Recognition Network (TRN) integrates subjective emotion
annotations and objective inference soft labels provided by the PIN, fostering
an understanding of inherent facial expression diversity, thus resolving
annotation ambiguity. Moreover, we introduce an uncertainty estimation module
to quantify and balance facial expression confidence. This module enables a
flexible approach to dealing with the uncertainties of subjective annotations.
Extensive experiments show that POI exhibits competitive performance on both
synthetic noisy datasets and multiple real-world datasets. All codes and
training logs will be publicly available at https://github.com/liuhw01/POI.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13024v1
"Enhancing Transportation Cyber-Physical Systems Security: A Shift to
  Post-Quantum Cryptography","Abdullah Al Mamun, Akid Abrar, Mizanur Rahman, M Sabbir Salek, Mashrur Chowdhury",2024-11-20T04:11:33Z,"The rise of quantum computing threatens traditional cryptographic algorithms
that secure Transportation Cyber-Physical Systems (TCPS). Shor's algorithm
poses a significant threat to RSA and ECC, while Grover's algorithm reduces the
security of symmetric encryption schemes, such as AES. The objective of this
paper is to underscore the urgency of transitioning to post-quantum
cryptography (PQC) to mitigate these risks in TCPS by analyzing the
vulnerabilities of traditional cryptographic schemes and the applicability of
standardized PQC schemes in TCPS. We analyzed vulnerabilities in traditional
cryptography against quantum attacks and reviewed the applicability of
NIST-standardized PQC schemes, including CRYSTALS-Kyber, CRYSTALS-Dilithium,
and SPHINCS+, in TCPS. We conducted a case study to analyze the vulnerabilities
of a TCPS application from the Architecture Reference for Cooperative and
Intelligent Transportation (ARC-IT) service package, i.e., Electronic Toll
Collection, leveraging the Microsoft Threat Modeling tool. This case study
highlights the cryptographic vulnerabilities of a TCPS application and presents
how PQC can effectively counter these threats. Additionally, we evaluated
CRYSTALS-Kyber's performance across wired and wireless TCPS data communication
scenarios. While CRYSTALS-Kyber proves effective in securing TCPS applications
over high-bandwidth, low-latency Ethernet networks, our analysis highlights
challenges in meeting the stringent latency requirements of safety-critical
wireless applications within TCPS. Future research should focus on developing
lightweight PQC solutions and hybrid schemes that integrate traditional and PQC
algorithms, to enhance compatibility, scalability, and real-time performance,
ensuring robust protection against emerging quantum threats in TCPS.",cs.CR,cs.CR,http://arxiv.org/abs/2411.13023v1
"Chanel-Orderer: A Channel-Ordering Predictor for Tri-Channel Natural
  Images","Shen Li, Lei Jiang, Wei Wang, Hongwei Hu, Liang Li",2024-11-20T03:53:32Z,"This paper shows a proof-of-concept that, given a typical 3-channel images
but in a randomly permuted channel order, a model (termed as Chanel-Orderer)
with ad-hoc inductive biases in terms of both architecture and loss functions
can accurately predict the channel ordering and knows how to make it right.
Specifically, Chanel-Orderer learns to score each of the three channels with
the priors of object semantics and uses the resulting scores to predict the
channel ordering. This brings up benefits into a typical scenario where an
\texttt{RGB} image is often mis-displayed in the \texttt{BGR} format and needs
to be corrected into the right order. Furthermore, as a byproduct, the
resulting model Chanel-Orderer is able to tell whether a given image is a
near-gray-scale image (near-monochromatic) or not (polychromatic). Our research
suggests that Chanel-Orderer mimics human visual coloring of our physical
natural world.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13021v1
"AsymDex: Leveraging Asymmetry and Relative Motion in Learning Bimanual
  Dexterity","Zhaodong Yang, Yunhai Han, Harish Ravichandar",2024-11-20T03:47:11Z,"We present Asymmetric Dexterity (AsymDex), a novel reinforcement learning
(RL) framework that can efficiently learn asymmetric bimanual skills for
multi-fingered hands without relying on demonstrations, which can be cumbersome
to collect. Two crucial ingredients enable AsymDex to reduce the observation
and action space dimensions and improve sample efficiency. First, AsymDex
leverages the natural asymmetry found in human bimanual manipulation and
assigns specific and interdependent roles to each hand: a facilitating hand
that moves and reorients the object, and a dominant hand that performs complex
manipulations on said object. Second, AsymDex defines and operates over
relative observation and action spaces, facilitating responsive coordination
between the two hands. Further, AsymDex can be easily integrated with recent
advances in grasp learning to handle both the object acquisition phase and the
interaction phase of bimanual dexterity. Unlike existing RL-based methods for
bimanual dexterity, which are tailored to a specific task, AsymDex can be used
to learn a wide variety of bimanual tasks that exhibit asymmetry. Detailed
experiments on four simulated asymmetric bimanual dexterous manipulation tasks
reveal that AsymDex consistently outperforms strong baselines that challenge
its design choices, in terms of success rate and sample efficiency. The project
website is at https://sites.google.com/view/asymdex-2024/.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13020v1
Scalable Deep Metric Learning on Attributed Graphs,"Xiang Li, Gagan Agrawal, Ruoming Jin, Rajiv Ramnath",2024-11-20T03:34:31Z,"We consider the problem of constructing embeddings of large attributed graphs
and supporting multiple downstream learning tasks. We develop a graph embedding
method, which is based on extending deep metric and unbiased contrastive
learning techniques to 1) work with attributed graphs, 2) enabling a mini-batch
based approach, and 3) achieving scalability. Based on a multi-class tuplet
loss function, we present two algorithms -- DMT for semi-supervised learning
and DMAT-i for the unsupervised case. Analyzing our methods, we provide a
generalization bound for the downstream node classification task and for the
first time relate tuplet loss to contrastive learning. Through extensive
experiments, we show high scalability of representation construction, and in
applying the method for three downstream tasks (node clustering, node
classification, and link prediction) better consistency over any single
existing method.",cs.LG,cs.LG,http://arxiv.org/abs/2411.13014v1
Deriving Activation Functions via Integration,Allen Hao Huang,2024-11-20T03:24:21Z,"Activation functions play a crucial role in introducing non-linearities to
deep neural networks. We propose a novel approach to designing activation
functions by focusing on their gradients and deriving the corresponding
functions through integration. Our work introduces the Expanded Integral of the
Exponential Linear Unit (xIELU), a trainable piecewise activation function
derived by integrating trainable affine transformations applied on the ELU
activation function. xIELU combines two key gradient properties: a trainable
and linearly increasing gradient for positive inputs, similar to ReLU$^2$, and
a trainable negative gradient flow for negative inputs, akin to xSiLU.
Conceptually, xIELU can be viewed as extending ReLU$^2$ to effectively handle
negative inputs. In experiments with 1.1B parameter Llama models trained on
126B tokens of FineWeb Edu, xIELU achieves lower perplexity compared to both
ReLU$^2$ and SwiGLU when matched for the same compute cost and parameter count.","cs.LG, cs.NE",cs.LG,http://arxiv.org/abs/2411.13010v1
"LLMSteer: Improving Long-Context LLM Inference by Steering Attention on
  Reused Contexts","Zhuohan Gu, Jiayi Yao, Kuntai Du, Junchen Jiang",2024-11-20T03:17:51Z,"As large language models (LLMs) show impressive performance on complex tasks,
they still struggle with longer contextual understanding and high computational
costs. To balance efficiency and quality, we introduce LLMSteer, a
fine-tuning-free framework that enhances LLMs through query-independent
attention steering. Tested on popular LLMs and datasets, LLMSteer narrows the
performance gap with baselines by 65.9% and reduces the runtime delay by up to
4.8x compared to recent attention steering methods.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.13009v1
Evaluating LLMs Capabilities Towards Understanding Social Dynamics,"Anique Tahir, Lu Cheng, Manuel Sandoval, Yasin N. Silva, Deborah L. Hall, Huan Liu",2024-11-20T03:16:07Z,"Social media discourse involves people from different backgrounds, beliefs,
and motives. Thus, often such discourse can devolve into toxic interactions.
Generative Models, such as Llama and ChatGPT, have recently exploded in
popularity due to their capabilities in zero-shot question-answering. Because
these models are increasingly being used to ask questions of social
significance, a crucial research question is whether they can understand social
media dynamics. This work provides a critical analysis regarding generative
LLM's ability to understand language and dynamics in social contexts,
particularly considering cyberbullying and anti-cyberbullying (posts aimed at
reducing cyberbullying) interactions. Specifically, we compare and contrast the
capabilities of different large language models (LLMs) to understand three key
aspects of social dynamics: language, directionality, and the occurrence of
bullying/anti-bullying messages. We found that while fine-tuned LLMs exhibit
promising results in some social media understanding tasks (understanding
directionality), they presented mixed results in others (proper paraphrasing
and bullying/anti-bullying detection). We also found that fine-tuning and
prompt engineering mechanisms can have positive effects in some tasks. We
believe that a understanding of LLM's capabilities is crucial to design future
models that can be effectively used in social applications.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.13008v1
DT-LSD: Deformable Transformer-based Line Segment Detection,"Sebastian Janampa, Marios Pattichis",2024-11-20T03:02:51Z,"Line segment detection is a fundamental low-level task in computer vision,
and improvements in this task can impact more advanced methods that depend on
it. Most new methods developed for line segment detection are based on
Convolutional Neural Networks (CNNs). Our paper seeks to address challenges
that prevent the wider adoption of transformer-based methods for line segment
detection. More specifically, we introduce a new model called Deformable
Transformer-based Line Segment Detection (DT-LSD) that supports cross-scale
interactions and can be trained quickly. This work proposes a novel Deformable
Transformer-based Line Segment Detector (DT-LSD) that addresses LETR's
drawbacks. For faster training, we introduce Line Contrastive DeNoising (LCDN),
a technique that stabilizes the one-to-one matching process and speeds up
training by 34$\times$. We show that DT-LSD is faster and more accurate than
its predecessor transformer-based model (LETR) and outperforms all CNN-based
models in terms of accuracy. In the Wireframe dataset, DT-LSD achieves 71.7 for
$sAP^{10}$ and 73.9 for $sAP^{15}$; while 33.2 for $sAP^{10}$ and 35.1 for
$sAP^{15}$ in the YorkUrban dataset.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13005v1
"MERLOT: A Distilled LLM-based Mixture-of-Experts Framework for Scalable
  Encrypted Traffic Classification","Yuxuan Chen, Rongpeng Li, Zhifeng Zhao, Honggang Zhang",2024-11-20T03:01:41Z,"We present MERLOT, a scalable mixture-of-expert (MoE) based refinement of
distilled large language model optimized for encrypted traffic classification.
By applying model distillation techniques in a teacher-student paradigm,
compact models derived from GPT-2-base retain high classification accuracy
while minimizing computational costs. These models function as specialized
experts in an MoE architecture, dynamically assigned via a gating network.
Unlike generation-based methods, our approach directly classifies encrypted
traffic using the final decoder token with contextual feature embedding as
input. Experiments on 10 datasets show superior or competitive performance over
the state-of-the-art models while significantly reducing resource demands,
underscoring its effectiveness and robustness.","cs.LG, cs.CR",cs.LG,http://arxiv.org/abs/2411.13004v1
"Collaborative Feature-Logits Contrastive Learning for Open-Set
  Semi-Supervised Object Detection","Xinhao Zhong, Siyu Jiao, Yao Zhao, Yunchao Wei",2024-11-20T02:57:35Z,"Current Semi-Supervised Object Detection (SSOD) methods enhance detector
performance by leveraging large amounts of unlabeled data, assuming that both
labeled and unlabeled data share the same label space. However, in open-set
scenarios, the unlabeled dataset contains both in-distribution (ID) classes and
out-of-distribution (OOD) classes. Applying semi-supervised detectors in such
settings can lead to misclassifying OOD class as ID classes. To alleviate this
issue, we propose a simple yet effective method, termed Collaborative
Feature-Logits Detector (CFL-Detector). Specifically, we introduce a
feature-level clustering method using contrastive loss to clarify vector
boundaries in the feature space and highlight class differences. Additionally,
by optimizing the logits-level uncertainty classification loss, the model
enhances its ability to effectively distinguish between ID and OOD classes.
Extensive experiments demonstrate that our method achieves state-of-the-art
performance compared to existing methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13001v1
"NCAirFL: CSI-Free Over-the-Air Federated Learning Based on Non-Coherent
  Detection","Haifeng Wen, Nicolò Michelusi, Osvaldo Simeone, Hong Xing",2024-11-20T02:53:04Z,"Over-the-air federated learning (FL), i.e., AirFL, leverages computing
primitively over multiple access channels. A long-standing challenge in AirFL
is to achieve coherent signal alignment without relying on expensive channel
estimation and feedback. This paper proposes NCAirFL, a CSI-free AirFL scheme
based on unbiased non-coherent detection at the edge server. By exploiting
binary dithering and a long-term memory based error-compensation mechanism,
NCAirFL achieves a convergence rate of order $\mathcal{O}(1/\sqrt{T})$ in terms
of the average square norm of the gradient for general non-convex and smooth
objectives, where $T$ is the number of communication rounds. Experiments
demonstrate the competitive performance of NCAirFL compared to vanilla FL with
ideal communications and to coherent transmission-based benchmarks.","cs.IT, cs.LG, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.13000v1
"BetterBench: Assessing AI Benchmarks, Uncovering Issues, and
  Establishing Best Practices","Anka Reuel, Amelia Hardy, Chandler Smith, Max Lamparth, Malcolm Hardy, Mykel J. Kochenderfer",2024-11-20T02:38:24Z,"AI models are increasingly prevalent in high-stakes environments,
necessitating thorough assessment of their capabilities and risks. Benchmarks
are popular for measuring these attributes and for comparing model performance,
tracking progress, and identifying weaknesses in foundation and non-foundation
models. They can inform model selection for downstream tasks and influence
policy initiatives. However, not all benchmarks are the same: their quality
depends on their design and usability. In this paper, we develop an assessment
framework considering 46 best practices across an AI benchmark's lifecycle and
evaluate 24 AI benchmarks against it. We find that there exist large quality
differences and that commonly used benchmarks suffer from significant issues.
We further find that most benchmarks do not report statistical significance of
their results nor allow for their results to be easily replicated. To support
benchmark developers in aligning with best practices, we provide a checklist
for minimum quality assurance based on our assessment. We also develop a living
repository of benchmark assessments to support benchmark comparability,
accessible at betterbench.stanford.edu.","cs.AI, cs.LG",cs.AI,http://arxiv.org/abs/2411.12990v1
Training Bilingual LMs with Data Constraints in the Targeted Language,"Skyler Seto, Maartje ter Hoeve, He Bai, Natalie Schluter, David Grangier",2024-11-20T02:27:40Z,"Large language models are trained on massive scrapes of the web, as required
by current scaling laws. Most progress is made for English, given its abundance
of high-quality pretraining data. For most other languages, however, such high
quality pretraining data is unavailable. In this work, we study how to boost
pretrained model performance in a data constrained target language by enlisting
data from an auxiliary language for which high quality data is available. We
study this by quantifying the performance gap between training with data in a
data-rich auxiliary language compared with training in the target language,
exploring the benefits of translation systems, studying the limitations of
model scaling for data constrained languages, and proposing new methods for
upsampling data from the auxiliary language. Our results show that stronger
auxiliary datasets result in performance gains without modification to the
model or training objective for close languages, and, in particular, that
performance gains due to the development of more information-rich English
pretraining datasets can extend to targeted language settings with limited
data.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.12986v1
"Hierarchical Diffusion Policy: manipulation trajectory generation via
  contact guidance","Dexin Wang, Chunsheng Liu, Faliang Chang, Yichen Xu",2024-11-20T02:19:18Z,"Decision-making in robotics using denoising diffusion processes has
increasingly become a hot research topic, but end-to-end policies perform
poorly in tasks with rich contact and have limited controllability. This paper
proposes Hierarchical Diffusion Policy (HDP), a new imitation learning method
of using objective contacts to guide the generation of robot trajectories. The
policy is divided into two layers: the high-level policy predicts the contact
for the robot's next object manipulation based on 3D information, while the
low-level policy predicts the action sequence toward the high-level contact
based on the latent variables of observation and contact. We represent both
level policies as conditional denoising diffusion processes, and combine
behavioral cloning and Q-learning to optimize the low level policy for
accurately guiding actions towards contact. We benchmark Hierarchical Diffusion
Policy across 6 different tasks and find that it significantly outperforms the
existing state of-the-art imitation learning method Diffusion Policy with an
average improvement of 20.8%. We find that contact guidance yields significant
improvements, including superior performance, greater interpretability, and
stronger controllability, especially on contact-rich tasks. To further unlock
the potential of HDP, this paper proposes a set of key technical contributions
including snapshot gradient optimization, 3D conditioning, and prompt guidance,
which improve the policy's optimization efficiency, spatial awareness, and
controllability respectively. Finally, real world experiments verify that HDP
can handle both rigid and deformable objects.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12982v1
GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting,"Xiaobao Wei, Peng Chen, Guangyu Li, Ming Lu, Hui Chen, Feng Tian",2024-11-20T02:15:23Z,"Gaze estimation encounters generalization challenges when dealing with
out-of-distribution data. To address this problem, recent methods use neural
radiance fields (NeRF) to generate augmented data. However, existing methods
based on NeRF are computationally expensive and lack facial details. 3D
Gaussian Splatting (3DGS) has become the prevailing representation of neural
fields. While 3DGS has been extensively examined in head avatars, it faces
challenges with accurate gaze control and generalization across different
subjects. In this work, we propose GazeGaussian, a high-fidelity gaze
redirection method that uses a two-stream 3DGS model to represent the face and
eye regions separately. By leveraging the unstructured nature of 3DGS, we
develop a novel eye representation for rigid eye rotation based on the target
gaze direction. To enhance synthesis generalization across various subjects, we
integrate an expression-conditional module to guide the neural renderer.
Comprehensive experiments show that GazeGaussian outperforms existing methods
in rendering speed, gaze redirection accuracy, and facial synthesis across
multiple datasets. We also demonstrate that existing gaze estimation methods
can leverage GazeGaussian to improve their generalization performance. The code
will be available at: https://ucwxb.github.io/GazeGaussian/.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12981v1
"MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong
  Collaborative Learning","Mircea Lică, Ojas Shirekar, Baptiste Colle, Chirag Raman",2024-11-20T02:10:44Z,"Contemporary embodied agents, such as Voyager in Minecraft, have demonstrated
promising capabilities in open-ended individual learning. However, when powered
with open large language models (LLMs), these agents often struggle with
rudimentary tasks, even when fine-tuned on domain-specific knowledge. Inspired
by human cultural learning, we present \collabvoyager, a novel framework that
enhances Voyager with lifelong collaborative learning through explicit
perspective-taking. \collabvoyager introduces three key innovations: (1) theory
of mind representations linking percepts, beliefs, desires, and actions; (2)
natural language communication between agents; and (3) semantic memory of task
and environment knowledge and episodic memory of collaboration episodes. These
advancements enable agents to reason about their and others' mental states,
empirically addressing two prevalent failure modes: false beliefs and faulty
task executions. In mixed-expertise Minecraft experiments, \collabvoyager
agents outperform Voyager counterparts, significantly improving task completion
rate by $66.6\% (+39.4\%)$ for collecting one block of dirt and $70.8\%
(+20.8\%)$ for collecting one wood block. They exhibit emergent behaviors like
knowledge transfer from expert to novice agents and collaborative code
correction. \collabvoyager agents also demonstrate the ability to adapt to
out-of-distribution tasks by using their previous experiences and beliefs
obtained through collaboration. In this open-ended social learning paradigm,
\collabvoyager paves the way for the democratic development of embodied AI,
where agents learn in deployment from both peer and environmental feedback.","cs.AI, cs.CL",cs.AI,http://arxiv.org/abs/2411.12977v1
"Adaptive Process-Guided Learning: An Application in Predicting Lake DO
  Concentrations","Runlong Yu, Chonghao Qiu, Robert Ladwig, Paul C. Hanson, Yiqun Xie, Yanhua Li, Xiaowei Jia",2024-11-20T01:58:20Z,"This paper introduces a \textit{Process-Guided Learning (Pril)} framework
that integrates physical models with recurrent neural networks (RNNs) to
enhance the prediction of dissolved oxygen (DO) concentrations in lakes, which
is crucial for sustaining water quality and ecosystem health. Unlike
traditional RNNs, which may deliver high accuracy but often lack physical
consistency and broad applicability, the \textit{Pril} method incorporates
differential DO equations for each lake layer, modeling it as a first-order
linear solution using a forward Euler scheme with a daily timestep. However,
this method is sensitive to numerical instabilities. When drastic fluctuations
occur, the numerical integration is neither mass-conservative nor stable.
Especially during stratified conditions, exogenous fluxes into each layer cause
significant within-day changes in DO concentrations. To address this challenge,
we further propose an \textit{Adaptive Process-Guided Learning (April)} model,
which dynamically adjusts timesteps from daily to sub-daily intervals with the
aim of mitigating the discrepancies caused by variations in entrainment fluxes.
\textit{April} uses a generator-discriminator architecture to identify days
with significant DO fluctuations and employs a multi-step Euler scheme with
sub-daily timesteps to effectively manage these variations. We have tested our
methods on a wide range of lakes in the Midwestern USA, and demonstrated robust
capability in predicting DO concentrations even with limited training data.
While primarily focused on aquatic ecosystems, this approach is broadly
applicable to diverse scientific and engineering disciplines that utilize
process-based models, such as power engineering, climate science, and
biomedicine.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12973v1
A Foundation Model for Unified Urban Spatio-Temporal Flow Prediction,"Yuan Yuan, Jingtao Ding, Chonghua Han, Depeng Jin, Yong Li",2024-11-20T01:54:52Z,"Urban spatio-temporal flow prediction, encompassing traffic flows and crowd
flows, is crucial for optimizing city infrastructure and managing traffic and
emergency responses. Traditional approaches have relied on separate models
tailored to either grid-based data, representing cities as uniform cells, or
graph-based data, modeling cities as networks of nodes and edges. In this
paper, we build UniFlow, a foundational model for general urban flow prediction
that unifies both grid-based and graphbased data. We first design a multi-view
spatio-temporal patching mechanism to standardize different data into a
consistent sequential format and then introduce a spatio-temporal transformer
architecture to capture complex correlations and dynamics. To leverage shared
spatio-temporal patterns across different data types and facilitate effective
cross-learning, we propose SpatioTemporal Memory Retrieval Augmentation
(ST-MRA). By creating structured memory modules to store shared spatio-temporal
patterns, ST-MRA enhances predictions through adaptive memory retrieval.
Extensive experiments demonstrate that UniFlow outperforms existing models in
both grid-based and graph-based flow prediction, excelling particularly in
scenarios with limited data availability, showcasing its superior performance
and broad applicability. The datasets and code implementation have been
released on https://github.com/YuanYuan98/UniFlow.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12972v1
Flexible electrical impedance tomography for tactile interfaces,"Huazhi Dong, Sihao Teng, Xiaopeng Wu, Xu Han, Francesco Giorgio-Serchi, Yunjie Yang",2024-11-20T13:20:52Z,"Flexible electrical impedance tomography (EIT) is an emerging technology for
tactile sensing in human-machine interfaces (HMI). It offers a unique
alternative to traditional array-based tactile sensors with its flexible,
scalable, and cost-effective one-piece design. This paper proposes a
lattice-patterned flexible EIT tactile sensor with a hydrogel-based conductive
layer, designed for enhanced sensitivity while maintaining durability. We
conducted simulation studies to explore the influence of lattice width and
conductive layer thickness on sensor performance, establishing optimized sensor
design parameters for enhanced functionality. Experimental evaluations
demonstrate the sensor's capacity to detect diverse tactile patterns with a
high accuracy. The practical utility of the sensor is demonstrated through its
integration within an HMI setup to control a virtual game, showcasing its
potential for dynamic, multi-functional tactile interactions in real-time
applications. This study reinforces the potential of EIT-based flexible tactile
sensors, establishing a foundation for future advancements in wearable,
adaptable HMI technologies.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13306v1
"KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware
  Attributes Learning","Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li",2024-11-20T00:47:03Z,"Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.",cs.AI,cs.AI,http://arxiv.org/abs/2411.12950v1
Epidemiology-informed Network for Robust Rumor Detection,"Wei Jiang, Tong Chen, Xinyi Gao, Wentao Zhang, Lizhen Cui, Hongzhi Yin",2024-11-20T00:43:32Z,"The rapid spread of rumors on social media has posed significant challenges
to maintaining public trust and information integrity. Since an information
cascade process is essentially a propagation tree, recent rumor detection
models leverage graph neural networks to additionally capture information
propagation patterns, thus outperforming text-only solutions. Given the
variations in topics and social impact of the root node, different source
information naturally has distinct outreach capabilities, resulting in
different heights of propagation trees. This variation, however, impedes the
data-driven design of existing graph-based rumor detectors. Given a shallow
propagation tree with limited interactions, it is unlikely for graph-based
approaches to capture sufficient cascading patterns, questioning their ability
to handle less popular news or early detection needs. In contrast, a deep
propagation tree is prone to noisy user responses, and this can in turn
obfuscate the predictions. In this paper, we propose a novel
Epidemiology-informed Network (EIN) that integrates epidemiological knowledge
to enhance performance by overcoming data-driven methods sensitivity to data
quality. Meanwhile, to adapt epidemiology theory to rumor detection, it is
expected that each users stance toward the source information will be
annotated. To bypass the costly and time-consuming human labeling process, we
take advantage of large language models to generate stance labels, facilitating
optimization objectives for learning epidemiology-informed representations. Our
experimental results demonstrate that the proposed EIN not only outperforms
state-of-the-art methods on real-world datasets but also exhibits enhanced
robustness across varying tree depths.","cs.SI, cs.IR",cs.SI,http://arxiv.org/abs/2411.12949v1
"Machine learned reconstruction of tsunami dynamics from sparse
  observations","Edward McDugald, Arvind Mohan, Darren Engwirda, Agnese Marcato, Javier Santos",2024-11-20T00:42:40Z,"We investigate the use of the Senseiver, a transformer neural network
designed for sparse sensing applications, to estimate full-field surface height
measurements of tsunami waves from sparse observations. The model is trained on
a large ensemble of simulated data generated via a shallow water equations
solver, which we show to be a faithful reproduction for the underlying dynamics
by comparison to historical events. We train the model on a dataset consisting
of 8 tsunami simulations whose epicenters correspond to historical USGS
earthquake records, and where the model inputs are restricted to measurements
obtained at actively deployed buoy locations. We test the Senseiver on a
dataset consisting of 8 simulations not included in training, demonstrating its
capability for extrapolation. The results show remarkable resolution of fine
scale phase and amplitude features from the true field, provided that at least
a few of the sensors have obtained a non-zero signal. Throughout, we discuss
which forecasting techniques can be improved by this method, and suggest ways
in which the flexibility of the architecture can be leveraged to incorporate
arbitrary remote sensing data (eg. HF Radar and satellite measurements) as well
as investigate optimal sensor placements.","cs.LG, physics.flu-dyn",cs.LG,http://arxiv.org/abs/2411.12948v1
"A Flexible Large Language Models Guardrail Development Methodology
  Applied to Off-Topic Prompt Detection","Gabriel Chua, Shing Yee Chan, Shaun Khoo",2024-11-20T00:31:23Z,"Large Language Models are prone to off-topic misuse, where users may prompt
these models to perform tasks beyond their intended scope. Current guardrails,
which often rely on curated examples or custom classifiers, suffer from high
false-positive rates, limited adaptability, and the impracticality of requiring
real-world data that is not available in pre-production. In this paper, we
introduce a flexible, data-free guardrail development methodology that
addresses these challenges. By thoroughly defining the problem space
qualitatively and passing this to an LLM to generate diverse prompts, we
construct a synthetic dataset to benchmark and train off-topic guardrails that
outperform heuristic approaches. Additionally, by framing the task as
classifying whether the user prompt is relevant with respect to the system
prompt, our guardrails effectively generalize to other misuse categories,
including jailbreak and harmful prompts. Lastly, we further contribute to the
field by open-sourcing both the synthetic dataset and the off-topic guardrail
models, providing valuable resources for developing guardrails in
pre-production environments and supporting future research and development in
LLM safety.","cs.CL, cs.LG, 68T50, I.2.7",cs.CL,http://arxiv.org/abs/2411.12946v1
"Enhancing Thermal MOT: A Novel Box Association Method Leveraging Thermal
  Identity and Motion Similarity","Wassim El Ahmar, Dhanvin Kolhatkar, Farzan Nowruzi, Robert Laganiere",2024-11-20T00:27:01Z,"Multiple Object Tracking (MOT) in thermal imaging presents unique challenges
due to the lack of visual features and the complexity of motion patterns. This
paper introduces an innovative approach to improve MOT in the thermal domain by
developing a novel box association method that utilizes both thermal object
identity and motion similarity. Our method merges thermal feature sparsity and
dynamic object tracking, enabling more accurate and robust MOT performance.
Additionally, we present a new dataset comprised of a large-scale collection of
thermal and RGB images captured in diverse urban environments, serving as both
a benchmark for our method and a new resource for thermal imaging. We conduct
extensive experiments to demonstrate the superiority of our approach over
existing methods, showing significant improvements in tracking accuracy and
robustness under various conditions. Our findings suggest that incorporating
thermal identity with motion data enhances MOT performance. The newly collected
dataset and source code is available at https://github.com/wassimea/thermalMOT","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12943v1
"LEDRO: LLM-Enhanced Design Space Reduction and Optimization for Analog
  Circuits","Dimple Vijay Kochar, Hanrui Wang, Anantha Chandrakasan, Xin Zhang",2024-11-19T23:43:25Z,"Traditional approaches for designing analog circuits are time-consuming and
require significant human expertise. Existing automation efforts using methods
like Bayesian Optimization (BO) and Reinforcement Learning (RL) are sub-optimal
and costly to generalize across different topologies and technology nodes. In
our work, we introduce a novel approach, LEDRO, utilizing Large Language Models
(LLMs) in conjunction with optimization techniques to iteratively refine the
design space for analog circuit sizing. LEDRO is highly generalizable compared
to other RL and BO baselines, eliminating the need for design annotation or
model training for different topologies or technology nodes. We conduct a
comprehensive evaluation of our proposed framework and baseline on 22 different
Op-Amp topologies across four FinFET technology nodes. Results demonstrate the
superior performance of LEDRO as it outperforms our best baseline by an average
of 13% FoM improvement with 2.15x speed-up on low complexity Op-Amps and 48%
FoM improvement with 1.7x speed-up on high complexity Op-Amps. This highlights
LEDRO's effective performance, efficiency, and generalizability.","cs.LG, cs.SY, eess.SY",cs.LG,http://arxiv.org/abs/2411.12930v1
Loss-to-Loss Prediction: Scaling Laws for All Datasets,"David Brandfonbrener, Nikhil Anand, Nikhil Vyas, Eran Malach, Sham Kakade",2024-11-19T23:23:16Z,"While scaling laws provide a reliable methodology for predicting train loss
across compute scales for a single data distribution, less is known about how
these predictions should change as we change the distribution. In this paper,
we derive a strategy for predicting one loss from another and apply it to
predict across different pre-training datasets and from pre-training data to
downstream task data. Our predictions extrapolate well even at 20x the largest
FLOP budget used to fit the curves. More precisely, we find that there are
simple shifted power law relationships between (1) the train losses of two
models trained on two separate datasets when the models are paired by training
compute (train-to-train), (2) the train loss and the test loss on any
downstream distribution for a single model (train-to-test), and (3) the test
losses of two models trained on two separate train datasets (test-to-test). The
results hold up for pre-training datasets that differ substantially (some are
entirely code and others have no code at all) and across a variety of
downstream tasks. Finally, we find that in some settings these shifted power
law relationships can yield more accurate predictions than extrapolating
single-dataset scaling laws.","cs.LG, cs.AI, cs.CL, stat.ML",cs.LG,http://arxiv.org/abs/2411.12925v1
Human-In-the-Loop Software Development Agents,"Wannita Takerngsaksiri, Jirat Pasuksmit, Patanamon Thongtanunam, Chakkrit Tantithamthavorn, Ruixiong Zhang, Fan Jiang, Jing Li, Evan Cook, Kun Chen, Ming Wu",2024-11-19T23:22:33Z,"Recently, Large Language Models (LLMs)-based multi-agent paradigms for
software engineering are introduced to automatically resolve software
development tasks (e.g., from a given issue to source code). However, existing
work is evaluated based on historical benchmark datasets, does not consider
human feedback at each stage of the automated software development process, and
has not been deployed in practice. In this paper, we introduce a
Human-in-the-loop LLM-based Agents framework (HULA) for software development
that allows software engineers to refine and guide LLMs when generating coding
plans and source code for a given task. We design, implement, and deploy the
HULA framework into Atlassian JIRA for internal uses. Through a multi-stage
evaluation of the HULA framework, Atlassian software engineers perceive that
HULA can minimize the overall development time and effort, especially in
initiating a coding plan and writing code for straightforward tasks. On the
other hand, challenges around code quality are raised to be solved in some
cases. We draw lessons learned and discuss opportunities for future work, which
will pave the way for the advancement of LLM-based agents in software
development.","cs.SE, cs.AI, cs.HC, cs.LG",cs.SE,http://arxiv.org/abs/2411.12924v1
VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge,"Vishwesh Nath, Wenqi Li, Dong Yang, Andriy Myronenko, Mingxin Zheng, Yao Lu, Zhijian Liu, Hongxu Yin, Yee Man Law, Yucheng Tang, Pengfei Guo, Can Zhao, Ziyue Xu, Yufan He, Greg Heinrich, Stephen Aylward, Marc Edgar, Michael Zephyr, Pavlo Molchanov, Baris Turkbey, Holger Roth, Daguang Xu",2024-11-19T22:59:14Z,"Generalist vision language models (VLMs) have made significant strides in
computer vision, but they fall short in specialized fields like healthcare,
where expert knowledge is essential. In traditional computer vision tasks,
creative or approximate answers may be acceptable, but in healthcare, precision
is paramount.Current large multimodal models like Gemini and GPT-4o are
insufficient for medical tasks due to their reliance on memorized internet
knowledge rather than the nuanced expertise required in healthcare. VLMs are
usually trained in three stages: vision pre-training, vision-language
pre-training, and instruction fine-tuning (IFT). IFT has been typically applied
using a mixture of generic and healthcare data. In contrast, we propose that
for medical VLMs, a fourth stage of specialized IFT is necessary, which focuses
on medical data and includes information from domain expert models. Domain
expert models developed for medical use are crucial because they are
specifically trained for certain clinical tasks, e.g. to detect tumors and
classify abnormalities through segmentation and classification, which learn
fine-grained features of medical data$-$features that are often too intricate
for a VLM to capture effectively especially in radiology. This paper introduces
a new framework, VILA-M3, for medical VLMs that utilizes domain knowledge via
expert models. Through our experiments, we show an improved state-of-the-art
(SOTA) performance with an average improvement of ~9% over the prior SOTA model
Med-Gemini and ~6% over models trained on the specific tasks. Our approach
emphasizes the importance of domain expertise in creating precise, reliable
VLMs for medical applications.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12915v1
Trojan Cleansing with Neural Collapse,"Xihe Gu, Greg Fields, Yaman Jandali, Tara Javidi, Farinaz Koushanfar",2024-11-19T22:57:40Z,"Trojan attacks are sophisticated training-time attacks on neural networks
that embed backdoor triggers which force the network to produce a specific
output on any input which includes the trigger. With the increasing relevance
of deep networks which are too large to train with personal resources and which
are trained on data too large to thoroughly audit, these training-time attacks
pose a significant risk. In this work, we connect trojan attacks to Neural
Collapse, a phenomenon wherein the final feature representations of
over-parameterized neural networks converge to a simple geometric structure. We
provide experimental evidence that trojan attacks disrupt this convergence for
a variety of datasets and architectures. We then use this disruption to design
a lightweight, broadly generalizable mechanism for cleansing trojan attacks
from a wide variety of different network architectures and experimentally
demonstrate its efficacy.","cs.LG, cs.CR",cs.LG,http://arxiv.org/abs/2411.12914v1
MLDGG: Meta-Learning for Domain Generalization on Graphs,"Qin Tian, Chen Zhao, Minglai Shao, Wenjun Wang, Yujie Lin, Dong Li",2024-11-19T22:57:38Z,"Domain generalization on graphs aims to develop models with robust
generalization capabilities, ensuring effective performance on the testing set
despite disparities between testing and training distributions. However,
existing methods often rely on static encoders directly applied to the target
domain, constraining its flexible adaptability. In contrast to conventional
methodologies, which concentrate on developing specific generalized models, our
framework, MLDGG, endeavors to achieve adaptable generalization across diverse
domains by integrating cross-multi-domain meta-learning with structure learning
and semantic identification. Initially, it introduces a generalized structure
learner to mitigate the adverse effects of task-unrelated edges, enhancing the
comprehensiveness of representations learned by Graph Neural Networks (GNNs)
while capturing shared structural information across domains. Subsequently, a
representation learner is designed to disentangle domain-invariant semantic and
domain-specific variation information in node embedding by leveraging causal
reasoning for semantic identification, further enhancing generalization. In the
context of meta-learning, meta-parameters for both learners are optimized to
facilitate knowledge transfer and enable effective adaptation to graphs through
fine-tuning within the target domains, where target graphs are inaccessible
during training. Our empirical results demonstrate that MLDGG surpasses
baseline methods, showcasing its effectiveness in three different distribution
shift settings.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12913v1
Signformer is all you need: Towards Edge AI for Sign Language,Eta Yang,2024-11-19T22:27:53Z,"Sign language translation, especially in gloss-free paradigm, is confronting
a dilemma of impracticality and unsustainability due to growing
resource-intensive methodologies. Contemporary state-of-the-arts (SOTAs) have
significantly hinged on pretrained sophiscated backbones such as Large Language
Models (LLMs), embedding sources, or extensive datasets, inducing considerable
parametric and computational inefficiency for sustainable use in real-world
scenario. Despite their success, following this research direction undermines
the overarching mission of this domain to create substantial value to bridge
hard-hearing and common populations. Committing to the prevailing trend of LLM
and Natural Language Processing (NLP) studies, we pursue a profound essential
change in architecture to achieve ground-up improvements without external aid
from pretrained models, prior knowledge transfer, or any NLP strategies
considered not-from-scratch.
  Introducing Signformer, a from-scratch Feather-Giant transforming the area
towards Edge AI that redefines extremities of performance and efficiency with
LLM-competence and edgy-deployable compactness. In this paper, we present
nature analysis of sign languages to inform our algorithmic design and deliver
a scalable transformer pipeline with convolution and attention novelty. We
achieve new 2nd place on leaderboard with a parametric reduction of 467-1807x
against the finests as of 2024 and outcompete almost every other methods in a
lighter configuration of 0.57 million parameters.","cs.CL, cs.CV, cs.CY, cs.HC, cs.LG",cs.CL,http://arxiv.org/abs/2411.12901v1
"Tree Species Classification using Machine Learning and 3D Tomographic
  SAR -- a case study in Northern Europe","Colverd Grace, Schade Laura, Takami Jumpei, Bot Karol, Gallego Joseph",2024-11-19T22:25:26Z,"Tree species classification plays an important role in nature conservation,
forest inventories, forest management, and the protection of endangered
species. Over the past four decades, remote sensing technologies have been
extensively utilized for tree species classification, with Synthetic Aperture
Radar (SAR) emerging as a key technique. In this study, we employed TomoSense,
a 3D tomographic dataset, which utilizes a stack of single-look complex (SLC)
images, a byproduct of SAR, captured at different incidence angles to generate
a three-dimensional representation of the terrain. Our research focuses on
evaluating multiple tabular machine-learning models using the height
information derived from the tomographic image intensities to classify eight
distinct tree species. The SLC data and tomographic imagery were analyzed
across different polarimetric configurations and geosplit configurations. We
investigated the impact of these variations on classification accuracy,
comparing the performance of various tabular machine-learning models and
optimizing them using Bayesian optimization. Additionally, we incorporated a
proxy for actual tree height using point cloud data from Light Detection and
Ranging (LiDAR) to provide height statistics associated with the model's
predictions. This comparison offers insights into the reliability of
tomographic data in predicting tree species classification based on height.","cs.LG, cs.CV, physics.data-an",cs.LG,http://arxiv.org/abs/2411.12897v1
"Selective Attention: Enhancing Transformer through Principled Context
  Control","Xuechen Zhang, Xiangyu Chang, Mingchen Li, Amit Roy-Chowdhury, Jiasi Chen, Samet Oymak",2024-11-19T22:17:18Z,"The attention mechanism within the transformer architecture enables the model
to weigh and combine tokens based on their relevance to the query. While
self-attention has enjoyed major success, it notably treats all queries $q$ in
the same way by applying the mapping $V^\top\text{softmax}(Kq)$, where $V,K$
are the value and key embeddings respectively. In this work, we argue that this
uniform treatment hinders the ability to control contextual sparsity and
relevance. As a solution, we introduce the $\textit{Selective Self-Attention}$
(SSA) layer that augments the softmax nonlinearity with a principled
temperature scaling strategy. By controlling temperature, SSA adapts the
contextual sparsity of the attention map to the query embedding and its
position in the context window. Through theory and experiments, we demonstrate
that this alleviates attention dilution, aids the optimization process, and
enhances the model's ability to control softmax spikiness of individual
queries. We also incorporate temperature scaling for value embeddings and show
that it boosts the model's ability to suppress irrelevant/noisy tokens.
Notably, SSA is a lightweight method which introduces less than 0.5% new
parameters through a weight-sharing strategy and can be fine-tuned on existing
LLMs. Extensive empirical evaluations demonstrate that SSA-equipped models
achieve a noticeable and consistent accuracy improvement on language modeling
benchmarks.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.12892v1
ProSec: Fortifying Code LLMs with Proactive Security Alignment,"Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang",2024-11-19T22:00:01Z,"Recent advances in code-specific large language models (LLMs) have greatly
enhanced code generation and refinement capabilities. However, the safety of
code LLMs remains under-explored, posing potential risks as insecure code
generated by these models may introduce vulnerabilities into real-world
systems. Previous work proposes to collect security-focused instruction-tuning
dataset from real-world vulnerabilities. It is constrained by the data sparsity
of vulnerable code, and has limited applicability in the iterative
post-training workflows of modern LLMs. In this paper, we propose ProSec, a
novel proactive security alignment approach designed to align code LLMs with
secure coding practices. ProSec systematically exposes the vulnerabilities in a
code LLM by synthesizing error-inducing coding scenarios from Common Weakness
Enumerations (CWEs), and generates fixes to vulnerable code snippets, allowing
the model to learn secure practices through advanced preference learning
objectives. The scenarios synthesized by ProSec triggers 25 times more
vulnerable code than a normal instruction-tuning dataset, resulting in a
security-focused alignment dataset 7 times larger than the previous work.
Experiments show that models trained with ProSec is 29.2% to 35.5% more secure
compared to previous work, with a marginal negative effect of less than 2
percentage points on model's utility.","cs.CR, cs.CL, cs.SE",cs.CR,http://arxiv.org/abs/2411.12882v1
The Illusion of Empathy: How AI Chatbots Shape Conversation Perception,"Tingting Liu, Salvatore Giorgi, Ankit Aich, Allison Lahnala, Brenda Curtis, Lyle Ungar, João Sedoc",2024-11-19T21:47:08Z,"As AI chatbots become more human-like by incorporating empathy, understanding
user-centered perceptions of chatbot empathy and its impact on conversation
quality remains essential yet under-explored. This study examines how chatbot
identity and perceived empathy influence users' overall conversation
experience. Analyzing 155 conversations from two datasets, we found that while
GPT-based chatbots were rated significantly higher in conversational quality,
they were consistently perceived as less empathetic than human conversational
partners. Empathy ratings from GPT-4o annotations aligned with users' ratings,
reinforcing the perception of lower empathy in chatbots. In contrast, 3 out of
5 empathy models trained on human-human conversations detected no significant
differences in empathy language between chatbots and humans. Our findings
underscore the critical role of perceived empathy in shaping conversation
quality, revealing that achieving high-quality human-AI interactions requires
more than simply embedding empathetic language; it necessitates addressing the
nuanced ways users interpret and experience empathy in conversations with
chatbots.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.12877v1
"Puppet-CNN: Input-Adaptive Convolutional Neural Networks with Model
  Compression using Ordinary Differential Equation","Yucheng Xing, Xin Wang",2024-11-19T21:44:21Z,"Convolutional Neural Network (CNN) has been applied to more and more
scenarios due to its excellent performance in many machine learning tasks,
especially with deep and complex structures. However, as the network goes
deeper, more parameters need to be stored and optimized. Besides, almost all
common CNN models adopt ""train-and-use"" strategy where the structure is
pre-defined and the kernel parameters are fixed after the training with the
same structure and set of parameters used for all data without considering the
content complexity. In this paper, we propose a new CNN framework, named as
$\textit{Puppet-CNN}$, which contains two modules: a $\textit{puppet module}$
and a $\textit{puppeteer module}$. The puppet module is a CNN model used to
actually process the input data just like other works, but its depth and
kernels are generated by the puppeteer module (realized with Ordinary
Differential Equation (ODE)) based on the input complexity each time. By
recurrently generating kernel parameters in the puppet module, we can take
advantage of the dependence among kernels of different convolutional layers to
significantly reduce the size of CNN model by only storing and training the
parameters of the much smaller puppeteer ODE module. Through experiments on
several datasets, our method has proven to be superior than the traditional
CNNs on both performance and efficiency. The model size can be reduced more
than 10 times.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12876v1
"Tensor-Based Foundations of Ordinary Least Squares and Neural Network
  Regression Models",Roberto Dias Algarte,2024-11-19T21:36:04Z,"This article introduces a novel approach to the mathematical development of
Ordinary Least Squares and Neural Network regression models, diverging from
traditional methods in current Machine Learning literature. By leveraging
Tensor Analysis and fundamental matrix computations, the theoretical
foundations of both models are meticulously detailed and extended to their
complete algorithmic forms. The study culminates in the presentation of three
algorithms, including a streamlined version of the Backpropagation Algorithm
for Neural Networks, illustrating the benefits of this new mathematical
approach.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12873v1
"From Text to Pose to Image: Improving Diffusion Model Control and
  Quality","Clément Bonnett, Ariel N. Lee, Franck Wertel, Antoine Tamano, Tanguy Cizain, Pablo Ducru",2024-11-19T21:34:50Z,"In the last two years, text-to-image diffusion models have become extremely
popular. As their quality and usage increase, a major concern has been the need
for better output control. In addition to prompt engineering, one effective
method to improve the controllability of diffusion models has been to condition
them on additional modalities such as image style, depth map, or keypoints.
This forms the basis of ControlNets or Adapters. When attempting to apply these
methods to control human poses in outputs of text-to-image diffusion models,
two main challenges have arisen. The first challenge is generating poses
following a wide range of semantic text descriptions, for which previous
methods involved searching for a pose within a dataset of (caption, pose)
pairs. The second challenge is conditioning image generation on a specified
pose while keeping both high aesthetic and high pose fidelity. In this article,
we fix these two main issues by introducing a text-to-pose (T2P) generative
model alongside a new sampling algorithm, and a new pose adapter that
incorporates more pose keypoints for higher pose fidelity. Together, these two
new state-of-the-art models enable, for the first time, a generative
text-to-pose-to-image framework for higher pose control in diffusion models. We
release all models and the code used for the experiments at
https://github.com/clement-bonnet/text-to-pose.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12872v1
The Game-Theoretic Symbiosis of Trust and AI in Networked Systems,"Yunfei Ge, Quanyan Zhu",2024-11-19T21:04:53Z,"This chapter explores the symbiotic relationship between Artificial
Intelligence (AI) and trust in networked systems, focusing on how these two
elements reinforce each other in strategic cybersecurity contexts. AI's
capabilities in data processing, learning, and real-time response offer
unprecedented support for managing trust in dynamic, complex networks. However,
the successful integration of AI also hinges on the trustworthiness of AI
systems themselves. Using a game-theoretic framework, this chapter presents
approaches to trust evaluation, the strategic role of AI in cybersecurity, and
governance frameworks that ensure responsible AI deployment. We investigate how
trust, when dynamically managed through AI, can form a resilient security
ecosystem. By examining trust as both an AI output and an AI requirement, this
chapter sets the foundation for a positive feedback loop where AI enhances
network security and the trust placed in AI systems fosters their adoption.",cs.AI,cs.AI,http://arxiv.org/abs/2411.12859v1
CDI: Copyrighted Data Identification in Diffusion Models,"Jan Dubiński, Antoni Kowalczuk, Franziska Boenisch, Adam Dziedzic",2024-11-19T21:02:09Z,"Diffusion Models (DMs) benefit from large and diverse datasets for their
training. Since this data is often scraped from the Internet without permission
from the data owners, this raises concerns about copyright and intellectual
property protections. While (illicit) use of data is easily detected for
training samples perfectly re-created by a DM at inference time, it is much
harder for data owners to verify if their data was used for training when the
outputs from the suspect DM are not close replicas. Conceptually, membership
inference attacks (MIAs), which detect if a given data point was used during
training, present themselves as a suitable tool to address this challenge.
However, we demonstrate that existing MIAs are not strong enough to reliably
determine the membership of individual images in large, state-of-the-art DMs.
To overcome this limitation, we propose CDI, a framework for data owners to
identify whether their dataset was used to train a given DM. CDI relies on
dataset inference techniques, i.e., instead of using the membership signal from
a single data point, CDI leverages the fact that most data owners, such as
providers of stock photography, visual media companies, or even individual
artists, own datasets with multiple publicly exposed data points which might
all be included in the training of a given DM. By selectively aggregating
signals from existing MIAs and using new handcrafted methods to extract
features for these datasets, feeding them to a scoring model, and applying
rigorous statistical testing, CDI allows data owners with as little as 70 data
points to identify with a confidence of more than 99% whether their data was
used to train a given DM. Thereby, CDI represents a valuable tool for data
owners to claim illegitimate use of their copyrighted data.","cs.LG, cs.CR",cs.LG,http://arxiv.org/abs/2411.12858v1
"Integrating Secondary Structures Information into Triangular Spatial
  Relationships (TSR) for Advanced Protein Classification","Poorya Khajouie, Titli Sarkar, Krishna Rauniyar, Li Chen, Wu Xu, Vijay Raghavan",2024-11-19T20:50:16Z,"Protein structures represent the key to deciphering biological functions. The
more detailed form of similarity among these proteins is sometimes overlooked
by the conventional structural comparison methods. In contrast, further
advanced methods, such as Triangular Spatial Relationship (TSR), have been
demonstrated to make finer differentiations. Still, the classical
implementation of TSR does not provide for the integration of secondary
structure information, which is important for a more detailed understanding of
the folding pattern of a protein. To overcome these limitations, we developed
the SSE-TSR approach. The proposed method integrates secondary structure
elements (SSEs) into TSR-based protein representations. This allows an enriched
representation of protein structures by considering 18 different combinations
of helix, strand, and coil arrangements. Our results show that using SSEs
improves the accuracy and reliability of protein classification to varying
degrees. We worked with two large protein datasets of 9.2K and 7.8K samples,
respectively. We applied the SSE-TSR approach and used a neural network model
for classification. Interestingly, introducing SSEs improved performance
statistics for Dataset 1, with accuracy moving from 96.0% to 98.3%. For Dataset
2, where the performance statistics were already good, further small
improvements were found with the introduction of SSE, giving an accuracy of
99.5% compared to 99.4%. These results show that SSE integration can
dramatically improve TSR key discrimination, with significant benefits in
datasets with low initial accuracies and only incremental gains in those with
high baseline performance. Thus, SSE-TSR is a powerful bioinformatics tool that
improves protein classification and understanding of protein function and
interaction.","cs.LG, q-bio.BM",cs.LG,http://arxiv.org/abs/2411.12853v1
"GenAI Assistance for Deep Reinforcement Learning-based VNF Placement and
  SFC Provisioning in 5G Cores","Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Emil Janulewicz",2024-11-19T20:46:10Z,"Virtualization technology, Network Function Virtualization (NFV), gives
flexibility to communication and 5G core network technologies for dynamic and
efficient resource allocation while reducing the cost and dependability of the
physical infrastructure. In the NFV context, Service Function Chain (SFC)
refers to the ordered arrangement of various Virtual Network Functions (VNFs).
To provide an automated SFC provisioning algorithm that satisfies high demands
of SFC requests having ultra-reliable and low latency communication (URLLC)
requirements, in the literature, Artificial Intelligence (AI) modules and Deep
Reinforcement Learning (DRL) algorithms are investigated in detail. This
research proposes a generative Variational Autoencoder (VAE) assisted
advanced-DRL module for handling SFC requests in a dynamic environment where
network configurations and request amounts can be changed. Using the hybrid
approach, including generative VAE and DRL, the algorithm leverages several
advantages, such as dimensionality reduction, better generalization on the VAE
side, exploration, and trial-error learning from the DRL model. Results show
that GenAI-assisted DRL surpasses the state-of-the-art model of DRL in SFC
provisioning in terms of SFC acceptance ratio, E2E delay, and throughput
maximization.",cs.NI,cs.NI,http://arxiv.org/abs/2411.12851v1
mDAE : modified Denoising AutoEncoder for missing data imputation,"Mariette Dupuy, Marie Chavent, Remi Dubois",2024-11-19T20:31:53Z,"This paper introduces a methodology based on Denoising AutoEncoder (DAE) for
missing data imputation. The proposed methodology, called mDAE hereafter,
results from a modification of the loss function and a straightforward
procedure for choosing the hyper-parameters. An ablation study shows on several
UCI Machine Learning Repository datasets, the benefit of using this modified
loss function and an overcomplete structure, in terms of Root Mean Squared
Error (RMSE) of reconstruction. This numerical study is completed by comparing
the mDAE methodology with eight other methods (four standard and four more
recent). A criterion called Mean Distance to Best (MDB) is proposed to measure
how a method performs globally well on all datasets. This criterion is defined
as the mean (over the datasets) of the distances between the RMSE of the
considered method and the RMSE of the best method. According to this criterion,
the mDAE methodology was consistently ranked among the top methods (along with
SoftImput and missForest), while the four more recent methods were
systematically ranked last. The Python code of the numerical study will be
available on GitHub so that results can be reproduced or generalized with other
datasets and methods.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12847v1
"Towards Fairness in AI for Melanoma Detection: Systemic Review and
  Recommendations","Laura N Montoya, Jennafer Shae Roberts, Belen Sanchez Hidalgo",2024-11-19T20:31:38Z,"Early and accurate melanoma detection is crucial for improving patient
outcomes. Recent advancements in artificial intelligence AI have shown promise
in this area, but the technologys effectiveness across diverse skin tones
remains a critical challenge. This study conducts a systematic review and
preliminary analysis of AI based melanoma detection research published between
2013 and 2024, focusing on deep learning methodologies, datasets, and skin tone
representation. Our findings indicate that while AI can enhance melanoma
detection, there is a significant bias towards lighter skin tones. To address
this, we propose including skin hue in addition to skin tone as represented by
the LOreal Color Chart Map for a more comprehensive skin tone assessment
technique. This research highlights the need for diverse datasets and robust
evaluation metrics to develop AI models that are equitable and effective for
all patients. By adopting best practices outlined in a PRISMA Equity framework
tailored for healthcare and melanoma detection, we can work towards reducing
disparities in melanoma outcomes.","cs.CY, cs.CV, cs.HC, eess.IV",cs.CY,http://arxiv.org/abs/2411.12846v1
Reward Modeling with Ordinal Feedback: Wisdom of the Crowd,"Shang Liu, Yu Pan, Guanting Chen, Xiaocheng Li",2024-11-19T20:17:04Z,"Learning a reward model (RM) from human preferences has been an important
component in aligning large language models (LLMs). The canonical setup of
learning RMs from pairwise preference data is rooted in the classic
Bradley-Terry (BT) model that accepts binary feedback, i.e., the label being
either Response 1 is better than Response 2, or the opposite. Such a setup
inevitably discards potentially useful samples (such as ""tied"" between the two
responses) and loses more fine-grained information (such as ""slightly better"").
In this paper, we propose a framework for learning RMs under ordinal feedback
which generalizes the case of binary preference feedback to any arbitrary
granularity. Specifically, we first identify a marginal unbiasedness condition,
which generalizes the assumption of the BT model in the existing binary
feedback setting. The condition validates itself via the sociological concept
of the wisdom of the crowd. Under the condition, we develop a natural
probability model for pairwise preference data under ordinal feedback and
analyze its properties. We prove the statistical benefits of ordinal feedback
in terms of reducing the Rademacher complexity compared to the case of binary
feedback. The proposed learning objective and the theory also extend to hinge
loss and direct policy optimization (DPO). In particular, the theoretical
analysis may be of independent interest when applying to a seemingly unrelated
problem of knowledge distillation to interpret the bias-variance trade-off
therein. The framework also sheds light on writing guidance for human
annotators. Our numerical experiments validate that fine-grained feedback leads
to better reward learning for both in-distribution and out-of-distribution
settings. Further experiments show that incorporating a certain proportion of
samples with tied preference boosts RM learning.","cs.LG, cs.AI, cs.CL, stat.ML",cs.LG,http://arxiv.org/abs/2411.12843v1
Data-to-Model Distillation: Data-Efficient Learning Framework,"Ahmad Sajedi, Samir Khaki, Lucy Z. Liu, Ehsan Amjadian, Yuri A. Lawryshyn, Konstantinos N. Plataniotis",2024-11-19T20:10:28Z,"Dataset distillation aims to distill the knowledge of a large-scale real
dataset into small yet informative synthetic data such that a model trained on
it performs as well as a model trained on the full dataset. Despite recent
progress, existing dataset distillation methods often struggle with
computational efficiency, scalability to complex high-resolution datasets, and
generalizability to deep architectures. These approaches typically require
retraining when the distillation ratio changes, as knowledge is embedded in raw
pixels. In this paper, we propose a novel framework called Data-to-Model
Distillation (D2M) to distill the real dataset's knowledge into the learnable
parameters of a pre-trained generative model by aligning rich representations
extracted from real and generated images. The learned generative model can then
produce informative training images for different distillation ratios and deep
architectures. Extensive experiments on 15 datasets of varying resolutions show
D2M's superior performance, re-distillation efficiency, and cross-architecture
generalizability. Our method effectively scales up to high-resolution 128x128
ImageNet-1K. Furthermore, we verify D2M's practical benefits for downstream
applications in neural architecture search.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.12841v1
"Anticipatory Planning for Performant Long-Lived Robot in Large-Scale
  Home-Like Environments","Md Ridwan Hossain Talukder, Raihan Islam Arnob, Gregory J. Stein",2024-11-19T19:49:43Z,"We consider the setting where a robot must complete a sequence of tasks in a
persistent large-scale environment, given one at a time. Existing task planners
often operate myopically, focusing solely on immediate goals without
considering the impact of current actions on future tasks. Anticipatory
planning, which reduces the joint objective of the immediate planning cost of
the current task and the expected cost associated with future subsequent tasks,
offers an approach for improving long-lived task planning. However, applying
anticipatory planning in large-scale environments presents significant
challenges due to the sheer number of assets involved, which strains the
scalability of learning and planning. In this research, we introduce a
model-based anticipatory task planning framework designed to scale to
large-scale realistic environments. Our framework uses a GNN in particular via
a representation inspired by a 3D Scene Graph to learn the essential properties
of the environment crucial to estimating the state's expected cost and a
sampling-based procedure for practical large-scale anticipatory planning. Our
experimental results show that our planner reduces the cost of task sequence by
5.38% in home and 31.5% in restaurant settings. If given time to prepare in
advance using our model reduces task sequence costs by 40.6% and 42.5%,
respectively.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12837v1
"Generalized Prompt Tuning: Adapting Frozen Univariate Time Series
  Foundation Models for Multivariate Healthcare Time Series","Mingzhu Liu, Angela H. Chen, George H. Chen",2024-11-19T19:20:58Z,"Time series foundation models are pre-trained on large datasets and are able
to achieve state-of-the-art performance in diverse tasks. However, to date,
there has been limited work demonstrating how well these models perform in
medical applications, where labeled data can be scarce. Further, we observe
that currently, the majority of time series foundation models either are
univariate in nature, or assume channel independence, meaning that they handle
multivariate time series but do not model how the different variables relate.
In this paper, we propose a prompt-tuning-inspired fine-tuning technique,
Generalized Prompt Tuning (Gen-P-Tuning), that enables us to adapt an existing
univariate time series foundation model (treated as frozen) to handle
multivariate time series prediction. Our approach provides a way to combine
information across channels (variables) of multivariate time series. We
demonstrate the effectiveness of our fine-tuning approach against various
baselines on two MIMIC classification tasks, and on influenza-like illness
forecasting.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12824v1
What Makes a Good Dataset for Knowledge Distillation?,"Logan Frank, Jim Davis",2024-11-19T19:10:12Z,"Knowledge distillation (KD) has been a popular and effective method for model
compression. One important assumption of KD is that the teacher's original
dataset will also be available when training the student. However, in
situations such as continual learning and distilling large models trained on
company-withheld datasets, having access to the original data may not always be
possible. This leads practitioners towards utilizing other sources of
supplemental data, which could yield mixed results. One must then ask: ""what
makes a good dataset for transferring knowledge from teacher to student?"" Many
would assume that only real in-domain imagery is viable, but is that the only
option? In this work, we explore multiple possible surrogate distillation
datasets and demonstrate that many different datasets, even unnatural synthetic
imagery, can serve as a suitable alternative in KD. From examining these
alternative datasets, we identify and present various criteria describing what
makes a good dataset for distillation. Source code will be available in the
future.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12817v1
"ACING: Actor-Critic for Instruction Learning in Black-Box Large Language
  Models","Salma Kharrat, Fares Fourati, Marco Canini",2024-11-19T18:58:03Z,"The effectiveness of Large Language Models (LLMs) in solving tasks vastly
depends on the quality of the instructions, which often require fine-tuning
through extensive human effort. This highlights the need for automated
instruction optimization; however, this optimization is particularly
challenging when dealing with black-box LLMs, where model parameters and
gradients remain inaccessible. We propose ACING, a task-specific prompt
optimization approach framed as a stateless continuous-action Reinforcement
Learning (RL) problem, known as the continuum bandit setting. ACING leverages
an actor-critic-based method to optimize prompts, learning from
non-differentiable reward signals. We validate ACING by optimizing prompts for
ChatGPT on 30 instruction-based tasks. ACING consistently outperforms baseline
methods, achieving a median score improvement of 10 percentage points.
Furthermore, ACING not only recovers but also surpasses human-crafted expert
instructions, achieving up to a 39 percentage point improvement against human
benchmarks.","cs.CL, cs.AI, cs.LG, cs.SY, eess.SY, math.OC",cs.CL,http://arxiv.org/abs/2411.12736v1
Soft Robotic Dynamic In-Hand Pen Spinning,"Yunchao Yao, Uksang Yoo, Jean Oh, Christopher G. Atkeson, Jeffrey Ichnowski",2024-11-19T18:57:41Z,"Dynamic in-hand manipulation remains a challenging task for soft robotic
systems that have demonstrated advantages in safe compliant interactions but
struggle with high-speed dynamic tasks. In this work, we present SWIFT, a
system for learning dynamic tasks using a soft and compliant robotic hand.
Unlike previous works that rely on simulation, quasi-static actions and precise
object models, the proposed system learns to spin a pen through trial-and-error
using only real-world data without requiring explicit prior knowledge of the
pen's physical attributes. With self-labeled trials sampled from the real
world, the system discovers the set of pen grasping and spinning primitive
parameters that enables a soft hand to spin a pen robustly and reliably. After
130 sampled actions per object, SWIFT achieves 100% success rate across three
pens with different weights and weight distributions, demonstrating the
system's generalizability and robustness to changes in object properties. The
results highlight the potential for soft robotic end-effectors to perform
dynamic tasks including rapid in-hand manipulation. We also demonstrate that
SWIFT generalizes to spinning items with different shapes and weights such as a
brush and a screwdriver which we spin with 10/10 and 5/10 success rates
respectively. Videos, data, and code are available at
https://soft-spin.github.io.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12734v1
Benchmarking Positional Encodings for GNNs and Graph Transformers,"Florian Grötschla, Jiaqing Xie, Roger Wattenhofer",2024-11-19T18:57:01Z,"Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs)
have been driven by innovations in architectures and Positional Encodings
(PEs), which are critical for augmenting node features and capturing graph
topology. PEs are essential for GTs, where topological information would
otherwise be lost without message-passing. However, PEs are often tested
alongside novel architectures, making it difficult to isolate their effect on
established models. To address this, we present a comprehensive benchmark of
PEs in a unified framework that includes both message-passing GNNs and GTs. We
also establish theoretical connections between MPNNs and GTs and introduce a
sparsified GRIT attention mechanism to examine the influence of global
connectivity. Our findings demonstrate that previously untested combinations of
GNN architectures and PEs can outperform existing methods and offer a more
comprehensive picture of the state-of-the-art. To support future research and
experimentation in our framework, we make the code publicly available.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12732v1
"Reinforcement Learning, Collusion, and the Folk Theorem","Galit Askenazi-Golan, Domenico Mergoni Cecchelli, Edward Plumb",2024-11-19T18:45:55Z,"We explore the behaviour emerging from learning agents repeatedly interacting
strategically for a wide range of learning dynamics that includes projected
gradient, replicator and log-barrier dynamics. Going beyond the
better-understood classes of potential games and zero-sum games, we consider
the setting of a general repeated game with finite recall, for different forms
of monitoring. We obtain a Folk Theorem-like result and characterise the set of
payoff vectors that can be obtained by these dynamics, discovering a wide range
of possibilities for the emergence of algorithmic collusion.","cs.GT, econ.TH, stat.ML",cs.GT,http://arxiv.org/abs/2411.12725v1
Heuristic-Free Multi-Teacher Learning,"Huy Thong Nguyen, En-Hung Chu, Lenord Melvix, Jazon Jiao, Chunglin Wen, Benjamin Louie",2024-11-19T18:45:16Z,"We introduce Teacher2Task, a novel framework for multi-teacher learning that
eliminates the need for manual aggregation heuristics. Existing multi-teacher
methods typically rely on such heuristics to combine predictions from multiple
teachers, often resulting in sub-optimal aggregated labels and the propagation
of aggregation errors. Teacher2Task addresses these limitations by introducing
teacher-specific input tokens and reformulating the training process. Instead
of relying on aggregated labels, the framework transforms the training data,
consisting of ground truth labels and annotations from N teachers, into N+1
distinct tasks: N auxiliary tasks that predict the labeling styles of the N
individual teachers, and one primary task that focuses on the ground truth
labels. This approach, drawing upon principles from multiple learning
paradigms, demonstrates strong empirical results across a range of
architectures, modalities, and tasks.","cs.LG, cs.AI, cs.CV",cs.LG,http://arxiv.org/abs/2411.12724v1
"Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech
  Evaluation","Praveen Srinivasa Varadhan, Amogh Gulati, Ashwin Sankar, Srija Anand, Anirudh Gupta, Anirudh Mukherjee, Shiva Kumar Marepally, Ankur Bhatia, Saloni Jaju, Suvrat Bhooshan, Mitesh M. Khapra",2024-11-19T18:37:45Z,"Despite rapid advancements in TTS models, a consistent and robust human
evaluation framework is still lacking. For example, MOS tests fail to
differentiate between similar models, and CMOS's pairwise comparisons are
time-intensive. The MUSHRA test is a promising alternative for evaluating
multiple TTS systems simultaneously, but in this work we show that its reliance
on matching human reference speech unduly penalises the scores of modern TTS
systems that can exceed human speech quality. More specifically, we conduct a
comprehensive assessment of the MUSHRA test, focusing on its sensitivity to
factors such as rater variability, listener fatigue, and reference bias. Based
on our extensive evaluation involving 471 human listeners across Hindi and
Tamil we identify two primary shortcomings: (i) reference-matching bias, where
raters are unduly influenced by the human reference, and (ii) judgement
ambiguity, arising from a lack of clear fine-grained guidelines. To address
these issues, we propose two refined variants of the MUSHRA test. The first
variant enables fairer ratings for synthesized samples that surpass human
reference quality. The second variant reduces ambiguity, as indicated by the
relatively lower variance across raters. By combining these approaches, we
achieve both more reliable and more fine-grained assessments. We also release
MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind
collection for Indian languages, aiding in analyzing human preferences and
developing automatic metrics for evaluating TTS systems.","cs.CL, cs.LG, cs.SD, eess.AS",cs.CL,http://arxiv.org/abs/2411.12719v1
"UBSoft: A Simulation Platform for Robotic Skill Learning in Unbounded
  Soft Environments","Chunru Lin, Jugang Fan, Yian Wang, Zeyuan Yang, Zhehuan Chen, Lixing Fang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan",2024-11-19T18:25:38Z,"It is desired to equip robots with the capability of interacting with various
soft materials as they are ubiquitous in the real world. While physics
simulations are one of the predominant methods for data collection and robot
training, simulating soft materials presents considerable challenges.
Specifically, it is significantly more costly than simulating rigid objects in
terms of simulation speed and storage requirements. These limitations typically
restrict the scope of studies on soft materials to small and bounded areas,
thereby hindering the learning of skills in broader spaces. To address this
issue, we introduce UBSoft, a new simulation platform designed to support
unbounded soft environments for robot skill acquisition. Our platform utilizes
spatially adaptive resolution scales, where simulation resolution dynamically
adjusts based on proximity to active robotic agents. Our framework markedly
reduces the demand for extensive storage space and computation costs required
for large-scale scenarios involving soft materials. We also establish a set of
benchmark tasks in our platform, including both locomotion and manipulation
tasks, and conduct experiments to evaluate the efficacy of various
reinforcement learning algorithms and trajectory optimization techniques, both
gradient-based and sampling-based. Preliminary results indicate that
sampling-based trajectory optimization generally achieves better results for
obtaining one trajectory to solve the task. Additionally, we conduct
experiments in real-world environments to demonstrate that advancements made in
our UBSoft simulator could translate to improved robot interactions with
large-scale soft material. More videos can be found at
https://vis-www.cs.umass.edu/ubsoft/.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12711v1
"Strengthening Fake News Detection: Leveraging SVM and Sophisticated Text
  Vectorization Techniques. Defying BERT?","Ahmed Akib Jawad Karim, Kazi Hafiz Md Asad, Aznur Azam",2024-11-19T18:15:46Z,"The rapid spread of misinformation, particularly through online platforms,
underscores the urgent need for reliable detection systems. This study explores
the utilization of machine learning and natural language processing,
specifically Support Vector Machines (SVM) and BERT, to detect news that are
fake. We employ three distinct text vectorization methods for SVM: Term
Frequency Inverse Document Frequency (TF-IDF), Word2Vec, and Bag of Words (BoW)
evaluating their effectiveness in distinguishing between genuine and fake news.
Additionally, we compare these methods against the transformer large language
model, BERT. Our comprehensive approach includes detailed preprocessing steps,
rigorous model implementation, and thorough evaluation to determine the most
effective techniques. The results demonstrate that while BERT achieves superior
accuracy with 99.98% and an F1-score of 0.9998, the SVM model with a linear
kernel and BoW vectorization also performs exceptionally well, achieving 99.81%
accuracy and an F1-score of 0.9980. These findings highlight that, despite
BERT's superior performance, SVM models with BoW and TF-IDF vectorization
methods come remarkably close, offering highly competitive performance with the
advantage of lower computational requirements.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12703v1
Learning multivariate Gaussians with imperfect advice,"Arnab Bhattacharyya, Davin Choo, Philips George John, Themis Gouleakis",2024-11-19T18:08:01Z,"We revisit the problem of distribution learning within the framework of
learning-augmented algorithms. In this setting, we explore the scenario where a
probability distribution is provided as potentially inaccurate advice on the
true, unknown distribution. Our objective is to develop learning algorithms
whose sample complexity decreases as the quality of the advice improves,
thereby surpassing standard learning lower bounds when the advice is
sufficiently accurate.
  Specifically, we demonstrate that this outcome is achievable for the problem
of learning a multivariate Gaussian distribution $N(\boldsymbol{\mu},
\boldsymbol{\Sigma})$ in the PAC learning setting. Classically, in the
advice-free setting, $\tilde{\Theta}(d^2/\varepsilon^2)$ samples are sufficient
and worst case necessary to learn $d$-dimensional Gaussians up to TV distance
$\varepsilon$ with constant probability. When we are additionally given a
parameter $\tilde{\boldsymbol{\Sigma}}$ as advice, we show that
$\tilde{O}(d^{2-\beta}/\varepsilon^2)$ samples suffices whenever $\|
\tilde{\boldsymbol{\Sigma}}^{-1/2} \boldsymbol{\Sigma}
\tilde{\boldsymbol{\Sigma}}^{-1/2} - \boldsymbol{I_d} \|_1 \leq \varepsilon
d^{1-\beta}$ (where $\|\cdot\|_1$ denotes the entrywise $\ell_1$ norm) for any
$\beta > 0$, yielding a polynomial improvement over the advice-free setting.","cs.LG, cs.DS, cs.IT, math.IT, stat.ML",cs.LG,http://arxiv.org/abs/2411.12700v1
Attribute Inference Attacks for Federated Regression Tasks,"Francesco Diana, Othmane Marfoq, Chuan Xu, Giovanni Neglia, Frédéric Giroire, Eoin Thomas",2024-11-19T18:06:06Z,"Federated Learning (FL) enables multiple clients, such as mobile phones and
IoT devices, to collaboratively train a global machine learning model while
keeping their data localized. However, recent studies have revealed that the
training phase of FL is vulnerable to reconstruction attacks, such as attribute
inference attacks (AIA), where adversaries exploit exchanged messages and
auxiliary public information to uncover sensitive attributes of targeted
clients. While these attacks have been extensively studied in the context of
classification tasks, their impact on regression tasks remains largely
unexplored. In this paper, we address this gap by proposing novel model-based
AIAs specifically designed for regression tasks in FL environments. Our
approach considers scenarios where adversaries can either eavesdrop on
exchanged messages or directly interfere with the training process. We
benchmark our proposed attacks against state-of-the-art methods using
real-world datasets. The results demonstrate a significant increase in
reconstruction accuracy, particularly in heterogeneous client datasets, a
common scenario in FL. The efficacy of our model-based AIAs makes them better
candidates for empirically quantifying privacy leakage for federated regression
tasks.","cs.LG, cs.AI, cs.CR",cs.LG,http://arxiv.org/abs/2411.12697v1
IMUVIE: Pickup Timeline Action Localization via Motion Movies,"John Clapham, Kenneth Koltermann, Yanfu Zhang, Yuming Sun, Evie N Burnet, Gang Zhou",2024-11-19T17:53:30Z,"Falls among seniors due to difficulties with tasks such as picking up objects
pose significant health and safety risks, impacting quality of life and
independence. Reliable, accessible assessment tools are critical for early
intervention but often require costly clinic-based equipment and trained
personnel, limiting their use in daily life. Existing wearable-based pickup
measurement solutions address some needs but face limitations in
generalizability.
  We present IMUVIE, a wearable system that uses motion movies and a
machine-learning model to automatically detect and measure pickup events,
providing a practical solution for frequent monitoring. IMUVIE's design
principles-data normalization, occlusion handling, and streamlined
visuals-enhance model performance and are adaptable to tasks beyond pickup
classification.
  In rigorous leave one subject out cross validation evaluations, IMUVIE
achieves exceptional window level localization accuracy of 91-92% for pickup
action classification on 256,291 motion movie frame candidates while
maintaining an event level recall of 97% when evaluated on 129 pickup events.
IMUVIE has strong generalization and performs well on unseen subjects. In an
interview survey, IMUVIE demonstrated strong user interest and trust, with ease
of use identified as the most critical factor for adoption. IMUVIE offers a
practical, at-home solution for fall risk assessment, facilitating early
detection of movement deterioration, and supporting safer, independent living
for seniors.","cs.LG, I.2; I.5.4; I.5.5; I.5.2; I.5; I.2.10; I.2.1; I.2.9; I.4.9; J.3; J.7",cs.LG,http://arxiv.org/abs/2411.12689v1
"Deep Learning-Driven Heat Map Analysis for Evaluating thickness of
  Wounded Skin Layers","Devakumar GR, JB Kaarthikeyan, Dominic Immanuel T, Sheena Christabel Pravin",2024-11-19T17:31:36Z,"Understanding the appropriate skin layer thickness in wounded sites is an
important tool to move forward on wound healing practices and treatment
protocols. Methods to measure depth often are invasive and less specific. This
paper introduces a novel method that is non-invasive with deep learning
techniques using classifying of skin layers that helps in measurement of wound
depth through heatmap analysis. A set of approximately 200 labeled images of
skin allows five classes to be distinguished: scars, wounds, and healthy skin,
among others. Each image has annotated key layers, namely the stratum cornetum,
the epidermis, and the dermis, in the software Roboflow. In the preliminary
stage, the Heatmap generator VGG16 was used to enhance the visibility of tissue
layers, based upon which their annotated images were used to train ResNet18
with early stopping techniques. It ended up at a very high accuracy rate of
97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,
and EfficientNet has been done where both EfficientNet and ResNet18 have
attained accuracy rates of almost 95.35%. For further hyperparameter tuning,
EfficientNet and ResNet18 were trained at six different learning rates to
determine the best model configuration. It has been noted that the accuracy has
huge variations with different learning rates. In the case of EfficientNet, the
maximum achievable accuracy was 95.35% at the rate of 0.0001. The same was true
for ResNet18, which also attained its peak value of 95.35% at the same rate.
These facts indicate that the model can be applied and utilized in actual-time,
non-invasive wound assessment, which holds a great promise to improve clinical
diagnosis and treatment planning.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12678v1
"IoT-Based 3D Pose Estimation and Motion Optimization for Athletes:
  Application of C3D and OpenPose","Fei Ren, Chao Ren, Tianyi Lyu",2024-11-19T17:29:59Z,"This study proposes the IoT-Enhanced Pose Optimization Network (IE-PONet) for
high-precision 3D pose estimation and motion optimization of track and field
athletes. IE-PONet integrates C3D for spatiotemporal feature extraction,
OpenPose for real-time keypoint detection, and Bayesian optimization for
hyperparameter tuning. Experimental results on NTURGB+D and FineGYM datasets
demonstrate superior performance, with AP\(^p50\) scores of 90.5 and 91.0, and
mAP scores of 74.3 and 74.0, respectively. Ablation studies confirm the
essential roles of each module in enhancing model accuracy. IE-PONet provides a
robust tool for athletic performance analysis and optimization, offering
precise technical insights for training and injury prevention. Future work will
focus on further model optimization, multimodal data integration, and
developing real-time feedback mechanisms to enhance practical applications.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.12676v1
Neurosymbolic Graph Enrichment for Grounded World Models,"Stefano De Giorgis, Aldo Gangemi, Alessandro Russo",2024-11-19T17:23:55Z,"The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.","cs.AI, cs.CL, cs.ET",cs.AI,http://arxiv.org/abs/2411.12671v1
"Constrained Coding and Deep Learning Aided Threshold Detection for
  Resistive Memories","Xingwei Zhong, Kui Cai, Guanghui Song, Weijie Wang, Yao Zhu",2024-11-19T17:21:43Z,"Resistive random access memory (ReRAM) is a promising emerging non-volatile
memory (NVM) technology that shows high potential for both data storage and
computing. However, its crossbar array architecture leads to the sneak path
problem, which may severely degrade the reliability of data stored in the ReRAM
cell. Due to the complication of memory physics and unique features of the
sneak path induced interference (SPI), it is difficult to derive an accurate
channel model for it. The deep learning (DL)-based detection scheme
\cite{zhong2020sneakdl} can better mitigate the SPI, at the cost of additional
power consumption and read latency. In this letter, we first propose a novel CC
scheme which can not only reduce the SPI in the memory array, but also
effectively differentiate the memory arrays into two categories of
sneak-path-free and sneak-path-affected arrays. For the sneak-path-free arrays,
we can use a simple middle-point threshold detector to detect the low and high
resistance cells of ReRAM. For the sneak-path-affected arrays, a DL detector is
first trained off-line (prior to the data detection of ReRAM). To avoid the
additional power consumption and latency introduced by the DL detector, we
further propose a DL-based threshold detector, whose detection threshold can be
derived based on the outputs of the DL detector. It is then utilized for the
online data detection of all the identified sneak-path-affected arrays.
Simulation results demonstrate that the above CC and DL aided threshold
detection scheme can effectively mitigate the SPI of the ReRAM array and
achieve better error rate performance than the prior art detection schemes,
without the prior knowledge of the channel.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.12669v1
"Machine Learning Approaches on Crop Pattern Recognition a Comparative
  Analysis","Kazi Hasibul Kabir, Md. Zahiruddin Aqib, Sharmin Sultana, Shamim Akhter",2024-11-19T17:19:20Z,"Monitoring agricultural activities is important to ensure food security.
Remote sensing plays a significant role for large-scale continuous monitoring
of cultivation activities. Time series remote sensing data were used for the
generation of the cropping pattern. Classification algorithms are used to
classify crop patterns and mapped agriculture land used. Some conventional
classification methods including support vector machine (SVM) and decision
trees were applied for crop pattern recognition. However, in this paper, we are
proposing Deep Neural Network (DNN) based classification to improve the
performance of crop pattern recognition and make a comparative analysis with
two (2) other machine learning approaches including Naive Bayes and Random
Forest.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.12667v1
Auto-Evaluation with Few Labels through Post-hoc Regression,"Benjamin Eyre, David Madras",2024-11-19T17:17:46Z,"Continually evaluating large generative models provides a unique challenge.
Often, human annotations are necessary to evaluate high-level properties of
these models (e.g. in text or images). However, collecting human annotations of
samples can be resource intensive, and using other machine learning systems to
provide the annotations, or automatic evaluation, can introduce systematic
errors into the evaluation. The Prediction Powered Inference (PPI) framework
provides a way of leveraging both the statistical power of automatic evaluation
and a small pool of labelled data to produce a low-variance, unbiased estimate
of the quantity being evaluated for. However, most work on PPI considers a
relatively sizable set of labelled samples, which is not always practical to
obtain. To this end, we present two new PPI-based techniques that leverage
robust regressors to produce even lower variance estimators in the few-label
regime.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.12665v1
PoM: Efficient Image and Video Generation with the Polynomial Mixer,"David Picard, Nicolas Dufour",2024-11-19T17:16:31Z,"Diffusion models based on Multi-Head Attention (MHA) have become ubiquitous
to generate high quality images and videos. However, encoding an image or a
video as a sequence of patches results in costly attention patterns, as the
requirements both in terms of memory and compute grow quadratically. To
alleviate this problem, we propose a drop-in replacement for MHA called the
Polynomial Mixer (PoM) that has the benefit of encoding the entire sequence
into an explicit state. PoM has a linear complexity with respect to the number
of tokens. This explicit state also allows us to generate frames in a
sequential fashion, minimizing memory and compute requirement, while still
being able to train in parallel. We show the Polynomial Mixer is a universal
sequence-to-sequence approximator, just like regular MHA. We adapt several
Diffusion Transformers (DiT) for generating images and videos with PoM
replacing MHA, and we obtain high quality samples while using less
computational resources. The code is available at
https://github.com/davidpicard/HoMM.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12663v1
Data-efficient Tactile Sensing with Electrical Impedance Tomography,"Huazhi Dong, Ronald B. Liu, Leo Micklem, Peisan Sharel E, Francesco Giorgio-Serchi, Yunjie Yang",2024-11-19T17:06:24Z,"Electrical Impedance Tomography (EIT)-inspired tactile sensors are gaining
attention in robotic tactile sensing due to their cost-effectiveness, safety,
and scalability with sparse electrode configurations. This paper presents a
data augmentation strategy for learning-based tactile reconstruction that
amplifies the original single-frame signal measurement into 32 distinct,
effective signal data for training. This approach supplements uncollected
conditions of position information, resulting in more accurate and
high-resolution tactile reconstructions. Data augmentation for EIT
significantly reduces the required EIT measurements and achieves promising
performance with even limited samples. Simulation results show that the
proposed method improves the correlation coefficient by over 12% and reduces
the relative error by over 21% under various noise levels. Furthermore, we
demonstrate that a standard deep neural network (DNN) utilizing the proposed
data augmentation reduces the required data down to 1/31 while achieving a
similar tactile reconstruction quality. Real-world tests further validate the
approach's effectiveness on a flexible EIT-based tactile sensor. These results
could help address the challenge of training tactile sensing networks with
limited available measurements, improving the accuracy and applicability of
EIT-based tactile sensing systems.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12658v1
"DLBacktrace: A Model Agnostic Explainability for any Deep Learning
  Models","Vinay Kumar Sankarapu, Chintan Chitroda, Yashwardhan Rathore, Neeraj Kumar Singh, Pratinav Seth",2024-11-19T16:54:30Z,"The rapid advancement of artificial intelligence has led to increasingly
sophisticated deep learning models, which frequently operate as opaque 'black
boxes' with limited transparency in their decision-making processes. This lack
of interpretability presents considerable challenges, especially in high-stakes
applications where understanding the rationale behind a model's outputs is as
essential as the outputs themselves. This study addresses the pressing need for
interpretability in AI systems, emphasizing its role in fostering trust,
ensuring accountability, and promoting responsible deployment in
mission-critical fields. To address the interpretability challenge in deep
learning, we introduce DLBacktrace, an innovative technique developed by the
AryaXAI team to illuminate model decisions across a wide array of domains,
including simple Multi Layer Perceptron (MLPs), Convolutional Neural Networks
(CNNs), Large Language Models (LLMs), Computer Vision Models, and more.
  We provide a comprehensive overview of the DLBacktrace algorithm and present
benchmarking results, comparing its performance against established
interpretability methods, such as SHAP, LIME, GradCAM, Integrated Gradients,
SmoothGrad, and Attention Rollout, using diverse task-based metrics. The
proposed DLBacktrace technique is compatible with various model architectures
built in PyTorch and TensorFlow, supporting models like Llama 3.2, other NLP
architectures such as BERT and LSTMs, computer vision models like ResNet and
U-Net, as well as custom deep neural network (DNN) models for tabular data.
This flexibility underscores DLBacktrace's adaptability and effectiveness in
enhancing model transparency across a broad spectrum of applications. The
library is open-sourced and available at https://github.com/AryaXAI/DLBacktrace .","cs.LG, cs.AI, cs.CL",cs.LG,http://arxiv.org/abs/2411.12643v1
"PyAWD: A Library for Generating Large Synthetic Datasets of Acoustic
  Wave Propagation with Devito","Pascal Tribel, Gianluca Bontempi",2024-11-19T16:49:58Z,"Seismic data is often sparse and unevenly distributed due to the high costs
and logistical challenges associated with deploying physical seismometers,
limiting the application of Machine Learning (ML) in earthquake analysis. To
address this gap, we introduce PyAWD, a Python library designed to generate
high-resolution synthetic datasets simulating spatio-temporal acoustic wave
propagation in both two-dimensional and three-dimensional heterogeneous media.
By allowing fine control over parameters such as wave speed, external forces,
spatial and temporal discretization, and media composition, PyAWD enables the
creation of ML-scale datasets that capture the complexity of seismic wave
behavior. We illustrate the library's potential with an epicenter retrieval
task, showcasing its suitability for designing complex, accurate seismic
problems that support advanced ML approaches in the absence or lack of dense
real-world data.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12636v1
Instant Policy: In-Context Imitation Learning via Graph Diffusion,"Vitalis Vosylius, Edward Johns",2024-11-19T16:45:52Z,"Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.","cs.RO, cs.AI, cs.CV, cs.LG",cs.RO,http://arxiv.org/abs/2411.12633v1
Exploring the Manifold of Neural Networks Using Diffusion Geometry,"Elliott Abel, Peyton Crevasse, Yvan Grinspan, Selma Mazioud, Folu Ogundipe, Kristof Reimann, Ellie Schueler, Andrew J. Steindl, Ellen Zhang, Dhananjay Bhaskar, Siddharth Viswanath, Yanlei Zhang, Tim G. J. Rudner, Ian Adelstein, Smita Krishnaswamy",2024-11-19T16:34:45Z,"Drawing motivation from the manifold hypothesis, which posits that most
high-dimensional data lies on or near low-dimensional manifolds, we apply
manifold learning to the space of neural networks. We learn manifolds where
datapoints are neural networks by introducing a distance between the hidden
layer representations of the neural networks. These distances are then fed to
the non-linear dimensionality reduction algorithm PHATE to create a manifold of
neural networks. We characterize this manifold using features of the
representation, including class separation, hierarchical cluster structure,
spectral entropy, and topological structure. Our analysis reveals that
high-performing networks cluster together in the manifold, displaying
consistent embedding patterns across all these features. Finally, we
demonstrate the utility of this approach for guiding hyperparameter
optimization and neural architecture search by sampling from the manifold.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12626v1
"Maps from Motion (MfM): Generating 2D Semantic Maps from Sparse
  Multi-view Images","Matteo Toso, Stefano Fiorini, Stuart James, Alessio Del Bue",2024-11-19T16:27:31Z,"World-wide detailed 2D maps require enormous collective efforts.
OpenStreetMap is the result of 11 million registered users manually annotating
the GPS location of over 1.75 billion entries, including distinctive landmarks
and common urban objects. At the same time, manual annotations can include
errors and are slow to update, limiting the map's accuracy. Maps from Motion
(MfM) is a step forward to automatize such time-consuming map making procedure
by computing 2D maps of semantic objects directly from a collection of
uncalibrated multi-view images. From each image, we extract a set of object
detections, and estimate their spatial arrangement in a top-down local map
centered in the reference frame of the camera that captured the image. Aligning
these local maps is not a trivial problem, since they provide incomplete, noisy
fragments of the scene, and matching detections across them is unreliable
because of the presence of repeated pattern and the limited appearance
variability of urban objects. We address this with a novel graph-based
framework, that encodes the spatial and semantic distribution of the objects
detected in each image, and learns how to combine them to predict the objects'
poses in a global reference system, while taking into account all possible
detection matches and preserving the topology observed in each image. Despite
the complexity of the problem, our best model achieves global 2D registration
with an average accuracy within 4 meters (i.e., below GPS accuracy) even on
sparse sequences with strong viewpoint change, on which COLMAP has an 80%
failure rate. We provide extensive evaluation on synthetic and real-world data,
showing how the method obtains a solution even in scenarios where standard
optimization techniques fail.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12620v1
"Leveraging Virtual Reality and AI Tutoring for Language Learning: A Case
  Study of a Virtual Campus Environment with OpenAI GPT Integration with Unity
  3D","Adithya TG, Abhinavaram N, Gowri Srinivasa",2024-11-19T16:26:19Z,"This paper presents a new approach to multiple language learning, with Hindi
the language to be learnt in our case, by using the integration of virtual
reality environments and AI enabled tutoring systems using OpenAIs GPT api
calls. We have developed a scenario which has a virtual campus environment
using Unity which focuses on a detailed representation of our universitys
buildings 11th floor, where most of the cultural and technological activities
take place. Within this virtual environment that we have created, we have an AI
tutor powered by OpenAI's GPT model which was called using an api which moves
around with the user. This provided language learning support in Hindi, as GPT
is able to take care of language translation. Our approach mainly involves
utilising speech to text, text to text conversion and text to speech
capabilities to facilitate real time interaction between users and the AI tutor
in the presence of internet. This research demonstrates the use of combining VR
technology with AI tutoring for immersive language learning experiences and
provides interaction.","cs.HC, cs.CL",cs.HC,http://arxiv.org/abs/2411.12619v1
"A Multimodal Approach Combining Structural and Cross-domain Textual
  Guidance for Weakly Supervised OCT Segmentation","Jiaqi Yang, Nitish Mehta, Xiaoling Hu, Chao Chen, Chia-Ling Tsai",2024-11-19T16:20:27Z,"Accurate segmentation of Optical Coherence Tomography (OCT) images is crucial
for diagnosing and monitoring retinal diseases. However, the labor-intensive
nature of pixel-level annotation limits the scalability of supervised learning
with large datasets. Weakly Supervised Semantic Segmentation (WSSS) provides a
promising alternative by leveraging image-level labels. In this study, we
propose a novel WSSS approach that integrates structural guidance with
text-driven strategies to generate high-quality pseudo labels, significantly
improving segmentation performance. In terms of visual information, our method
employs two processing modules that exchange raw image features and structural
features from OCT images, guiding the model to identify where lesions are
likely to occur. In terms of textual information, we utilize large-scale
pretrained models from cross-domain sources to implement label-informed textual
guidance and synthetic descriptive integration with two textual processing
modules that combine local semantic features with consistent synthetic
descriptions. By fusing these visual and textual components within a multimodal
framework, our approach enhances lesion localization accuracy. Experimental
results on three OCT datasets demonstrate that our method achieves
state-of-the-art performance, highlighting its potential to improve diagnostic
accuracy and efficiency in medical imaging.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.12615v1
STREAM: A Universal State-Space Model for Sparse Geometric Data,"Mark Schöne, Yash Bhisikar, Karan Bania, Khaleelulla Khan Nazeer, Christian Mayr, Anand Subramoney, David Kappel",2024-11-19T16:06:32Z,"Handling sparse and unstructured geometric data, such as point clouds or
event-based vision, is a pressing challenge in the field of machine vision.
Recently, sequence models such as Transformers and state-space models entered
the domain of geometric data. These methods require specialized preprocessing
to create a sequential view of a set of points. Furthermore, prior works
involving sequence models iterate geometric data with either uniform or learned
step sizes, implicitly relying on the model to infer the underlying geometric
structure. In this work, we propose to encode geometric structure explicitly
into the parameterization of a state-space model. State-space models are based
on linear dynamics governed by a one-dimensional variable such as time or a
spatial coordinate. We exploit this dynamic variable to inject relative
differences of coordinates into the step size of the state-space model. The
resulting geometric operation computes interactions between all pairs of N
points in O(N) steps. Our model deploys the Mamba selective state-space model
with a modified CUDA kernel to efficiently map sparse geometric data to modern
hardware. The resulting sequence model, which we call STREAM, achieves
competitive results on a range of benchmarks from point-cloud classification to
event-based vision and audio classification. STREAM demonstrates a powerful
inductive bias for sparse geometric data by improving the PointMamba baseline
when trained from scratch on the ModelNet40 and ScanObjectNN point cloud
analysis datasets. It further achieves, for the first time, 100% test accuracy
on all 11 classes of the DVS128 Gestures dataset.","cs.CV, cs.AI, cs.LG, cs.NE",cs.CV,http://arxiv.org/abs/2411.12603v1
"SAM Carries the Burden: A Semi-Supervised Approach Refining Pseudo
  Labels for Medical Segmentation","Ron Keuth, Lasse Hansen, Maren Balks, Ronja Jäger, Anne-Nele Schröder, Ludger Tüshaus, Mattias Heinrich",2024-11-19T16:06:21Z,"Semantic segmentation is a crucial task in medical imaging. Although
supervised learning techniques have proven to be effective in performing this
task, they heavily depend on large amounts of annotated training data. The
recently introduced Segment Anything Model (SAM) enables prompt-based
segmentation and offers zero-shot generalization to unfamiliar objects. In our
work, we leverage SAM's abstract object understanding for medical image
segmentation to provide pseudo labels for semi-supervised learning, thereby
mitigating the need for extensive annotated training data. Our approach refines
initial segmentations that are derived from a limited amount of annotated data
(comprising up to 43 cases) by extracting bounding boxes and seed points as
prompts forwarded to SAM. Thus, it enables the generation of dense segmentation
masks as pseudo labels for unlabelled data. The results show that training with
our pseudo labels yields an improvement in Dice score from $74.29\,\%$ to
$84.17\,\%$ and from $66.63\,\%$ to $74.87\,\%$ for the segmentation of bones
of the paediatric wrist and teeth in dental radiographs, respectively. As a
result, our method outperforms intensity-based post-processing methods,
state-of-the-art supervised learning for segmentation (nnU-Net), and the
semi-supervised mean teacher approach. Our Code is available on GitHub.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12602v1
Provable unlearning in topic modeling and downstream tasks,"Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal",2024-11-19T16:04:31Z,"Machine unlearning algorithms are increasingly important as legal concerns
arise around the provenance of training data, but verifying the success of
unlearning is often difficult. Provable guarantees for unlearning are often
limited to supervised learning settings. In this paper, we provide the first
theoretical guarantees for unlearning in the pre-training and fine-tuning
paradigm by studying topic models, simple bag-of-words language models that can
be adapted to solve downstream tasks like retrieval and classification. First,
we design a provably effective unlearning algorithm for topic models that
incurs a computational overhead independent of the size of the original
dataset. Our analysis additionally quantifies the deletion capacity of the
model -- i.e., the number of examples that can be unlearned without incurring a
significant cost in model performance. Finally, we formally extend our analyses
to account for adaptation to a given downstream task. In particular, we design
an efficient algorithm to perform unlearning after fine-tuning the topic model
via a linear head. Notably, we show that it is easier to unlearn pre-training
data from models that have been fine-tuned to a particular task, and one can
unlearn this data without modifying the base model.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12600v2
"CLIC: Contrastive Learning Framework for Unsupervised Image Complexity
  Representation","Shipeng Liu, Liang Zhao, Dengfeng Chen",2024-11-19T16:03:14Z,"As an essential visual attribute, image complexity affects human image
comprehension and directly influences the performance of computer vision tasks.
However, accurately assessing and quantifying image complexity faces
significant challenges. Previous works needed more generalization capabilities
and well-labeled datasets to learn image complexity features. However, creating
such datasets requires expensive manual labeling costs, and the models
inevitably learn about human subjective biases. To address the above problems,
we propose CLIC, an unsupervised framework based on contrastive learning, for
learning image complexity representations. The method learns image complexity
features on unlabeled data, avoiding the high labeling cost. Specifically, we
propose a unique positive and negative sample selection strategy to reinforce
the differences in complexity features. At the same time, we introduce an image
prior-based Complexity-Aware Loss to constrain the learning process of the
model. We conducted extensive experiments for verification, and the results
show that CLIC can effectively learn the image complexity representation. CLIC
obtained competitive results with supervised methods by fine-tuning on IC9600.
In addition, CLIC applied to downstream tasks shows significant performance
improvements, demonstrating the potential for application in various real-world
scenarios. \href{https://github.com/xauat-liushipeng/CLIC}{code}",cs.CV,cs.CV,http://arxiv.org/abs/2411.12792v1
Learning To Sample the Meta-Paths for Social Event Detection,"Congbo Ma, Hu Wang, Zitai Qiu, Shan Xue, Jia Wu, Jian Yang, Preslav Nakov, Quan Z. Sheng",2024-11-19T15:56:13Z,"Social media data is inherently rich, as it includes not only text content,
but also users, geolocation, entities, temporal information, and their
relationships. This data richness can be effectively modeled using
heterogeneous information networks (HINs) as it can handle multiple types of
nodes and relationships, allowing for a comprehensive representation of complex
interactions within social data. Meta-path-based methods use the sequences of
relationships between different types of nodes in an HIN to capture the diverse
and rich relationships within the social networks. However, the performance of
social event detection methods is highly sensitive to the selection of
meta-paths and existing meta-path based detectors either rely on human efforts
or struggle to determining the effective meta-path set for model training and
evaluation. In order to automatically discover the most important meta-paths,
we propose a simple, yet effective, end-to-end Learning To Sample (LTS)
framework for meta-path searching. Specifically, we build graphs that contain
not only user profiles, textual content, and details about entities, but also
the intricate relationships among them. The prioritized meta-paths, based on
their importance, are sampled from the maintained distribution and their
features are constructed before feeding into the social event detector. After
picking up the top-ranked meta-paths, we streamline the exponential increment
of meta-path combinations into a finite set of highly influential ones. The
chosen meta-paths, along with their respective weights, are then used to train
our social event detection model. As an alternative to social event detector
training, we further propose an extra non-parametric evaluation process in
order to determine the importance of each meta-path, which can further guide
the paths sampling during model training.",cs.SI,cs.SI,http://arxiv.org/abs/2411.12588v1
"Procedural Knowledge in Pretraining Drives Reasoning in Large Language
  Models","Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo",2024-11-19T15:47:12Z,"The capabilities and limitations of Large Language Models have been sketched
out in great detail in recent years, providing an intriguing yet conflicting
picture. On the one hand, LLMs demonstrate a general ability to solve problems.
On the other hand, they show surprising reasoning gaps when compared to humans,
casting doubt on the robustness of their generalisation strategies. The sheer
volume of data used in the design of LLMs has precluded us from applying the
method traditionally used to measure generalisation: train-test set separation.
To overcome this, we study what kind of generalisation strategies LLMs employ
when performing reasoning tasks by investigating the pretraining data they rely
on. For two models of different sizes (7B and 35B) and 2.5B of their
pretraining tokens, we identify what documents influence the model outputs for
three simple mathematical reasoning tasks and contrast this to the data that
are influential for answering factual questions. We find that, while the models
rely on mostly distinct sets of data for each factual question, a document
often has a similar influence across different reasoning questions within the
same task, indicating the presence of procedural knowledge. We further find
that the answers to factual questions often show up in the most influential
data. However, for reasoning questions the answers usually do not show up as
highly influential, nor do the answers to the intermediate reasoning steps.
When we characterise the top ranked documents for the reasoning questions
qualitatively, we confirm that the influential documents often contain
procedural knowledge, like demonstrating how to obtain a solution using
formulae or code. Our findings indicate that the approach to reasoning the
models use is unlike retrieval, and more like a generalisable strategy that
synthesises procedural knowledge from documents doing a similar form of
reasoning.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.12580v1
"Topological Symmetry Enhanced Graph Convolution for Skeleton-Based
  Action Recognition","Zeyu Liang, Hailun Xia, Naichuan Zheng, Huan Xu",2024-11-19T15:23:59Z,"Skeleton-based action recognition has achieved remarkable performance with
the development of graph convolutional networks (GCNs). However, most of these
methods tend to construct complex topology learning mechanisms while neglecting
the inherent symmetry of the human body. Additionally, the use of temporal
convolutions with certain fixed receptive fields limits their capacity to
effectively capture dependencies in time sequences. To address the issues, we
(1) propose a novel Topological Symmetry Enhanced Graph Convolution (TSE-GC) to
enable distinct topology learning across different channel partitions while
incorporating topological symmetry awareness and (2) construct a Multi-Branch
Deformable Temporal Convolution (MBDTC) for skeleton-based action recognition.
The proposed TSE-GC emphasizes the inherent symmetry of the human body while
enabling efficient learning of dynamic topologies. Meanwhile, the design of
MBDTC introduces the concept of deformable modeling, leading to more flexible
receptive fields and stronger modeling capacity of temporal dependencies.
Combining TSE-GC with MBDTC, our final model, TSE-GCN, achieves competitive
performance with fewer parameters compared with state-of-the-art methods on
three large datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. On the
cross-subject and cross-set evaluations of NTU RGB+D 120, the accuracies of our
model reach 90.0\% and 91.1\%, with 1.1M parameters and 1.38 GFLOPS for one
stream.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12560v2
"Recall and Refine: A Simple but Effective Source-free Open-set Domain
  Adaptation Framework","Ismail Nejjar, Hao Dong, Olga Fink",2024-11-19T15:18:50Z,"Open-set Domain Adaptation (OSDA) aims to adapt a model from a labeled source
domain to an unlabeled target domain, where novel classes - also referred to as
target-private unknown classes - are present. Source-free Open-set Domain
Adaptation (SF-OSDA) methods address OSDA without accessing labeled source
data, making them particularly relevant under privacy constraints. However,
SF-OSDA presents significant challenges due to distribution shifts and the
introduction of novel classes. Existing SF-OSDA methods typically rely on
thresholding the prediction entropy of a sample to identify it as either a
known or unknown class but fail to explicitly learn discriminative features for
the target-private unknown classes. We propose Recall and Refine (RRDA), a
novel SF-OSDA framework designed to address these limitations by explicitly
learning features for target-private unknown classes. RRDA employs a two-step
process. First, we enhance the model's capacity to recognize unknown classes by
training a target classifier with an additional decision boundary, guided by
synthetic samples generated from target domain features. This enables the
classifier to effectively separate known and unknown classes. In the second
step, we adapt the entire model to the target domain, addressing both domain
shifts and improving generalization to unknown classes. Any off-the-shelf
source-free domain adaptation method (e.g., SHOT, AaD) can be seamlessly
integrated into our framework at this stage. Extensive experiments on three
benchmark datasets demonstrate that RRDA significantly outperforms existing
SF-OSDA and OSDA methods.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12558v1
UMGAD: Unsupervised Multiplex Graph Anomaly Detection,"Xiang Li, Jianpeng Qi, Zhongying Zhao, Guanjie Zheng, Lei Cao, Junyu Dong, Yanwei Yu",2024-11-19T15:15:45Z,"Graph anomaly detection (GAD) is a critical task in graph machine learning,
with the primary objective of identifying anomalous nodes that deviate
significantly from the majority. This task is widely applied in various
real-world scenarios, including fraud detection and social network analysis.
However, existing GAD methods still face two major challenges: (1) They are
often limited to detecting anomalies in single-type interaction graphs and
struggle with multiple interaction types in multiplex heterogeneous graphs; (2)
In unsupervised scenarios, selecting appropriate anomaly score thresholds
remains a significant challenge for accurate anomaly detection. To address the
above challenges, we propose a novel Unsupervised Multiplex Graph Anomaly
Detection method, named UMGAD. We first learn multi-relational correlations
among nodes in multiplex heterogeneous graphs and capture anomaly information
during node attribute and structure reconstruction through graph-masked
autoencoder (GMAE). Then, to further weaken the influence of noise and
redundant information on abnormal information extraction, we generate
attribute-level and subgraph-level augmented-view graphs respectively, and
perform attribute and structure reconstruction through GMAE. Finally, We learn
to optimize node attributes and structural features through contrastive
learning between original-view and augmented-view graphs to improve the model's
ability to capture anomalies. Meanwhile, we also propose a new anomaly score
threshold selection strategy, which allows the model to be independent of the
ground truth in real unsupervised scenarios. Extensive experiments on four
datasets show that our \model significantly outperforms state-of-the-art
methods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1
across all datasets.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12556v1
Virtual Reality for Action Evaluation,"Mario De Lucas Garcia, Mark Roman Miller",2024-11-19T14:45:04Z,"Physical rehabilitation plays a crucial role in restoring functional
abilities, but traditional approaches often face challenges in terms of cost,
accessibility, and personalized monitoring. Asynchronous physical
rehabilitation has gained traction as a cost-effective and convenient
alternative, but it lacks real-time monitoring and assessment capabilities.
This study investigates the feasibility of using low-cost Virtual Reality (VR)
devices for action evaluation in rehabilitation exercises. We leverage
state-of-the-art deep learning models and evaluate their performance on three
data streams (head and hands) derived from existing rehabilitation datasets
that approximate VR headset and hand data. Our results demonstrate that VR
tracking data can be effectively utilized for action evaluation, paving the way
for more accessible and affordable remote monitoring solutions in physical
therapy. By leveraging artificial intelligence techniques and consumer-grade
virtual reality technology, this study proposes an approach that could
potentially address some of the challenges in asynchronous rehabilitation, such
as the need for expensive motion capture systems or in-person sessions.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12542v1
"Predicting Customer Satisfaction by Replicating the Survey Response
  Distribution","Etienne Manderscheid, Matthias Lee",2024-11-19T14:39:29Z,"For many call centers, customer satisfaction (CSAT) is a key performance
indicator (KPI). However, only a fraction of customers take the CSAT survey
after the call, leading to a biased and inaccurate average CSAT value, and
missed opportunities for coaching, follow-up, and rectification. Therefore,
call centers can benefit from a model predicting customer satisfaction on calls
where the customer did not complete the survey. Given that CSAT is a closely
monitored KPI, it is critical to minimize any bias in the average predicted
CSAT (pCSAT). In this paper, we introduce a method such that predicted CSAT
(pCSAT) scores accurately replicate the distribution of survey CSAT responses
for every call center with sufficient data in a live production environment.
The method can be applied to many multiclass classification problems to improve
the class balance and minimize its changes upon model updates.","cs.LG, cs.AI, cs.CL",cs.LG,http://arxiv.org/abs/2411.12539v1
Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues,"Riccardo Grazzi, Julien Siems, Jörg K. H. Franke, Arber Zela, Frank Hutter, Massimiliano Pontil",2024-11-19T14:35:38Z,"Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and
DeltaNet have emerged as efficient alternatives to Transformers in large
language modeling, offering linear scaling with sequence length and improved
training efficiency. However, LRNNs struggle to perform state-tracking which
may impair performance in tasks such as code evaluation or tracking a chess
game. Even parity, the simplest state-tracking task, which non-linear RNNs like
LSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et
al. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity
stems from restricting the value range of their diagonal state-transition
matrices to $[0, 1]$ and that incorporating negative values can resolve this
issue. We extend this result to non-diagonal LRNNs, which have recently shown
promise in models such as DeltaNet. We prove that finite precision LRNNs with
state-transition matrices having only positive eigenvalues cannot solve parity,
while complex eigenvalues are needed to count modulo $3$. Notably, we also
prove that LRNNs can learn any regular language when their state-transition
matrices are products of identity minus vector outer product matrices, each
with eigenvalues in the range $[-1, 1]$. Our empirical results confirm that
extending the eigenvalue range of models like Mamba and DeltaNet to include
negative values not only enables them to solve parity but consistently improves
their performance on state-tracking tasks. Furthermore, pre-training LRNNs with
an extended eigenvalue range for language modeling achieves comparable
performance and stability while showing promise on code and math data. Our work
enhances the expressivity of modern LRNNs, broadening their applicability
without changing the cost of training or inference.","cs.LG, cs.CL, cs.FL",cs.LG,http://arxiv.org/abs/2411.12537v1
"Contourlet Refinement Gate Framework for Thermal Spectrum Distribution
  Regularized Infrared Image Super-Resolution","Yang Zou, Zhixin Chen, Zhipeng Zhang, Xingyuan Li, Long Ma, Jinyuan Liu, Peng Wang, Yanning Zhang",2024-11-19T14:24:03Z,"Image super-resolution (SR) is a classical yet still active low-level vision
problem that aims to reconstruct high-resolution (HR) images from their
low-resolution (LR) counterparts, serving as a key technique for image
enhancement. Current approaches to address SR tasks, such as transformer-based
and diffusion-based methods, are either dedicated to extracting RGB image
features or assuming similar degradation patterns, neglecting the inherent
modal disparities between infrared and visible images. When directly applied to
infrared image SR tasks, these methods inevitably distort the infrared spectral
distribution, compromising the machine perception in downstream tasks. In this
work, we emphasize the infrared spectral distribution fidelity and propose a
Contourlet refinement gate framework to restore infrared modal-specific
features while preserving spectral distribution fidelity. Our approach captures
high-pass subbands from multi-scale and multi-directional infrared spectral
decomposition to recover infrared-degraded information through a gate
architecture. The proposed Spectral Fidelity Loss regularizes the spectral
frequency distribution during reconstruction, which ensures the preservation of
both high- and low-frequency components and maintains the fidelity of
infrared-specific features. We propose a two-stage prompt-learning optimization
to guide the model in learning infrared HR characteristics from LR degradation.
Extensive experiments demonstrate that our approach outperforms existing image
SR models in both visual and perceptual tasks while notably enhancing machine
perception in downstream tasks. Our code is available at
https://github.com/hey-it-s-me/CoRPLE.","cs.CV, 68T45, I.4.3",cs.CV,http://arxiv.org/abs/2411.12530v1
"Rethinking Top Probability from Multi-view for Distracted Driver
  Behaviour Localization","Quang Vinh Nguyen, Vo Hoang Thanh Son, Chau Truong Vinh Hoang, Duc Duy Nguyen, Nhat Huy Nguyen Minh, Soo-Hyung Kim",2024-11-19T14:18:02Z,"Naturalistic driving action localization task aims to recognize and
comprehend human behaviors and actions from video data captured during
real-world driving scenarios. Previous studies have shown great action
localization performance by applying a recognition model followed by
probability-based post-processing. Nevertheless, the probabilities provided by
the recognition model frequently contain confused information causing challenge
for post-processing. In this work, we adopt an action recognition model based
on self-supervise learning to detect distracted activities and give potential
action probabilities. Subsequently, a constraint ensemble strategy takes
advantages of multi-camera views to provide robust predictions. Finally, we
introduce a conditional post-processing operation to locate distracted
behaviours and action temporal boundaries precisely. Experimenting on test set
A2, our method obtains the sixth position on the public leaderboard of track 3
of the 2024 AI City Challenge.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12525v1
Data Pruning in Generative Diffusion Models,"Rania Briq, Jiangtao Wang, Steffan Kesselheim",2024-11-19T14:13:25Z,"Data pruning is the problem of identifying a core subset that is most
beneficial to training and discarding the remainder. While pruning strategies
are well studied for discriminative models like those used in classification,
little research has gone into their application to generative models.
Generative models aim to estimate the underlying distribution of the data, so
presumably they should benefit from larger datasets. In this work we aim to
shed light on the accuracy of this statement, specifically answer the question
of whether data pruning for generative diffusion models could have a positive
impact. Contrary to intuition, we show that eliminating redundant or noisy data
in large datasets is beneficial particularly when done strategically. We
experiment with several pruning methods including recent-state-of-art methods,
and evaluate over CelebA-HQ and ImageNet datasets. We demonstrate that a simple
clustering method outperforms other sophisticated and computationally demanding
methods. We further exhibit how we can leverage clustering to balance skewed
datasets in an unsupervised manner to allow fair sampling for underrepresented
populations in the data distribution, which is a crucial problem in generative
models.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.12523v1
"VMGNet: A Low Computational Complexity Robotic Grasping Network Based on
  VMamba with Multi-Scale Feature Fusion","Yuhao Jin, Qizhong Gao, Xiaohui Zhu, Yong Yue, Eng Gee Lim, Yuqing Chen, Prudence Wong, Yijie Chu",2024-11-19T14:07:17Z,"While deep learning-based robotic grasping technology has demonstrated strong
adaptability, its computational complexity has also significantly increased,
making it unsuitable for scenarios with high real-time requirements. Therefore,
we propose a low computational complexity and high accuracy model named VMGNet
for robotic grasping. For the first time, we introduce the Visual State Space
into the robotic grasping field to achieve linear computational complexity,
thereby greatly reducing the model's computational cost. Meanwhile, to improve
the accuracy of the model, we propose an efficient and lightweight multi-scale
feature fusion module, named Fusion Bridge Module, to extract and fuse
information at different scales. We also present a new loss function
calculation method to enhance the importance differences between subtasks,
improving the model's fitting ability. Experiments show that VMGNet has only
8.7G Floating Point Operations and an inference time of 8.1 ms on our devices.
VMGNet also achieved state-of-the-art performance on the Cornell and Jacquard
public datasets. To validate VMGNet's effectiveness in practical applications,
we conducted real grasping experiments in multi-object scenarios, and VMGNet
achieved an excellent performance with a 94.4% success rate in real-world
grasping tasks. The video for the real-world robotic grasping experiments is
available at https://youtu.be/S-QHBtbmLc4.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.12520v1
The Hermeneutic Turn of AI: Is the Machine Capable of Interpreting?,Remy Demichelis,2024-11-19T13:59:16Z,"This article aims to demonstrate how the approach to computing is being
disrupted by deep learning (artificial neural networks), not only in terms of
techniques but also in our interactions with machines. It also addresses the
philosophical tradition of hermeneutics (Don Ihde, Wilhelm Dilthey) to
highlight a parallel with this movement and to demystify the idea of human-like
AI.","cs.CY, cs.AI, cs.HC",cs.CY,http://arxiv.org/abs/2411.12517v1
Probe-Me-Not: Protecting Pre-trained Encoders from Malicious Probing,"Ruyi Ding, Tong Zhou, Lili Su, Aidong Adam Ding, Xiaolin Xu, Yunsi Fei",2024-11-19T13:50:08Z,"Adapting pre-trained deep learning models to customized tasks has become a
popular choice for developers to cope with limited computational resources and
data volume. More specifically, probing--training a downstream head on a
pre-trained encoder--has been widely adopted in transfer learning, which helps
to prevent overfitting and catastrophic forgetting. However, such
generalizability of pre-trained encoders raises concerns about the potential
misuse of probing for harmful intentions, such as discriminatory speculation
and warfare applications. In this work, we introduce EncoderLock, a novel
applicability authorization method designed to protect pre-trained encoders
from malicious probing, i.e., yielding poor performance on specified prohibited
domains while maintaining their utility in authorized ones. Achieving this
balance is challenging because of the opposite optimization objectives and the
variety of downstream heads that adversaries can utilize adaptively. To address
these challenges, EncoderLock employs two techniques: domain-aware weight
selection and updating to restrict applications on prohibited domains/tasks,
and self-challenging training scheme that iteratively strengthens resistance
against any potential downstream classifiers that adversaries may apply.
Moreover, recognizing the potential lack of data from prohibited domains in
practical scenarios, we introduce three EncoderLock variants with different
levels of data accessibility: supervised (prohibited domain data with labels),
unsupervised (prohibited domain data without labels), and zero-shot (no data or
labels available). We verify EncoderLock's effectiveness and practicality with
a real-world pre-trained Vision Transformer (ViT) encoder from Facebook. These
results underscore the valuable contributions EncoderLock brings to the
development of responsible AI.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12508v1
"ManiSkill-ViTac 2025: Challenge on Manipulation Skill Learning With
  Vision and Tactile Sensing","Chuanyu Li, Renjun Dang, Xiang Li, Zhiyuan Wu, Jing Xu, Hamidreza Kasaei, Roberto Calandra, Nathan Lepora, Shan Luo, Hao Su, Rui Chen",2024-11-19T13:42:18Z,"This article introduces the ManiSkill-ViTac Challenge 2025, which focuses on
learning contact-rich manipulation skills using both tactile and visual
sensing. Expanding upon the 2024 challenge, ManiSkill-ViTac 2025 includes 3
independent tracks: tactile manipulation, tactile-vision fusion manipulation,
and tactile sensor structure design. The challenge aims to push the boundaries
of robotic manipulation skills, emphasizing the integration of tactile and
visual data to enhance performance in complex, real-world tasks. Participants
will be evaluated using standardized metrics across both simulated and
real-world environments, spurring innovations in sensor design and
significantly advancing the field of vision-tactile fusion in robotics.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12503v1
Transformer Neural Processes -- Kernel Regression,"Daniel Jenson, Jhonathan Navott, Mengyan Zhang, Makkunda Sharma, Elizaveta Semenova, Seth Flaxman",2024-11-19T13:40:49Z,"Stochastic processes model various natural phenomena from disease
transmission to stock prices, but simulating and quantifying their uncertainty
can be computationally challenging. For example, modeling a Gaussian Process
with standard statistical methods incurs an $\mathcal{O}(n^3)$ penalty, and
even using state-of-the-art Neural Processes (NPs) incurs an $\mathcal{O}(n^2)$
penalty due to the attention mechanism. We introduce the Transformer Neural
Process - Kernel Regression (TNP-KR), a new architecture that incorporates a
novel transformer block we call a Kernel Regression Block (KRBlock), which
reduces the computational complexity of attention in transformer-based Neural
Processes (TNPs) from $\mathcal{O}((n_C+n_T)^2)$ to $O(n_C^2+n_Cn_T)$ by
eliminating masked computations, where $n_C$ is the number of context, and
$n_T$ is the number of test points, respectively, and a fast attention variant
that further reduces all attention calculations to $\mathcal{O}(n_C)$ in space
and time complexity. In benchmarks spanning such tasks as meta-regression,
Bayesian optimization, and image completion, we demonstrate that the full
variant matches the performance of state-of-the-art methods while training
faster and scaling two orders of magnitude higher in number of test points, and
the fast variant nearly matches that performance while scaling to millions of
both test and context points on consumer hardware.","cs.LG, cs.AI, stat.ML",cs.LG,http://arxiv.org/abs/2411.12502v1
"Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic
  Corpus","Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, Yasuhiro Sogawa",2024-11-19T13:31:53Z,"Large language models (LLMs) are capable of solving a wide range of tasks,
yet they have struggled with reasoning. To address this, we propose
$\textbf{Additional Logic Training (ALT)}$, which aims to enhance LLMs'
reasoning capabilities by program-generated logical reasoning samples. We first
establish principles for designing high-quality samples by integrating symbolic
logic theory and previous empirical insights. Then, based on these principles,
we construct a synthetic corpus named $\textbf{Formal Logic Deduction Diverse}$
($\textbf{FLD}$$^{\times 2}$), comprising numerous samples of multi-step
deduction with unknown facts, diverse reasoning rules, diverse linguistic
expressions, and challenging distractors. Finally, we empirically show that ALT
on FLD$^{\times2}$ substantially enhances the reasoning capabilities of
state-of-the-art LLMs, including LLaMA-3.1-70B. Improvements include gains of
up to 30 points on logical reasoning benchmarks, up to 10 points on math and
coding benchmarks, and 5 points on the benchmark suite BBH.","cs.LG, cs.AI, cs.LO",cs.LG,http://arxiv.org/abs/2411.12498v1
Bias Free Sentiment Analysis,Hubert Plisiecki,2024-11-19T13:23:53Z,"This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12493v1
Regular-pattern-sensitive CRFs for Distant Label Interactions,"Sean Papay, Roman Klinger, Sebastian Pado",2024-11-19T13:08:03Z,"Linear-chain conditional random fields (CRFs) are a common model component
for sequence labeling tasks when modeling the interactions between different
labels is important. However, the Markov assumption limits linear-chain CRFs to
only directly modeling interactions between adjacent labels. Weighted
finite-state transducers (FSTs) are a related approach which can be made to
model distant label-label interactions, but exact label inference is
intractable for these models in the general case, and the task of selecting an
appropriate automaton structure for the desired interaction types poses a
practical challenge. In this work, we present regular-pattern-sensitive CRFs
(RPCRFs), a method of enriching standard linear-chain CRFs with the ability to
learn long-distance label interactions which occur in user-specified patterns.
This approach allows users to write regular-expression label patterns concisely
specifying which types of interactions the model should take into account,
allowing the model to learn from data whether and in which contexts these
patterns occur. The result can be interpreted alternatively as a CRF augmented
with additional, non-local potentials, or as a finite-state transducer whose
structure is defined by a set of easily-interpretable patterns. Critically,
unlike the general case for FSTs (and for non-chain CRFs), exact training and
inference are tractable for many pattern sets. In this work, we detail how a
RPCRF can be automatically constructed from a set of user-specified patterns,
and demonstrate the model's effectiveness on synthetic data, showing how
different types of patterns can capture different nonlocal dependency
structures in label sequences.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.12484v1
"Robotic transcatheter tricuspid valve replacement with hybrid enhanced
  intelligence: a new paradigm and first-in-vivo study","Shuangyi Wang, Haichuan Lin, Yiping Xie, Ziqi Wang, Dong Chen, Longyue Tan, Xilong Hou, Chen Chen, Xiao-Hu Zhou, Shengtao Lin, Fei Pan, Kent Chak-Yu So, Zeng-Guang Hou",2024-11-19T13:00:47Z,"Transcatheter tricuspid valve replacement (TTVR) is the latest treatment for
tricuspid regurgitation and is in the early stages of clinical adoption.
Intelligent robotic approaches are expected to overcome the challenges of
surgical manipulation and widespread dissemination, but systems and protocols
with high clinical utility have not yet been reported. In this study, we
propose a complete solution that includes a passive stabilizer, robotic drive,
detachable delivery catheter and valve manipulation mechanism. Working towards
autonomy, a hybrid augmented intelligence approach based on reinforcement
learning, Monte Carlo probabilistic maps and human-robot co-piloted control was
introduced. Systematic tests in phantom and first-in-vivo animal experiments
were performed to verify that the system design met the clinical requirement.
Furthermore, the experimental results confirmed the advantages of co-piloted
control over conventional master-slave control in terms of time efficiency,
control efficiency, autonomy and stability of operation. In conclusion, this
study provides a comprehensive pathway for robotic TTVR and, to our knowledge,
completes the first animal study that not only successfully demonstrates the
application of hybrid enhanced intelligence in interventional robotics, but
also provides a solution with high application value for a cutting-edge
procedure.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.12478v1
"Comparing Prior and Learned Time Representations in Transformer Models
  of Timeseries","Natalia Koliou, Tatiana Boura, Stasinos Konstantopoulos, George Meramveliotakis, George Kosmadakis",2024-11-19T12:56:43Z,"What sets timeseries analysis apart from other machine learning exercises is
that time representation becomes a primary aspect of the experiment setup, as
it must adequately represent the temporal relations that are relevant for the
application at hand. In the work described here we study wo different
variations of the Transformer architecture: one where we use the fixed time
representation proposed in the literature and one where the time representation
is learned from the data. Our experiments use data from predicting the energy
output of solar panels, a task that exhibits known periodicities (daily and
seasonal) that is straight-forward to encode in the fixed time representation.
Our results indicate that even in an experiment where the phenomenon is
well-understood, it is difficult to encode prior knowledge due to side-effects
that are difficult to mitigate. We conclude that research work is needed to
work the human into the learning loop in ways that improve the robustness and
trust-worthiness of the network.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12476v1
SCIGS: 3D Gaussians Splatting from a Snapshot Compressive Image,"Zixu Wang, Hao Yang, Yu Guo, Fei Wang",2024-11-19T12:52:37Z,"Snapshot Compressive Imaging (SCI) offers a possibility for capturing
information in high-speed dynamic scenes, requiring efficient reconstruction
method to recover scene information. Despite promising results, current deep
learning-based and NeRF-based reconstruction methods face challenges: 1) deep
learning-based reconstruction methods struggle to maintain 3D structural
consistency within scenes, and 2) NeRF-based reconstruction methods still face
limitations in handling dynamic scenes. To address these challenges, we propose
SCIGS, a variant of 3DGS, and develop a primitive-level transformation network
that utilizes camera pose stamps and Gaussian primitive coordinates as
embedding vectors. This approach resolves the necessity of camera pose in
vanilla 3DGS and enhances multi-view 3D structural consistency in dynamic
scenes by utilizing transformed primitives. Additionally, a high-frequency
filter is introduced to eliminate the artifacts generated during the
transformation. The proposed SCIGS is the first to reconstruct a 3D explicit
scene from a single compressed image, extending its application to dynamic 3D
scenes. Experiments on both static and dynamic scenes demonstrate that SCIGS
not only enhances SCI decoding but also outperforms current state-of-the-art
methods in reconstructing dynamic 3D scenes from a single compressed image. The
code will be made available upon publication.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12471v1
"GaussianPretrain: A Simple Unified 3D Gaussian Representation for Visual
  Pre-training in Autonomous Driving","Shaoqing Xu, Fang Li, Shengyin Jiang, Ziying Song, Li Liu, Zhi-xin Yang",2024-11-19T12:19:45Z,"Self-supervised learning has made substantial strides in image processing,
while visual pre-training for autonomous driving is still in its infancy.
Existing methods often focus on learning geometric scene information while
neglecting texture or treating both aspects separately, hindering comprehensive
scene understanding. In this context, we are excited to introduce
GaussianPretrain, a novel pre-training paradigm that achieves a holistic
understanding of the scene by uniformly integrating geometric and texture
representations. Conceptualizing 3D Gaussian anchors as volumetric LiDAR
points, our method learns a deepened understanding of scenes to enhance
pre-training performance with detailed spatial structure and texture, achieving
that 40.6% faster than NeRF-based method UniPAD with 70% GPU memory only. We
demonstrate the effectiveness of GaussianPretrain across multiple 3D perception
tasks, showing significant performance improvements, such as a 7.05% increase
in NDS for 3D object detection, boosts mAP by 1.9% in HD map construction and
0.8% improvement on Occupancy prediction. These significant gains highlight
GaussianPretrain's theoretical innovation and strong practical potential,
promoting visual pre-training development for autonomous driving. Source code
will be available at https://github.com/Public-BOTs/GaussianPretrain",cs.CV,cs.CV,http://arxiv.org/abs/2411.12452v1
"Empirical Privacy Evaluations of Generative and Predictive Machine
  Learning Models -- A review and challenges for practice","Flavio Hafner, Chang Sun",2024-11-19T12:19:28Z,"Synthetic data generators, when trained using privacy-preserving techniques
like differential privacy, promise to produce synthetic data with formal
privacy guarantees, facilitating the sharing of sensitive data. However, it is
crucial to empirically assess the privacy risks associated with the generated
synthetic data before deploying generative technologies. This paper outlines
the key concepts and assumptions underlying empirical privacy evaluation in
machine learning-based generative and predictive models. Then, this paper
explores the practical challenges for privacy evaluations of generative models
for use cases with millions of training records, such as data from statistical
agencies and healthcare providers. Our findings indicate that methods designed
to verify the correct operation of the training algorithm are effective for
large datasets, but they often assume an adversary that is unrealistic in many
scenarios. Based on the findings, we highlight a crucial trade-off between the
computational feasibility of the evaluation and the level of realism of the
assumed threat model. Finally, we conclude with ideas and suggestions for
future research.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12451v1
"Large Language Models for Lossless Image Compression: Next-Pixel
  Prediction in Language Space is All You Need","Kecheng Chen, Pingping Zhang, Hui Liu, Jie Liu, Yibing Liu, Jixin Huang, Shiqi Wang, Hong Yan, Haoliang Li",2024-11-19T12:15:40Z,"We have recently witnessed that ``Intelligence"" and `` Compression"" are the
two sides of the same coin, where the language large model (LLM) with
unprecedented intelligence is a general-purpose lossless compressor for various
data modalities. This attribute particularly appeals to the lossless image
compression community, given the increasing need to compress high-resolution
images in the current streaming media era. Consequently, a spontaneous envision
emerges: Can the compression performance of the LLM elevate lossless image
compression to new heights? However, our findings indicate that the naive
application of LLM-based lossless image compressors suffers from a considerable
performance gap compared with existing state-of-the-art (SOTA) codecs on common
benchmark datasets. In light of this, we are dedicated to fulfilling the
unprecedented intelligence (compression) capacity of the LLM for lossless image
compression tasks, thereby bridging the gap between theoretical and practical
compression performance. Specifically, we propose P$^{2}$-LLM, a next-pixel
prediction-based LLM, which integrates various elaborated insights and
methodologies, \textit{e.g.,} pixel-level priors, the in-context ability of
LLM, and a pixel-level semantic preservation strategy, to enhance the
understanding capacity of pixel sequences for better next-pixel predictions.
Extensive experiments on benchmark datasets demonstrate that P$^{2}$-LLM can
beat SOTA classical and learned codecs.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.12448v1
"Dimension Reduction via Sum-of-Squares and Improved Clustering
  Algorithms for Non-Spherical Mixtures","Prashanti Anderson, Mitali Bafna, Rares-Darius Buhai, Pravesh K. Kothari, David Steurer",2024-11-19T11:58:51Z,"We develop a new approach for clustering non-spherical (i.e., arbitrary
component covariances) Gaussian mixture models via a subroutine, based on the
sum-of-squares method, that finds a low-dimensional separation-preserving
projection of the input data. Our method gives a non-spherical analog of the
classical dimension reduction, based on singular value decomposition, that
forms a key component of the celebrated spherical clustering algorithm of
Vempala and Wang [VW04] (in addition to several other applications).
  As applications, we obtain an algorithm to (1) cluster an arbitrary
total-variation separated mixture of $k$ centered (i.e., zero-mean) Gaussians
with $n\geq \operatorname{poly}(d) f(w_{\min}^{-1})$ samples and
$\operatorname{poly}(n)$ time, and (2) cluster an arbitrary total-variation
separated mixture of $k$ Gaussians with identical but arbitrary unknown
covariance with $n \geq d^{O(\log w_{\min}^{-1})} f(w_{\min}^{-1})$ samples and
$n^{O(\log w_{\min}^{-1})}$ time. Here, $w_{\min}$ is the minimum mixing weight
of the input mixture, and $f$ does not depend on the dimension $d$. Our
algorithms naturally extend to tolerating a dimension-independent fraction of
arbitrary outliers. Before this work, the techniques in the state-of-the-art
non-spherical clustering algorithms needed $d^{O(k)} f(w_{\min}^{-1})$ time and
samples for clustering such mixtures.
  Our results may come as a surprise in the context of the $d^{\Omega(k)}$
statistical query lower bound [DKS17] for clustering non-spherical Gaussian
mixtures. While this result is usually thought to rule out $d^{o(k)}$ cost
algorithms for the problem, our results show that the lower bounds can in fact
be circumvented for a remarkably general class of Gaussian mixtures.","cs.DS, cs.LG, stat.ML",cs.DS,http://arxiv.org/abs/2411.12438v1
STRisk: A Socio-Technical Approach to Assess Hacking Breaches Risk,"Hicham Hammouchi, Narjisse Nejjari, Ghita Mezzour, Mounir Ghogho, Houda Benbrahim",2024-11-19T11:52:10Z,"Data breaches have begun to take on new dimensions and their prediction is
becoming of great importance to organizations. Prior work has addressed this
issue mainly from a technical perspective and neglected other interfering
aspects such as the social media dimension. To fill this gap, we propose STRisk
which is a predictive system where we expand the scope of the prediction task
by bringing into play the social media dimension. We study over 3800 US
organizations including both victim and non-victim organizations. For each
organization, we design a profile composed of a variety of externally measured
technical indicators and social factors. In addition, to account for unreported
incidents, we consider the non-victim sample to be noisy and propose a noise
correction approach to correct mislabeled organizations. We then build several
machine learning models to predict whether an organization is exposed to
experience a hacking breach. By exploiting both technical and social features,
we achieve a Area Under Curve (AUC) score exceeding 98%, which is 12% higher
than the AUC achieved using only technical features. Furthermore, our feature
importance analysis reveals that open ports and expired certificates are the
best technical predictors, while spreadability and agreeability are the best
social predictors.","cs.CR, cs.LG",cs.CR,http://arxiv.org/abs/2411.12435v1
"Motif Channel Opened in a White-Box: Stereo Matching via Motif
  Correlation Graph","Ziyang Chen, Yongjun Zhang, Wenting Li, Bingshu Wang, Yong Zhao, C. L. Philip Chen",2024-11-19T11:26:21Z,"Real-world applications of stereo matching, such as autonomous driving, place
stringent demands on both safety and accuracy. However, learning-based stereo
matching methods inherently suffer from the loss of geometric structures in
certain feature channels, creating a bottleneck in achieving precise detail
matching. Additionally, these methods lack interpretability due to the
black-box nature of deep learning. In this paper, we propose MoCha-V2, a novel
learning-based paradigm for stereo matching. MoCha-V2 introduces the Motif
Correlation Graph (MCG) to capture recurring textures, which are referred to as
``motifs"" within feature channels. These motifs reconstruct geometric
structures and are learned in a more interpretable way. Subsequently, we
integrate features from multiple frequency domains through wavelet inverse
transformation. The resulting motif features are utilized to restore geometric
structures in the stereo matching process. Experimental results demonstrate the
effectiveness of MoCha-V2. MoCha-V2 achieved 1st place on the Middlebury
benchmark at the time of its release. Code is available at
https://github.com/ZYangChen/MoCha-Stereo.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12426v1
"Visual Cue Enhancement and Dual Low-Rank Adaptation for Efficient Visual
  Instruction Fine-Tuning","Pengkun Jiao, Bin Zhu, Jingjing Chen, Chong-Wah Ngo, Yu-Gang Jiang",2024-11-19T11:03:09Z,"Fine-tuning multimodal large language models (MLLMs) presents significant
challenges, including a reliance on high-level visual features that limits
fine-grained detail comprehension, and data conflicts that arise from task
complexity. To address these issues, we propose an efficient fine-tuning
framework with two novel approaches: Vision Cue Enhancement (VCE) and Dual
Low-Rank Adaptation (Dual-LoRA). VCE enhances the vision projector by
integrating multi-level visual cues, improving the model's ability to capture
fine-grained visual features. Dual-LoRA introduces a dual low-rank structure
for instruction tuning, decoupling learning into skill and task spaces to
enable precise control and efficient adaptation across diverse tasks. Our
method simplifies implementation, enhances visual comprehension, and improves
adaptability. Experiments on both downstream tasks and general benchmarks
demonstrate the effectiveness of our proposed approach.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12787v1
"Classification of Geographical Land Structure Using Convolution Neural
  Network and Transfer Learning","Mustafa M. Abd Zaid, Ahmed Abed Mohammed, Putra Sumari",2024-11-19T11:01:30Z,"Satellite imagery has dramatically revolutionized the field of geography by
giving academics, scientists, and policymakers unprecedented global access to
spatial data. Manual methods typically require significant time and effort to
detect the generic land structure in satellite images. This study can produce a
set of applications such as urban planning and development, environmental
monitoring, disaster management, etc. Therefore, the research presents a
methodology to minimize human labor, reducing the expenses and duration needed
to identify the land structure. This article developed a deep learning-based
approach to automate the process of classifying geographical land structures.
We used a satellite image dataset acquired from MLRSNet. The study compared the
performance of three architectures, namely CNN, ResNet-50, and Inception-v3. We
used three optimizers with any model: Adam, SGD, and RMSProp. We conduct the
training process for a fixed number of epochs, specifically 100 epochs, with a
batch size of 64. The ResNet-50 achieved an accuracy of 76.5% with the ADAM
optimizer, the Inception-v3 with RMSProp achieved an accuracy of 93.8%, and the
proposed approach, CNN with RMSProp optimizer, achieved the highest level of
performance and an accuracy of 94.8%. Moreover, a thorough examination of the
CNN model demonstrated its exceptional accuracy, recall, and F1 scores for all
categories, confirming its resilience and dependability in precisely detecting
various terrain formations. The results highlight the potential of deep
learning models in scene understanding, as well as their significance in
efficiently identifying and categorizing land structures from satellite
imagery.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12415v1
"Non-IID data in Federated Learning: A Systematic Review with Taxonomy,
  Metrics, Methods, Frameworks and Future Directions","Daniel M. Jimenez G., David Solans, Mikko Heikkila, Andrea Vitaletti, Nicolas Kourtellis, Aris Anagnostopoulos, Ioannis Chatzigiannakis",2024-11-19T09:53:28Z,"Recent advances in machine learning have highlighted Federated Learning (FL)
as a promising approach that enables multiple distributed users (so-called
clients) to collectively train ML models without sharing their private data.
While this privacy-preserving method shows potential, it struggles when data
across clients is not independent and identically distributed (non-IID) data.
The latter remains an unsolved challenge that can result in poorer model
performance and slower training times. Despite the significance of non-IID data
in FL, there is a lack of consensus among researchers about its classification
and quantification. This systematic review aims to fill that gap by providing a
detailed taxonomy for non-IID data, partition protocols, and metrics to
quantify data heterogeneity. Additionally, we describe popular solutions to
address non-IID data and standardized frameworks employed in FL with
heterogeneous data. Based on our state-of-the-art review, we present key
lessons learned and suggest promising future research directions.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12377v1
RedPajama: an Open Dataset for Training Large Language Models,"Maurice Weber, Daniel Fu, Quentin Anthony, Yonatan Oren, Shane Adams, Anton Alexandrov, Xiaozhong Lyu, Huu Nguyen, Xiaozhe Yao, Virginia Adams, Ben Athiwaratkun, Rahul Chalamala, Kezhen Chen, Max Ryabinin, Tri Dao, Percy Liang, Christopher Ré, Irina Rish, Ce Zhang",2024-11-19T09:35:28Z,"Large language models are increasingly becoming a cornerstone technology in
artificial intelligence, the sciences, and society as a whole, yet the optimal
strategies for dataset composition and filtering remain largely elusive. Many
of the top-performing models lack transparency in their dataset curation and
model development processes, posing an obstacle to the development of fully
open language models. In this paper, we identify three core data-related
challenges that must be addressed to advance open-source language models. These
include (1) transparency in model development, including the data curation
process, (2) access to large quantities of high-quality data, and (3)
availability of artifacts and metadata for dataset curation and analysis. To
address these challenges, we release RedPajama-V1, an open reproduction of the
LLaMA training dataset. In addition, we release RedPajama-V2, a massive
web-only dataset consisting of raw, unfiltered text data together with quality
signals and metadata. Together, the RedPajama datasets comprise over 100
trillion tokens spanning multiple domains and with their quality signals
facilitate the filtering of data, aiming to inspire the development of numerous
new datasets. To date, these datasets have already been used in the training of
strong language models used in production, such as Snowflake Arctic,
Salesforce's XGen and AI2's OLMo. To provide insight into the quality of
RedPajama, we present a series of analyses and ablation studies with
decoder-only language models with up to 1.6B parameters. Our findings
demonstrate how quality signals for web data can be effectively leveraged to
curate high-quality subsets of the dataset, underscoring the potential of
RedPajama to advance the development of transparent and high-performing
language models at scale.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.12372v1
Ultra-Sparse Memory Network,"Zihao Huang, Qiyang Min, Hongzhi Huang, Defa Zhu, Yutao Zeng, Ran Guo, Xun Zhou",2024-11-19T09:24:34Z,"It is widely acknowledged that the performance of Transformer models is
exponentially related to their number of parameters and computational
complexity. While approaches like Mixture of Experts (MoE) decouple parameter
count from computational complexity, they still face challenges in inference
due to high memory access costs. This work introduces UltraMem, incorporating
large-scale, ultra-sparse memory layer to address these limitations. Our
approach significantly reduces inference latency while maintaining model
performance. We also investigate the scaling laws of this new architecture,
demonstrating that it not only exhibits favorable scaling properties but
outperforms traditional models. In our experiments, we train networks with up
to 20 million memory slots. The results show that our method achieves
state-of-the-art inference speed and model performance within a given
computational budget.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12364v1
"Breathless: An 8-hour Performance Contrasting Human and Robot
  Expressiveness","Catie Cuan, Tianshuang Qiu, Shreya Ganti, Ken Goldberg",2024-11-19T09:20:51Z,"This paper describes the robot technology behind an original performance that
pairs a human dancer (Cuan) with an industrial robot arm for an eight-hour
dance that unfolds over the timespan of an American workday. To control the
robot arm, we combine a range of sinusoidal motions with varying amplitude,
frequency and offset at each joint to evoke human motions common in physical
labor such as stirring, digging, and stacking. More motions were developed
using deep learning techniques for video-based human-pose tracking and
extraction. We combine these pre-recorded motions with improvised robot motions
created live by putting the robot into teach-mode and triggering force sensing
from the robot joints onstage. All motions are combined with commercial and
original music using a custom suite of python software with AppleScript,
Keynote, and Zoom to facilitate on-stage communication with the dancer. The
resulting performance contrasts the expressivity of the human body with the
precision of robot machinery. Video, code and data are available on the project
website: https://sites.google.com/playing.studio/breathless","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.12361v1
"DynFocus: Dynamic Cooperative Network Empowers LLMs with Video
  Understanding","Yudong Han, Qingpei Guo, Liyuan Pan, Liu Liu, Yu Guan, Ming Yang",2024-11-19T09:16:54Z,"The challenge in LLM-based video understanding lies in preserving visual and
semantic information in long videos while maintaining a memory-affordable token
count. However, redundancy and correspondence in videos have hindered the
performance potential of existing methods. Through statistical learning on
current datasets, we observe that redundancy occurs in both repeated and
answer-irrelevant frames, and the corresponding frames vary with different
questions. This suggests the possibility of adopting dynamic encoding to
balance detailed video information preservation with token budget reduction. To
this end, we propose a dynamic cooperative network, DynFocus, for
memory-efficient video encoding in this paper. Specifically, i) a Dynamic Event
Prototype Estimation (DPE) module to dynamically select meaningful frames for
question answering; (ii) a Compact Cooperative Encoding (CCE) module that
encodes meaningful frames with detailed visual appearance and the remaining
frames with sketchy perception separately. We evaluate our method on five
publicly available benchmarks, and experimental results consistently
demonstrate that our method achieves competitive performance.","cs.CV, I.2.10",cs.CV,http://arxiv.org/abs/2411.12355v1
"DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for
  Semi-supervised Medical Image Segmentation","Bingli Wang, Houcheng Su, Nan Yin, Mengzhu Wang, Li Shen",2024-11-19T09:07:26Z,"As a technique to alleviate the pressure of data annotation, semi-supervised
learning (SSL) has attracted widespread attention. In the specific domain of
medical image segmentation, semi-supervised methods (SSMIS) have become a
research hotspot due to their ability to reduce the need for large amounts of
precisely annotated data. SSMIS focuses on enhancing the model's generalization
performance by leveraging a small number of labeled samples and a large number
of unlabeled samples. The latest sharpness-aware optimization (SAM) technique,
which optimizes the model by reducing the sharpness of the loss function, has
shown significant success in SSMIS. However, SAM and its variants may not fully
account for the distribution differences between different datasets. To address
this issue, we propose a sharpness-aware optimization method based on
$f$-divergence minimization (DiM) for semi-supervised medical image
segmentation. This method enhances the model's stability by fine-tuning the
sensitivity of model parameters and improves the model's adaptability to
different datasets through the introduction of $f$-divergence. By reducing
$f$-divergence, the DiM method not only improves the performance balance
between the source and target datasets but also prevents performance
degradation due to overfitting on the source dataset.","cs.CV, cs.AI, 68T07, 92C55, 62H35, I.2.6; I.4.10; J.3",cs.CV,http://arxiv.org/abs/2411.12350v1
Learning from Label Proportions and Covariate-shifted Instances,"Sagalpreet Singh, Navodita Sharma, Shreyas Havaldar, Rishi Saket, Aravindan Raghuveer",2024-11-19T08:36:34Z,"In many applications, especially due to lack of supervision or privacy
concerns, the training data is grouped into bags of instances (feature-vectors)
and for each bag we have only an aggregate label derived from the
instance-labels in the bag. In learning from label proportions (LLP) the
aggregate label is the average of the instance-labels in a bag, and a
significant body of work has focused on training models in the LLP setting to
predict instance-labels. In practice however, the training data may have fully
supervised albeit covariate-shifted source data, along with the usual target
data with bag-labels, and we wish to train a good instance-level predictor on
the target domain. We call this the covariate-shifted hybrid LLP problem. Fully
supervised covariate shifted data often has useful training signals and the
goal is to leverage them for better predictive performance in the hybrid LLP
setting. To achieve this, we develop methods for hybrid LLP which naturally
incorporate the target bag-labels along with the source instance-labels, in the
domain adaptation framework. Apart from proving theoretical guarantees bounding
the target generalization error, we also conduct experiments on several
publicly available datasets showing that our methods outperform LLP and domain
adaptation baselines as well techniques from previous related work.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12334v1
"Graph as a feature: improving node classification with non-neural
  graph-aware logistic regression","Simon Delarue, Thomas Bonald, Tiphaine Viard",2024-11-19T08:32:14Z,"Graph Neural Networks (GNNs) and their message passing framework that
leverages both structural and feature information, have become a standard
method for solving graph-based machine learning problems. However, these
approaches still struggle to generalise well beyond datasets that exhibit
strong homophily, where nodes of the same class tend to connect. This
limitation has led to the development of complex neural architectures that pose
challenges in terms of efficiency and scalability. In response to these
limitations, we focus on simpler and more scalable approaches and introduce
Graph-aware Logistic Regression (GLR), a non-neural model designed for node
classification tasks. Unlike traditional graph algorithms that use only a
fraction of the information accessible to GNNs, our proposed model
simultaneously leverages both node features and the relationships between
entities. However instead of relying on message passing, our approach encodes
each node's relationships as an additional feature vector, which is then
combined with the node's self attributes. Extensive experimental results,
conducted within a rigorous evaluation framework, show that our proposed GLR
approach outperforms both foundational and sophisticated state-of-the-art GNN
models in node classification tasks. Going beyond the traditional limited
benchmarks, our experiments indicate that GLR increases generalisation ability
while reaching performance gains in computation time up to two orders of
magnitude compared to it best neural competitor.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12330v1
Attributed Graph Clustering in Collaborative Settings,"Rui Zhang, Xiaoyang Hou, Zhihua Tian, Jian Liu, Qingbiao Wu, Kui Ren",2024-11-19T08:30:22Z,"Graph clustering is an unsupervised machine learning method that partitions
the nodes in a graph into different groups. Despite achieving significant
progress in exploiting both attributed and structured data information, graph
clustering methods often face practical challenges related to data isolation.
Moreover, the absence of collaborative methods for graph clustering limits
their effectiveness.
  In this paper, we propose a collaborative graph clustering framework for
attributed graphs, supporting attributed graph clustering over vertically
partitioned data with different participants holding distinct features of the
same data. Our method leverages a novel technique that reduces the sample
space, improving the efficiency of the attributed graph clustering method.
Furthermore, we compare our method to its centralized counterpart under a
proximity condition, demonstrating that the successful local results of each
participant contribute to the overall success of the collaboration.
  We fully implement our approach and evaluate its utility and efficiency by
conducting experiments on four public datasets. The results demonstrate that
our method achieves comparable accuracy levels to centralized attributed graph
clustering methods. Our collaborative graph clustering framework provides an
efficient and effective solution for graph clustering challenges related to
data isolation.","cs.LG, cs.SI",cs.LG,http://arxiv.org/abs/2411.12329v1
CLIP Unreasonable Potential in Single-Shot Face Recognition,Nhan T. Luu,2024-11-19T08:23:52Z,"Face recognition is a core task in computer vision designed to identify and
authenticate individuals by analyzing facial patterns and features. This field
intersects with artificial intelligence image processing and machine learning
with applications in security authentication and personalization. Traditional
approaches in facial recognition focus on capturing facial features like the
eyes, nose and mouth and matching these against a database to verify
identities. However challenges such as high false positive rates have persisted
often due to the similarity among individuals facial features. Recently
Contrastive Language Image Pretraining (CLIP) a model developed by OpenAI has
shown promising advancements by linking natural language processing with vision
tasks allowing it to generalize across modalities. Using CLIP's vision language
correspondence and single-shot finetuning the model can achieve lower false
positive rates upon deployment without the need of mass facial features
extraction. This integration demonstrating CLIP's potential to address
persistent issues in face recognition model performance without complicating
our training paradigm.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12319v2
"Faster Multi-GPU Training with PPLL: A Pipeline Parallelism Framework
  Leveraging Local Learning","Xiuyuan Guo, Chengqi Xu, Guinan Guo, Feiyu Zhu, Changpeng Cai, Peizhe Wang, Xiaoming Wei, Junhao Su, Jialin Gao",2024-11-19T08:09:18Z,"Currently, training large-scale deep learning models is typically achieved
through parallel training across multiple GPUs. However, due to the inherent
communication overhead and synchronization delays in traditional model
parallelism methods, seamless parallel training cannot be achieved, which, to
some extent, affects overall training efficiency. To address this issue, we
present PPLL (Pipeline Parallelism based on Local Learning), a novel framework
that leverages local learning algorithms to enable effective parallel training
across multiple GPUs. PPLL divides the model into several distinct blocks, each
allocated to a separate GPU. By utilizing queues to manage data transfers
between GPUs, PPLL ensures seamless cross-GPU communication, allowing multiple
blocks to execute forward and backward passes in a pipelined manner. This
design minimizes idle times and prevents bottlenecks typically caused by
sequential gradient updates, thereby accelerating the overall training process.
We validate PPLL through extensive experiments using ResNet and Vision
Transformer (ViT) architectures on CIFAR-10, SVHN, and STL-10 datasets. Our
results demonstrate that PPLL significantly enhances the training speed of the
local learning method while achieving comparable or even superior training
speed to traditional pipeline parallelism (PP) without sacrificing model
performance. In a 4-GPU training setup, PPLL accelerated local learning
training on ViT and ResNet by 162% and 33%, respectively, achieving 1.25x and
0.85x the speed of traditional pipeline parallelism.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12780v1
"C$^{2}$INet: Realizing Incremental Trajectory Prediction with
  Prior-Aware Continual Causal Intervention","Xiaohe Li, Feilong Huang, Zide Fan, Fangli Mou, Leilei Lin, Yingyan Hou, Lijie Wen",2024-11-19T08:01:20Z,"Trajectory prediction for multi-agents in complex scenarios is crucial for
applications like autonomous driving. However, existing methods often overlook
environmental biases, which leads to poor generalization. Additionally,
hardware constraints limit the use of large-scale data across environments, and
continual learning settings exacerbate the challenge of catastrophic
forgetting. To address these issues, we propose the Continual Causal
Intervention (C$^{2}$INet) method for generalizable multi-agent trajectory
prediction within a continual learning framework. Using variational inference,
we align environment-related prior with posterior estimator of confounding
factors in the latent space, thereby intervening in causal correlations that
affect trajectory representation. Furthermore, we store optimal variational
priors across various scenarios using a memory queue, ensuring continuous
debiasing during incremental task training. The proposed C$^{2}$INet enhances
adaptability to diverse tasks while preserving previous task information to
prevent catastrophic forgetting. It also incorporates pruning strategies to
mitigate overfitting. Comparative evaluations on three real and synthetic
complex datasets against state-of-the-art methods demonstrate that our proposed
method consistently achieves reliable prediction performance, effectively
mitigating confounding factors unique to different scenarios. This highlights
the practical value of our method for real-world applications.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.12313v1
Variable-Frequency Imitation Learning for Variable-Speed Motion,"Nozomu Masuya, Sho Sakaino, Toshiaki Tsuji",2024-11-19T07:55:01Z,"Conventional methods of imitation learning for variable-speed motion have
difficulty extrapolating speeds because they rely on learning models running at
a constant sampling frequency. This study proposes variable-frequency imitation
learning (VFIL), a novel method for imitation learning with learning models
trained to run at variable sampling frequencies along with the desired speeds
of motion. The experimental results showed that the proposed method improved
the velocity-wise accuracy along both the interpolated and extrapolated
frequency labels, in addition to a 12.5 % increase in the overall success rate.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12310v1
SNN-Based Online Learning of Concepts and Action Laws in an Open World,"Christel Grimaud, Dominique Longin, Andreas Herzig",2024-11-19T07:49:22Z,"We present the architecture of a fully autonomous, bio-inspired cognitive
agent built around a spiking neural network (SNN) implementing the agent's
semantic memory. The agent explores its universe and learns concepts of
objects/situations and of its own actions in a one-shot manner. While
object/situation concepts are unary, action concepts are triples made up of an
initial situation, a motor activity, and an outcome. They embody the agent's
knowledge of its universe's actions laws. Both kinds of concepts have different
degrees of generality. To make decisions the agent queries its semantic memory
for the expected outcomes of envisaged actions and chooses the action to take
on the basis of these predictions. Our experiments show that the agent handles
new situations by appealing to previously learned general concepts and rapidly
modifies its concepts to adapt to environment changes.","cs.AI, cs.LG, cs.NE, cs.RO",cs.AI,http://arxiv.org/abs/2411.12308v1
Emergence of Implicit World Models from Mortal Agents,"Kazuya Horibe, Naoto Yoshida",2024-11-19T07:43:30Z,"We discuss the possibility of world models and active exploration as emergent
properties of open-ended behavior optimization in autonomous agents. In
discussing the source of the open-endedness of living things, we start from the
perspective of biological systems as understood by the mechanistic approach of
theoretical biology and artificial life. From this perspective, we discuss the
potential of homeostasis in particular as an open-ended objective for
autonomous agents and as a general, integrative extrinsic motivation. We then
discuss the possibility of implicitly acquiring a world model and active
exploration through the internal dynamics of a network, and a hypothetical
architecture for this, by combining meta-reinforcement learning, which assumes
domain adaptation as a system that achieves robust homeostasis.","cs.NE, cs.LG",cs.NE,http://arxiv.org/abs/2411.12304v1
Physics-Guided Detector for SAR Airplanes,"Zhongling Huang, Long Liu, Shuxin Yang, Zhirui Wang, Gong Cheng, Junwei Han",2024-11-19T07:41:09Z,"The disperse structure distributions (discreteness) and variant scattering
characteristics (variability) of SAR airplane targets lead to special
challenges of object detection and recognition. The current deep learning-based
detectors encounter challenges in distinguishing fine-grained SAR airplanes
against complex backgrounds. To address it, we propose a novel physics-guided
detector (PGD) learning paradigm for SAR airplanes that comprehensively
investigate their discreteness and variability to improve the detection
performance. It is a general learning paradigm that can be extended to
different existing deep learning-based detectors with ""backbone-neck-head""
architectures. The main contributions of PGD include the physics-guided
self-supervised learning, feature enhancement, and instance perception, denoted
as PGSSL, PGFE, and PGIP, respectively. PGSSL aims to construct a
self-supervised learning task based on a wide range of SAR airplane targets
that encodes the prior knowledge of various discrete structure distributions
into the embedded space. Then, PGFE enhances the multi-scale feature
representation of a detector, guided by the physics-aware information learned
from PGSSL. PGIP is constructed at the detection head to learn the refined and
dominant scattering point of each SAR airplane instance, thus alleviating the
interference from the complex background. We propose two implementations,
denoted as PGD and PGD-Lite, and apply them to various existing detectors with
different backbones and detection heads. The experiments demonstrate the
flexibility and effectiveness of the proposed PGD, which can improve existing
detectors on SAR airplane detection with fine-grained classification task (an
improvement of 3.1\% mAP most), and achieve the state-of-the-art performance
(90.7\% mAP) on SAR-AIRcraft-1.0 dataset. The project is open-source at
\url{https://github.com/XAI4SAR/PGD}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12301v1
Consistency Regularization for Complementary Clothing Recommendations,"Shuiying Liao, P. Y. Mok, Li Li",2024-11-19T07:30:07Z,"This paper reports on the development of a Consistency Regularized model for
Bayesian Personalized Ranking (CR-BPR), addressing to the drawbacks in existing
complementary clothing recommendation methods, namely limited consistency and
biased learning caused by diverse feature scale of multi-modal data. Compared
to other product types, fashion preferences are inherently subjective and more
personal, and fashion are often presented, not by individual clothing product,
but with other complementary product(s) in a well coordinated fashion outfit.
Current complementary-product recommendation studies primarily focus on user
preference and product matching, this study further emphasizes the consistency
observed in user-product interactions as well as product-product interactions,
in the specific context of clothing matching. Most traditional approaches often
underplayed the impact of existing wardrobe items on future matching choices,
resulting in less effective preference prediction models. Moreover, many
multi-modal information based models overlook the limitations arising from
various feature scales being involved. To address these gaps, the CR-BPR model
integrates collaborative filtering techniques to incorporate both user
preference and product matching modeling, with a unique focus on consistency
regularization for each aspect. Additionally, the incorporation of a feature
scaling process further addresses the imbalances caused by different feature
scales, ensuring that the model can effectively handle multi-modal data without
being skewed by any particular type of feature. The effectiveness of the CR-BPR
model was validated through detailed analysis involving two benchmark datasets.
The results confirmed that the proposed approach significantly outperforms
existing models.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12295v1
SSEditor: Controllable Mask-to-Scene Generation with Diffusion Model,"Haowen Zheng, Yanyan Liang",2024-11-19T07:19:05Z,"Recent advancements in 3D diffusion-based semantic scene generation have
gained attention. However, existing methods rely on unconditional generation
and require multiple resampling steps when editing scenes, which significantly
limits their controllability and flexibility. To this end, we propose SSEditor,
a controllable Semantic Scene Editor that can generate specified target
categories without multiple-step resampling. SSEditor employs a two-stage
diffusion-based framework: (1) a 3D scene autoencoder is trained to obtain
latent triplane features, and (2) a mask-conditional diffusion model is trained
for customizable 3D semantic scene generation. In the second stage, we
introduce a geometric-semantic fusion module that enhance the model's ability
to learn geometric and semantic information. This ensures that objects are
generated with correct positions, sizes, and categories. Extensive experiments
on SemanticKITTI and CarlaSC demonstrate that SSEditor outperforms previous
approaches in terms of controllability and flexibility in target generation, as
well as the quality of semantic scene generation and reconstruction. More
importantly, experiments on the unseen Occ-3D Waymo dataset show that SSEditor
is capable of generating novel urban scenes, enabling the rapid construction of
3D scenes.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12290v1
"Construction of the UXAR-CT -- a User eXperience Questionnaire for
  Augmented Reality in Corporate Training","Stefan Graser, Martin Schrepp, Stephan Böhm",2024-11-19T07:17:37Z,"Measuring User Experience (UX) with questionnaires is essential for
developing and improving products. However, no domain-specific standardized UX
questionnaire exists for Augmented Reality (AR) in Corporate Training (CT).
Thus, this study introduces the UXAR-CT questionnaire - an AR-specific UX
questionnaire for CT environments. We describe the construction procedure and
the evaluation process of the questionnaire. A set of candidate items was
constructed, and a larger sample of participants evaluated several AR-based
learning scenarios with these items. Based on the results, we performed a
Principal Component Analysis (PCA) to identify relevant measurement items for
each scale. The three best-fitting items were selected based on the results to
form the final questionnaire. The first results regarding scale quality
indicate a high level of internal consistency. The final version of the UXAR-CT
questionnaire is provided and will be evaluated in further research.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12288v1
"DT-RaDaR: Digital Twin Assisted Robot Navigation using Differential
  Ray-Tracing","Sunday Amatare, Gaurav Singh, Raul Shakya, Aavash Kharel, Ahmed Alkhateeb, Debashri Roy",2024-11-19T07:06:56Z,"Autonomous system navigation is a well-researched and evolving field. Recent
advancements in improving robot navigation have sparked increased interest
among researchers and practitioners, especially in the use of sensing data.
However, this heightened focus has also raised significant privacy concerns,
particularly for robots that rely on cameras and LiDAR for navigation. Our
innovative concept of Radio Frequency (RF) map generation through ray-tracing
(RT) within digital twin environments effectively addresses these concerns. In
this paper, we propose DT-RaDaR, a robust privacy-preserving, deep
reinforcement learning-based framework for robot navigation that leverages RF
ray-tracing in both static and dynamic indoor scenarios as well as in smart
cities. We introduce a streamlined framework for generating RF digital twins
using open-source tools like Blender and NVIDIA's Sionna RT. This approach
allows for high-fidelity replication of real-world environments and RF
propagation models, optimized for service robot navigation. Several
experimental validations and results demonstrate the feasibility of the
proposed framework in indoor environments and smart cities, positioning our
work as a significant advancement toward the practical implementation of robot
navigation using ray-tracing-generated data.",cs.NI,cs.NI,http://arxiv.org/abs/2411.12284v1
libcll: an Extendable Python Toolkit for Complementary-Label Learning,"Nai-Xuan Ye, Tan-Ha Mai, Hsiu-Hsuan Wang, Wei-I Lin, Hsuan-Tien Lin",2024-11-19T06:56:24Z,"Complementary-label learning (CLL) is a weakly supervised learning paradigm
for multiclass classification, where only complementary labels -- indicating
classes an instance does not belong to -- are provided to the learning
algorithm. Despite CLL's increasing popularity, previous studies highlight two
main challenges: (1) inconsistent results arising from varied assumptions on
complementary label generation, and (2) high barriers to entry due to the lack
of a standardized evaluation platform across datasets and algorithms. To
address these challenges, we introduce \texttt{libcll}, an extensible Python
toolkit for CLL research. \texttt{libcll} provides a universal interface that
supports a wide range of generation assumptions, both synthetic and real-world
datasets, and key CLL algorithms. The toolkit is designed to mitigate
inconsistencies and streamline the research process, with easy installation,
comprehensive usage guides, and quickstart tutorials that facilitate efficient
adoption and implementation of CLL techniques. Extensive ablation studies
conducted with \texttt{libcll} demonstrate its utility in generating valuable
insights to advance future CLL research.","cs.LG, cs.AI, cs.CV",cs.LG,http://arxiv.org/abs/2411.12276v1
"A Review on Generative AI Models for Synthetic Medical Text, Time
  Series, and Longitudinal Data","Mohammad Loni, Fatemeh Poursalim, Mehdi Asadi, Arash Gharehbaghi",2024-11-19T06:53:54Z,"This paper presents the results of a novel scoping review on the practical
models for generating three different types of synthetic health records (SHRs):
medical text, time series, and longitudinal data. The innovative aspects of the
review, which incorporate study objectives, data modality, and research
methodology of the reviewed studies, uncover the importance and the scope of
the topic for the digital medicine context. In total, 52 publications met the
eligibility criteria for generating medical time series (22), longitudinal data
(17), and medical text (13). Privacy preservation was found to be the main
research objective of the studied papers, along with class imbalance, data
scarcity, and data imputation as the other objectives. The adversarial
network-based, probabilistic, and large language models exhibited superiority
for generating synthetic longitudinal data, time series, and medical texts,
respectively. Finding a reliable performance measure to quantify SHR
re-identification risk is the major research gap of the topic.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.12274v1
KDC-MAE: Knowledge Distilled Contrastive Mask Auto-Encoder,"Maheswar Bora, Saurabh Atreya, Aritra Mukherjee, Abhijit Das",2024-11-19T06:47:56Z,"In this work, we attempted to extend the thought and showcase a way forward
for the Self-supervised Learning (SSL) learning paradigm by combining
contrastive learning, self-distillation (knowledge distillation) and masked
data modelling, the three major SSL frameworks, to learn a joint and
coordinated representation. The proposed technique of SSL learns by the
collaborative power of different learning objectives of SSL. Hence to jointly
learn the different SSL objectives we proposed a new SSL architecture KDC-MAE,
a complementary masking strategy to learn the modular correspondence, and a
weighted way to combine them coordinately. Experimental results conclude that
the contrastive masking correspondence along with the KD learning objective has
lent a hand to performing better learning for multiple modalities over multiple
tasks.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12270v1
Entropy Bootstrapping for Weakly Supervised Nuclei Detection,"James Willoughby, Irina Voiculescu",2024-11-20T18:24:11Z,"Microscopy structure segmentation, such as detecting cells or nuclei,
generally requires a human to draw a ground truth contour around each instance.
Weakly supervised approaches (e.g. consisting of only single point labels) have
the potential to reduce this workload significantly. Our approach uses
individual point labels for an entropy estimation to approximate an underlying
distribution of cell pixels. We infer full cell masks from this distribution,
and use Mask-RCNN to produce an instance segmentation output. We compare this
point--annotated approach with training on the full ground truth masks. We show
that our method achieves a comparatively good level of performance, despite a
95% reduction in pixel labels.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13528v1
"Combining Autoregressive and Autoencoder Language Models for Text
  Classification",João Gonçalves,2024-11-20T12:49:42Z,"This paper presents CAALM-TC (Combining Autoregressive and Autoencoder
Language Models for Text Classification), a novel method that enhances text
classification by integrating autoregressive and autoencoder language models.
Autoregressive large language models such as Open AI's GPT, Meta's Llama or
Microsoft's Phi offer promising prospects for content analysis practitioners,
but they generally underperform supervised BERT based models for text
classification. CAALM leverages autoregressive models to generate contextual
information based on input texts, which is then combined with the original text
and fed into an autoencoder model for classification. This hybrid approach
capitalizes on the extensive contextual knowledge of autoregressive models and
the efficient classification capabilities of autoencoders. Experimental results
on four benchmark datasets demonstrate that CAALM consistently outperforms
existing methods, particularly in tasks with smaller datasets and more abstract
classification objectives. The findings indicate that CAALM offers a scalable
and effective solution for automated content analysis in social science
research that minimizes sample size requirements.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13282v1
Conversational Medical AI: Ready for Practice,"Antoine Lizée, Pierre-Auguste Beaucoté, James Whitbeck, Marion Doumeingts, Anaël Beaugnon, Isabelle Feldhaus",2024-11-19T19:00:31Z,"The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as ""good""
or ""excellent"" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.","cs.AI, cs.CY, cs.HC",cs.AI,http://arxiv.org/abs/2411.12808v1
"On the Accuracy and Precision of Moving Averages to Estimate Wi-Fi Link
  Quality","Gianluca Cena, Gabriele Formis, Matteo Rosani, Stefano Scanzio",2024-11-19T06:28:58Z,"The radio spectrum is characterized by a noticeable variability, which
impairs performance and determinism of every wireless communication technology.
To counteract this aspect, mechanisms like Minstrel are customarily employed in
real Wi-Fi devices, and the adoption of machine learning for optimization is
envisaged in next-generation Wi-Fi 8. All these approaches require
communication quality to be monitored at runtime.
  In this paper, the effectiveness of simple techniques based on moving
averages to estimate wireless link quality is analyzed, to assess their
advantages and weaknesses. Results can be used, e.g., as a baseline when
studying how artificial intelligence can be employed to mitigate
unpredictability of wireless networks by providing reliable estimates about
current spectrum conditions.","cs.NI, cs.LG",cs.NI,http://arxiv.org/abs/2411.12265v1
Prototype Optimization with Neural ODE for Few-Shot Learning,"Baoquan Zhang, Shanshan Feng, Bingqi Shan, Xutao Li, Yunming Ye, Yew-Soon Ong",2024-11-19T06:17:25Z,"Few-Shot Learning (FSL) is a challenging task, which aims to recognize novel
classes with few examples. Pre-training based methods effectively tackle the
problem by pre-training a feature extractor and then performing class
prediction via a cosine classifier with mean-based prototypes. Nevertheless,
due to the data scarcity, the mean-based prototypes are usually biased. In this
paper, we attempt to diminish the prototype bias by regarding it as a prototype
optimization problem. To this end, we propose a novel prototype optimization
framework to rectify prototypes, i.e., introducing a meta-optimizer to optimize
prototypes. Although the existing meta-optimizers can also be adapted to our
framework, they all overlook a crucial gradient bias issue, i.e., the
mean-based gradient estimation is also biased on sparse data. To address this
issue, in this paper, we regard the gradient and its flow as meta-knowledge and
then propose a novel Neural Ordinary Differential Equation (ODE)-based
meta-optimizer to optimize prototypes, called MetaNODE. Although MetaNODE has
shown superior performance, it suffers from a huge computational burden. To
further improve its computation efficiency, we conduct a detailed analysis on
MetaNODE and then design an effective and efficient MetaNODE extension version
(called E2MetaNODE). It consists of two novel modules: E2GradNet and E2Solver,
which aim to estimate accurate gradient flows and solve optimal prototypes in
an effective and efficient manner, respectively. Extensive experiments show
that 1) our methods achieve superior performance over previous FSL methods and
2) our E2MetaNODE significantly improves computation efficiency meanwhile
without performance degradation.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12259v1
A Digital Twin for Telesurgery under Intermittent Communication,"Junxiang Wang, Juan Antonio Barragan, Hisashi Ishida, Jingkai Guo, Yu-Chun Ku, Peter Kazanzides",2024-11-20T16:43:43Z,"Telesurgery is an effective way to deliver service from expert surgeons to
areas without immediate access to specialized resources. However, many of these
areas, such as rural districts or battlefields, might be subject to different
problems in communication, especially latency and intermittent periods of
communication outage. This challenge motivates the use of a digital twin for
the surgical system, where a simulation would mirror the robot hardware and
surgical environment in the real world. The surgeon would then be able to
interact with the digital twin during communication outage, followed by a
recovery strategy on the real robot upon reestablishing communication. This
paper builds the digital twin for the da Vinci surgical robot, with a buffering
and replay strategy that reduces the mean task completion time by 23% when
compared to the baseline, for a peg transfer task subject to intermittent
communication outage.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13449v1
"HyperGAN-CLIP: A Unified Framework for Domain Adaptation, Image
  Synthesis and Manipulation","Abdul Basit Anees, Ahmet Canberk Baykal, Muhammed Burak Kizil, Duygu Ceylan, Erkut Erdem, Aykut Erdem",2024-11-19T19:36:18Z,"Generative Adversarial Networks (GANs), particularly StyleGAN and its
variants, have demonstrated remarkable capabilities in generating highly
realistic images. Despite their success, adapting these models to diverse tasks
such as domain adaptation, reference-guided synthesis, and text-guided
manipulation with limited training data remains challenging. Towards this end,
in this study, we present a novel framework that significantly extends the
capabilities of a pre-trained StyleGAN by integrating CLIP space via
hypernetworks. This integration allows dynamic adaptation of StyleGAN to new
domains defined by reference images or textual descriptions. Additionally, we
introduce a CLIP-guided discriminator that enhances the alignment between
generated images and target domains, ensuring superior image quality. Our
approach demonstrates unprecedented flexibility, enabling text-guided image
manipulation without the need for text-specific training data and facilitating
seamless style transfer. Comprehensive qualitative and quantitative evaluations
confirm the robustness and superior performance of our framework compared to
existing methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12832v1
Weighted Envy Freeness With Limited Subsidies,"Noga Klein Elmalem, Rica Gonen, Erel Segal-Halevi",2024-11-19T18:02:44Z,"We explore solutions for fairly allocating indivisible items among agents
assigned weights representing their entitlements. Our fairness goal is
weighted-envy-freeness (WEF), where each agent deems their allocated portion
relative to their entitlement at least as favorable as any other's relative to
their own. In many cases, achieving WEF necessitates monetary transfers, which
can be modeled as third-party subsidies. The goal is to attain WEF with bounded
subsidies. Previous work in the unweighted setting of subsidies relied on basic
characterizations of EF that fail in the weighted settings. This makes our new
setting challenging and theoretically intriguing. We present polynomial-time
algorithms that compute WEF-able allocations with an upper bound on the subsidy
per agent in three distinct additive valuation scenarios: (1) general, (2)
identical, and (3) binary. When all weights are equal, our bounds reduce to the
bounds derived in the literature for the unweighted setting.","cs.GT, cs.DS",cs.GT,http://arxiv.org/abs/2411.12696v1
"Meeting Future Mobile Traffic Needs by Peak-Throughput Design of
  Next-Gen RAN","Paolo Fiore, Ilario Filippini, Danilo De Donno",2024-11-19T16:30:07Z,"Growing congestion in current mobile networks necessitates innovative
solutions. This paper explores the potential of mmWave 5G networks in urban
settings, focusing on Integrated Access and Backhaul (IAB) and the Smart Radio
Environment (SRE). The mmWave traffic will be mainly made of short bursts to
transfer large volumes of data and long idle periods where data are processed.
This must change the way of designing mobile radio networks. To this extent, we
propose network planning models leveraging the maximization of the achievable
peak throughput. Results highlight the advantages of this approach during the
network planning phase, providing insights into better accommodating the
demands of mobile traffic without sacrificing the overall network capacity.","cs.NI, eess.SP",cs.NI,http://arxiv.org/abs/2411.12621v1
"REDUCIO! Generating 1024$\times$1024 Video within 16 Seconds using
  Extremely Compressed Motion Latents","Rui Tian, Qi Dai, Jianmin Bao, Kai Qiu, Yifan Yang, Chong Luo, Zuxuan Wu, Yu-Gang Jiang",2024-11-20T18:59:52Z,"Commercial video generation models have exhibited realistic, high-fidelity
results but are still restricted to limited access. One crucial obstacle for
large-scale applications is the expensive training and inference cost. In this
paper, we argue that videos contain much more redundant information than
images, thus can be encoded by very few motion latents based on a content
image. Towards this goal, we design an image-conditioned VAE to encode a video
to an extremely compressed motion latent space. This magic Reducio charm
enables 64x reduction of latents compared to a common 2D VAE, without
sacrificing the quality. Training diffusion models on such a compact
representation easily allows for generating 1K resolution videos. We then adopt
a two-stage video generation paradigm, which performs text-to-image and
text-image-to-video sequentially. Extensive experiments show that our
Reducio-DiT achieves strong performance in evaluation, though trained with
limited GPU resources. More importantly, our method significantly boost the
efficiency of video LDMs both in training and inference. We train Reducio-DiT
in around 3.2K training hours in total and generate a 16-frame 1024*1024 video
clip within 15.5 seconds on a single A100 GPU. Code released at
https://github.com/microsoft/Reducio-VAE .",cs.CV,cs.CV,http://arxiv.org/abs/2411.13552v1
Find Any Part in 3D,"Ziqi Ma, Yisong Yue, Georgia Gkioxari",2024-11-20T18:59:01Z,"We study open-world part segmentation in 3D: segmenting any part in any
object based on any text query. Prior methods are limited in object categories
and part vocabularies. Recent advances in AI have demonstrated effective
open-world recognition capabilities in 2D. Inspired by this progress, we
propose an open-world, direct-prediction model for 3D part segmentation that
can be applied zero-shot to any object. Our approach, called Find3D, trains a
general-category point embedding model on large-scale 3D assets from the
internet without any human annotation. It combines a data engine, powered by
foundation models for annotating data, with a contrastive training method. We
achieve strong performance and generalization across multiple datasets, with up
to a 3x improvement in mIoU over the next best method. Our model is 6x to over
300x faster than existing baselines. To encourage research in general-category
open-world 3D part segmentation, we also release a benchmark for general
objects and parts. Project website: https://ziqi-ma.github.io/find3dsite/",cs.CV,cs.CV,http://arxiv.org/abs/2411.13550v1
"DIS-Mine: Instance Segmentation for Disaster-Awareness in Poor-Light
  Condition in Underground Mines","Mizanur Rahman Jewel, Mohamed Elmahallawy, Sanjay Madria, Samuel Frimpong",2024-11-20T18:54:36Z,"Detecting disasters in underground mining, such as explosions and structural
damage, has been a persistent challenge over the years. This problem is
compounded for first responders, who often have no clear information about the
extent or nature of the damage within the mine. The poor-light or even total
darkness inside the mines makes rescue efforts incredibly difficult, leading to
a tragic loss of life. In this paper, we propose a novel instance segmentation
method called DIS-Mine, specifically designed to identify disaster-affected
areas within underground mines under low-light or poor visibility conditions,
aiding first responders in rescue efforts. DIS-Mine is capable of detecting
objects in images, even in complete darkness, by addressing challenges such as
high noise, color distortions, and reduced contrast. The key innovations of
DIS-Mine are built upon four core components: i) Image brightness improvement,
ii) Instance segmentation with SAM integration, iii) Mask R-CNN-based
segmentation, and iv) Mask alignment with feature matching. On top of that, we
have collected real-world images from an experimental underground mine,
introducing a new dataset named ImageMine, specifically gathered in
low-visibility conditions. This dataset serves to validate the performance of
DIS-Mine in realistic, challenging environments. Our comprehensive experiments
on the ImageMine dataset, as well as on various other datasets demonstrate that
DIS-Mine achieves a superior F1 score of 86.0% and mIoU of 72.0%, outperforming
state-of-the-art instance segmentation methods, with at least 15x improvement
and up to 80% higher precision in object detection.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13544v1
"A Distributed-memory Tridiagonal Solver Based on a Specialised Data
  Structure Optimised for CPU and GPU Architectures","Semih Akkurt, Sébastien Lemaire, Paul Bartholomew, Sylvain Laizet",2024-11-20T18:31:39Z,"Various numerical methods used for solving partial differential equations
(PDE) result in tridiagonal systems. Solving tridiagonal systems on
distributed-memory environments is not straightforward, and often requires
significant amount of communication. In this article, we present a novel
distributed-memory tridiagonal solver algorithm, DistD2-TDS, based on a
specialised data structure. DistD2-TDS algorithm takes advantage of the
diagonal dominance in tridiagonal systems to reduce the communications in
distributed-memory environments. The underlying data structure plays a crucial
role for the performance of the algorithm. First, the data structure improves
data localities and makes it possible to minimise data movements via cache
blocking and kernel fusion strategies. Second, data continuity enables a
contiguous data access pattern and results in efficient utilisation of the
available memory bandwidth. Finally, the data layout supports vectorisation on
CPUs and thread level parallelisation on GPUs for improved performance. In
order to demonstrate the robustness of the algorithm, we implemented and
benchmarked the algorithm on CPUs and GPUs. We investigated the single rank
performance and compared against existing algorithms. Furthermore, we analysed
the strong scaling of the implementation up to 384 NVIDIA H100 GPUs and up to
8192 AMD EPYC 7742 CPUs. Finally, we demonstrated a practical use case of the
algorithm by using compact finite difference schemes to solve a 3D non-linear
PDE. The results demonstrate that DistD2 algorithm can sustain around 66% of
the theoretical peak bandwidth at scale on CPU and GPU based supercomputers.","cs.DC, physics.comp-ph",cs.DC,http://arxiv.org/abs/2411.13532v1
"Advancing Complex Medical Communication in Arabic with Sporo AraSum:
  Surpassing Existing Large Language Models","Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt",2024-11-20T18:10:19Z,"The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.13518v1
"Dynamically Feasible Path Planning in Cluttered Environments via
  Reachable Bezier Polytopes","Noel Csomay-Shanklin, William D. Compton, Aaron D. Ames",2024-11-20T17:57:33Z,"The deployment of robotic systems in real world environments requires the
ability to quickly produce paths through cluttered, non-convex spaces. These
planned trajectories must be both kinematically feasible (i.e., collision free)
and dynamically feasible (i.e., satisfy the underlying system dynamics),
necessitating a consideration of both the free space and the dynamics of the
robot in the path planning phase. In this work, we explore the application of
reachable Bezier polytopes as an efficient tool for generating trajectories
satisfying both kinematic and dynamic requirements. Furthermore, we demonstrate
that by offloading specific computation tasks to the GPU, such an algorithm can
meet tight real time requirements. We propose a layered control architecture
that efficiently produces collision free and dynamically feasible paths for
nonlinear control systems, and demonstrate the framework on the tasks of 3D
hopping in a cluttered environment.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.13507v1
Disentangling Memory and Reasoning Ability in Large Language Models,"Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang",2024-11-20T17:55:38Z,"Large Language Models (LLMs) have demonstrated strong performance in handling
complex tasks requiring both extensive knowledge and reasoning abilities.
However, the existing LLM inference pipeline operates as an opaque process
without explicit separation between knowledge retrieval and reasoning steps,
making the model's decision-making process unclear and disorganized. This
ambiguity can lead to issues such as hallucinations and knowledge forgetting,
which significantly impact the reliability of LLMs in high-stakes domains. In
this paper, we propose a new inference paradigm that decomposes the complex
inference process into two distinct and clear actions: (1) memory recall: which
retrieves relevant knowledge, and (2) reasoning: which performs logical steps
based on the recalled knowledge. To facilitate this decomposition, we introduce
two special tokens memory and reason, guiding the model to distinguish between
steps that require knowledge retrieval and those that involve reasoning. Our
experiment results show that this decomposition not only improves model
performance but also enhances the interpretability of the inference process,
enabling users to identify sources of error and refine model responses
effectively. The code is available at
https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13504v1
"VBench++: Comprehensive and Versatile Benchmark Suite for Video
  Generative Models","Ziqi Huang, Fan Zhang, Xiaojie Xu, Yinan He, Jiashuo Yu, Ziyue Dong, Qianli Ma, Nattapol Chanpaisit, Chenyang Si, Yuming Jiang, Yaohui Wang, Xinyuan Chen, Ying-Cong Chen, Limin Wang, Dahua Lin, Yu Qiao, Ziwei Liu",2024-11-20T17:54:41Z,"Video generation has witnessed significant advancements, yet evaluating these
models remains a challenge. A comprehensive evaluation benchmark for video
generation is indispensable for two reasons: 1) Existing metrics do not fully
align with human perceptions; 2) An ideal evaluation system should provide
insights to inform future developments of video generation. To this end, we
present VBench, a comprehensive benchmark suite that dissects ""video generation
quality"" into specific, hierarchical, and disentangled dimensions, each with
tailored prompts and evaluation methods. VBench has several appealing
properties: 1) Comprehensive Dimensions: VBench comprises 16 dimensions in
video generation (e.g., subject identity inconsistency, motion smoothness,
temporal flickering, and spatial relationship, etc). The evaluation metrics
with fine-grained levels reveal individual models' strengths and weaknesses. 2)
Human Alignment: We also provide a dataset of human preference annotations to
validate our benchmarks' alignment with human perception, for each evaluation
dimension respectively. 3) Valuable Insights: We look into current models'
ability across various evaluation dimensions, and various content types. We
also investigate the gaps between video and image generation models. 4)
Versatile Benchmarking: VBench++ supports evaluating text-to-video and
image-to-video. We introduce a high-quality Image Suite with an adaptive aspect
ratio to enable fair evaluations across different image-to-video generation
settings. Beyond assessing technical quality, VBench++ evaluates the
trustworthiness of video generative models, providing a more holistic view of
model performance. 5) Full Open-Sourcing: We fully open-source VBench++ and
continually add new video generation models to our leaderboard to drive forward
the field of video generation.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13503v1
PatentEdits: Framing Patent Novelty as Textual Entailment,"Ryan Lee, Alexander Spangher, Xuezhe Ma",2024-11-20T17:23:40Z,"A patent must be deemed novel and non-obvious in order to be granted by the
US Patent Office (USPTO). If it is not, a US patent examiner will cite the
prior work, or prior art, that invalidates the novelty and issue a non-final
rejection. Predicting what claims of the invention should change given the
prior art is an essential and crucial step in securing invention rights, yet
has not been studied before as a learnable task. In this work we introduce the
PatentEdits dataset, which contains 105K examples of successful revisions that
overcome objections to novelty. We design algorithms to label edits sentence by
sentence, then establish how well these edits can be predicted with large
language models (LLMs). We demonstrate that evaluating textual entailment
between cited references and draft sentences is especially effective in
predicting which inventive claims remained unchanged or are novel in relation
to prior art.","cs.CL, cs.AI, cs.CY, cs.IR",cs.CL,http://arxiv.org/abs/2411.13477v1
"When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context
  Training","Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang",2024-11-20T17:22:31Z,"Extending context window sizes allows large language models (LLMs) to process
longer sequences and handle more complex tasks. Rotary Positional Embedding
(RoPE) has become the de facto standard due to its relative positional encoding
properties that benefit long-context training. However, we observe that using
RoPE with BFloat16 format results in numerical issues, causing it to deviate
from its intended relative positional encoding, especially in long-context
scenarios. This issue arises from BFloat16's limited precision and accumulates
as context length increases, with the first token contributing significantly to
this problem. To address this, we develop AnchorAttention, a plug-and-play
attention method that alleviates numerical issues caused by BFloat16, improves
long-context capabilities, and speeds up training. AnchorAttention reduces
unnecessary attention computations, maintains semantic coherence, and boosts
computational efficiency by treating the first token as a shared anchor with a
consistent position ID, making it visible to all documents within the training
context. Experiments on three types of LLMs demonstrate that AnchorAttention
significantly improves long-context performance and reduces training time by
over 50\% compared to standard full attention mechanisms, while preserving the
original LLM's capabilities on general tasks. Our code is available at
https://github.com/haonan3/AnchorContext.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13476v1
"LIMBA: An Open-Source Framework for the Preservation and Valorization of
  Low-Resource Languages using Generative Models","Salvatore Mario Carta, Stefano Chessa, Giulia Contu, Andrea Corriga, Andrea Deidda, Gianni Fenu, Luca Frigau, Alessandro Giuliani, Luca Grassi, Marco Manolo Manca, Mirko Marras, Francesco Mola, Bastianino Mossa, Piergiorgio Mura, Marco Ortu, Leonardo Piano, Simone Pisano, Alessia Pisu, Alessandro Sebastian Podda, Livio Pompianu, Simone Seu, Sandro Gabriele Tiddia",2024-11-20T16:59:41Z,"Minority languages are vital to preserving cultural heritage, yet they face
growing risks of extinction due to limited digital resources and the dominance
of artificial intelligence models trained on high-resource languages. This
white paper proposes a framework to generate linguistic tools for low-resource
languages, focusing on data creation to support the development of language
models that can aid in preservation efforts. Sardinian, an endangered language,
serves as the case study to demonstrate the framework's effectiveness. By
addressing the data scarcity that hinders intelligent applications for such
languages, we contribute to promoting linguistic diversity and support ongoing
efforts in language standardization and revitalization through modern
technologies.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.13453v1
"A Case Study of API Design for Interoperability and Security of the
  Internet of Things","Dongha Kim, Chanhee Lee, Hokeun Kim",2024-11-20T16:29:57Z,"Heterogeneous distributed systems, including the Internet of Things (IoT) or
distributed cyber-physical systems (CPS), often suffer a lack of
interoperability and security, which hinders the wider deployment of such
systems. Specifically, the different levels of security requirements and the
heterogeneity in terms of communication models, for instance, point-to-point
vs. publish-subscribe, are the example challenges of IoT and distributed CPS
consisting of heterogeneous devices and applications. In this paper, we propose
a working application programming interface (API) and runtime to enhance
interoperability and security while addressing the challenges that stem from
the heterogeneity in the IoT and distributed CPS. In our case study, we design
and implement our application programming interface (API) design approach using
open-source software, and with our working implementation, we evaluate the
effectiveness of our proposed approach. Our experimental results suggest that
our approach can achieve both interoperability and security in the IoT and
distributed CPS with a reasonably small overhead and better-managed software.","cs.DC, cs.SY, eess.SY",cs.DC,http://arxiv.org/abs/2411.13441v1
"CAFE A Novel Code switching Dataset for Algerian Dialect French and
  English","Houssam Eddine-Othman Lachemat, Akli Abbas, Nourredine Oukas, Yassine El Kheir, Samia Haboussi, Absar Showdhury Shammur",2024-11-20T16:09:16Z,"The paper introduces and publicly releases (Data download link available
after acceptance) CAFE -- the first Code-switching dataset between Algerian
dialect, French, and english languages. The CAFE speech data is unique for (a)
its spontaneous speaking style in vivo human-human conversation capturing
phenomena like code-switching and overlapping speech, (b) addresses distinct
linguistic challenges in North African Arabic dialect; (c) the CAFE captures
dialectal variations from various parts of Algeria within different
sociolinguistic contexts. CAFE data contains approximately 37 hours of speech,
with a subset, CAFE-small, of 2 hours and 36 minutes released with manual human
annotation including speech segmentation, transcription, explicit annotation of
code-switching points, overlapping speech, and other events such as noises, and
laughter among others. The rest approximately 34.58 hours contain pseudo label
transcriptions. In addition to the data release, the paper also highlighted the
challenges of using state-of-the-art Automatic Speech Recognition (ASR) models
such as Whisper large-v2,3 and PromptingWhisper to handle such content.
Following, we benchmark CAFE data with the aforementioned Whisper models and
show how well-designed data processing pipelines and advanced decoding
techniques can improve the ASR performance in terms of Mixed Error Rate (MER)
of 0.310, Character Error Rate (CER) of 0.329 and Word Error Rate (WER) of
0.538.","cs.SD, cs.CL, eess.AS",cs.SD,http://arxiv.org/abs/2411.13424v1
Complete Test Suites for Automata in Monoidal Closed Categories,"Bálint Kocsis, Jurriaan Rot",2024-11-20T15:52:27Z,"Conformance testing of automata is about checking the equivalence of a known
specification and a black-box implementation. An important notion in
conformance testing is that of a complete test suite, which guarantees that if
an implementation satisfying certain conditions passes all tests, then it is
equivalent to the specification.
  We introduce a framework for proving completeness of test suites at the
general level of automata in monoidal closed categories. Moreover, we provide a
generalization of a classical conformance testing technique, the W-method. We
demonstrate the applicability of our results by recovering the W-method for
deterministic finite automata, Moore machines, and Mealy machines, and by
deriving new instances of complete test suites for weighted automata and
deterministic nominal automata.","cs.FL, cs.LO",cs.FL,http://arxiv.org/abs/2411.13412v1
"Unification of Balti and trans-border sister dialects in the essence of
  LLMs and AI Technology","Muhammad Sharif, Jiangyan Yi, Muhammad Shoaib",2024-11-20T15:48:21Z,"The language called Balti belongs to the Sino-Tibetan, specifically the
Tibeto-Burman language family. It is understood with variations, across
populations in India, China, Pakistan, Nepal, Tibet, Burma, and Bhutan,
influenced by local cultures and producing various dialects. Considering the
diverse cultural, socio-political, religious, and geographical impacts, it is
important to step forward unifying the dialects, the basis of common root,
lexica, and phonological perspectives, is vital. In the era of globalization
and the increasingly frequent developments in AI technology, understanding the
diversity and the efforts of dialect unification is important to understanding
commonalities and shortening the gaps impacted by unavoidable circumstances.
This article analyzes and examines how artificial intelligence AI in the
essence of Large Language Models LLMs, can assist in analyzing, documenting,
and standardizing the endangered Balti Language, based on the efforts made in
different dialects so far.","cs.CL, cs.AI, cs.CV",cs.CL,http://arxiv.org/abs/2411.13409v1
"On the structure of normalized models of circular-arc graphs -- Hsu's
  approach revisited",Tomasz Krawczyk,2024-11-20T14:52:43Z,"Circular-arc graphs are the intersection graphs of arcs of a circle. The main
result of this work describes the structure of all \emph{normalized
intersection models} of circular-arc graphs. Normalized models of a
circular-arc graph reflect the neighborhood relation between its vertices and
can be seen as its canonical representations; in particular, any intersection
model can be made normalized by possibly extending some of its arcs. We~devise
a data-structure, called \emph{PQM-tree}, that maintains the set of all
normalized models of a circular-arc graph. We show that the PQM-tree of a
circular-arc graph can be computed in linear time. Finally, basing on
PQM-trees, we provide a linear-time algorithm for the canonization and the
isomorphism problem for circular-arc graphs.
  We describe the structure of the normalized models of circular-arc graphs
using an approach proposed by Hsu~[\emph{SIAM J. Comput. 24(3), 411--439,
(1995)}]. In the aforementioned work, Hsu claimed the construction of
decomposition trees representing the set of all normalized intersection models
of circular-arc graphs and an $\mathcal{O}(nm)$ time isomorphism algorithm for
this class of graphs. However, the counterexample given in~[\emph{Discrete
Math. Theor. Comput. Sci., 15(1), 157--182, 2013}] shows that Hsu's isomorphism
algorithm is not incorrect. Also, in a companion paper we show that the
decomposition trees proposed by Hsu are not constructed correctly; in
particular, we showed that there are circular-arc graphs whose all normalized
models do not follow the description given by Hsu.","cs.DS, E.1; F.2",cs.DS,http://arxiv.org/abs/2411.13374v1
Parameterized Complexity of Star Decomposition Problem,"Sahab Hajebi, Ramin Javadi",2024-11-20T14:19:30Z,"A star of length $ \ell $ is defined as the complete bipartite graph $
K_{1,\ell } $. In this paper we deal with the problem of edge decomposition of
graphs into stars of varying lengths. Given a graph $ G $ and a list of
integers $S=(s_1,\ldots, s_t) $, an $S$-star decomposition of $ G $ is an edge
decomposition of $ G $ into graphs $G_1 ,G_2 ,\ldots,G_t $ such that $G_i$ is
isomorphic to an star of length $s_i$, for each $i \in\{1,2,\ldots,t\}$. Given
a graph $G$ and a list of integers $S$, \sdp problem asks if $G$ admits an $ S
$-star decomposition. The problem in known to be NP-complete even when all
stars are of length three. In this paper, we investigate parametrized
complexity of the problem with respect to the structural parameters such as
minimum vertex cover, treewidth, tree-depth and neighborhood diversity as well
as some intrinsic parameters of the problem such as number of distinct star
lengths, the maximum size of stars and the maximum degree of the graph, giving
a roughly complete picture of the parameterized complexity landscape of the
problem.",cs.CC,cs.CC,http://arxiv.org/abs/2411.13348v1
Fact-Level Confidence Calibration and Self-Correction,"Yige Yuan, Bingbing Xu, Hexiang Tan, Fei Sun, Teng Xiao, Wei Li, Huawei Shen, Xueqi Cheng",2024-11-20T14:15:18Z,"Confidence calibration in LLMs, i.e., aligning their self-assessed confidence
with the actual accuracy of their responses, enabling them to self-evaluate the
correctness of their outputs. However, current calibration methods for LLMs
typically estimate two scalars to represent overall response confidence and
correctness, which is inadequate for long-form generation where the response
includes multiple atomic facts and may be partially confident and correct.
These methods also overlook the relevance of each fact to the query. To address
these challenges, we propose a Fact-Level Calibration framework that operates
at a finer granularity, calibrating confidence to relevance-weighted
correctness at the fact level. Furthermore, comprehensive analysis under the
framework inspired the development of Confidence-Guided Fact-level
Self-Correction ($\textbf{ConFix}$), which uses high-confidence facts within a
response as additional knowledge to improve low-confidence ones. Extensive
experiments across four datasets and six models demonstrate that ConFix
effectively mitigates hallucinations without requiring external knowledge
sources such as retrieval systems.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.13343v1
"WHALES: A Multi-agent Scheduling Dataset for Enhanced Cooperation in
  Autonomous Driving","Siwei Chen, Yinsong, Wang, Ziyi Song, Sheng Zhou",2024-11-20T14:12:34Z,"Achieving high levels of safety and reliability in autonomous driving remains
a critical challenge, especially due to occlusion and limited perception ranges
in standalone systems. Cooperative perception among vehicles offers a promising
solution, but existing research is hindered by datasets with a limited number
of agents. Scaling up the number of cooperating agents is non-trivial and
introduces significant computational and technical hurdles that have not been
addressed in previous works. To bridge this gap, we present Wireless enHanced
Autonomous vehicles with Large number of Engaged agentS (WHALES), a dataset
generated using CARLA simulator that features an unprecedented average of 8.4
agents per driving sequence. In addition to providing the largest number of
agents and viewpoints among autonomous driving datasets, WHALES records agent
behaviors, enabling cooperation across multiple tasks. This expansion allows
for new supporting tasks in cooperative perception. As a demonstration, we
conduct experiments on agent scheduling task, where the ego agent selects one
of multiple candidate agents to cooperate with, optimizing perception gains in
autonomous driving. The WHALES dataset and codebase can be found at
https://github.com/chensiweiTHU/WHALES.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13340v1
Sublinear-time Sampling of Spanning Trees in the Congested Clique,"Sriram V. Pemmaraju, Sourya Roy, Joshua Z. Sobel",2024-11-20T14:07:23Z,"We present the first sublinear round algorithm for approximately sampling
uniform spanning trees in the CongestedClique model of distributed computing.
In particular, our algorithm requires $\~O(n^{0.658})$ rounds for sampling a
spanning tree from a distribution within total variation distance $1/n^c$, for
arbitrary constant $c > 0$, from the uniform distribution. More precisely, our
algorithm requires $\~O(n^{1/2 + \alpha})$ rounds, where $O(n^\alpha)$ is the
running time of matrix multiplication in the CongestedClique model, currently
at $\alpha = 1 - 2/\omega = 0.158$, where $\omega$ is the sequential matrix
multiplication time exponent.
  In addition, we show how to take somewhat shorter random walks even more
efficiently in the CongestedClique model. Specifically, we show how to
construct length-$\tau$ walks, for $\tau = \Omega(n/\log n)$, in
$O\left(\frac{\tau}{n} \log \tau \log n\right)$ rounds and for $\tau = O(n/\log
n)$ in $O(\log \tau)$ rounds. This implies an $O(\log^3 n)$-round algorithm in
the CongestedClique model for sampling spanning trees for Erd\H{o}s-R\'enyi
graphs and regular expander graphs due to the $O(n \log n)$ bound on their
cover time. This also implies that polylogarithmic-length walks, which are
useful for page rank estimation, can be constructed in $O(\log \log n)$ rounds
in the CongestedClique model. These results are obtained by adding a load
balancing component to the random walk algorithm of Bahmani, Chakrabarti and
Xin (SIGMOD 2011) that uses the ``doubling'' technique.",cs.DC,cs.DC,http://arxiv.org/abs/2411.13334v1
"Proceedings Combined 31st International Workshop on Expressiveness in
  Concurrency and 21st Workshop on Structural Operational Semantics","Georgiana Caltais, Cinzia Di Giusto",2024-11-20T13:38:13Z,"This volume contains the proceedings of EXPRESS/SOS 2024: the Combined 31st
International Workshop on Expressiveness in Concurrency and the 21st Workshop
on Structural Operational Semantics, which was held in Calgary, Canada, as an
affiliated workshop of CONFEST 2024. The EXPRESS/SOS workshop series aims at
bringing together researchers interested in the formal semantics of systems and
programming concepts, and in the expressiveness of computational models.","cs.FL, cs.LO",cs.FL,http://arxiv.org/abs/2411.13318v1
Permissive Equilibria in Multiplayer Reachability Games,"Aline Goeminne, Benjamin Monmege",2024-11-20T13:06:31Z,"We study multi-strategies in multiplayer reachability games played on finite
graphs. A multi-strategy prescribes a set of possible actions, instead of a
single action as usual strategies: it represents a set of all strategies that
are consistent with it. We aim for profiles of multi-strategies (a
multi-strategy per player), where each profile of consistent strategies is a
Nash equilibrium, or a subgame perfect equilibrium. The permissiveness of two
multi-strategies can be compared with penalties, as already used in the
two-player zero-sum setting by Bouyer, Duflot, Markey and Renault. We show that
we can decide the existence of a multi-strategy that is a Nash equilibrium or a
subgame perfect equilibrium, while satisfying some upper-bound constraints on
the penalties in PSPACE, if the upper-bound penalties are given in unary. The
same holds when we search for multi-strategies where certain players are asked
to win in at least one play or in all plays",cs.GT,cs.GT,http://arxiv.org/abs/2411.13296v1
"DATAP-SfM: Dynamic-Aware Tracking Any Point for Robust Structure from
  Motion in the Wild","Weicai Ye, Xinyu Chen, Ruohao Zhan, Di Huang, Xiaoshui Huang, Haoyi Zhu, Hujun Bao, Wanli Ouyang, Tong He, Guofeng Zhang",2024-11-20T13:01:16Z,"This paper proposes a concise, elegant, and robust pipeline to estimate
smooth camera trajectories and obtain dense point clouds for casual videos in
the wild. Traditional frameworks, such as
ParticleSfM~\cite{zhao2022particlesfm}, address this problem by sequentially
computing the optical flow between adjacent frames to obtain point
trajectories. They then remove dynamic trajectories through motion segmentation
and perform global bundle adjustment. However, the process of estimating
optical flow between two adjacent frames and chaining the matches can introduce
cumulative errors. Additionally, motion segmentation combined with single-view
depth estimation often faces challenges related to scale ambiguity. To tackle
these challenges, we propose a dynamic-aware tracking any point (DATAP) method
that leverages consistent video depth and point tracking. Specifically, our
DATAP addresses these issues by estimating dense point tracking across the
video sequence and predicting the visibility and dynamics of each point. By
incorporating the consistent video depth prior, the performance of motion
segmentation is enhanced. With the integration of DATAP, it becomes possible to
estimate and optimize all camera poses simultaneously by performing global
bundle adjustments for point tracking classified as static and visible, rather
than relying on incremental camera registration. Extensive experiments on
dynamic sequences, e.g., Sintel and TUM RGBD dynamic sequences, and on the wild
video, e.g., DAVIS, demonstrate that the proposed method achieves
state-of-the-art performance in terms of camera pose estimation even in complex
dynamic challenge scenes.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13291v1
"Unbiased Scene Graph Generation by Type-Aware Message Passing on
  Heterogeneous and Dual Graphs","Guanglu Sun, Jin Qiu, Lili Liang",2024-11-20T12:54:47Z,"Although great progress has been made in the research of unbiased scene graph
generation, issues still hinder improving the predictive performance of both
head and tail classes. An unbiased scene graph generation (TA-HDG) is proposed
to address these issues. For modeling interactive and non-interactive
relations, the Interactive Graph Construction is proposed to model the
dependence of relations on objects by combining heterogeneous and dual graph,
when modeling relations between multiple objects. It also implements a
subject-object pair selection strategy to reduce meaningless edges. Moreover,
the Type-Aware Message Passing enhances the understanding of complex
interactions by capturing intra- and inter-type context in the Intra-Type and
Inter-Type stages. The Intra-Type stage captures the semantic context of
inter-relaitons and inter-objects. On this basis, the Inter-Type stage captures
the context between objects and relations for interactive and non-interactive
relations, respectively. Experiments on two datasets show that TA-HDG achieves
improvements in the metrics of R@K and mR@K, which proves that TA-HDG can
accurately predict the tail class while maintaining the competitive performance
of the head class.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13287v1
"VideoAutoArena: An Automated Arena for Evaluating Large Multimodal
  Models in Video Analysis through User Simulation","Ziyang Luo, Haoning Wu, Dongxu Li, Jing Ma, Mohan Kankanhalli, Junnan Li",2024-11-20T12:48:34Z,"Large multimodal models (LMMs) with advanced video analysis capabilities have
recently garnered significant attention. However, most evaluations rely on
traditional methods like multiple-choice questions in benchmarks such as
VideoMME and LongVideoBench, which are prone to lack the depth needed to
capture the complex demands of real-world users. To address this limitation-and
due to the prohibitive cost and slow pace of human annotation for video
tasks-we introduce VideoAutoArena, an arena-style benchmark inspired by LMSYS
Chatbot Arena's framework, designed to automatically assess LMMs' video
analysis abilities. VideoAutoArena utilizes user simulation to generate
open-ended, adaptive questions that rigorously assess model performance in
video understanding. The benchmark features an automated, scalable evaluation
framework, incorporating a modified ELO Rating System for fair and continuous
comparisons across multiple LMMs. To validate our automated judging system, we
construct a 'gold standard' using a carefully curated subset of human
annotations, demonstrating that our arena strongly aligns with human judgment
while maintaining scalability. Additionally, we introduce a fault-driven
evolution strategy, progressively increasing question complexity to push models
toward handling more challenging video analysis scenarios. Experimental results
demonstrate that VideoAutoArena effectively differentiates among
state-of-the-art LMMs, providing insights into model strengths and areas for
improvement. To further streamline our evaluation, we introduce VideoAutoBench
as an auxiliary benchmark, where human annotators label winners in a subset of
VideoAutoArena battles. We use GPT-4o as a judge to compare responses against
these human-validated answers. Together, VideoAutoArena and VideoAutoBench
offer a cost-effective, and scalable framework for evaluating LMMs in
user-centric video analysis.","cs.CV, cs.AI, cs.CL, cs.MM",cs.CV,http://arxiv.org/abs/2411.13281v1
Interface for Sparse Linear Algebra Operations,"Ahmad Abdelfattah, Willow Ahrens, Hartwig Anzt, Chris Armstrong, Ben Brock, Aydin Buluc, Federico Busato, Terry Cojean, Tim Davis, Jim Demmel, Grace Dinh, David Gardener, Jan Fiala, Mark Gates, Azzam Haider, Toshiyuki Imamura, Pedro Valero Lara, Jose Moreira, Sherry Li, Piotr Luszczek, Max Melichenko, Jose Moeira, Yvan Mokwinski, Riley Murray, Spencer Patty, Slaven Peles, Tobias Ribizel, Jason Riedy, Siva Rajamanickam, Piyush Sao, Manu Shantharam, Keita Teranishi, Stan Tomov, Yu-Hsiang Tsai, Heiko Weichelt",2024-11-20T12:20:45Z,"The standardization of an interface for dense linear algebra operations in
the BLAS standard has enabled interoperability between different linear algebra
libraries, thereby boosting the success of scientific computing, in particular
in scientific HPC. Despite numerous efforts in the past, the community has not
yet agreed on a standardization for sparse linear algebra operations due to
numerous reasons. One is the fact that sparse linear algebra objects allow for
many different storage formats, and different hardware may favor different
storage formats. This makes the definition of a FORTRAN-style all-circumventing
interface extremely challenging. Another reason is that opposed to dense linear
algebra functionality, in sparse linear algebra, the size of the sparse data
structure for the operation result is not always known prior to the
information. Furthermore, as opposed to the standardization effort for dense
linear algebra, we are late in the technology readiness cycle, and many
production-ready software libraries using sparse linear algebra routines have
implemented and committed to their own sparse BLAS interface. At the same time,
there exists a demand for standardization that would improve interoperability,
and sustainability, and allow for easier integration of building blocks. In an
inclusive, cross-institutional effort involving numerous academic institutions,
US National Labs, and industry, we spent two years designing a
hardware-portable interface for basic sparse linear algebra functionality that
serves the user needs and is compatible with the different interfaces currently
used by different vendors. In this paper, we present a C++ API for sparse
linear algebra functionality, discuss the design choices, and detail how
software developers preserve a lot of freedom in terms of how to implement
functionality behind this API.",cs.MS,cs.MS,http://arxiv.org/abs/2411.13259v1
"XMask3D: Cross-modal Mask Reasoning for Open Vocabulary 3D Semantic
  Segmentation","Ziyi Wang, Yanbo Wang, Xumin Yu, Jie Zhou, Jiwen Lu",2024-11-20T12:02:12Z,"Existing methodologies in open vocabulary 3D semantic segmentation primarily
concentrate on establishing a unified feature space encompassing 3D, 2D, and
textual modalities. Nevertheless, traditional techniques such as global feature
alignment or vision-language model distillation tend to impose only approximate
correspondence, struggling notably with delineating fine-grained segmentation
boundaries. To address this gap, we propose a more meticulous mask-level
alignment between 3D features and the 2D-text embedding space through a
cross-modal mask reasoning framework, XMask3D. In our approach, we developed a
mask generator based on the denoising UNet from a pre-trained diffusion model,
leveraging its capability for precise textual control over dense pixel
representations and enhancing the open-world adaptability of the generated
masks. We further integrate 3D global features as implicit conditions into the
pre-trained 2D denoising UNet, enabling the generation of segmentation masks
with additional 3D geometry awareness. Subsequently, the generated 2D masks are
employed to align mask-level 3D representations with the vision-language
feature space, thereby augmenting the open vocabulary capability of 3D geometry
embeddings. Finally, we fuse complementary 2D and 3D mask features, resulting
in competitive performance across multiple benchmarks for 3D open vocabulary
semantic segmentation. Code is available at
https://github.com/wangzy22/XMask3D.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13243v1
Transforming the Hybrid Cloud for Emerging AI Workloads,"Deming Chen, Alaa Youssef, Ruchi Pendse, André Schleife, Bryan K. Clark, Hendrik Hamann, Jingrui He, Teodoro Laino, Lav Varshney, Yuxiong Wang, Avirup Sil, Reyhaneh Jabbarvand, Tianyin Xu, Volodymyr Kindratenko, Carlos Costa, Sarita Adve, Charith Mendis, Minjia Zhang, Santiago Núñez-Corrales, Raghu Ganti, Mudhakar Srivatsa, Nam Sung Kim, Josep Torrellas, Jian Huang, Seetharami Seelam, Klara Nahrstedt, Tarek Abdelzaher, Tamar Eilam, Huimin Zhao, Matteo Manica, Ravishankar Iyer, Martin Hirzel, Vikram Adve, Darko Marinov, Hubertus Franke, Hanghang Tong, Elizabeth Ainsworth, Han Zhao, Deepak Vasisht, Minh Do, Fabio Oliveira, Giovanni Pacifici, Ruchir Puri, Priya Nagpurkar",2024-11-20T11:57:43Z,"This white paper, developed through close collaboration between IBM Research
and UIUC researchers within the IIDAI Institute, envisions transforming hybrid
cloud systems to meet the growing complexity of AI workloads through
innovative, full-stack co-design approaches, emphasizing usability,
manageability, affordability, adaptability, efficiency, and scalability. By
integrating cutting-edge technologies such as generative and agentic AI,
cross-layer automation and optimization, unified control plane, and composable
and adaptive system architecture, the proposed framework addresses critical
challenges in energy efficiency, performance, and cost-effectiveness.
Incorporating quantum computing as it matures will enable quantum-accelerated
simulations for materials science, climate modeling, and other high-impact
domains. Collaborative efforts between academia and industry are central to
this vision, driving advancements in foundation models for material design and
climate solutions, scalable multimodal data processing, and enhanced
physics-based AI emulators for applications like weather forecasting and carbon
sequestration. Research priorities include advancing AI agentic systems, LLM as
an Abstraction (LLMaaA), AI model optimization and unified abstractions across
heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient
programming model, middleware and platform, secure infrastructure,
application-adaptive cloud systems, and new quantum-classical collaborative
workflows. These ideas and solutions encompass both theoretical and practical
research questions, requiring coordinated input and support from the research
community. This joint initiative aims to establish hybrid clouds as secure,
efficient, and sustainable platforms, fostering breakthroughs in AI-driven
applications and scientific discovery across academia, industry, and society.","cs.DC, cs.AI, cs.AR, cs.ET, cs.MA",cs.DC,http://arxiv.org/abs/2411.13239v1
"BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting
  Constrained Generation Framework",Xu Zou,2024-11-20T11:56:56Z,"Recently, generative pre-trained models have made significant strides,
particularly highlighted by the release of ChatGPT and GPT-4, which exhibit
superior cross-domain capabilities. However, these models still face challenges
on constrained writing tasks like poem generation under open-domain titles. In
response to this challenge, we introduce Block Inverse Prompting (BIPro)
constrained generation framework. BIPro leverages two block inverse prompting
methods, revise and rewrite, that mimic the process of human text writing using
block generative models. It significantly improves the zero-shot generation
quality on the formidable constrained generation task of open-domain
traditional-form Chinese poem generation. Based on a less powerful block
generative model GLM-10B-Chinese, poems composed via BIPro without priming or
additional training outperform both most advanced direct generative systems
like GPT-4 or GLM-4 and best domain-specific systems such as Yusheng,
Shisanbai, or Baidu Poetry Helper in human evaluation by proficient poets.
Finally, BIPro considerably narrows the gap between AI-generated works and
short-listed human literary arts in another human evaluation, unveiling the
promising potential of block generative models in improving the quality of
constrained generation.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13237v1
"AIDBench: A benchmark for evaluating the authorship identification
  capability of large language models","Zichen Wen, Dadi Guo, Huishuai Zhang",2024-11-20T11:41:08Z,"As large language models (LLMs) rapidly advance and integrate into daily
life, the privacy risks they pose are attracting increasing attention. We focus
on a specific privacy risk where LLMs may help identify the authorship of
anonymous texts, which challenges the effectiveness of anonymity in real-world
systems such as anonymous peer review systems. To investigate these risks, we
present AIDBench, a new benchmark that incorporates several author
identification datasets, including emails, blogs, reviews, articles, and
research papers. AIDBench utilizes two evaluation methods: one-to-one
authorship identification, which determines whether two texts are from the same
author; and one-to-many authorship identification, which, given a query text
and a list of candidate texts, identifies the candidate most likely written by
the same author as the query text. We also introduce a Retrieval-Augmented
Generation (RAG)-based method to enhance the large-scale authorship
identification capabilities of LLMs, particularly when input lengths exceed the
models' context windows, thereby establishing a new baseline for authorship
identification using LLMs. Our experiments with AIDBench demonstrate that LLMs
can correctly guess authorship at rates well above random chance, revealing new
privacy risks posed by these powerful models. The source code and data will be
made publicly available after acceptance.",cs.CL,cs.CL,http://arxiv.org/abs/2411.13226v1
On Minimal and Minimum Cylindrical Algebraic Decompositions,"Lucas Michel, Pierre Mathonet, Naïm Zénaïdi",2024-11-20T11:24:49Z,"We consider cylindrical algebraic decompositions (CADs) as a tool for
representing semi-algebraic subsets of $\mathbb{R}^n$. In this framework, a CAD
$\mathscr{C}$ is adapted to a given set $S$ if $S$ is a union of cells of
$\mathscr{C}$. Different algorithms computing an adapted CAD may produce
different outputs, usually with redundant cell divisions. In this paper we
analyse the possibility to remove the superfluous data. More precisely we
consider the set CAD$(S)$ of CADs that are adapted to $S$, endowed with the
refinement partial order and we study the existence of minimal and minimum
elements in this poset.
  We show that for every semi-algebraic set $S$ of $\mathbb{R}^n$ and every CAD
$\mathscr{C}$ adapted to $S$, there is a minimal CAD adapted to $S$ and smaller
(i.e. coarser) than or equal to $\mathscr{C}$. Moreover, when $n=1$ or $n=2$,
we strengthen this result by proving the existence of a minimum element in
CAD$(S)$. Astonishingly for $n \geq 3$, there exist semi-algebraic sets whose
associated poset of adapted CADs does not admit a minimum. We prove this result
by providing explicit examples. We finally use a reduction relation on CAD$(S)$
to define an algorithm for the computation of minimal CADs. We conclude with a
characterization of those semi-algebraic sets $S$ for which CAD$(S)$ has a
minimum by means of confluence of the associated reduction system.","cs.SC, 14P10, I.1.0",cs.SC,http://arxiv.org/abs/2411.13218v1
"Proceedings Sixth International Workshop on Formal Methods for
  Autonomous Systems","Matt Luckcuck, Mengwei Xu",2024-11-20T11:21:22Z,"This EPTCS volume contains the papers from the Sixth International Workshop
on Formal Methods for Autonomous Systems (FMAS 2024), which was held between
the 11th and 13th of November 2024. FMAS 2024 was co-located with 19th
International Conference on integrated Formal Methods (iFM'24), hosted by the
University of Manchester in the United Kingdom, in the University of
Manchester's Core Technology Facility.","cs.LO, cs.AI, cs.RO",cs.LO,http://arxiv.org/abs/2411.13215v1
"Comparative Analysis of Audio Feature Extraction for Real-Time Talking
  Portrait Synthesis","Pegah Salehi, Sajad Amouei Sheshkal, Vajira Thambawita, Sushant Gautam, Saeed S. Sabet, Dag Johansen, Michael A. Riegler, Pål Halvorsen",2024-11-20T11:18:05Z,"This paper examines the integration of real-time talking-head generation for
interviewer training, focusing on overcoming challenges in Audio Feature
Extraction (AFE), which often introduces latency and limits responsiveness in
real-time applications. To address these issues, we propose and implement a
fully integrated system that replaces conventional AFE models with Open AI's
Whisper, leveraging its encoder to optimize processing and improve overall
system efficiency. Our evaluation of two open-source real-time models across
three different datasets shows that Whisper not only accelerates processing but
also improves specific aspects of rendering quality, resulting in more
realistic and responsive talking-head interactions. These advancements make the
system a more effective tool for immersive, interactive training applications,
expanding the potential of AI-driven avatars in interviewer training.","cs.SD, cs.AI, cs.HC, eess.AS, 68T45, 68T07, 68T01",cs.SD,http://arxiv.org/abs/2411.13209v1
An Integrated Approach to Robotic Object Grasping and Manipulation,"Owais Ahmed, M Huzaifa, M Areeb, Hamza Ali Khan",2024-11-20T11:07:37Z,"In response to the growing challenges of manual labor and efficiency in
warehouse operations, Amazon has embarked on a significant transformation by
incorporating robotics to assist with various tasks. While a substantial number
of robots have been successfully deployed for tasks such as item transportation
within warehouses, the complex process of object picking from shelves remains a
significant challenge. This project addresses the issue by developing an
innovative robotic system capable of autonomously fulfilling a simulated order
by efficiently selecting specific items from shelves. A distinguishing feature
of the proposed robotic system is its capacity to navigate the challenge of
uncertain object positions within each bin of the shelf. The system is
engineered to autonomously adapt its approach, employing strategies that enable
it to efficiently locate and retrieve the desired items, even in the absence of
pre-established knowledge about their placements.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.13205v1
VADet: Multi-frame LiDAR 3D Object Detection using Variable Aggregation,"Chengjie Huang, Vahdat Abdelzad, Sean Sedwards, Krzysztof Czarnecki",2024-11-20T10:36:41Z,"Input aggregation is a simple technique used by state-of-the-art LiDAR 3D
object detectors to improve detection. However, increasing aggregation is known
to have diminishing returns and even performance degradation, due to objects
responding differently to the number of aggregated frames. To address this
limitation, we propose an efficient adaptive method, which we call Variable
Aggregation Detection (VADet). Instead of aggregating the entire scene using a
fixed number of frames, VADet performs aggregation per object, with the number
of frames determined by an object's observed properties, such as speed and
point density. VADet thus reduces the inherent trade-offs of fixed aggregation
and is not architecture specific. To demonstrate its benefits, we apply VADet
to three popular single-stage detectors and achieve state-of-the-art
performance on the Waymo dataset.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13186v1
"Click; Single Object Tracking; Video Object Segmentation; Real-time
  Interaction","Kuiran Wang, Xuehui Yu, Wenwen Yu, Guorong Li, Xiangyuan Lan, Qixiang Ye, Jianbin Jiao, Zhenjun Han",2024-11-20T10:30:33Z,"Single object tracking(SOT) relies on precise object bounding box
initialization. In this paper, we reconsidered the deficiencies in the current
approaches to initializing single object trackers and propose a new paradigm
for single object tracking algorithms, ClickTrack, a new paradigm using
clicking interaction for real-time scenarios. Moreover, click as an input type
inherently lack hierarchical information. To address ambiguity in certain
special scenarios, we designed the Guided Click Refiner(GCR), which accepts
point and optional textual information as inputs, transforming the point into
the bounding box expected by the operator. The bounding box will be used as
input of single object trackers. Experiments on LaSOT and GOT-10k benchmarks
show that tracker combined with GCR achieves stable performance in real-time
interactive scenarios. Furthermore, we explored the integration of GCR into the
Segment Anything model(SAM), significantly reducing ambiguity issues when SAM
receives point inputs.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13183v1
Parameterized Geometric Graph Modification with Disk Scaling,"Fedor V. Fomin, Petr A. Golovach, Tanmay Inamdar, Saket Saurabh, Meirav Zehavi",2024-11-20T10:10:23Z,"The parameterized analysis of graph modification problems represents the most
extensively studied area within Parameterized Complexity. Given a graph $G$ and
an integer $k\in\mathbb{N}$ as input, the goal is to determine whether we can
perform at most $k$ operations on $G$ to transform it into a graph belonging to
a specified graph class $\mathcal{F}$. Typical operations are combinatorial and
include vertex deletions and edge deletions, insertions, and contractions.
However, in many real-world scenarios, when the input graph is constrained to
be a geometric intersection graph, the modification of the graph is influenced
by changes in the geometric properties of the underlying objects themselves,
rather than by combinatorial modifications. It raises the question of whether
vertex deletions or adjacency modifications are necessarily the most
appropriate modification operations for studying modifications of geometric
graphs.
  We propose the study of the disk intersection graph modification through the
scaling of disks. This operation is typical in the realm of topology control
but has not yet been explored in the context of Parameterized Complexity. We
design parameterized algorithms and kernels for modifying to the most basic
graph classes: edgeless, connected, and acyclic. Our technical contributions
encompass a novel combination of linear programming, branching, and
kernelization techniques, along with a fresh application of bidimensionality
theory to analyze the area covered by disks, which may have broader
applicability.","cs.CG, cs.DS",cs.CG,http://arxiv.org/abs/2411.13171v1
"IC Mechanisms for Risk-Averse Advertisers in the Online Advertising
  System","Bingzhe Wang, Ruohan Qian, Yuejia Dou, Qi Qi, Bo Shen, Changyuan Li, Yixuan Zhang, Yixin Su, Xin Yuan, Wenqiang liu, Bin Zou, Wen Yi, Zhi Guo, Shuanglong Li, Liu Lin",2024-11-20T09:56:55Z,"The autobidding system generates huge revenue for advertising platforms,
garnering substantial research attention. Existing studies in autobidding
systems focus on designing Autobidding Incentive Compatible (AIC) mechanisms,
where the mechanism is Incentive Compatible (IC) under ex ante expectations.
However, upon deploying AIC mechanisms in advertising platforms, we observe a
notable deviation between the actual auction outcomes and these expectations
during runtime, particularly in the scene with few clicks (sparse-click). This
discrepancy undermines truthful bidding among advertisers in AIC mechanisms,
especially for risk-averse advertisers who are averse to outcomes that do not
align with the expectations. To address this issue, we propose a mechanism,
Decoupled First-Price Auction (DFP), that retains its IC property even during
runtime. DFP dynamically adjusts the payment based on real-time user conversion
outcomes, ensuring that advertisers' realized utilities closely approximate
their expected utilities during runtime. To realize the payment mechanism of
DFP, we propose a PPO-based RL algorithm, with a meticulously crafted reward
function. This algorithm dynamically adjusts the payment to fit DFP mechanism.
We conduct extensive experiments leveraging real-world data to validate our
findings.",cs.GT,cs.GT,http://arxiv.org/abs/2411.13162v1
"Hard-Synth: Synthesizing Diverse Hard Samples for ASR using Zero-Shot
  TTS and LLM","Jiawei Yu, Yuang Li, Xiaosong Qiao, Huan Zhao, Xiaofeng Zhao, Wei Tang, Min Zhang, Hao Yang, Jinsong Su",2024-11-20T09:49:37Z,"Text-to-speech (TTS) models have been widely adopted to enhance automatic
speech recognition (ASR) systems using text-only corpora, thereby reducing the
cost of labeling real speech data. Existing research primarily utilizes
additional text data and predefined speech styles supported by TTS models. In
this paper, we propose Hard-Synth, a novel ASR data augmentation method that
leverages large language models (LLMs) and advanced zero-shot TTS. Our approach
employs LLMs to generate diverse in-domain text through rewriting, without
relying on additional text data. Rather than using predefined speech styles, we
introduce a hard prompt selection method with zero-shot TTS to clone speech
styles that the ASR model finds challenging to recognize. Experiments
demonstrate that Hard-Synth significantly enhances the Conformer model,
achieving relative word error rate (WER) reductions of 6.5\%/4.4\% on
LibriSpeech dev/test-other subsets. Additionally, we show that Hard-Synth is
data-efficient and capable of reducing bias in ASR.","cs.CL, cs.SD, eess.AS",cs.CL,http://arxiv.org/abs/2411.13159v1
CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models,"Naen Xu, Changjiang Li, Tianyu Du, Minxi Li, Wenjie Luo, Jiacheng Liang, Yuyuan Li, Xuhong Zhang, Meng Han, Jianwei Yin, Ting Wang",2024-11-20T09:19:10Z,"Text-to-image diffusion models have emerged as powerful tools for generating
high-quality images from textual descriptions. However, their increasing
popularity has raised significant copyright concerns, as these models can be
misused to reproduce copyrighted content without authorization. In response,
recent studies have proposed various copyright protection methods, including
adversarial perturbation, concept erasure, and watermarking techniques.
However, their effectiveness and robustness against advanced attacks remain
largely unexplored. Moreover, the lack of unified evaluation frameworks has
hindered systematic comparison and fair assessment of different approaches. To
bridge this gap, we systematize existing copyright protection methods and
attacks, providing a unified taxonomy of their design spaces. We then develop
CopyrightMeter, a unified evaluation framework that incorporates 17
state-of-the-art protections and 16 representative attacks. Leveraging
CopyrightMeter, we comprehensively evaluate protection methods across multiple
dimensions, thereby uncovering how different design choices impact fidelity,
efficacy, and resilience under attacks. Our analysis reveals several key
findings: (i) most protections (16/17) are not resilient against attacks; (ii)
the ""best"" protection varies depending on the target priority; (iii) more
advanced attacks significantly promote the upgrading of protections. These
insights provide concrete guidance for developing more robust protection
methods, while its unified evaluation protocol establishes a standard benchmark
for future copyright protection research in text-to-image generation.","cs.CR, cs.AI, cs.CV",cs.CR,http://arxiv.org/abs/2411.13144v1
(Independent) Roman Domination Parameterized by Distance to Cluster,"Pradeesha Ashok, Gautam K. Das, Arti Pandey, Kaustav Paul, Subhabrata Paul",2024-11-20T09:14:03Z,"Given a graph $G=(V,E)$, a function $f:V\to \{0,1,2\}$ is said to be a
\emph{Roman Dominating function} (RDF) if for every $v\in V$ with $f(v)=0$,
there exists a vertex $u\in N(v)$ such that $f(u)=2$. A Roman Dominating
function $f$ is said to be an \emph{Independent Roman Dominating function}
(IRDF), if $V_1\cup V_2$ forms an independent set, where $V_i=\{v\in
V~\vert~f(v)=i\}$, for $i\in \{0,1,2\}$. The total weight of $f$ is equal to
$\sum_{v\in V} f(v)$, and is denoted as $w(f)$. The \emph{Roman Domination
Number} (resp. \emph{Independent Roman Domination Number}) of $G$, denoted by
$\gamma_R(G)$ (resp. $i_R(G)$), is defined as min$\{w(f)~\vert~f$ is an RDF
(resp. IRDF) of $G\}$. For a given graph $G$, the problem of computing
$\gamma_R(G)$ (resp. $i_R(G)$) is defined as the \emph{Roman Domination
problem} (resp. \emph{Independent Roman Domination problem}).
  In this paper, we examine structural parameterizations of the (Independent)
Roman Domination problem. We propose fixed-parameter tractable (FPT) algorithms
for the (Independent) Roman Domination problem in graphs that are $k$ vertices
away from a cluster graph. These graphs have a set of $k$ vertices whose
removal results in a cluster graph. We refer to $k$ as the distance to the
cluster graph. Specifically, we prove the following results when parameterized
by the deletion distance $k$ to cluster graphs: we can find the Roman
Domination Number (and Independent Roman Domination Number) in time
$4^kn^{O(1)}$. In terms of lower bounds, we show that the Roman Domination
number can not be computed in time $2^{\epsilon k}n^{O(1)}$, for any
$0<\epsilon <1$ unless a well-known conjecture, SETH fails. In addition, we
also show that the Roman Domination problem parameterized by distance to
cluster, does not admit a polynomial kernel unless NP $\subseteq$ coNP$/$poly.","cs.CC, cs.DM, cs.DS, math.CO",cs.CC,http://arxiv.org/abs/2411.13141v1
An Expressive Trace Logic for Recursive Programs,"Dilian Gurov, Reiner Hähnle",2024-11-20T08:35:29Z,"We present an expressive logic over trace formulas, based on binary state
predicates, chop, and least fixed-points, for precise specification of programs
with recursive procedures. Both, programs and trace formulas, are equipped with
a direct-style, fully compositional, denotational semantics that on programs
coincides with the standard SOS of recursive programs. We design a
compositional proof calculus for proving finite-trace program properties, and
prove soundness as well as (relative) completeness. We show that each program
can be mapped to a semantics-preserving trace formula and, vice versa, each
trace formula can be mapped to a canonical program over slightly extended
programs, resulting in a Galois connection between programs and formulas. Our
results shed light on the correspondence between programming constructs and
logical connectives.","cs.LO, cs.SE, 68Q55 (Primary) 03B45 (Secondary), F.3.2; F.3.1; F.4.1",cs.LO,http://arxiv.org/abs/2411.13125v1
"DriveMLLM: A Benchmark for Spatial Understanding with Multimodal Large
  Language Models in Autonomous Driving","Xianda Guo, Ruijun Zhang, Yiqun Duan, Yuhang He, Chenming Zhang, Shuai Liu, Long Chen",2024-11-20T08:14:01Z,"Autonomous driving requires a comprehensive understanding of 3D environments
to facilitate high-level tasks such as motion prediction, planning, and
mapping. In this paper, we introduce DriveMLLM, a benchmark specifically
designed to evaluate the spatial understanding capabilities of multimodal large
language models (MLLMs) in autonomous driving. DriveMLLM includes 2,734
front-facing camera images and introduces both absolute and relative spatial
reasoning tasks, accompanied by linguistically diverse natural language
questions. To measure MLLMs' performance, we propose novel evaluation metrics
focusing on spatial understanding. We evaluate several state-of-the-art MLLMs
on DriveMLLM, and our results reveal the limitations of current models in
understanding complex spatial relationships in driving contexts. We believe
these findings underscore the need for more advanced MLLM-based spatial
reasoning methods and highlight the potential for DriveMLLM to drive further
research in autonomous driving. Code will be available at
\url{https://github.com/XiandaGuo/Drive-MLLM}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13112v1
"Song Form-aware Full-Song Text-to-Lyrics Generation with Multi-Level
  Granularity Syllable Count Control","Yunkee Chae, Eunsik Shin, Hwang Suntae, Seungryeol Paik, Kyogu Lee",2024-11-20T07:57:58Z,"Lyrics generation presents unique challenges, particularly in achieving
precise syllable control while adhering to song form structures such as verses
and choruses. Conventional line-by-line approaches often lead to unnatural
phrasing, underscoring the need for more granular syllable management. We
propose a framework for lyrics generation that enables multi-level syllable
control at the word, phrase, line, and paragraph levels, aware of song form.
Our approach generates complete lyrics conditioned on input text and song form,
ensuring alignment with specified syllable constraints. Generated lyrics
samples are available at: https://tinyurl.com/lyrics9999","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.13100v1
Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension,"Yongdong Luo, Xiawu Zheng, Xiao Yang, Guilin Li, Haojia Lin, Jinfa Huang, Jiayi Ji, Fei Chao, Jiebo Luo, Rongrong Ji",2024-11-20T07:44:34Z,"Existing large video-language models (LVLMs) struggle to comprehend long
videos correctly due to limited context. To address this problem, fine-tuning
long-context LVLMs and employing GPT-based agents have emerged as promising
solutions. However, fine-tuning LVLMs would require extensive high-quality data
and substantial GPU resources, while GPT-based agents would rely on proprietary
models (e.g., GPT-4o). In this paper, we propose Video Retrieval-Augmented
Generation (Video-RAG), a training-free and cost-effective pipeline that
employs visually-aligned auxiliary texts to help facilitate cross-modality
alignment while providing additional information beyond the visual content.
Specifically, we leverage open-source external tools to extract
visually-aligned information from pure video data (e.g., audio, optical
character, and object detection), and incorporate the extracted information
into an existing LVLM as auxiliary texts, alongside video frames and queries,
in a plug-and-play manner. Our Video-RAG offers several key advantages: (i)
lightweight with low computing overhead due to single-turn retrieval; (ii) easy
implementation and compatibility with any LVLM; and (iii) significant,
consistent performance gains across long video understanding benchmarks,
including Video-MME, MLVU, and LongVideoBench. Notably, our model demonstrates
superior performance over proprietary models like Gemini-1.5-Pro and GPT-4o
when utilized with a 72B model.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.13093v1
"Hints of Prompt: Enhancing Visual Representation for Multimodal LLMs in
  Autonomous Driving","Hao Zhou, Zhanning Gao, Maosheng Ye, Zhili Chen, Qifeng Chen, Tongyi Cao, Honggang Qi",2024-11-20T06:58:33Z,"In light of the dynamic nature of autonomous driving environments and
stringent safety requirements, general MLLMs combined with CLIP alone often
struggle to represent driving-specific scenarios accurately, particularly in
complex interactions and long-tail cases. To address this, we propose the Hints
of Prompt (HoP) framework, which introduces three key enhancements: Affinity
hint to emphasize instance-level structure by strengthening token-wise
connections, Semantic hint to incorporate high-level information relevant to
driving-specific cases, such as complex interactions among vehicles and traffic
signs, and Question hint to align visual features with the query context,
focusing on question-relevant regions. These hints are fused through a Hint
Fusion module, enriching visual representations and enhancing multimodal
reasoning for autonomous driving VQA tasks. Extensive experiments confirm the
effectiveness of the HoP framework, showing it significantly outperforms
previous state-of-the-art methods across all key metrics.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13076v1
"AMaze: An intuitive benchmark generator for fast prototyping of
  generalizable agents","Kevin Godin-Dubois, Karine Miras, Anna V. Kononova",2024-11-20T06:47:29Z,"Traditional approaches to training agents have generally involved a single,
deterministic environment of minimal complexity to solve various tasks such as
robot locomotion or computer vision. However, agents trained in static
environments lack generalization capabilities, limiting their potential in
broader scenarios. Thus, recent benchmarks frequently rely on multiple
environments, for instance, by providing stochastic noise, simple permutations,
or altogether different settings. In practice, such collections result mainly
from costly human-designed processes or the liberal use of random number
generators. In this work, we introduce AMaze, a novel benchmark generator in
which embodied agents must navigate a maze by interpreting visual signs of
arbitrary complexities and deceptiveness. This generator promotes human
interaction through the easy generation of feature-specific mazes and an
intuitive understanding of the resulting agents' strategies. As a
proof-of-concept, we demonstrate the capabilities of the generator in a simple,
fully discrete case with limited deceptiveness. Agents were trained under three
different regimes (one-shot, scaffolding, interactive), and the results showed
that the latter two cases outperform direct training in terms of generalization
capabilities. Indeed, depending on the combination of generalization metric,
training regime, and algorithm, the median gain ranged from 50% to 100% and
maximal performance was achieved through interactive training, thereby
demonstrating the benefits of a controllable human-in-the-loop benchmark
generator.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.13072v1
"Automatic marker-free registration based on similar tetrahedras for
  single-tree point clouds","Jing Ren, Pei Wang, Hanlong Li, Yuhan Wu, Yuhang Gao, Wenxin Chen, Mingtai Zhang, Lingyun Zhang",2024-11-20T06:34:47Z,"In recent years, terrestrial laser scanning technology has been widely used
to collect tree point cloud data, aiding in measurements of diameter at breast
height, biomass, and other forestry survey data. Since a single scan from
terrestrial laser systems captures data from only one angle, multiple scans
must be registered and fused to obtain complete tree point cloud data. This
paper proposes a marker-free automatic registration method for single-tree
point clouds based on similar tetrahedras. First, two point clouds from two
scans of the same tree are used to generate tree skeletons, and key point sets
are constructed from these skeletons. Tetrahedra are then filtered and matched
according to similarity principles, with the vertices of these two matched
tetrahedras selected as matching point pairs, thus completing the coarse
registration of the point clouds from the two scans. Subsequently, the ICP
method is applied to the coarse-registered leaf point clouds to obtain fine
registration parameters, completing the precise registration of the two tree
point clouds. Experiments were conducted using terrestrial laser scanning data
from eight trees, each from different species and with varying shapes. The
proposed method was evaluated using RMSE and Hausdorff distance, compared
against the traditional ICP and NDT methods. The experimental results
demonstrate that the proposed method significantly outperforms both ICP and NDT
in registration accuracy, achieving speeds up to 593 times and 113 times faster
than ICP and NDT, respectively. In summary, the proposed method shows good
robustness in single-tree point cloud registration, with significant advantages
in accuracy and speed compared to traditional ICP and NDT methods, indicating
excellent application prospects in practical registration scenarios.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13069v1
"""It was 80% me, 20% AI"": Seeking Authenticity in Co-Writing with Large
  Language Models","Angel Hsing-Chi Hwang, Q. Vera Liao, Su Lin Blodgett, Alexandra Olteanu, Adam Trischler",2024-11-20T04:42:32Z,"Given the rising proliferation and diversity of AI writing assistance tools,
especially those powered by large language models (LLMs), both writers and
readers may have concerns about the impact of these tools on the authenticity
of writing work. We examine whether and how writers want to preserve their
authentic voice when co-writing with AI tools and whether personalization of AI
writing support could help achieve this goal. We conducted semi-structured
interviews with 19 professional writers, during which they co-wrote with both
personalized and non-personalized AI writing-support tools. We supplemented
writers' perspectives with opinions from 30 avid readers about the written work
co-produced with AI collected through an online survey. Our findings illuminate
conceptions of authenticity in human-AI co-creation, which focus more on the
process and experience of constructing creators' authentic selves. While
writers reacted positively to personalized AI writing tools, they believed the
form of personalization needs to target writers' growth and go beyond the phase
of text production. Overall, readers' responses showed less concern about
human-AI co-writing. Readers could not distinguish AI-assisted work,
personalized or not, from writers' solo-written work and showed positive
attitudes toward writers experimenting with new technology for creative
writing.","cs.HC, cs.AI, cs.CY",cs.HC,http://arxiv.org/abs/2411.13032v1
Open-World Amodal Appearance Completion,"Jiayang Ao, Yanbei Jiang, Qiuhong Ke, Krista A. Ehinger",2024-11-20T03:45:48Z,"Understanding and reconstructing occluded objects is a challenging problem,
especially in open-world scenarios where categories and contexts are diverse
and unpredictable. Traditional methods, however, are typically restricted to
closed sets of object categories, limiting their use in complex, open-world
scenes. We introduce Open-World Amodal Appearance Completion, a training-free
framework that expands amodal completion capabilities by accepting flexible
text queries as input. Our approach generalizes to arbitrary objects specified
by both direct terms and abstract queries. We term this capability reasoning
amodal completion, where the system reconstructs the full appearance of the
queried object based on the provided image and language query. Our framework
unifies segmentation, occlusion analysis, and inpainting to handle complex
occlusions and generates completed objects as RGBA elements, enabling seamless
integration into applications such as 3D reconstruction and image editing.
Extensive evaluations demonstrate the effectiveness of our approach in
generalizing to novel objects and occlusions, establishing a new benchmark for
amodal completion in open-world settings. The code and datasets will be
released after paper acceptance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.13019v1
"Breaking the Cycle of Recurring Failures: Applying Generative AI to Root
  Cause Analysis in Legacy Banking Systems","Siyuan Jin, Zhendong Bei, Bichao Chen, Yong Xia",2024-11-20T03:43:03Z,"Traditional banks face significant challenges in digital transformation,
primarily due to legacy system constraints and fragmented ownership. Recent
incidents show that such fragmentation often results in superficial incident
resolutions, leaving root causes unaddressed and causing recurring failures. We
introduce a novel approach to post-incident analysis, integrating
knowledge-based GenAI agents with the ""Five Whys"" technique to examine problem
descriptions and change request data. This method uncovered that approximately
70% of the incidents previously attributed to management or vendor failures
were due to underlying internal code issues. We present a case study to show
the impact of our method. By scanning over 5,000 projects, we identified over
400 files with a similar root cause. Overall, we leverage the knowledge-based
agents to automate and elevate root cause analysis, transforming it into a more
proactive process. These agents can be applied across other phases of the
software development lifecycle, further improving development processes.","cs.SE, cs.CL",cs.SE,http://arxiv.org/abs/2411.13017v1
Strong XOR Lemma for Information Complexity,"Pachara Sawettamalya, Huacheng Yu",2024-11-20T03:36:48Z,"For any $\{0,1\}$-valued function $f$, its \emph{$n$-folded XOR} is the
function $f^{\oplus n}$ where $f^{\oplus n}(X_1, \ldots, X_n) = f(X_1) \oplus
\cdots \oplus f(X_n)$. Given a procedure for computing the function $f$, one
can apply a ``naive"" approach to compute $f^{\oplus n}$ by computing each
$f(X_i)$ independently, followed by XORing the outputs. This approach uses $n$
times the resources required for computing $f$.
  In this paper, we prove a strong XOR lemma for \emph{information complexity}
in the two-player randomized communication model: if computing $f$ with an
error probability of $O(n^{-1})$ requires revealing $I$ bits of information
about the players' inputs, then computing $f^{\oplus n}$ with a constant error
requires revealing $\Omega(n) \cdot (I - 1 - o_n(1))$ bits of information about
the players' inputs. Our result demonstrates that the naive protocol for
computing $f^{\oplus n}$ is both information-theoretically optimal and
asymptotically tight in error trade-offs.","cs.CC, cs.IT, math.IT",cs.CC,http://arxiv.org/abs/2411.13015v1
"MemoryFormer: Minimize Transformer Computation by Removing
  Fully-Connected Layers","Ning Ding, Yehui Tang, Haochen Qin, Zhenli Zhou, Chao Xu, Lin Li, Kai Han, Heng Liao, Yunhe Wang",2024-11-20T02:41:53Z,"In order to reduce the computational complexity of large language models,
great efforts have been made to to improve the efficiency of transformer models
such as linear attention and flash-attention. However, the model size and
corresponding computational complexity are constantly scaled up in pursuit of
higher performance. In this work, we present MemoryFormer, a novel transformer
architecture which significantly reduces the computational complexity (FLOPs)
from a new perspective. We eliminate nearly all the computations of the
transformer model except for the necessary computation required by the
multi-head attention operation. This is made possible by utilizing an
alternative method for feature transformation to replace the linear projection
of fully-connected layers. Specifically, we first construct a group of
in-memory lookup tables that store a large amount of discrete vectors to
replace the weight matrix used in linear projection. We then use a hash
algorithm to retrieve a correlated subset of vectors dynamically based on the
input embedding. The retrieved vectors combined together will form the output
embedding, which provides an estimation of the result of matrix multiplication
operation in a fully-connected layer. Compared to conducting matrix
multiplication, retrieving data blocks from memory is a much cheaper operation
which requires little computations. We train MemoryFormer from scratch and
conduct extensive experiments on various benchmarks to demonstrate the
effectiveness of the proposed model.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12992v1
"LaVida Drive: Vision-Text Interaction VLM for Autonomous Driving with
  Token Selection, Recovery and Enhancement","Siwen Jiao, Yangyi Fang",2024-11-20T02:14:07Z,"Recent advancements in Visual Language Models (VLMs) have made them crucial
for visual question answering (VQA) in autonomous driving, enabling natural
human-vehicle interactions. However, existing methods often struggle in dynamic
driving environments, as they usually focus on static images or videos and rely
on downsampling to manage computational costs. This results in the loss of
critical details and the difficulty in effectively integrating spatial and
temporal information, undermining fine-grained perception and temporal
coherence essential for effective decision-making. To tackle these challenges,
we introduce LaVida Drive, a novel and efficient VQA framework for autonomous
driving. LaVida Drive seamlessly integrates temporal data while maintaining
high-resolution inputs for detailed visual perception. It optimizes spatial
processing by retaining high-resolution data for intricate details and using
lower-resolution inputs for temporal analysis to focus on motion-related
features, thereby boosting computational efficiency. The core of LaVida Drive
consists of two modules: the \textit{Query-aware Token Selection} module and
the \textit{Spatial-Temporal Token Recovery and Enhancement} module. The former
dynamically selects the most relevant visual tokens based on semantic alignment
with the input query, reducing the token count from high-resolution spatial
input. The latter ensures smooth and coherent interactions between spatial and
temporal information, preserving contextual continuity across frames. Extensive
experiments on various autonomous driving question-answering benchmarks show
that LaVida Drive significantly reduces visual tokens, enhances efficiency, and
improves overall performance.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12980v1
"Oblivious Algorithms for Maximum Directed Cut: New Upper and Lower
  Bounds","Samuel Hwang, Noah G. Singer, Santhoshini Velusamy",2024-11-20T02:06:04Z,"In the maximum directed cut problem, the input is a directed graph $G=(V,E)$,
and the goal is to pick a partition $V = S \cup (V \setminus S)$ of the
vertices such that as many edges as possible go from $S$ to $V\setminus S$.
Oblivious algorithms, introduced by Feige and Jozeph (Algorithmica'17), are a
simple class of algorithms for this problem. These algorithms independently and
randomly assign each vertex $v$ to either $S$ or $V \setminus S$, and the
distribution of $v$'s assignment is determined using only extremely local
information about $v$: its bias, i.e., the relative difference between its out-
and in-degrees. These algorithms have natural implementations in certain graph
streaming models, where they have important implications (Saxena, Singer,
Sudan, and Velusamy, SODA'23, FOCS'23, Kallaugher, Parekh, and Voronova,
STOC'24).
  In this work, we narrow the gap between upper and lower bounds on the best
approximation ratio achievable by oblivious algorithms for Max-Directed-Cut. We
show that there exists an oblivious algorithm achieving an approximation ratio
of at least $0.4853$, while every oblivious algorithm obeying a natural
symmetry property achieves an approximation ratio of at most $0.4889$. The
previous known bounds were $0.4844$ and $0.4899$, due to Singer (APPROX'23) and
Feige and Jozeph, respectively. Our techniques involve designing principled
parameterizations of the spaces of algorithms and lower bounds and then
executing computer searches through these spaces.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12976v1
Real-Time Energy-Optimal Path Planning for Electric Vehicles,"Saman Ahmadi, Guido Tack, Daniel Harabor, Philip Kilby, Mahdi Jalili",2024-11-20T01:39:08Z,"The rapid adoption of electric vehicles (EVs) in modern transport systems has
made energy-aware routing a critical task in their successful integration,
especially within large-scale networks. In cases where an EV's remaining energy
is limited and charging locations are not easily accessible, some destinations
may only be reachable through an energy-optimal path: a route that consumes
less energy than all other alternatives. The feasibility of such
energy-efficient paths depends heavily on the accuracy of the energy model used
for planning, and thus failing to account for vehicle dynamics can lead to
inaccurate energy estimates, rendering some planned routes infeasible in
reality. This paper explores the impact of vehicle dynamics on energy-optimal
path planning for EVs. We develop an accurate energy model that incorporates
key vehicle dynamics parameters into energy calculations, thereby reducing the
risk of planning infeasible paths under battery constraints. The paper also
introduces two novel online reweighting functions that allow for a faster,
pre-processing free, pathfinding in the presence of negative energy costs
resulting from regenerative braking, making them ideal for real-time
applications. Through extensive experimentation on real-world transport
networks, we demonstrate that our approach considerably enhances energy-optimal
pathfinding for EVs in both computational efficiency and energy estimation
accuracy.",cs.AI,cs.AI,http://arxiv.org/abs/2411.12964v1
"Bring the Heat: Rapid Trajectory Optimization with Pseudospectral
  Techniques and the Affine Geometric Heat Flow Equation","Challen Enninful Adu, César E. Ramos Chuquiure, Bohao Zhang, Ram Vasudevan",2024-11-20T01:37:14Z,"Generating optimal trajectories for high-dimensional robotic systems in a
time-efficient manner while adhering to constraints is a challenging task. To
address this challenge, this paper introduces PHLAME, which applies
pseudospectral collocation and spatial vector algebra to efficiently solve the
Affine Geometric Heat Flow (AGHF) Partial Differential Equation (PDE) for
trajectory optimization. Unlike traditional PDE approaches like the
Hamilton-Jacobi-Bellman (HJB) PDE, which solve for a function over the entire
state space, computing a solution to the AGHF PDE scales more efficiently
because its solution is defined over a two-dimensional domain, thereby avoiding
the intractability of state-space scaling. To solve the AGHF one usually
applies the Method of Lines (MOL), which works by discretizing one variable of
the AGHF PDE, effectively converting the PDE into a system of ordinary
differential equations (ODEs) that can be solved using standard
time-integration methods. Though powerful, this method requires a fine
discretization to generate accurate solutions and still requires evaluating the
AGHF PDE which can be computationally expensive for high-dimensional systems.
PHLAME overcomes this deficiency by using a pseudospectral method, which
reduces the number of function evaluations required to yield a high accuracy
solution thereby allowing it to scale efficiently to high-dimensional robotic
systems. To further increase computational speed, this paper presents
analytical expressions for the AGHF and its Jacobian, both of which can be
computed efficiently using rigid body dynamics algorithms. The proposed method
PHLAME is tested across various dynamical systems, with and without obstacles
and compared to a number of state-of-the-art techniques. PHLAME generates
trajectories for a 44-dimensional state-space system in $\sim3$ seconds, much
faster than current state-of-the-art techniques.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.12962v1
"On the Consistency of Video Large Language Models in Temporal
  Comprehension","Minjoon Jung, Junbin Xiao, Byoung-Tak Zhang, Angela Yao",2024-11-20T00:47:17Z,"Video large language models (Video-LLMs) can temporally ground language
queries and retrieve video moments. Yet, such temporal comprehension
capabilities are neither well-studied nor understood. So we conduct a study on
prediction consistency -- a key indicator for robustness and trustworthiness of
temporal grounding. After the model identifies an initial moment within the
video content, we apply a series of probes to check if the model's responses
align with this initial grounding as an indicator of reliable comprehension.
Our results reveal that current Video-LLMs are sensitive to variations in video
contents, language queries, and task settings, unveiling severe deficiencies in
maintaining consistency. We further explore common prompting and
instruction-tuning methods as potential solutions, but find that their
improvements are often unstable. To that end, we propose event temporal
verification tuning that explicitly accounts for consistency, and demonstrate
significant improvements for both grounding and consistency. Our data and code
will be available at https://github.com/minjoong507/Consistency-of-Video-LLM.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12951v1
Towards Automated Verification of Logarithmic Arithmetic,"Mark G. Arnold, Thomas A. Bailey, John R. Cowles",2024-11-19T23:21:20Z,"Correctness proofs for floating point programs are difficult to verify. To
simplify the task, a similar, but less complex system, known as logarithmic
arithmetic can be used. The Boyer-Moore Theorem Prover, NQTHM, mechanically
verified the correctness of a simple implementation of logarithmic arithmetic.
It also verified some useful theorems about accumulated relative error bounds
for addition, multiplication and division in this logarithmic number system.
These theorems were used to verify a program that approximates e^x using a
truncated Taylor series. Axioms that characterize the finite precision of the
logarithmic system using a rational base, b, were shown by the prover to be
satisfiable for any choice of 1 < b < 2. The prover verified the correctness of
a function for converting an arbitrary rational value to a logarithmic
representation. It also verified that multiplication and division
implementations produce exact results for exact inputs, and that addition
implementation produces a result as accurate as possible for exact inputs. When
these operations are used in combination by a program, such as evaluating a
polynomial, the relative error increases in a way that can be bounded by simple
expressions, referred to here as tolerances. Several mechanically verified
theorems about tolerances allow us to construct mechanically verified proofs
about logarithmic arithmetic programs. Although similar to interval arithmetic,
tolerances are especially suited to logarithmic arithmetic.","cs.LO, cs.AR, B.2",cs.LO,http://arxiv.org/abs/2411.12923v1
Fast and Efficient Memory Reclamation For Serverless MicroVMs,"Orestis Lagkas Nikolos, Chloe Alverti, Stratos Psomadakis, Georgios Goumas, Nectarios Koziris",2024-11-19T22:18:31Z,"Resource elasticity is one of the key defining characteristics of the
Function-as-a-Service (FaaS) serverless computing paradigm. In order to provide
strong multi-tenant isolation, FaaS providers commonly sandbox functions inside
virtual machines (VMs or microVMs). While compute resources assigned to
VM-sandboxed functions can be seamlessly adjusted on the fly, memory elasticity
remains challenging, especially when scaling down. State-of-the-art mechanisms
for VM memory elasticity suffer from increased reclaim latency when memory
needs to be released, compounded by CPU and memory bandwidth overheads. We
identify the obliviousness of the Linux memory manager to the virtually
hotplugged memory as the key issue hindering hot-unplug performance, and design
HotMem, a novel approach for fast and efficient VM memory hot(un)plug,
targeting VM-sandboxed serverless functions. Our key insight is that by
segregating virtually hotplugged memory regions from regular VM memory, we are
able to bound the lifetimes of allocations within these regions thus enabling
their fast and efficient reclamation. We implement HotMem in Linux v6.6 and our
evaluation shows that it is an order of magnitude faster than state-of-practice
to reclaim VM memory, while achieving the same P99 function latency with a
model that statically over-provisions VMs.",cs.OS,cs.OS,http://arxiv.org/abs/2411.12893v1
"AzSLD: Azerbaijani Sign Language Dataset for Fingerspelling, Word, and
  Sentence Translation with Baseline Software","Nigar Alishzade, Jamaladdin Hasanov",2024-11-19T21:15:47Z,"Sign language processing technology development relies on extensive and
reliable datasets, instructions, and ethical guidelines. We present a
comprehensive Azerbaijani Sign Language Dataset (AzSLD) collected from diverse
sign language users and linguistic parameters to facilitate advancements in
sign recognition and translation systems and support the local sign language
community. The dataset was created within the framework of a vision-based AzSL
translation project. This study introduces the dataset as a summary of the
fingerspelling alphabet and sentence- and word-level sign language datasets.
The dataset was collected from signers of different ages, genders, and signing
styles, with videos recorded from two camera angles to capture each sign in
full detail. This approach ensures robust training and evaluation of gesture
recognition models. AzSLD contains 30,000 videos, each carefully annotated with
accurate sign labels and corresponding linguistic translations. The dataset is
accompanied by technical documentation and source code to facilitate its use in
training and testing. This dataset offers a valuable resource of labeled data
for researchers and developers working on sign language recognition,
translation, or synthesis. Ethical guidelines were strictly followed throughout
the project, with all participants providing informed consent for collecting,
publishing, and using the data.","cs.CL, I.4.0",cs.CL,http://arxiv.org/abs/2411.12865v1
An Abstract Domain for Heap Commutativity,"Jared Pincus, Eric Koskinen",2024-11-19T20:58:00Z,"Commutativity of program code (the equivalence of two code fragments composed
in alternate orders) is of ongoing interest in many settings such as program
verification, scalable concurrency, and security analysis. While some recent
works have explored static analysis for code commutativity, few have
specifically catered to heap-manipulating programs. We introduce an abstract
domain in which commutativity synthesis or verification techniques can safely
be performed on abstract mathematical models and, from those results, one can
directly obtain commutativity conditions for concrete heap programs. This
approach offloads challenges of concrete heap reasoning into the simpler
abstract space. We show this reasoning supports framing and composition, and
conclude with commutativity analysis of programs operating on example heap data
structures. Our work has been mechanized in Coq and is available in the
supplement.","cs.PL, cs.LO",cs.PL,http://arxiv.org/abs/2411.12857v1
SCOUT: A Situated and Multi-Modal Human-Robot Dialogue Corpus,"Stephanie M. Lukin, Claire Bonial, Matthew Marge, Taylor Hudson, Cory J. Hayes, Kimberly A. Pollard, Anthony Baker, Ashley N. Foots, Ron Artstein, Felix Gervits, Mitchell Abrams, Cassidy Henry, Lucia Donatelli, Anton Leuski, Susan G. Hill, David Traum, Clare R. Voss",2024-11-19T20:18:55Z,"We introduce the Situated Corpus Of Understanding Transactions (SCOUT), a
multi-modal collection of human-robot dialogue in the task domain of
collaborative exploration. The corpus was constructed from multiple
Wizard-of-Oz experiments where human participants gave verbal instructions to a
remotely-located robot to move and gather information about its surroundings.
SCOUT contains 89,056 utterances and 310,095 words from 278 dialogues averaging
320 utterances per dialogue. The dialogues are aligned with the multi-modal
data streams available during the experiments: 5,785 images and 30 maps. The
corpus has been annotated with Abstract Meaning Representation and Dialogue-AMR
to identify the speaker's intent and meaning within an utterance, and with
Transactional Units and Relations to track relationships between utterances to
reveal patterns of the Dialogue Structure. We describe how the corpus and its
annotations have been used to develop autonomous human-robot systems and enable
research in open questions of how humans speak to robots. We release this
corpus to accelerate progress in autonomous, situated, human-robot dialogue,
especially in the context of navigation tasks where details about the
environment need to be discovered.","cs.HC, cs.CL, cs.RO, I.2.7; I.2.9; I.2.10; H.5.2; J.7",cs.HC,http://arxiv.org/abs/2411.12844v1
Towards motion from video diffusion models,"Paul Janson, Tiberiu Popa, Eugene Belilovsky",2024-11-19T19:35:28Z,"Text-conditioned video diffusion models have emerged as a powerful tool in
the realm of video generation and editing. But their ability to capture the
nuances of human movement remains under-explored. Indeed the ability of these
models to faithfully model an array of text prompts can lead to a wide host of
applications in human and character animation. In this work, we take initial
steps to investigate whether these models can effectively guide the synthesis
of realistic human body animations. Specifically we propose to synthesize human
motion by deforming an SMPL-X body representation guided by Score distillation
sampling (SDS) calculated using a video diffusion model. By analyzing the
fidelity of the resulting animations, we gain insights into the extent to which
we can obtain motion using publicly available text-to-video diffusion models
using SDS. Our findings shed light on the potential and limitations of these
models for generating diverse and plausible human motions, paving the way for
further research in this exciting area.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12831v1
Human-Robot Dialogue Annotation for Multi-Modal Common Ground,"Claire Bonial, Stephanie M. Lukin, Mitchell Abrams, Anthony Baker, Lucia Donatelli, Ashley Foots, Cory J. Hayes, Cassidy Henry, Taylor Hudson, Matthew Marge, Kimberly A. Pollard, Ron Artstein, David Traum, Clare R. Voss",2024-11-19T19:33:54Z,"In this paper, we describe the development of symbolic representations
annotated on human-robot dialogue data to make dimensions of meaning accessible
to autonomous systems participating in collaborative, natural language
dialogue, and to enable common ground with human partners. A particular
challenge for establishing common ground arises in remote dialogue (occurring
in disaster relief or search-and-rescue tasks), where a human and robot are
engaged in a joint navigation and exploration task of an unfamiliar
environment, but where the robot cannot immediately share high quality visual
information due to limited communication constraints. Engaging in a dialogue
provides an effective way to communicate, while on-demand or lower-quality
visual information can be supplemented for establishing common ground. Within
this paradigm, we capture propositional semantics and the illocutionary force
of a single utterance within the dialogue through our Dialogue-AMR annotation,
an augmentation of Abstract Meaning Representation. We then capture patterns in
how different utterances within and across speaker floors relate to one another
in our development of a multi-floor Dialogue Structure annotation schema.
Finally, we begin to annotate and analyze the ways in which the visual
modalities provide contextual information to the dialogue for overcoming
disparities in the collaborators' understanding of the environment. We conclude
by discussing the use-cases, architectures, and systems we have implemented
from our annotations that enable physical robots to autonomously engage with
humans in bi-directional dialogue and navigation.","cs.HC, cs.CL, cs.RO, I.2.7; I.2.9; I.2.10; H.5.2; J.7",cs.HC,http://arxiv.org/abs/2411.12829v1
"Probing the Capacity of Language Model Agents to Operationalize
  Disparate Experiential Context Despite Distraction","Sonny George, Chris Sypherd, Dylan Cashman",2024-11-19T19:33:16Z,"Large language model (LLM) agents show promise in an increasing number of
domains. In many proposed applications, it is expected that the agent reasons
over accumulated experience presented in an input prompt. We propose the OEDD
(Operationalize Experience Despite Distraction) corpus, a
human-annotator-validated body of scenarios with pre-scripted agent histories
where the agent must make a decision based on disparate experiential
information in the presence of a distractor. We evaluate three state-of-the-art
LLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal
chain-of-thought prompting strategy and observe that when (1) the input context
contains over 1,615 tokens of historical interactions, (2) a crucially
decision-informing premise is the rightful conclusion over two disparate
environment premises, and (3) a trivial, but distracting red herring fact
follows, all LLMs perform worse than random choice at selecting the better of
two actions. Our code and test corpus are publicly available at:
https://github.com/sonnygeorge/OEDD .","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12828v1
"Declare and Justify: Explicit assumptions in AI evaluations are
  necessary for effective regulation","Peter Barnett, Lisa Thiergart",2024-11-19T19:13:56Z,"As AI systems advance, AI evaluations are becoming an important pillar of
regulations for ensuring safety. We argue that such regulation should require
developers to explicitly identify and justify key underlying assumptions about
evaluations as part of their case for safety. We identify core assumptions in
AI evaluations (both for evaluating existing models and forecasting future
models), such as comprehensive threat modeling, proxy task validity, and
adequate capability elicitation. Many of these assumptions cannot currently be
well justified. If regulation is to be based on evaluations, it should require
that AI development be halted if evaluations demonstrate unacceptable danger or
if these assumptions are inadequately justified. Our presented approach aims to
enhance transparency in AI development, offering a practical path towards more
effective governance of advanced AI systems.","cs.AI, cs.CY",cs.AI,http://arxiv.org/abs/2411.12820v1
Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline,"Junlong Cheng, Bin Fu, Jin Ye, Guoan Wang, Tianbin Li, Haoyu Wang, Ruoyu Li, He Yao, Junren Chen, JingWen Li, Yanzhou Su, Min Zhu, Junjun He",2024-11-19T19:06:29Z,"Interactive Medical Image Segmentation (IMIS) has long been constrained by
the limited availability of large-scale, diverse, and densely annotated
datasets, which hinders model generalization and consistent evaluation across
different models. In this paper, we introduce the IMed-361M benchmark dataset,
a significant advancement in general IMIS research. First, we collect and
standardize over 6.4 million medical images and their corresponding ground
truth masks from multiple data sources. Then, leveraging the strong object
recognition capabilities of a vision foundational model, we automatically
generated dense interactive masks for each image and ensured their quality
through rigorous quality control and granularity management. Unlike previous
datasets, which are limited by specific modalities or sparse annotations,
IMed-361M spans 14 modalities and 204 segmentation targets, totaling 361
million masks-an average of 56 masks per image. Finally, we developed an IMIS
baseline network on this dataset that supports high-quality mask generation
through interactive inputs, including clicks, bounding boxes, text prompts, and
their combinations. We evaluate its performance on medical image segmentation
tasks from multiple perspectives, demonstrating superior accuracy and
scalability compared to existing interactive segmentation models. To facilitate
research on foundational models in medical computer vision, we release the
IMed-361M and model at https://github.com/uni-medical/IMIS-Bench.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12814v1
Stylecodes: Encoding Stylistic Information For Image Generation,Ciara Rowles,2024-11-19T19:04:31Z,"Diffusion models excel in image generation, but controlling them remains a
challenge. We focus on the problem of style-conditioned image generation.
Although example images work, they are cumbersome: srefs (style-reference
codes) from MidJourney solve this issue by expressing a specific image style in
a short numeric code. These have seen widespread adoption throughout social
media due to both their ease of sharing and the fact they allow using an image
for style control, without having to post the source images themselves.
However, users are not able to generate srefs from their own images, nor is the
underlying training procedure public. We propose StyleCodes: an open-source and
open-research style encoder architecture and training procedure to express
image style as a 20-symbol base64 code. Our experiments show that our encoding
results in minimal loss in quality compared to traditional image-to-style
techniques.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12811v1
The More the Merrier: On Evolving Five-valued Spectra Boolean Functions,"Claude Carlet, Marko Ðurasevic, Domagoj Jakobovic, Luca Mariot, Stjepan Picek",2024-11-19T18:57:55Z,"Evolving Boolean functions with specific properties is an interesting
optimization problem since, depending on the combination of properties and
Boolean function size, the problem can range from very simple to (almost)
impossible to solve. Moreover, some problems are more interesting as there may
be only a few options for generating the required Boolean functions. This paper
investigates one such problem: evolving five-valued spectra Boolean functions,
which are the functions whose Walsh-Hadamard coefficients can only take five
distinct values. We experimented with three solution encodings, two fitness
functions, and 12 Boolean function sizes and showed that the tree encoding is
superior to other choices, as we can obtain five-valued Boolean functions with
high nonlinearity.",cs.NE,cs.NE,http://arxiv.org/abs/2411.12735v1
Information Theory of Meaningful Communication,"Doron Sivan, Misha Tsodyks",2024-11-19T18:51:23Z,"In Shannon's seminal paper, entropy of printed English, treated as a
stationary stochastic process, was estimated to be roughly 1 bit per character.
However, considered as a means of communication, language differs considerably
from its printed form: (i) the units of information are not characters or even
words but clauses, i.e. shortest meaningful parts of speech; and (ii) what is
transmitted is principally the meaning of what is being said or written, while
the precise phrasing that was used to communicate the meaning is typically
ignored. In this study, we show that one can leverage recently developed large
language models to quantify information communicated in meaningful narratives
in terms of bits of meaning per clause.","cs.CL, cs.IT, math.IT",cs.CL,http://arxiv.org/abs/2411.12728v1
"An AI-Enabled Side Channel Power Analysis Based Hardware Trojan
  Detection Method for Securing the Integrated Circuits in Cyber-Physical
  Systems","Sefatun-Noor Puspa, Abyad Enan, Reek Majumdar, M Sabbir Salek, Gurcan Comert, Mashrur Chowdhury",2024-11-19T18:39:20Z,"Cyber-physical systems rely on sensors, communication, and computing, all
powered by integrated circuits (ICs). ICs are largely susceptible to various
hardware attacks with malicious intents. One of the stealthiest threats is the
insertion of a hardware trojan into the IC, causing the circuit to malfunction
or leak sensitive information. Due to supply chain vulnerabilities, ICs face
risks of trojan insertion during various design and fabrication stages. These
trojans typically remain inactive until triggered. Once triggered, trojans can
severely compromise system safety and security. This paper presents a
non-invasive method for hardware trojan detection based on side-channel power
analysis. We utilize the dynamic power measurements for twelve hardware trojans
from IEEE DataPort. Our approach applies to signal processing techniques to
extract crucial time-domain and frequency-domain features from the power
traces, which are then used for trojan detection leveraging Artificial
Intelligence (AI) models. Comparison with a baseline detection approach
indicates that our approach achieves higher detection accuracy than the
baseline models used on the same side-channel power dataset.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12721v1
Scaling laws for nonlinear dynamical models of speech,Sam Kirkham,2024-11-19T18:38:01Z,"The addition of a nonlinear restoring force to dynamical models of the speech
gesture significantly improves the empirical accuracy of model predictions, but
nonlinearity introduces challenges in selecting appropriate parameters and
numerical stability, especially when modelling variation in empirical data. We
address this issue by introducing simple numerical methods for parameterization
of nonlinear task dynamic models. We first illustrate the problem and then
outline solutions in the form of power laws that scale nonlinear stiffness
terms. We apply the scaling laws to a cubic model and show how they facilitate
interpretable simulations of the nonlinear gestural dynamics underpinning
speech production.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12720v1
"CATCH: Complementary Adaptive Token-level Contrastive Decoding to
  Mitigate Hallucinations in LVLMs","Zhehan Kan, Ce Zhang, Zihan Liao, Yapeng Tian, Wenming Yang, Junyuan Xiao, Xu Li, Dongmei Jiang, Yaowei Wang, Qingmin Liao",2024-11-19T18:27:31Z,"Large Vision-Language Model (LVLM) systems have demonstrated impressive
vision-language reasoning capabilities but suffer from pervasive and severe
hallucination issues, posing significant risks in critical domains such as
healthcare and autonomous systems. Despite previous efforts to mitigate
hallucinations, a persistent issue remains: visual defect from vision-language
misalignment, creating a bottleneck in visual processing capacity. To address
this challenge, we develop Complementary Adaptive Token-level Contrastive
Decoding to Mitigate Hallucinations in LVLMs (CATCH), based on the Information
Bottleneck theory. CATCH introduces Complementary Visual Decoupling (CVD) for
visual information separation, Non-Visual Screening (NVS) for hallucination
detection, and Adaptive Token-level Contrastive Decoding (ATCD) for
hallucination mitigation. CATCH addresses issues related to visual defects that
cause diminished fine-grained feature perception and cumulative hallucinations
in open-ended scenarios. It is applicable to various visual question-answering
tasks without requiring any specific data or prior knowledge, and generalizes
robustly to new tasks without additional training, opening new possibilities
for advancing LVLM in various challenging applications.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12713v1
"Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular,
  Nervous System, and Digestive Disorders Using Advanced LLMs","Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam",2024-11-19T18:27:25Z,"In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12712v1
Travel Time Based Task Mapping for NoC-Based DNN Accelerator,"Yizhi Chen, Wenyao Zhu, Zhonghai Lu",2024-11-19T18:25:35Z,"Network-on-Chip (NoC) based architectures are recently proposed to accelerate
deep neural networks in specialized hardware. Given that the hardware
configuration is fixed post-manufacture, proper task mapping attracts
researchers' interest. We propose a travel time-based task mapping method that
allocates uneven counts of tasks across different Processing Elements (PEs).
This approach utilizes the travel time recorded in the sampling window and
implicitly makes use of static NoC architecture information and dynamic NoC
congestion status. Furthermore, we examine the effectiveness of our method
under various configurations, including different mapping iterations, flit
sizes, and NoC architecture. Our method achieves up to 12.1% improvement
compared with even mapping and static distance mapping for one layer. For a
complete NN example, our method achieves 10.37% and 13.75% overall improvements
to row-major mapping and distance-based mapping, respectively. While ideal
travel time-based mapping (post-run) achieves 10.37% overall improvements to
row-major mapping, we adopt a sampling window to efficiently map tasks during
the running, achieving 8.17% (sampling window 10) improvement.",cs.AR,cs.AR,http://arxiv.org/abs/2411.12710v1
Dimensions of Generative AI Evaluation Design,"P. Alex Dow, Jennifer Wortman Vaughan, Solon Barocas, Chad Atalla, Alexandra Chouldechova, Hanna Wallach",2024-11-19T18:25:30Z,"There are few principles or guidelines to ensure evaluations of generative AI
(GenAI) models and systems are effective. To help address this gap, we propose
a set of general dimensions that capture critical choices involved in GenAI
evaluation design. These dimensions include the evaluation setting, the task
type, the input source, the interaction style, the duration, the metric type,
and the scoring method. By situating GenAI evaluations within these dimensions,
we aim to guide decision-making during GenAI evaluation design and provide a
structure for comparing different evaluations. We illustrate the utility of the
proposed set of general dimensions using two examples: a hypothetical
evaluation of the fairness of a GenAI system and three real-world GenAI
evaluations of biological threats.",cs.CY,cs.CY,http://arxiv.org/abs/2411.12709v1
"AdaCM$^2$: On Understanding Extremely Long-Term Video with Adaptive
  Cross-Modality Memory Reduction","Yuanbin Man, Ying Huang, Chengming Zhang, Bingzhe Li, Wei Niu, Miao Yin",2024-11-19T18:04:13Z,"The advancements in large language models (LLMs) have propelled the
improvement of video understanding tasks by incorporating LLMs with visual
models. However, most existing LLM-based models (e.g., VideoLLaMA, VideoChat)
are constrained to processing short-duration videos. Recent attempts to
understand long-term videos by extracting and compressing visual features into
a fixed memory size. Nevertheless, those methods leverage only visual modality
to merge video tokens and overlook the correlation between visual and textual
queries, leading to difficulties in effectively handling complex
question-answering tasks. To address the challenges of long videos and complex
prompts, we propose AdaCM$^2$, which, for the first time, introduces an
adaptive cross-modality memory reduction approach to video-text alignment in an
auto-regressive manner on video streams. Our extensive experiments on various
video understanding tasks, such as video captioning, video question answering,
and video classification, demonstrate that AdaCM$^2$ achieves state-of-the-art
performance across multiple datasets while significantly reducing memory usage.
Notably, it achieves a 4.5% improvement across multiple tasks in the LVU
dataset with a GPU memory consumption reduction of up to 65%.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12593v1
Local Density and its Distributed Approximation,"Aleksander Bjørn Christiansen, Ivor van der Hoog, Eva Rotenberg",2024-11-19T18:00:50Z,"The densest subgraph problem is a classic problem in combinatorial
optimisation. Danisch, Chan, and Sozio propose a definition for \emph{local
density} that assigns to each vertex $v$ a value $\rho^*(v)$. This local
density is a generalisation of the maximum subgraph density of a graph. I.e.,
if $\rho(G)$ is the subgraph density of a finite graph $G$, then $\rho(G)$
equals the maximum local density $\rho^*(v)$ over vertices $v$ in $G$. They
approximate the local density of each vertex with no theoretical (asymptotic)
guarantees.
  We provide an extensive study of this local density measure. Just as with
(global) maximum subgraph density, we show that there is a dual relation
between the local out-degrees and the minimum out-degree orientations of the
graph. We introduce the definition of the local out-degree $g^*(v)$ of a vertex
$v$, and show it to be equal to the local density $\rho^*(v)$. We consider the
local out-degree to be conceptually simpler, shorter to define, and easier to
compute.
  Using the local out-degree we show a previously unknown fact: that existing
algorithms already dynamically approximate the local density. Next, we provide
the first distributed algorithms that compute the local density with provable
guarantees: given any $\varepsilon$ such that $\varepsilon^{-1} \in O(poly \,
n)$, we show a deterministic distributed algorithm in the LOCAL model where,
after $O(\varepsilon^{-2} \log^2 n)$ rounds, every vertex $v$ outputs a $(1 +
\varepsilon)$-approximation of their local density $\rho^*(v)$. In CONGEST, we
show a deterministic distributed algorithm that requires $\text{poly}(\log
n,\varepsilon^{-1}) \cdot 2^{O(\sqrt{\log n})}$ rounds, which is sublinear in
$n$.
  As a corollary, we obtain the first deterministic algorithm running in a
sublinear number of rounds for $(1+\varepsilon)$-approximate densest subgraph
detection in the CONGEST model.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12694v2
"MORE-Stress: Model Order Reduction based Efficient Numerical Algorithm
  for Thermal Stress Simulation of TSV Arrays in 2.5D/3D IC","Tianxiang Zhu, Qipan Wang, Yibo Lin, Runsheng Wang, Ru Huang",2024-11-19T17:55:18Z,"Thermomechanical stress induced by through-silicon vias (TSVs) plays an
important role in the performance and reliability analysis of 2.5D/3D ICs.
While the finite element method (FEM) adopted by commercial software can
provide accurate simulation results, it is very time- and memory-consuming for
large-scale analysis. Over the past decade, the linear superposition method has
been utilized to perform fast thermal stress estimations of TSV arrays, but it
suffers from a lack of accuracy. In this paper, we propose MORE-Stress, a novel
strict numerical algorithm for efficient thermal stress simulation of TSV
arrays based on model order reduction. Extensive experimental results
demonstrate that our algorithm can realize a 153-504 times reduction in
computational time and a 39-115 times reduction in memory usage compared with
the commercial software ANSYS, with negligible errors less than 1%. Our
algorithm is as efficient as the linear superposition method, with an order of
magnitude smaller errors and fast convergence.",cs.CE,cs.CE,http://arxiv.org/abs/2411.12690v1
"Enhanced Sign Language Translation between American Sign Language (ASL)
  and Indian Sign Language (ISL) Using LLMs","Malay Kumar, S. Sarvajit Visagan, Tanish Sarang Mahajan, Anisha Natarajan",2024-11-19T17:45:12Z,"We have come up with a research that hopes to provide a bridge between the
users of American Sign Language and the users of spoken language and Indian
Sign Language (ISL). The research enabled us to create a novel framework that
we have developed for Learner Systems. Leveraging art of Large models to create
key features including: - Real-time translation between these two sign
languages in an efficient manner. Making LLM's capability available for
seamless translations to ISL. Here is the full study showing its implementation
in this paper. The core of the system is a sophisticated pipeline that begins
with reclassification and recognition of ASL gestures based on a strong Random
Forest Classifier. By recognizing the ASL, it is translated into text which can
be more easily processed. Highly evolved natural language NLP (Natural Language
Processing) techniques come in handy as they play a role in our LLM integration
where you then use LLMs to be able to convert the ASL text to ISL which
provides you with the intent of sentence or phrase. The final step is to
synthesize the translated text back into ISL gestures, creating an end-to-end
translation experience using RIFE-Net. This framework is tasked with key
challenges such as automatically dealing with gesture variability and
overcoming the linguistic differences between ASL and ISL. By automating the
translation process, we hope to vastly improve accessibility for sign language
users. No longer will the communication gap between ASL and ISL create
barriers; this totally cool innovation aims to bring our communities closer
together. And we believe, with full confidence in our framework, that we're
able to apply the same principles across a wide variety of sign language
dialects.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12685v1
"Optimizing Airline Reservation Systems with Edge-Enabled Microservices:
  A Framework for Real-Time Data Processing and Enhanced User Responsiveness","Biman Barua, M. Shamim Kaiser",2024-11-19T16:58:15Z,"The growing complexity of the operations of airline reservations requires a
smart solution for the adoption of novel approaches to the development of
quick, efficient, and adaptive reservation systems. This paper outlines in
detail a conceptual framework for the implementation of edge computing
microservices in order to address the shortcomings of traditional centralized
architectures. Specifically, as edge computing allows for certain activities
such as seat inventory checks, booking processes and even confirmation to be
done nearer to the user, thus lessening the overall response time and improving
the performance of the system. In addition, the framework value should include
achieving the high performance of the system such as low latency, high
throughput and higher user experience. The major design components include
deployed distributed computing microservices orchestrated by Kubernetes,
real-time message processing system with Kafka and its elastic scaling. Other
operational components include Prometheus and Grafana, which are used to
monitor and manage resources, ensuring that all operational processes are
optimized. Although this research focuses on a design and theoretical scheming
of the framework, its use is foreseen to be more advantageous in facilitating a
transform in the provision of services in the airline industry by improving
customers' satisfaction, providing infrastructure which is cheap to install and
efficiently supporting technology changes such as artificial intelligence and
internet of things embedded systems. This research addresses the increasing
demand for new technologies with modern well-distributed and real-time-centric
systems and also provides a basis for future case implementation and testing.
As such, the proposed architecture offers a market-ready, extensible solution
to the problems posed by existing airline reservation systems .","cs.SE, cs.AI, cs.CE, cs.CL, cs.DC",cs.SE,http://arxiv.org/abs/2411.12650v1
"ChemSICal: Evaluating a Stochastic Chemical Reaction Network for
  Molecular Multiple Access","Alexander Wietfeld, Marina Wendrich, Sebastian Schmidt, Wolfgang Kellerer",2024-11-19T16:50:22Z,"Proposals for molecular communication networks as part of a future internet
of bio-nano-things have become more intricate and the question of practical
implementation is gaining more importance. One option is to apply detailed
chemical modeling to capture more realistic effects of computing processes in
biological systems. In this paper, we present ChemSICal, a detailed model for
implementing the successive interference cancellation (SIC) algorithm for
molecular multiple access in diffusion-based molecular communication networks
as a chemical reaction network (CRN). We describe the structure of the model as
a number of smaller reaction blocks, their speed controlled by reaction rate
constants (RRCs). Deterministic and stochastic methods are utilized to first
iteratively improve the choice of RRCs and subsequently investigate the
performance of the model in terms of an error probability. We analyze the
model's sensitivity to parameter changes and find that the analytically optimal
values for the non-chemical model do not necessarily translate to the chemical
domain. This necessitates careful optimization, especially of the RRCs, which
are crucial for the successful operation of the ChemSICal system.",cs.ET,cs.ET,http://arxiv.org/abs/2411.12637v1
"M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for
  High-Fidelity Single-View 3D Reconstruction","Luoxi Zhang, Pragyan Shrestha, Yu Zhou, Chun Xie, Itaru Kitahara",2024-11-19T16:49:24Z,"The precise reconstruction of 3D objects from a single RGB image in complex
scenes presents a critical challenge in virtual reality, autonomous driving,
and robotics. Existing neural implicit 3D representation methods face
significant difficulties in balancing the extraction of global and local
features, particularly in diverse and complex environments, leading to
insufficient reconstruction precision and quality. We propose M3D, a novel
single-view 3D reconstruction framework, to tackle these challenges. This
framework adopts a dual-stream feature extraction strategy based on Selective
State Spaces to effectively balance the extraction of global and local
features, thereby improving scene comprehension and representation precision.
Additionally, a parallel branch extracts depth information, effectively
integrating visual and geometric features to enhance reconstruction quality and
preserve intricate details. Experimental results indicate that the fusion of
multi-scale features with depth information via the dual-branch feature
extraction significantly boosts geometric consistency and fidelity, achieving
state-of-the-art reconstruction performance.","cs.CV, I.3.5",cs.CV,http://arxiv.org/abs/2411.12635v2
"SG-LRA: Self-Generating Automatic Scoliosis Cobb Angle Measurement with
  Low-Rank Approximation","Zhiwen Shao, Yichen Yuan, Lizhuang Ma, Dit-Yan Yeung, Xiaojia Zhu",2024-11-19T16:07:58Z,"Automatic Cobb angle measurement from X-ray images is crucial for scoliosis
screening and diagnosis. However, most existing regression-based methods and
segmentation-based methods struggle with inaccurate spine representations or
mask connectivity/fragmentation issues. Besides, landmark-based methods suffer
from insufficient training data and annotations. To address these challenges,
we propose a novel framework including Self-Generation pipeline and Low-Rank
Approximation representation (SG-LRA) for automatic Cobb angle measurement.
Specifically, we propose a parameterized spine contour representation based on
LRA, which enables eigen-spine decomposition and spine contour reconstruction.
We can directly obtain spine contour with only regressed LRA coefficients,
which form a more accurate spine representation than rectangular boxes. Also,
we combine LRA coefficient regression with anchor box classification to solve
inaccurate predictions and mask connectivity issues. Moreover, we develop a
data engine with automatic annotation and automatic selection in an iterative
manner, which is trained on a private Spinal2023 dataset. With our data engine,
we generate the largest scoliosis X-ray dataset named Spinal-AI2024 largely
without privacy leaks. Extensive experiments on public AASCE2019, private
Spinal2023, and generated Spinal-AI2024 datasets demonstrate that our method
achieves state-of-the-art Cobb angle measurement performance. Our code and
Spinal-AI2024 dataset are available at https://github.com/Ernestchenchen/SG-LRA
and https://github.com/Ernestchenchen/Spinal-AI2024, respectively.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12604v1
Whisper Finetuning on Nepali Language,"Sanjay Rijal, Shital Adhikari, Manish Dahal, Manish Awale, Vaghawan Ojha",2024-11-19T15:55:56Z,"Despite the growing advancements in Automatic Speech Recognition (ASR)
models, the development of robust models for underrepresented languages, such
as Nepali, remains a challenge. This research focuses on making an exhaustive
and generalized dataset followed by fine-tuning OpenAI's Whisper models of
different sizes to improve transcription (speech-to-text) accuracy for the
Nepali language. We leverage publicly available ASR datasets and self-recorded
custom datasets with a diverse range of accents, dialects, and speaking styles
further enriched through augmentation. Our experimental results demonstrate
that fine-tuning Whisper models on our curated custom dataset substantially
reduces the Word Error Rate (WER) across all model sizes attributed to larger
data variations in terms of speaker's age, gender, and sentiment, acoustic
environment, dialect, denser audio segments (15-30 seconds) that are more
compatible with Whisper's input, and manual curation of audios and
transcriptions. Notably, our approach outperforms Whisper's baseline models
trained on Fleur's dataset, achieving WER reductions of up to 36.2% on the
small and 23.8% on medium models. Furthermore, we show that data augmentation
plays a significant role in enhancing model robustness. Our approach underlines
the importance of dataset quality, variation, and augmentation in the
adaptation of state-of-the-art models to underrepresented languages for
developing accurate ASR systems.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12587v1
"Large Language Models for Combinatorial Optimization of Design Structure
  Matrix","Shuo Jiang, Min Xie, Jianxi Luo",2024-11-19T15:39:51Z,"Combinatorial optimization (CO) is essential for improving efficiency and
performance in engineering applications. As complexity increases with larger
problem sizes and more intricate dependencies, identifying the optimal solution
become challenging. When it comes to real-world engineering problems,
algorithms based on pure mathematical reasoning are limited and incapable to
capture the contextual nuances necessary for optimization. This study explores
the potential of Large Language Models (LLMs) in solving engineering CO
problems by leveraging their reasoning power and contextual knowledge. We
propose a novel LLM-based framework that integrates network topology and domain
knowledge to optimize the sequencing of Design Structure Matrix (DSM)-a common
CO problem. Our experiments on various DSM cases demonstrate that the proposed
method achieves faster convergence and higher solution quality than benchmark
methods. Moreover, results show that incorporating contextual domain knowledge
significantly improves performance despite the choice of LLMs. These findings
highlight the potential of LLMs in tackling complex real-world CO problems by
combining semantic and mathematical reasoning. This approach paves the way for
a new paradigm in in real-world combinatorial optimization.","cs.CE, cs.AI, cs.CL, I.2.7; I.2.1",cs.CE,http://arxiv.org/abs/2411.12571v1
Emulating a computing grid in a local environment for feature evaluation,"Jananga Kalawana, Malith Dilshan, Kaveesha Dinamidu, Kalana Wijethunga, Maksim Stortvedt, Indika Perera",2024-11-19T15:20:24Z,"The necessity for complex calculations in high-energy physics and large-scale
data analysis has led to the development of computing grids, such as the ALICE
computing grid at CERN. These grids outperform traditional supercomputers but
present challenges in directly evaluating new features, as changes can disrupt
production operations and require comprehensive assessments, entailing
significant time investments across all components. This paper proposes a
solution to this challenge by introducing a novel approach for emulating a
computing grid within a local environment. This emulation, resembling a mini
clone of the original computing grid, encompasses its essential components and
functionalities. Local environments provide controlled settings for emulating
grid components, enabling researchers to evaluate system features without
impacting production environments. This investigation contributes to the
evolving field of computing grids and distributed systems, offering insights
into the emulation of a computing grid in a local environment for feature
evaluation.",cs.DC,cs.DC,http://arxiv.org/abs/2411.12559v1
"Tactile interaction with social robots influences attitudes and
  behaviour","Qiaoqiao Ren, Tony Belpaeme",2024-11-19T15:03:02Z,"Tactile interaction plays an essential role in human-to-human interaction.
People gain comfort and support from tactile interactions with others and touch
is an important predictor for trust. While touch has been explored as a
communicative modality in HCI and HRI, we here report on two studies in which
touching a social robot is used to regulate people's stress levels and
consequently their actions. In the first study, we look at whether different
intensities of tactile interaction result in a physiological response related
to stress, and whether the interaction impacts risk-taking behaviour and trust.
We let 38 participants complete a Balloon Analogue Risk Task (BART), a
computer-based game that serves as a proxy for risk-taking behaviour. In our
study, participants are supported by a robot during the BART task. The robot
builds trust and encourages participants to take more risk. The results show
that affective tactile interaction with the robot increases participants'
risk-taking behaviour, but gentle affective tactile interaction increases
comfort and lowers stress whereas high-intensity touch does not. We also find
that male participants exhibit more risk-taking behaviour than females while
being less stressed. Based on this experiment, a second study is used to
ascertain whether these effects are caused by the social nature of tactile
interaction or by the physical interaction alone. For this, instead of a social
robot, participants now have a tactile interaction with a non-social device.
The non-social interaction does not result in any effect, leading us to
conclude that tactile interaction with humanoid robots is a social phenomenon
rather than a mere physical phenomenon.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12549v1
"Mitigating Perception Bias: A Training-Free Approach to Enhance LMM for
  Image Quality Assessment","Siyi Pan, Baoliang Chen, Danni Huang, Hanwei Zhu, Lingyu Zhu, Xiangjie Sui, Shiqi Wang",2024-11-19T15:00:59Z,"Despite the impressive performance of large multimodal models (LMMs) in
high-level visual tasks, their capacity for image quality assessment (IQA)
remains limited. One main reason is that LMMs are primarily trained for
high-level tasks (e.g., image captioning), emphasizing unified image semantics
extraction under varied quality. Such semantic-aware yet quality-insensitive
perception bias inevitably leads to a heavy reliance on image semantics when
those LMMs are forced for quality rating. In this paper, instead of retraining
or tuning an LMM costly, we propose a training-free debiasing framework, in
which the image quality prediction is rectified by mitigating the bias caused
by image semantics. Specifically, we first explore several semantic-preserving
distortions that can significantly degrade image quality while maintaining
identifiable semantics. By applying these specific distortions to the query or
test images, we ensure that the degraded images are recognized as poor quality
while their semantics remain. During quality inference, both a query image and
its corresponding degraded version are fed to the LMM along with a prompt
indicating that the query image quality should be inferred under the condition
that the degraded one is deemed poor quality.This prior condition effectively
aligns the LMM's quality perception, as all degraded images are consistently
rated as poor quality, regardless of their semantic difference.Finally, the
quality scores of the query image inferred under different prior conditions
(degraded versions) are aggregated using a conditional probability model.
Extensive experiments on various IQA datasets show that our debiasing framework
could consistently enhance the LMM performance and the code will be publicly
available.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.12791v1
"Visual-Oriented Fine-Grained Knowledge Editing for MultiModal Large
  Language Models","Zhen Zeng, Leijiang Gu, Xun Yang, Zhangling Duan, Zenglin Shi, Meng Wang",2024-11-19T14:49:36Z,"Knowledge editing aims to efficiently and cost-effectively correct
inaccuracies and update outdated information. Recently, there has been growing
interest in extending knowledge editing from Large Language Models (LLMs) to
Multimodal Large Language Models (MLLMs), which integrate both textual and
visual information, introducing additional editing complexities. Existing
multimodal knowledge editing works primarily focus on text-oriented,
coarse-grained scenarios, failing to address the unique challenges posed by
multimodal contexts. In this paper, we propose a visual-oriented, fine-grained
multimodal knowledge editing task that targets precise editing in images with
multiple interacting entities. We introduce the Fine-Grained Visual Knowledge
Editing (FGVEdit) benchmark to evaluate this task. Moreover, we propose a
Multimodal Scope Classifier-based Knowledge Editor (MSCKE) framework. MSCKE
leverages a multimodal scope classifier that integrates both visual and textual
information to accurately identify and update knowledge related to specific
entities within images. This approach ensures precise editing while preserving
irrelevant information, overcoming the limitations of traditional text-only
editing methods. Extensive experiments on the FGVEdit benchmark demonstrate
that MSCKE outperforms existing methods, showcasing its effectiveness in
solving the complex challenges of multimodal knowledge editing.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12790v1
"Multilayer occupancy grid for obstacle avoidance in an autonomous ground
  vehicle using RGB-D camera","Jhair S. Gallego, Ricardo E. Ramirez",2024-11-19T14:33:47Z,"This work describes the process of integrating a depth camera into the
navigation system of a self-driving ground vehicle (SDV) and the implementation
of a multilayer costmap that enhances the vehicle's obstacle identification
process by expanding its two-dimensional field of view, based on 2D LIDAR, to a
three-dimensional perception system using an RGB-D camera. This approach lays
the foundation for a robust vision-based navigation and obstacle detection
system. A theoretical review is presented and implementation results are
discussed for future work.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12535v1
"Human-AI Co-Creativity: Exploring Synergies Across Levels of Creative
  Collaboration","Jennifer Haase, Sebastian Pokutta",2024-11-19T14:19:43Z,"Human-AI co-creativity represents a transformative shift in how humans and
generative AI tools collaborate in creative processes. This chapter explores
the synergies between human ingenuity and AI capabilities across four levels of
interaction: Digital Pen, AI Task Specialist, AI Assistant, and AI Co-Creator.
While earlier digital tools primarily facilitated creativity, generative AI
systems now contribute actively, demonstrating autonomous creativity in
producing novel and valuable outcomes. Empirical evidence from mathematics
showcases how AI can extend human creative potential, from computational
problem-solving to co-creative partnerships yielding breakthroughs in
longstanding challenges. By analyzing these collaborations, the chapter
highlights AI's potential to enhance human creativity without replacing it,
underscoring the importance of balancing AI's contributions with human
oversight and contextual understanding. This integration pushes the boundaries
of creative achievements, emphasizing the need for human-centered AI systems
that foster collaboration while preserving the unique qualities of human
creativity.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12527v1
"3D Reconstruction by Looking: Instantaneous Blind Spot Detector for
  Indoor SLAM through Mixed Reality","Hanbeom Chang, Jongseong Brad Choi, Chul Min Yeum",2024-11-19T13:55:58Z,"Indoor SLAM often suffers from issues such as scene drifting, double walls,
and blind spots, particularly in confined spaces with objects close to the
sensors (e.g. LiDAR and cameras) in reconstruction tasks. Real-time
visualization of point cloud registration during data collection may help
mitigate these issues, but a significant limitation remains in the inability to
in-depth compare the scanned data with actual physical environments. These
challenges obstruct the quality of reconstruction products, frequently
necessitating revisit and rescan efforts. For this regard, we developed the
LiMRSF (LiDAR-MR-RGB Sensor Fusion) system, allowing users to perceive the
in-situ point cloud registration by looking through a Mixed-Reality (MR)
headset. This tailored framework visualizes point cloud meshes as holograms,
seamlessly matching with the real-time scene on see-through glasses, and
automatically highlights errors detected while they overlap. Such holographic
elements are transmitted via a TCP server to an MR headset, where it is
calibrated to align with the world coordinate, the physical location. This
allows users to view the localized reconstruction product instantaneously,
enabling them to quickly identify blind spots and errors, and take prompt
action on-site. Our blind spot detector achieves an error detection precision
with an F1 Score of 75.76% with acceptably high fidelity of monitoring through
the LiMRSF system (highest SSIM of 0.5619, PSNR of 14.1004, and lowest MSE of
0.0389 in the five different sections of the simplified mesh model which users
visualize through the LiMRSF device see-through glasses). This method ensures
the creation of detailed, high-quality datasets for 3D models, with potential
applications in Building Information Modeling (BIM) but not limited.","cs.HC, cs.CV, cs.GR",cs.HC,http://arxiv.org/abs/2411.12514v1
Near-Optimal Time-Sparsity Trade-Offs for Solving Noisy Linear Equations,"Kiril Bangachev, Guy Bresler, Stefan Tiegel, Vinod Vaikuntanathan",2024-11-19T13:53:43Z,"We present a polynomial-time reduction from solving noisy linear equations
over $\mathbb{Z}/q\mathbb{Z}$ in dimension $\Theta(k\log n/\mathsf{poly}(\log
k,\log q,\log\log n))$ with a uniformly random coefficient matrix to noisy
linear equations over $\mathbb{Z}/q\mathbb{Z}$ in dimension $n$ where each row
of the coefficient matrix has uniformly random support of size $k$. This allows
us to deduce the hardness of sparse problems from their dense counterparts. In
particular, we derive hardness results in the following canonical settings. 1)
Assuming the $\ell$-dimensional (dense) LWE over a polynomial-size field takes
time $2^{\Omega(\ell)}$, $k$-sparse LWE in dimension $n$ takes time
$n^{\Omega({k}/{(\log k \cdot (\log k + \log \log n))})}.$ 2) Assuming the
$\ell$-dimensional (dense) LPN over $\mathbb{F}_2$ takes time
$2^{\Omega(\ell/\log \ell)}$, $k$-sparse LPN in dimension $n$ takes time
$n^{\Omega(k/(\log k \cdot (\log k + \log \log n)^2))}~.$ These running time
lower bounds are nearly tight as both sparse problems can be solved in time
$n^{O(k)},$ given sufficiently many samples. We further give a reduction from
$k$-sparse LWE to noisy tensor completion. Concretely, composing the two
reductions implies that order-$k$ rank-$2^{k-1}$ noisy tensor completion in
$\mathbb{R}^{n^{\otimes k}}$ takes time $n^{\Omega(k/ \log k \cdot (\log k +
\log \log n))}$, assuming the exponential hardness of standard worst-case
lattice problems.","cs.CC, cs.CR, cs.DM, math.ST, stat.TH",cs.CC,http://arxiv.org/abs/2411.12512v1
PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy,"Joanna Kaleta, Weronika Smolak-Dyżewska, Dawid Malarz, Diego Dall'Alba, Przemysław Korzeniowski, Przemysław Spurek",2024-11-19T13:52:30Z,"Endoscopic procedures are crucial for colorectal cancer diagnosis, and
three-dimensional reconstruction of the environment for real-time novel-view
synthesis can significantly enhance diagnosis. We present PR-ENDO, a framework
that leverages 3D Gaussian Splatting within a physically based, relightable
model tailored for the complex acquisition conditions in endoscopy, such as
restricted camera rotations and strong view-dependent illumination. By
exploiting the connection between the camera and light source, our approach
introduces a relighting model to capture the intricate interactions between
light and tissue using physically based rendering and MLP. Existing methods
often produce artifacts and inconsistencies under these conditions, which
PR-ENDO overcomes by incorporating a specialized diffuse MLP that utilizes
light angles and normal vectors, achieving stable reconstructions even with
limited training camera rotations. We benchmarked our framework using a
publicly available dataset and a newly introduced dataset with wider camera
rotations. Our methods demonstrated superior image quality compared to baseline
approaches.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12510v1
"Analysing Explanation-Related Interactions in Collaborative
  Perception-Cognition-Communication-Action","Marc Roig Vilamala, Jack Furby, Julian de Gortari Briseno, Mani Srivastava, Alun Preece, Carolina Fuentes Toro",2024-11-19T13:07:04Z,"Effective communication is essential in collaborative tasks, so AI-equipped
robots working alongside humans need to be able to explain their behaviour in
order to cooperate effectively and earn trust. We analyse and classify
communications among human participants collaborating to complete a simulated
emergency response task. The analysis identifies messages that relate to
various kinds of interactive explanations identified in the explainable AI
literature. This allows us to understand what type of explanations humans
expect from their teammates in such settings, and thus where AI-equipped robots
most need explanation capabilities. We find that most explanation-related
messages seek clarification in the decisions or actions taken. We also confirm
that messages have an impact on the performance of our simulated task.","cs.HC, cs.AI, cs.CL",cs.HC,http://arxiv.org/abs/2411.12483v1
"NMT-Obfuscator Attack: Ignore a sentence in translation with only one
  word","Sahar Sadrizadeh, César Descalzo, Ljiljana Dolamic, Pascal Frossard",2024-11-19T12:55:22Z,"Neural Machine Translation systems are used in diverse applications due to
their impressive performance. However, recent studies have shown that these
systems are vulnerable to carefully crafted small perturbations to their
inputs, known as adversarial attacks. In this paper, we propose a new type of
adversarial attack against NMT models. In this attack, we find a word to be
added between two sentences such that the second sentence is ignored and not
translated by the NMT model. The word added between the two sentences is such
that the whole adversarial text is natural in the source language. This type of
attack can be harmful in practical scenarios since the attacker can hide
malicious information in the automatic translation made by the target NMT
model. Our experiments show that different NMT models and translation tasks are
vulnerable to this type of attack. Our attack can successfully force the NMT
models to ignore the second part of the input in the translation for more than
50% of all cases while being able to maintain low perplexity for the whole
input.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12473v1
"Automated 3D Physical Simulation of Open-world Scene with Gaussian
  Splatting","Haoyu Zhao, Hao Wang, Xingyue Zhao, Hongqiu Wang, Zhiyu Wu, Chengjiang Long, Hua Zou",2024-11-19T12:52:21Z,"Recent advancements in 3D generation models have opened new possibilities for
simulating dynamic 3D object movements and customizing behaviors, yet creating
this content remains challenging. Current methods often require manual
assignment of precise physical properties for simulations or rely on video
generation models to predict them, which is computationally intensive. In this
paper, we rethink the usage of multi-modal large language model (MLLM) in
physics-based simulation, and present Sim Anything, a physics-based approach
that endows static 3D objects with interactive dynamics. We begin with detailed
scene reconstruction and object-level 3D open-vocabulary segmentation,
progressing to multi-view image in-painting. Inspired by human visual
reasoning, we propose MLLM-based Physical Property Perception (MLLM-P3) to
predict mean physical properties of objects in a zero-shot manner. Based on the
mean values and the object's geometry, the Material Property Distribution
Prediction model (MPDP) model then estimates the full distribution,
reformulating the problem as probability distribution estimation to reduce
computational costs. Finally, we simulate objects in an open-world scene with
particles sampled via the Physical-Geometric Adaptive Sampling (PGAS) strategy,
efficiently capturing complex deformations and significantly reducing
computational costs. Extensive experiments and user studies demonstrate our Sim
Anything achieves more realistic motion than state-of-the-art methods within 2
minutes on a single GPU.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12789v1
Guide-to-Explain for Controllable Summarization,"Sangwon Ryu, Heejin Do, Daehee Kim, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok",2024-11-19T12:36:02Z,"Recently, large language models (LLMs) have demonstrated remarkable
performance in abstractive summarization tasks. However, controllable
summarization with LLMs remains underexplored, limiting their ability to
generate summaries that align with specific user preferences. In this paper, we
first investigate the capability of LLMs to control diverse attributes,
revealing that they encounter greater challenges with numerical attributes,
such as length and extractiveness, compared to linguistic attributes. To
address this challenge, we propose a guide-to-explain framework (GTE) for
controllable summarization. Our GTE framework enables the model to identify
misaligned attributes in the initial draft and guides it in explaining errors
in the previous output. Based on this reflection, the model generates a
well-adjusted summary. As a result, by allowing the model to reflect on its
misalignment, we generate summaries that satisfy the desired attributes in
surprisingly fewer iterations than other iterative methods solely using LLMs.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12460v1
Variation between Credible and Non-Credible News Across Topics,Emilie Francis,2024-11-19T12:29:30Z,"'Fake News' continues to undermine trust in modern journalism and politics.
Despite continued efforts to study fake news, results have been conflicting.
Previous attempts to analyse and combat fake news have largely focused on
distinguishing fake news from truth, or differentiating between its various
sub-types (such as propaganda, satire, misinformation, etc.) This paper
conducts a linguistic and stylistic analysis of fake news, focusing on
variation between various news topics. It builds on related work identifying
features from discourse and linguistics in deception detection by analysing
five distinct news topics: Economy, Entertainment, Health, Science, and Sports.
The results emphasize that linguistic features vary between credible and
deceptive news in each domain and highlight the importance of adapting
classification tasks to accommodate variety-based stylistic and linguistic
differences in order to achieve better real-world performance.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12458v1
Ichnos: A Carbon Footprint Estimator for Scientific Workflows,"Kathleen West, Yehia Elkhatib, Lauritz Thamsen",2024-11-19T12:26:36Z,"We propose Ichnos, a novel and flexible tool to estimate the carbon footprint
of Nextflow workflows based on detailed workflow traces, CI time series, and
power models. First, Ichnos takes as input the automatically-generated workflow
trace produced by Nextflow. Use of these traces is an original contribution,
ensuring that users do not need to manually monitor power consumption and
enabling analysis of previously executed workflows. Next, Ichnos allows users
to provide their own resource power model for utilised compute resources to
accurately reflect processor settings, such as the processor frequency, instead
of solely relying on a linear function. Finally, Ichnos converts estimated
energy consumption to overall carbon emissions using fine-grained time-series
CI data for each workflow task and only resorts to coarse-grained yearly
averages where high-resolution location-based CI data are not available.
Additionally, Ichnos reports estimated energy consumption and carbon emissions
per task, providing greater granularity than existing methodologies and
allowing users to identify which of their tasks have the largest footprint to
address. We provide the implementation of Ichnos as open-source. We demonstrate
our tool on traces of two real-world Nextflow workflows, compare the estimated
energy consumption against RAPL and the GA methodology, and show the tool's
functionality by varying the granularity of provided CI data and varying the
processor frequency settings of assigned compute resources.",cs.DC,cs.DC,http://arxiv.org/abs/2411.12456v1
"StrTune: Data Dependence-based Code Slicing for Binary Similarity
  Detection with Fine-tuned Representation","Kaiyan He, Yikun Hu, Xuehui Li, Yunhao Song, Yubo Zhao, Dawu Gu",2024-11-19T12:20:08Z,"Binary Code Similarity Detection (BCSD) is significant for software security
as it can address binary tasks such as malicious code snippets identification
and binary patch analysis by comparing code patterns. Recently, there has been
a growing focus on artificial intelligence-based approaches in BCSD due to
their scalability and generalization. Because binaries are compiled with
different compilation configurations, existing approaches still face notable
limitations when comparing binary similarity. First, BCSD requires analysis on
code behavior, and existing work claims to extract semantic, but actually still
makes analysis in terms of syntax. Second, directly extracting features from
assembly sequences, existing work cannot address the issues of instruction
reordering and different syntax expressions caused by various compilation
configurations. In this paper, we propose StrTune, which slices binary code
based on data dependence and perform slice-level fine-tuning. To address the
first limitation, StrTune performs backward slicing based on data dependence to
capture how a value is computed along the execution. Each slice reflects the
collecting semantics of the code, which is stable across different compilation
configurations. StrTune introduces flow types to emphasize the independence of
computations between slices, forming a graph representation. To overcome the
second limitation, based on slices corresponding to the same value computation
but having different syntax representation, StrTune utilizes a Siamese Network
to fine-tune such pairs, making their representations closer in the feature
space.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12454v1
"Frequency-Aware Guidance for Blind Image Restoration via Diffusion
  Models","Jun Xiao, Zihang Lyu, Hao Xie, Cong Zhang, Yakun Ju, Changjian Shui, Kin-Man Lam",2024-11-19T12:18:16Z,"Blind image restoration remains a significant challenge in low-level vision
tasks. Recently, denoising diffusion models have shown remarkable performance
in image synthesis. Guided diffusion models, leveraging the potent generative
priors of pre-trained models along with a differential guidance loss, have
achieved promising results in blind image restoration. However, these models
typically consider data consistency solely in the spatial domain, often
resulting in distorted image content. In this paper, we propose a novel
frequency-aware guidance loss that can be integrated into various diffusion
models in a plug-and-play manner. Our proposed guidance loss, based on 2D
discrete wavelet transform, simultaneously enforces content consistency in both
the spatial and frequency domains. Experimental results demonstrate the
effectiveness of our method in three blind restoration tasks: blind image
deblurring, imaging through turbulence, and blind restoration for multiple
degradations. Notably, our method achieves a significant improvement in PSNR
score, with a remarkable enhancement of 3.72\,dB in image deblurring. Moreover,
our method exhibits superior capability in generating images with rich details
and reduced distortion, leading to the best visual quality.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.12450v1
Neon: News Entity-Interaction Extraction for Enhanced Question Answering,"Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar",2024-11-19T12:17:43Z,"Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.","cs.CL, cs.IR",cs.CL,http://arxiv.org/abs/2411.12449v2
"Advancing Cloud Computing Capabilities on gem5 by Implementing the
  RISC-V Hypervisor Extension","George-Marios Fragkoulis, Nikos Karystinos, George Papadimitriou, Dimitris Gizopoulos",2024-11-19T12:07:40Z,"This paper presents the implementation and evaluation of the H (hypervisor)
extension for the RISC-V instruction set architecture (ISA) on top of the gem5
microarchitectural simulator. The RISC-V ISA, known for its simplicity and
modularity, has seen widespread adoption in various computing domains. The H
extension aims to enhance RISC-V's capabilities for cloud computing and
virtualization. In this paper, we present the architectural integration of the
H extension into gem5, an open-source, modular platform for computer system
architecture research. We detail the modifications required in gem5's CPU
models and virtualization support to accommodate the H extension. We also
present evaluation results regarding the performance impact and functional
correctness of the extension's implementation on gem5. This study not only
provides a pathway for further research and development of RISC-V extensions
but also contributes valuable insights into the optimization of the gem5
simulator for advanced architectural features.",cs.AR,cs.AR,http://arxiv.org/abs/2411.12444v2
"Beyond Gaussians: Fast and High-Fidelity 3D Splatting with Linear
  Kernels","Haodong Chen, Runnan Chen, Qiang Qu, Zhaoqing Wang, Tongliang Liu, Xiaoming Chen, Yuk Ying Chung",2024-11-19T11:59:54Z,"Recent advancements in 3D Gaussian Splatting (3DGS) have substantially
improved novel view synthesis, enabling high-quality reconstruction and
real-time rendering. However, blurring artifacts, such as floating primitives
and over-reconstruction, remain challenging. Current methods address these
issues by refining scene structure, enhancing geometric representations,
addressing blur in training images, improving rendering consistency, and
optimizing density control, yet the role of kernel design remains
underexplored. We identify the soft boundaries of Gaussian ellipsoids as one of
the causes of these artifacts, limiting detail capture in high-frequency
regions. To bridge this gap, we introduce 3D Linear Splatting (3DLS), which
replaces Gaussian kernels with linear kernels to achieve sharper and more
precise results, particularly in high-frequency regions. Through evaluations on
three datasets, 3DLS demonstrates state-of-the-art fidelity and accuracy, along
with a 30% FPS improvement over baseline 3DGS. The implementation will be made
publicly available upon acceptance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12440v2
"Preference-Conditioned Gradient Variations for Multi-Objective
  Quality-Diversity","Hannah Janmohamed, Maxence Faldor, Thomas Pierrot, Antoine Cully",2024-11-19T11:50:03Z,"In a variety of domains, from robotics to finance, Quality-Diversity
algorithms have been used to generate collections of both diverse and
high-performing solutions. Multi-Objective Quality-Diversity algorithms have
emerged as a promising approach for applying these methods to complex,
multi-objective problems. However, existing methods are limited by their search
capabilities. For example, Multi-Objective Map-Elites depends on random genetic
variations which struggle in high-dimensional search spaces. Despite efforts to
enhance search efficiency with gradient-based mutation operators, existing
approaches consider updating solutions to improve on each objective separately
rather than achieving desired trade-offs. In this work, we address this
limitation by introducing Multi-Objective Map-Elites with
Preference-Conditioned Policy-Gradient and Crowding Mechanisms: a new
Multi-Objective Quality-Diversity algorithm that uses preference-conditioned
policy-gradient mutations to efficiently discover promising regions of the
objective space and crowding mechanisms to promote a uniform distribution of
solutions on the Pareto front. We evaluate our approach on six robotics
locomotion tasks and show that our method outperforms or matches all
state-of-the-art Multi-Objective Quality-Diversity methods in all six,
including two newly proposed tri-objective tasks. Importantly, our method also
achieves a smoother set of trade-offs, as measured by newly-proposed
sparsity-based metrics. This performance comes at a lower computational storage
cost compared to previous methods.",cs.AI,cs.AI,http://arxiv.org/abs/2411.12433v1
"Mini-Splatting2: Building 360 Scenes within Minutes via Aggressive
  Gaussian Densification","Guangchi Fang, Bing Wang",2024-11-19T11:47:40Z,"In this study, we explore the essential challenge of fast scene optimization
for Gaussian Splatting. Through a thorough analysis of the geometry modeling
process, we reveal that dense point clouds can be effectively reconstructed
early in optimization through Gaussian representations. This insight leads to
our approach of aggressive Gaussian densification, which provides a more
efficient alternative to conventional progressive densification methods. By
significantly increasing the number of critical Gaussians, we enhance the model
capacity to capture dense scene geometry at the early stage of optimization.
This strategy is seamlessly integrated into the Mini-Splatting densification
and simplification framework, enabling rapid convergence without compromising
quality. Additionally, we introduce visibility culling within Gaussian
Splatting, leveraging per-view Gaussian importance as precomputed visibility to
accelerate the optimization process. Our Mini-Splatting2 achieves a balanced
trade-off among optimization time, the number of Gaussians, and rendering
quality, establishing a strong baseline for future Gaussian-Splatting-based
works. Our work sets the stage for more efficient, high-quality 3D scene
modeling in real-world applications, and the code will be made available no
matter acceptance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12788v1
CV-Cities: Advancing Cross-View Geo-Localization in Global Cities,"Gaoshuang Huang, Yang Zhou, Luying Zhao, Wenjian Gan",2024-11-19T11:41:22Z,"Cross-view geo-localization (CVGL), which involves matching and retrieving
satellite images to determine the geographic location of a ground image, is
crucial in GNSS-constrained scenarios. However, this task faces significant
challenges due to substantial viewpoint discrepancies, the complexity of
localization scenarios, and the need for global localization. To address these
issues, we propose a novel CVGL framework that integrates the vision
foundational model DINOv2 with an advanced feature mixer. Our framework
introduces the symmetric InfoNCE loss and incorporates near-neighbor sampling
and dynamic similarity sampling strategies, significantly enhancing
localization accuracy. Experimental results show that our framework surpasses
existing methods across multiple public and self-built datasets. To further
improve globalscale performance, we have developed CV-Cities, a novel dataset
for global CVGL. CV-Cities includes 223,736 ground-satellite image pairs with
geolocation data, spanning sixteen cities across six continents and covering a
wide range of complex scenarios, providing a challenging benchmark for CVGL.
The framework trained with CV-Cities demonstrates high localization accuracy in
various test cities, highlighting its strong globalization and generalization
capabilities. Our datasets and codes are available at
https://github.com/GaoShuang98/CVCities.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12431v1
"Blockchain-Enhanced Framework for Secure Third-Party Vendor Risk
  Management and Vigilant Security Controls","Deepti Gupta, Lavanya Elluri, Avi Jain, Shafika Showkat Moni, Omer Aslan",2024-11-20T16:42:14Z,"In an era of heightened digital interconnectedness, businesses increasingly
rely on third-party vendors to enhance their operational capabilities. However,
this growing dependency introduces significant security risks, making it
crucial to develop a robust framework to mitigate potential vulnerabilities.
This paper proposes a comprehensive secure framework for managing third-party
vendor risk, integrating blockchain technology to ensure transparency,
traceability, and immutability in vendor assessments and interactions. By
leveraging blockchain, the framework enhances the integrity of vendor security
audits, ensuring that vendor assessments remain up-to-date and tamperproof.
This proposed framework leverages smart contracts to reduce human error while
ensuring real-time monitoring of compliance and security controls. By
evaluating critical security controls-such as data encryption, access control
mechanisms, multi-factor authentication, and zero-trust architecture-this
approach strengthens an organization's defense against emerging cyber threats.
Additionally, continuous monitoring enabled by blockchain ensures the
immutability and transparency of vendor compliance processes. In this paper, a
case study on iHealth's transition to AWS Cloud demonstrates the practical
implementation of the framework, showing a significant reduction in
vulnerabilities and marked improvement in incident response times. Through the
adoption of this blockchain-enabled approach, organizations can mitigate vendor
risks, streamline compliance, and enhance their overall security posture.",cs.CR,cs.CR,http://arxiv.org/abs/2411.13447v1
From Prompt Engineering to Prompt Craft,"Joseph Lindley, Roger Whitham",2024-11-20T16:08:20Z,"This pictorial presents an ongoing research programme comprising three
practice-based Design Research projects conducted through 2024, exploring the
affordances of diffusion-based AI image generation systems, specifically Stable
Diffusion. The research employs tangible and embodied interactions to
investigate emerging qualitative aspects of generative AI, including
uncertainty and materiality. Our approach leverages the flexibility and
adaptability of Design Research to navigate the rapidly evolving field of
generative AI. The pictorial proposes the notion of prompt craft as a
productive reframing of prompt engineering. This is comprised of two
contributions: (1) reflections on the notion of materiality for diffusion-based
generative AI and a proposed method for a craft-like navigation of the latent
space within generative AI models and (2) discussing interaction design
strategies for designing user interfaces informed by these affordances. The
outcomes are presented as strong concepts or intermediate knowledge, applicable
to various situations and domains.",cs.HC,cs.HC,http://arxiv.org/abs/2411.13422v1
REVISE: Robust Probabilistic Motion Planning in a Gaussian Random Field,"Alex Rose, Naman Aggarwal, Christopher Jewison, Jonathan P. How",2024-11-20T14:51:19Z,"This paper presents Robust samplE-based coVarIance StEering (REVISE), a
multi-query algorithm that generates robust belief roadmaps for dynamic systems
navigating through spatially dependent disturbances modeled as a Gaussian
random field. Our proposed method develops a novel robust sample-based
covariance steering edge controller to safely steer a robot between state
distributions, satisfying state constraints along the trajectory. Our proposed
approach also incorporates an edge rewiring step into the belief roadmap
construction process, which provably improves the coverage of the belief
roadmap. When compared to state-of-the-art methods, REVISE improves median plan
accuracy (as measured by Wasserstein distance between the actual and planned
final state distribution) by 10x in multi-query planning and reduces median
plan cost (as measured by the largest eigenvalue of the planned state
covariance at the goal) by 2.5x in single-query planning for a 6DoF system. We
will release our code at https://acl.mit.edu/REVISE/.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.13369v1
"Geometry-informed Channel Statistics Prediction Based upon Uncalibrated
  Digital Twins","Mahmoud Saad Abouamer, Robin J. Williams, Petar Popovski",2024-11-20T14:32:40Z,"Digital twins (DTs) of wireless environments can be utilized to predict the
propagation channel and reduce the overhead of required to estimate the channel
statistics. However, direct channel prediction requires data-intensive
calibration of the DT to capture the environment properties relevant for
propagation of electromagnetic signals. We introduce a framework that starts
from a satellite image of the environment to produce an uncalibrated DT, which
has no or imprecise information about the materials and their electromagnetic
properties. The key idea is to use the uncalibrated DT to implicitly provide a
geometric prior for the environment. This is utilized to inform a Gaussian
process (GP), which permits the use of few channel measurements to attain an
accurate prediction of the channel statistics. Additionally, the framework is
able to quantify the uncertainty in channel statistics prediction and select
rate in ultra-reliable low-latency communication (URLLC) that complies with
statistical guarantees. The efficacy of the proposed geometry-informed GP is
validated using experimental data obtained through a measurement campaign.
Furthermore, the proposed prediction framework is shown to provide significant
improvements compared to the benchmarks where i) direct channel statistics
prediction is obtained using an uncalibrated DT and (ii) the GP predicts
channel statistics using information about the location.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.13360v1
"I2TTS: Image-indicated Immersive Text-to-speech Synthesis with Spatial
  Perception","Jiawei Zhang, Tian-Hao Zhang, Jun Wang, Jiaran Gao, Xinyuan Qian, Xu-Cheng Yin",2024-11-20T13:28:42Z,"Controlling the style and characteristics of speech synthesis is crucial for
adapting the output to specific contexts and user requirements. Previous
Text-to-speech (TTS) works have focused primarily on the technical aspects of
producing natural-sounding speech, such as intonation, rhythm, and clarity.
However, they overlook the fact that there is a growing emphasis on spatial
perception of synthesized speech, which may provide immersive experience in
gaming and virtual reality. To solve this issue, in this paper, we present a
novel multi-modal TTS approach, namely Image-indicated Immersive Text-to-speech
Synthesis (I2TTS). Specifically, we introduce a scene prompt encoder that
integrates visual scene prompts directly into the synthesis pipeline to control
the speech generation process. Additionally, we propose a reverberation
classification and refinement technique that adjusts the synthesized
mel-spectrogram to enhance the immersive experience, ensuring that the involved
reverberation condition matches the scene accurately. Experimental results
demonstrate that our model achieves high-quality scene and spatial matching
without compromising speech naturalness, marking a significant advancement in
the field of context-aware speech synthesis. Project demo page:
https://spatialTTS.github.io/ Index Terms-Speech synthesis, scene prompt,
spatial perception","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.13314v1
A Stopping Game on Zero-Sum Sequences,"Adrian Dumitrescu, Arsenii Sagdeev",2024-11-20T11:08:42Z,"We introduce and analyze a natural game formulated as follows. In this
one-person game, the player is given a random permutation $A=(a_1,\dots, a_n)$
of a multiset $M$ of $n$ reals that sum up to $0$, where each of the $n!$
permutation sequences is equally likely. The player only knows the value of $n$
beforehand. The elements of the sequence are revealed one by one and the player
can stop the game at any time. Once the process stops, say, after the $i$th
element is revealed, the player collects the amount $\sum_{j=i+1}^{n} a_j$ as
his/her payoff and the game is over (the payoff corresponds to the unrevealed
part of the sequence).
  Three online algorithms are given for maximizing the expected payoff in the
binary case when $M$ contains only $1$'s and $-1$'s. $\texttt{Algorithm 1}$ is
slightly suboptimal, but is easier to analyze. Moreover, it can also be used
when $n$ is only known with some approximation. $\texttt{Algorithm 2}$ is
exactly optimal but not so easy to analyze on its own. $\texttt{Algorithm 3}$
is the simplest of all three. It turns out that the expected payoffs of the
player are $\Theta(\sqrt{n})$ for all three algorithms.
  In the end, we address the general problem and deal with an arbitrary
zero-sum multiset, for which we show that our $\texttt{Algorithm 3}$ returns a
payoff proportional to $\sqrt{n}$, which is worst case-optimal.","cs.DM, math.CO, 68R05, 91A60, 05A10, G.2; F.2",cs.DM,http://arxiv.org/abs/2411.13206v1
"Simultaneous Communication and Tracking using Fused Bistatic
  Measurements","Avinash M, Srikrishna Bhashyam",2024-11-20T11:02:09Z,"In this paper, we propose a bistatic sensing-assisted beam tracking method
for simultaneous communication and tracking of user vehicles navigating
arbitrary-shaped road trajectories. Prior work on simultaneous communication
and tracking assumes a colocated radar receiver at the transmitter for sensing
measurements using the reflected Integrated Sensing and Communication (ISAC)
signals in the mmWave band. Full isolation between transmitter and receiver is
required here to avoid self-interference. We consider the bistatic setting
where the sensing receivers are not colocated and can be realized in practice
using traditional half-duplex transmit or receive nodes. First, we process the
echoes reflected from the vehicle at multiple multi-antenna nodes at various
locations, facilitating estimation of the vehicle's current position. Then, we
propose selection criteria for the estimates and a maximum likelihood (ML)
fusion scheme to fuse these selected estimates based on the estimated error
covariance matrices of these measurements. This fusion scheme is important in
bistatic and multistatic settings as the localization error depends
significantly on the geometry of the transmitter, target, and receiver
locations. Finally, we predict the vehicle's next location using a simple
kinematic equation-based model. Through extensive simulation, we study the
average spectral efficiency of communication with a moving user using the
proposed simultaneous communication and tracking scheme. The proposed
fusion-based scheme achieves almost the same average spectral efficiency as an
ideal scheme that knows the exact trajectory. We also show that the proposed
scheme can be easily extended to systems with Hybrid Digital-Analog
architectures and performs similarly even in these systems.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.13201v1
Guided Object-Oriented Development,"Harrie Passier, Lex Bijlsma, Ruurd Kuiper, Kees Huizing",2024-11-20T11:01:33Z,"To improve the quality of programs we provide an approach to guidance in the
process of program development. At the higher level the various activities and
their dependencies to structure the process are identified. At the lower level,
detailed, practical rules are given for the decision-making in the development
steps during these activities. The approach concentrates on structure and
behavior of a single class. It includes design and specification and is
compatible with methodologies for programming in the large. Informal
specifications are introduced to help develop correct and robust code as well
as corresponding tests. A strict distinction is made between external design
and specification on one hand and internal design and specification on the
other hand, which helps in keeping control over complexity. The approach also
exploits the separation of success and failure scenarios. A worked-out example
is provided.","cs.SE, D.2.2",cs.SE,http://arxiv.org/abs/2411.13200v1
HapKnob -- A Motorized Shape-changing Haptic Knob Interface,"Zhili Gong, Zitong Wei, Jeremy D. Brown",2024-11-20T02:44:50Z,"The absence of physical interfaces creates challenges when interacting with
touchscreen technology. This study aims to investigate an innovative haptic
solution for interacting with graphical user interfaces. A motorized
shape-changing rotary knob interface, HapKnob, has been developed, achieving
seven distinctive shape configurations and various force feedback renderings.
HapKnob presents a compact design and can provide additional configurations and
combinations based on user needs. The anticipated results hold the potential to
advance the development of future user interfaces, especially in situations
where visual interaction is unavailable.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12993v1
"Veryl: A New Hardware Description Language as an Altarnative to
  SystemVerilog","Naoya Hatta, Taichi Ishitani, Ryota Shioya",2024-11-20T02:20:09Z,"Veryl, a hardware description language based on SystemVerilog, offers
optimized syntax tailored for logic design, ensuring synthesizability and
simplifying common constructs. It prioritizes interoperability with
SystemVerilog, allowing for smooth integration with existing projects while
maintaining high readability. Additionally, Veryl includes a comprehensive set
of development support tools, such as package managers and real-time checkers,
to boost productivity and streamline the design process. These features empower
designers to conduct high-quality hardware design efficiently.","cs.AR, B.6.3",cs.AR,http://arxiv.org/abs/2411.12983v1
Shrinking POMCP: A Framework for Real-Time UAV Search and Rescue,"Yunuo Zhang, Baiting Luo, Ayan Mukhopadhyay, Daniel Stojcsics, Daniel Elenius, Anirban Roy, Susmit Jha, Miklos Maroti, Xenofon Koutsoukos, Gabor Karsai, Abhishek Dubey",2024-11-20T01:41:29Z,"Efficient path optimization for drones in search and rescue operations faces
challenges, including limited visibility, time constraints, and complex
information gathering in urban environments. We present a comprehensive
approach to optimize UAV-based search and rescue operations in neighborhood
areas, utilizing both a 3D AirSim-ROS2 simulator and a 2D simulator. The path
planning problem is formulated as a partially observable Markov decision
process (POMDP), and we propose a novel ``Shrinking POMCP'' approach to address
time constraints. In the AirSim environment, we integrate our approach with a
probabilistic world model for belief maintenance and a neurosymbolic navigator
for obstacle avoidance. The 2D simulator employs surrogate ROS2 nodes with
equivalent functionality. We compare trajectories generated by different
approaches in the 2D simulator and evaluate performance across various belief
types in the 3D AirSim-ROS simulator. Experimental results from both simulators
demonstrate that our proposed shrinking POMCP solution achieves significant
improvements in search times compared to alternative methods, showcasing its
potential for enhancing the efficiency of UAV-assisted search and rescue
operations.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.12967v1
"An Experimental Multi-Band Channel Characterization in the Upper
  Mid-Band","Roberto Bomfin, Ahmad Bazzi, Hao Guo, Hyeongtaek Lee, Marco Mezzavilla, Sundeep Rangan, Junil Choi, Marwa Chafii",2024-11-19T22:10:34Z,"The following paper provides a multi-band channel measurement analysis on the
frequency range (FR)3. This study focuses on the FR3 low frequencies 6.5 GHz
and 8.75 GHz with a setup tailored to the context of integrated sensing and
communication (ISAC), where the data are collected with and without the
presence of a target. A method based on multiple signal classification (MUSIC)
is used to refine the delays of the channel impulse response estimates. The
results reveal that the channel at the lower frequency 6.5 GHz has additional
distinguishable multipath components in the presence of the target, while the
one associated with the higher frequency 8.75 GHz has more blockage. The set of
results reported in this paper serves as a benchmark for future multi-band
studies in the FR3 spectrum.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.12888v1
"Advancing Large Language Models for Spatiotemporal and Semantic
  Association Mining of Similar Environmental Events","Yuanyuan Tian, Wenwen Li, Lei Hu, Xiao Chen, Michael Brook, Michael Brubaker, Fan Zhang, Anna K. Liljedahl",2024-11-19T21:57:22Z,"Retrieval and recommendation are two essential tasks in modern search tools.
This paper introduces a novel retrieval-reranking framework leveraging Large
Language Models (LLMs) to enhance the spatiotemporal and semantic associated
mining and recommendation of relevant unusual climate and environmental events
described in news articles and web posts. This framework uses advanced natural
language processing techniques to address the limitations of traditional manual
curation methods in terms of high labor cost and lack of scalability.
Specifically, we explore an optimized solution to employ cutting-edge embedding
models for semantically analyzing spatiotemporal events (news) and propose a
Geo-Time Re-ranking (GT-R) strategy that integrates multi-faceted criteria
including spatial proximity, temporal association, semantic similarity, and
category-instructed similarity to rank and identify similar spatiotemporal
events. We apply the proposed framework to a dataset of four thousand Local
Environmental Observer (LEO) Network events, achieving top performance in
recommending similar events among multiple cutting-edge dense retrieval models.
The search and recommendation pipeline can be applied to a wide range of
similar data search tasks dealing with geospatial and temporal data. We hope
that by linking relevant events, we can better aid the general public to gain
an enhanced understanding of climate change and its impact on different
communities.","cs.IR, cs.AI",cs.IR,http://arxiv.org/abs/2411.12880v1
"When Backdoors Speak: Understanding LLM Backdoor Attacks Through
  Model-Generated Explanations","Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang",2024-11-19T18:11:36Z,"Large Language Models (LLMs) are vulnerable to backdoor attacks, where hidden
triggers can maliciously manipulate model behavior. While several backdoor
attack methods have been proposed, the mechanisms by which backdoor functions
operate in LLMs remain underexplored. In this paper, we move beyond attacking
LLMs and investigate backdoor functionality through the novel lens of natural
language explanations. Specifically, we leverage LLMs' generative capabilities
to produce human-understandable explanations for their decisions, allowing us
to compare explanations for clean and poisoned samples. We explore various
backdoor attacks and embed the backdoor into LLaMA models for multiple tasks.
Our experiments show that backdoored models produce higher-quality explanations
for clean data compared to poisoned data, while generating significantly more
consistent explanations for poisoned data than for clean data. We further
analyze the explanation generation process, revealing that at the token level,
the explanation token of poisoned samples only appears in the final few
transformer layers of the LLM. At the sentence level, attention dynamics
indicate that poisoned inputs shift attention from the input context when
generating the explanation. These findings deepen our understanding of backdoor
attack mechanisms in LLMs and offer a framework for detecting such
vulnerabilities through explainability techniques, contributing to the
development of more secure LLMs.","cs.CR, cs.AI",cs.CR,http://arxiv.org/abs/2411.12701v1
"OrigamiPlot: An R Package and Shiny Web App Enhanced Visualizations for
  Multivariate Data","Yiwen Lu, Jiayi Tong, Yuqing Lei, Alex J. Sutton, Haitao Chu, Lisa D. Levine, Thomas Lumley, David A. Asch, Rui Duan, Christopher H. Schmid, Yong Chen",2024-11-19T17:27:01Z,"We introduce OrigamiPlot, an open-source R package and Shiny web application
designed to enhance the visualization of multivariate data. This package
implements the origami plot, a novel visualization technique proposed by Duan
et al. in 2023, which improves upon traditional radar charts by ensuring that
the area of the connected region is invariant to the ordering of attributes,
addressing a key limitation of radar charts. The software facilitates
multivariate decision-making by supporting comparisons across multiple objects
and attributes, offering customizable features such as auxiliary axes and
weighted attributes for enhanced clarity. Through the R package and
user-friendly Shiny interface, researchers can efficiently create and customize
plots without requiring extensive programming knowledge. Demonstrated using
network meta-analysis as a real-world example, OrigamiPlot proves to be a
versatile tool for visualizing multivariate data across various fields. This
package opens new opportunities for simplifying decision-making processes with
complex data.","cs.HC, stat.ME",cs.HC,http://arxiv.org/abs/2411.12674v1
"ISAC Super-Resolution Receivers: The Effect of Different Dictionary
  Matrices","Iman Valiulahi, Christos Masouros, Athina P. Petropulu",2024-11-19T17:25:00Z,"This paper presents an off-the-grid estimator for ISAC systems using lifted
atomic norm minimization (LANM). The main challenge in the ISAC systems is the
unknown nature of both transmitted signals and radar-communication channels. We
use a known dictionary to encode transmit signals and show that LANM can
localize radar targets and decode communication symbols when the number of
observations is proportional to the system's degrees of freedom and the
coherence of the dictionary matrix. We reformulate LANM using a dual method and
solve it with semidefinite relaxation (SDR) for different dictionary matrices
to reduce the number of observations required at the receiver. Simulations
demonstrate that the proposed LANM accurately estimates communication data and
target parameters under varying complexity by selecting different dictionary
matrices.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.12672v1
PseudoSeer: a Search Engine for Pseudocode,"Levent Toksoz, Mukund Srinath, Gang Tan, C. Lee Giles",2024-11-19T16:58:03Z,"A novel pseudocode search engine is designed to facilitate efficient
retrieval and search of academic papers containing pseudocode. By leveraging
Elasticsearch, the system enables users to search across various facets of a
paper, such as the title, abstract, author information, and LaTeX code
snippets, while supporting advanced features like combined facet searches and
exact-match queries for more targeted results. A description of the data
acquisition process is provided, with arXiv as the primary data source, along
with methods for data extraction and text-based indexing, highlighting how
different data elements are stored and optimized for search. A weighted
BM25-based ranking algorithm is used by the search engine, and factors
considered when prioritizing search results for both single and combined facet
searches are described. We explain how each facet is weighted in a combined
search. Several search engine results pages are displayed. Finally, there is a
brief overview of future work and potential evaluation methodology for
assessing the effectiveness and performance of the search engine is described.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12649v1
"Improving Controllability and Editability for Pretrained Text-to-Music
  Generation Models",Yixiao Zhang,2024-11-19T16:52:34Z,"The field of AI-assisted music creation has made significant strides, yet
existing systems often struggle to meet the demands of iterative and nuanced
music production. These challenges include providing sufficient control over
the generated content and allowing for flexible, precise edits. This thesis
tackles these issues by introducing a series of advancements that progressively
build upon each other, enhancing the controllability and editability of
text-to-music generation models.
  First, we introduce Loop Copilot, a system that tries to address the need for
iterative refinement in music creation. Loop Copilot leverages a large language
model (LLM) to coordinate multiple specialised AI models, enabling users to
generate and refine music interactively through a conversational interface.
Central to this system is the Global Attribute Table, which records and
maintains key musical attributes throughout the iterative process, ensuring
that modifications at any stage preserve the overall coherence of the music.
While Loop Copilot excels in orchestrating the music creation process, it does
not directly address the need for detailed edits to the generated content.
  To overcome this limitation, MusicMagus is presented as a further solution
for editing AI-generated music. MusicMagus introduces a zero-shot text-to-music
editing approach that allows for the modification of specific musical
attributes, such as genre, mood, and instrumentation, without the need for
retraining. By manipulating the latent space within pre-trained diffusion
models, MusicMagus ensures that these edits are stylistically coherent and that
non-targeted attributes remain unchanged. This system is particularly effective
in maintaining the structural integrity of the music during edits, but it
encounters challenges with more complex and real-world audio scenarios.
  ...","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.12641v1
Securing Satellite Link Segment: A Secure-by-Component Design,"Olfa Ben Yahia, William Ferguson, Sumit Chakravarty, Nesrine Benchoubane, Gunes Karabulut Kurt, Gürkan Gür, Gregory Falco",2024-11-19T16:45:12Z,"The rapid evolution of communication technologies, compounded by recent
geopolitical events such as the Viasat cyberattack in February 2022, has
highlighted the urgent need for fast and reliable satellite missions for
military and civil security operations. Consequently, this paper examines two
Earth observation (EO) missions: one utilizing a single low Earth orbit (LEO)
satellite and another through a network of LEO satellites, employing a
secure-by-component design strategy. This approach begins by defining the scope
of technical security engineering, decomposing the system into components and
data flows, and enumerating attack surfaces. Then it proceeds by identifying
threats to low-level components, applying secure-by-design principles,
redesigning components into secure blocks in alignment with the Space Attack
Research & Tactic Analysis (SPARTA) framework, and crafting shall statements to
refactor the system design, with a particular focus on improving the security
of the link segment.","cs.CR, eess.SP",cs.CR,http://arxiv.org/abs/2411.12632v1
"Locomotion Mode Transitions: Tackling System- and User-Specific
  Variability in Lower-Limb Exoskeletons","Andrea Dal Prete, Zeynep Özge Orhan, Anastasia Bolotnikova, Marta Gandolla, Auke Ijspeert, Mohamed Bouri",2024-11-19T15:41:43Z,"Accurate detection of locomotion transitions, such as walk to sit, walk to
stair ascent, and descent, is crucial to effectively control robotic assistive
devices, such as lower-limb exoskeletons, as each locomotion mode requires
specific assistance. Variability in collected sensor data introduced by user-
or system-specific characteristics makes it challenging to maintain high
transition detection accuracy while avoiding latency using non-adaptive
classification models. In this study, we identified key factors influencing
transition detection performance, including variations in user behavior, and
different mechanical designs of the exoskeletons. To boost the transition
detection accuracy, we introduced two methods for adapting a finite-state
machine classifier to system- and user-specific variability: a Statistics-Based
approach and Bayesian Optimization. Our experimental results demonstrate that
both methods remarkably improve transition detection accuracy across diverse
users, achieving up to an 80% increase in certain scenarios compared to the
non-personalized threshold method. These findings emphasize the importance of
personalization in adaptive control systems, underscoring the potential for
enhanced user experience and effectiveness in assistive devices. By
incorporating subject- and system-specific data into the model training
process, our approach offers a precise and reliable solution for detecting
locomotion transitions, catering to individual user needs, and ultimately
improving the performance of assistive devices.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12573v2
"Online RMLSA in EONs with $A^3G$: Adaptive ACO with Augmentation of
  Graph","M Jyothi Kiran, Venkatesh Chebolu, Goutam Das, Raja Datta",2024-11-19T12:05:23Z,"Routing and Spectrum Assignment (RSA) represents a significant challenge
within Elastic Optical Networks (EONs), particularly in dynamic traffic
scenarios where the network undergoes continuous changes. Integrating multiple
modulation formats transforms it into Routing Modulation Level and Spectrum
Assignment (RMLSA) problem, thereby making it more challenging. Traditionally,
addressing the RSA problem involved identifying a fixed number of paths and
subsequently allocating spectrum among them. Numerous heuristic and
metaheuristic approaches have been proposed for RSA using this two-step
methodology. However, solving for routing and assignment of spectrum
independently is not recommended due to their interdependencies and their
impact on resource utilization, fragmentation and bandwidth blocking
probability. In this paper, we propose a novel approach to solve the RMLSA
problem jointly in dynamic traffic scenarios, inspired by Ant Colony
Optimization (ACO). This approach involves augmenting the network into an
Auxiliary Graph and transforming conventional ACO into a constraint-based ACO
variant that adapts to the constraints of EONs. This adaptation also includes
an adaptive initiation process and an aggressive termination strategy aimed at
achieving faster convergence. Moreover, we have introduced a novel
objective/fitness function, to minimize average network fragmentation while
ensuring optimal spectrum resource utilization, thereby reducing overall
blocking probability.",cs.NI,cs.NI,http://arxiv.org/abs/2411.12442v1
"Efficient terabyte-scale text compression via stable local consistency
  and parallel grammar processing",Diego Diaz-Dominguez,2024-11-19T11:59:27Z,"We present a highly parallelizable text compression algorithm that scales
efficiently to terabyte-sized datasets. Our method builds on locally consistent
grammars, a lightweight form of compression, combined with simple recompression
techniques to achieve further space reductions. Locally consistent grammar
algorithms are particularly suitable for scaling, as they need minimal
satellite information to compact the text. We introduce a novel concept to
enable parallelisation, stable local consistency. A grammar algorithm ALG is
stable, if for any pattern $P$ occurring in a collection $\mathcal{T}=\{T_1,
T_2, \ldots, T_k\}$, the instances $ALG(T_1), ALG(T_2), \ldots, ALG(T_k)$
independently produce cores for $P$ with the same topology. In a locally
consistent grammar, the core of $P$ is a subset of nodes and edges in
$\mathcal{T}$'s parse tree that remains the same in all the occurrences of $P$.
This feature is important to achieve compression, but it only holds if ALG
synchronises the parsing of the strings, for instance, by defining a common set
of nonterminal symbols for them. Stability removes the need for synchronisation
during the parsing phase. Consequently, we can run $ALG(T_1), ALG(T_2), \ldots,
ALG(T_k)$ fully in parallel and then merge the resulting grammars into a single
compressed output equivalent to $ALG(\mathcal{T})$. We implemented our ideas
and tested them on massive datasets. Our results showed that our method could
process a diverse collection of bacterial genomes (7.9 TB) in around nine
hours, requiring 16 threads and 0.43 bits/symbol of working memory, producing a
compressed representation 85 times smaller than the original input.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12439v1
Combinational Backdoor Attack against Customized Text-to-Image Models,"Wenbo Jiang, Jiaming He, Hongwei Li, Guowen Xu, Rui Zhang, Hanxiao Chen, Meng Hao, Haomiao Yang",2024-11-19T10:20:31Z,"Recently, Text-to-Image (T2I) synthesis technology has made tremendous
strides. Numerous representative T2I models have emerged and achieved promising
application outcomes, such as DALL-E, Stable Diffusion, Imagen, etc. In
practice, it has become increasingly popular for model developers to
selectively adopt various pre-trained text encoders and conditional diffusion
models from third-party platforms, integrating them to build customized
(personalized) T2I models. However, such an adoption approach is vulnerable to
backdoor attacks. In this work, we propose a Combinational Backdoor Attack
against Customized T2I models (CBACT2I) targeting this application scenario.
Different from previous backdoor attacks against T2I models, CBACT2I embeds the
backdoor into the text encoder and the conditional diffusion model separately.
The customized T2I model exhibits backdoor behaviors only when the backdoor
text encoder is used in combination with the backdoor conditional diffusion
model. These properties make CBACT2I more stealthy and flexible than prior
backdoor attacks against T2I models. Extensive experiments demonstrate the
effectiveness of CBACT2I with different backdoor triggers and different
backdoor targets on the open-sourced Stable Diffusion model. This work reveals
the backdoor vulnerabilities of customized T2I models and urges countermeasures
to mitigate backdoor threats in this scenario.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12389v1
Semi-Automatic Extraction of Formal Models from Object Oriented Code,P. H. M. van Spaendonck,2024-11-19T10:14:40Z,"Behavioral models are incredibly useful for understanding and validating
software. However, the automatic extraction of such models from actual
industrial code remains a largely unsolved problem with current solutions often
not scaling well with the complexity and size of industrial systems or having
to rely on approximations. To enable the extraction of useful models from code,
we provide a framework for transforming object-oriented code into processes
from which, when paired with minimal user input, models can be automatically
generated and composed. Paired with this, we introduce the novel SSTraGen
(StateSpace Transformation & Generation) tool, which provides an implementation
of this framework. Through case studies at Philips Image Guided Therapy
Systems, we showcase the practical applicability and usefulness of this tool,
including the transformation of a component with >1000 LOC.","cs.SE, cs.FL",cs.SE,http://arxiv.org/abs/2411.12386v1
Joint Vision-Language Social Bias Removal for CLIP,"Haoyu Zhang, Yangyang Guo, Mohan Kankanhalli",2024-11-19T10:14:26Z,"Vision-Language (V-L) pre-trained models such as CLIP show prominent
capabilities in various downstream tasks. Despite this promise, V-L models are
notoriously limited by their inherent social biases. A typical demonstration is
that V-L models often produce biased predictions against specific groups of
people, significantly undermining their real-world applicability. Existing
approaches endeavor to mitigate the social bias problem in V-L models by
removing biased attribute information from model embeddings. However, after our
revisiting of these methods, we find that their bias removal is frequently
accompanied by greatly compromised V-L alignment capabilities. We then reveal
that this performance degradation stems from the unbalanced debiasing in image
and text embeddings. To address this issue, we propose a novel V-L debiasing
framework to align image and text biases followed by removing them from both
modalities. By doing so, our method achieves multi-modal bias mitigation while
maintaining the V-L alignment in the debiased embeddings. Additionally, we
advocate a new evaluation protocol that can 1) holistically quantify the model
debiasing and V-L alignment ability, and 2) evaluate the generalization of
social bias removal models. We believe this work will offer new insights and
guidance for future studies addressing the social bias problem in CLIP.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12785v1
Med-2E3: A 2D-Enhanced 3D Medical Multimodal Large Language Model,"Yiming Shi, Xun Zhu, Ying Hu, Chenyi Guo, Miao Li, Ji Wu",2024-11-19T09:59:59Z,"The analysis of 3D medical images is crucial for modern healthcare, yet
traditional task-specific models are becoming increasingly inadequate due to
limited generalizability across diverse clinical scenarios. Multimodal large
language models (MLLMs) offer a promising solution to these challenges.
However, existing MLLMs have limitations in fully leveraging the rich,
hierarchical information embedded in 3D medical images. Inspired by clinical
practice, where radiologists focus on both 3D spatial structure and 2D planar
content, we propose Med-2E3, a novel MLLM for 3D medical image analysis that
integrates 3D and 2D encoders. To aggregate 2D features more effectively, we
design a Text-Guided Inter-Slice (TG-IS) scoring module, which scores the
attention of each 2D slice based on slice contents and task instructions. To
the best of our knowledge, Med-2E3 is the first MLLM to integrate both 3D and
2D features for 3D medical image analysis. Experiments on a large-scale,
open-source 3D medical multimodal benchmark demonstrate that Med-2E3 exhibits
task-specific attention distribution and significantly outperforms current
state-of-the-art models, with a 14% improvement in report generation and a 5%
gain in medical visual question answering (VQA), highlighting the model's
potential in addressing complex multimodal clinical tasks. The code will be
released upon acceptance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12783v1
DGSNA: prompt-based Dynamic Generative Scene-based Noise Addition method,"Zihao Chen, Zhentao Lin, Bi Zeng, Linyi Huang, Zhi Li, Jia Cai",2024-11-19T09:23:22Z,"This paper addresses the challenges of accurately enumerating and describing
scenes and the labor-intensive process required to replicate acoustic
environments using non-generative methods. We introduce the prompt-based
Dynamic Generative Sce-ne-based Noise Addition method (DGSNA), which
innovatively combines the Dynamic Generation of Scene Information (DGSI) with
Scene-based Noise Addition for Audio (SNAA). Employing generative chat models
structured within the Back-ground-Examples-Task (BET) prompt framework, DGSI
com-ponent facilitates the dynamic synthesis of tailored Scene Infor-mation
(SI) for specific acoustic environments. Additionally, the SNAA component
leverages Room Impulse Response (RIR) fil-ters and Text-To-Audio (TTA) systems
to generate realistic, scene-based noise that can be adapted for both indoor
and out-door environments. Through comprehensive experiments, the adaptability
of DGSNA across different generative chat models was demonstrated. The results,
assessed through both objective and subjective evaluations, show that DGSNA
provides robust performance in dynamically generating precise SI and
effectively enhancing scene-based noise addition capabilities, thus offering
significant improvements over traditional methods in acoustic scene simulation.
Our implementation and demos are available at https://dgsna.github.io.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.12363v1
"Scalable and Effective Negative Sample Generation for Hyperedge
  Prediction","Shilin Qu, Weiqing Wang, Yuan-Fang Li, Quoc Viet Hung Nguyen, Hongzhi Yin",2024-11-19T09:16:25Z,"Hyperedge prediction is crucial in hypergraph analysis for understanding
complex multi-entity interactions in various web-based applications, including
social networks and e-commerce systems. Traditional methods often face
difficulties in generating high-quality negative samples due to the imbalance
between positive and negative instances. To address this, we present the
Scalable and Effective Negative Sample Generation for Hyperedge Prediction
(SEHP) framework, which utilizes diffusion models to tackle these challenges.
SEHP employs a boundary-aware loss function that iteratively refines negative
samples, moving them closer to decision boundaries to improve classification
performance. SEHP samples positive instances to form sub-hypergraphs for
scalable batch processing. By using structural information from sub-hypergraphs
as conditions within the diffusion process, SEHP effectively captures global
patterns. To enhance efficiency, our approach operates directly in latent
space, avoiding the need for discrete ID generation and resulting in
significant speed improvements while preserving accuracy. Extensive experiments
show that SEHP outperforms existing methods in accuracy, efficiency, and
scalability, representing a substantial advancement in hyperedge prediction
techniques. Our code is available here.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12354v1
"Target Height Estimation Using a Single Acoustic Camera for Compensation
  in 2D Seabed Mosaicking","Xiaoteng Zhou, Yusheng Wang, Katsunori Mizuno",2024-11-19T08:42:24Z,"This letter proposes a novel approach for compensating target height data in
2D seabed mosaicking for low-visibility underwater perception. Acoustic cameras
are effective sensors for sensing the marine environments due to their
high-resolution imaging capabilities and robustness to darkness and turbidity.
However, the loss of elevation angle during the imaging process results in a
lack of target height information in the original acoustic camera images,
leading to a simplistic 2D representation of the seabed mosaicking. In
perceiving cluttered and unexplored marine environments, target height data is
crucial for avoiding collisions with marine robots. This study proposes a novel
approach for estimating seabed target height using a single acoustic camera and
integrates height data into 2D seabed mosaicking to compensate for the missing
3D dimension of seabed targets. Unlike classic methods that model the loss of
elevation angle to achieve seabed 3D reconstruction, this study focuses on
utilizing available acoustic cast shadow clues and simple sensor motion to
quickly estimate target height. The feasibility of our proposal is verified
through a water tank experiment and a simulation experiment.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.12338v1
FGP: Feature-Gradient-Prune for Efficient Convolutional Layer Pruning,"Qingsong Lv, Jiasheng Sun, Sheng Zhou, Xu Zhang, Liangcheng Li, Yun Gao, Sun Qiao, Jie Song, Jiajun Bu",2024-11-19T08:42:15Z,"To reduce computational overhead while maintaining model performance, model
pruning techniques have been proposed. Among these, structured pruning, which
removes entire convolutional channels or layers, significantly enhances
computational efficiency and is compatible with hardware acceleration. However,
existing pruning methods that rely solely on image features or gradients often
result in the retention of redundant channels, negatively impacting inference
efficiency. To address this issue, this paper introduces a novel pruning method
called Feature-Gradient Pruning (FGP). This approach integrates both
feature-based and gradient-based information to more effectively evaluate the
importance of channels across various target classes, enabling a more accurate
identification of channels that are critical to model performance. Experimental
results demonstrate that the proposed method improves both model compactness
and practicality while maintaining stable performance. Experiments conducted
across multiple tasks and datasets show that FGP significantly reduces
computational costs and minimizes accuracy loss compared to existing methods,
highlighting its effectiveness in optimizing pruning outcomes. The source code
is available at: https://github.com/FGP-code/FGP.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12781v1
Accelerating UMAP for Large-Scale Datasets Through Spectral Coarsening,Yongyu Wang,2024-11-19T08:32:17Z,"This paper introduces an innovative approach to dramatically accelerate UMAP
using spectral data compression.The proposed method significantly reduces the
size of the dataset, preserving its essential manifold structure through an
advanced spectral compression technique. This allows UMAP to perform much
faster while maintaining the quality of its embeddings. Experiments on
real-world datasets, such as USPS, demonstrate the method's ability to achieve
substantial data reduction without compromising embedding fidelity.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12331v1
"Enhancing Blind Source Separation with Dissociative Principal Component
  Analysis",Muhammad Usman Khalid,2024-11-19T08:24:01Z,"Sparse principal component analysis (sPCA) enhances the interpretability of
principal components (PCs) by imposing sparsity constraints on loading vectors
(LVs). However, when used as a precursor to independent component analysis
(ICA) for blind source separation (BSS), sPCA may underperform due to its focus
on simplicity, potentially disregarding some statistical information essential
for effective ICA. To overcome this limitation, a sophisticated approach is
proposed that preserves the interpretability advantages of sPCA while
significantly enhancing its source extraction capabilities. This consists of
two tailored algorithms, dissociative PCA (DPCA1 and DPCA2), which employ
adaptive and firm thresholding alongside gradient and coordinate descent
approaches to optimize the proposed model dynamically. These algorithms
integrate left and right singular vectors from singular value decomposition
(SVD) through dissociation matrices (DMs) that replace traditional singular
values, thus capturing latent interdependencies effectively to model complex
source relationships. This leads to refined PCs and LVs that more accurately
represent the underlying data structure. The proposed approach avoids focusing
on individual eigenvectors, instead, it collaboratively combines multiple
eigenvectors to disentangle interdependencies within each SVD variate. The
superior performance of the proposed DPCA algorithms is demonstrated across
four varied imaging applications including functional magnetic resonance
imaging (fMRI) source retrieval, foreground-background separation, image
reconstruction, and image inpainting. They outperformed traditional methods
such as PCA+ICA, PPCA+ICA, SPCA+ICA, PMD, and GPower.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12321v1
"DGTR: Distributed Gaussian Turbo-Reconstruction for Sparse-View Vast
  Scenes","Hao Li, Yuanyuan Gao, Haosong Peng, Chenming Wu, Weicai Ye, Yufeng Zhan, Chen Zhao, Dingwen Zhang, Jingdong Wang, Junwei Han",2024-11-19T07:51:44Z,"Novel-view synthesis (NVS) approaches play a critical role in vast scene
reconstruction. However, these methods rely heavily on dense image inputs and
prolonged training times, making them unsuitable where computational resources
are limited. Additionally, few-shot methods often struggle with poor
reconstruction quality in vast environments. This paper presents DGTR, a novel
distributed framework for efficient Gaussian reconstruction for sparse-view
vast scenes. Our approach divides the scene into regions, processed
independently by drones with sparse image inputs. Using a feed-forward Gaussian
model, we predict high-quality Gaussian primitives, followed by a global
alignment algorithm to ensure geometric consistency. Synthetic views and depth
priors are incorporated to further enhance training, while a distillation-based
model aggregation mechanism enables efficient reconstruction. Our method
achieves high-quality large-scale scene reconstruction and novel-view synthesis
in significantly reduced training times, outperforming existing approaches in
both speed and scalability. We demonstrate the effectiveness of our framework
on vast aerial scenes, achieving high-quality results within minutes. Code will
released on our [https://3d-aigc.github.io/DGTR].",cs.CV,cs.CV,http://arxiv.org/abs/2411.12309v2
Diffusion Product Quantization,"Jie Shao, Hanxiao Zhang, Jianxin Wu",2024-11-19T07:47:37Z,"In this work, we explore the quantization of diffusion models in extreme
compression regimes to reduce model size while maintaining performance. We
begin by investigating classical vector quantization but find that diffusion
models are particularly susceptible to quantization error, with the codebook
size limiting generation quality. To address this, we introduce product
quantization, which offers improved reconstruction precision and larger
capacity -- crucial for preserving the generative capabilities of diffusion
models. Furthermore, we propose a method to compress the codebook by evaluating
the importance of each vector and removing redundancy, ensuring the model size
remaining within the desired range. We also introduce an end-to-end calibration
approach that adjusts assignments during the forward pass and optimizes the
codebook using the DDPM loss. By compressing the model to as low as 1 bit
(resulting in over 24 times reduction in model size), we achieve a balance
between compression and quality. We apply our compression method to the DiT
model on ImageNet and consistently outperform other quantization approaches,
demonstrating competitive generative performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12306v1
"An Integrated (Crop Model, Cloud and Big Data Analytic) Framework to
  support Agriculture Activity Monitoring System","Shamim Akhter, Kiyoshi Honda, Kento Aida, Amor V. M. Ines",2024-11-19T07:43:10Z,"Agriculture activity monitoring needs to deal with large amounts of data
originating from various organizations (weather stations, agriculture
repositories, field management, farm management, universities, etc.) and mass
people. Therefore, a scalable environment with flexible information access,
easy communication, and real-time collaboration from all types of computing
devices, including mobile handheld devices such as smartphones, PDAs and iPads,
Geo-sensor devices, etc. are essential. The system must be accessible,
scalable, and transparent from location, migration, and resources. In addition,
the framework should support modern information retrieval and management
systems, unstructured information to structured information processing, task
prioritization, task distribution, workflow and task scheduling systems,
processing power, and data storage. Thus, High Scalability Computing (HSC) or
Cloud-based systems with Big data analytics can be a prominent and convincing
solution for this circumstance. In this paper, we are going to propose an
integrated (crop model, cloud, and big data analytics) geo-information
framework to support agriculture activity monitoring systems.",cs.DC,cs.DC,http://arxiv.org/abs/2411.12303v1
Lucia: A Temporal Computing Platform for Contextual Intelligence,"Weizhe Lin, Junxiao Shen",2024-11-19T07:38:31Z,"The rapid evolution of artificial intelligence, especially through
multi-modal large language models, has redefined user interactions, enabling
responses that are contextually rich and human-like. As AI becomes an integral
part of daily life, a new frontier has emerged: developing systems that not
only understand spatial and sensory data but also interpret temporal contexts
to build long-term, personalized memories. This report introduces Lucia, an
open-source Temporal Computing Platform designed to enhance human cognition by
capturing and utilizing continuous contextual memory. Lucia introduces a
lightweight, wearable device that excels in both comfort and real-time data
accessibility, distinguishing itself from existing devices that typically
prioritize either wearability or perceptual capabilities alone. By recording
and interpreting daily activities over time, Lucia enables users to access a
robust temporal memory, enhancing cognitive processes such as decision-making
and memory recall.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.12778v1
"Bezier Reachable Polytopes: Efficient Certificates for Robust Motion
  Planning with Layered Architectures","Noel Csomay-Shanklin, Aaron D. Ames",2024-11-20T17:56:56Z,"Control architectures are often implemented in a layered fashion, combining
independently designed blocks to achieve complex tasks. Providing guarantees
for such hierarchical frameworks requires considering the capabilities and
limitations of each layer and their interconnections at design time. To address
this holistic design challenge, we introduce the notion of Bezier Reachable
Polytopes -- certificates of reachable points in the space of Bezier polynomial
reference trajectories. This approach captures the set of trajectories that can
be tracked by a low-level controller while satisfying state and input
constraints, and leverages the geometric properties of Bezier polynomials to
maintain an efficient polytopic representation. As a result, these certificates
serve as a constructive tool for layered architectures, enabling long-horizon
tasks to be reasoned about in a computationally tractable manner.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.13506v1
"On the Statistical Significance with Relevance Assessments of Large
  Language Models","David Otero, Javier Parapar, Álvaro Barreiro",2024-11-20T11:19:35Z,"Test collections are an integral part of Information Retrieval (IR) research.
They allow researchers to evaluate and compare ranking algorithms in a quick,
easy and reproducible way. However, constructing these datasets requires great
efforts in manual labelling and logistics, and having only few human relevance
judgements can introduce biases in the comparison. Recent research has explored
the use of Large Language Models (LLMs) for labelling the relevance of
documents for building new retrieval test collections. Their strong
text-understanding capabilities and low cost compared to human-made judgements
makes them an appealing tool for gathering relevance judgements. Results
suggest that LLM-generated labels are promising for IR evaluation in terms of
ranking correlation, but nothing is said about the implications in terms of
statistical significance. In this work, we look at how LLM-generated judgements
preserve the same pairwise significance evaluation as human judgements. Our
results show that LLM judgements detect most of the significant differences
while maintaining acceptable numbers of false positives. However, we also show
that some systems are treated differently under LLM-generated labels,
suggesting that evaluation with LLM judgements might not be entirely fair. Our
work represents a step forward in the evaluation of statistical testing results
provided by LLM judgements. We hope that this will serve as a basis for other
researchers to develop reliable models for automatic relevance assessments.",cs.IR,cs.IR,http://arxiv.org/abs/2411.13212v1
Data Watermarking for Sequential Recommender Systems,"Sixiao Zhang, Cheng Long, Wei Yuan, Hongxu Chen, Hongzhi Yin",2024-11-20T02:34:21Z,"In the era of large foundation models, data has become a crucial component
for building high-performance AI systems. As the demand for high-quality and
large-scale data continues to rise, data copyright protection is attracting
increasing attention. In this work, we explore the problem of data watermarking
for sequential recommender systems, where a watermark is embedded into the
target dataset and can be detected in models trained on that dataset. We
address two specific challenges: dataset watermarking, which protects the
ownership of the entire dataset, and user watermarking, which safeguards the
data of individual users. We systematically define these problems and present a
method named DWRS to address them. Our approach involves randomly selecting
unpopular items to create a watermark sequence, which is then inserted into
normal users' interaction sequences. Extensive experiments on five
representative sequential recommendation models and three benchmark datasets
demonstrate the effectiveness of DWRS in protecting data copyright while
preserving model utility.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12989v1
A Comparative Study of Text Retrieval Models on DaReCzech,"Jakub Stetina, Martin Fajcik, Michal Stefanik, Michal Hradis",2024-11-19T23:19:46Z,"This article presents a comprehensive evaluation of 7 off-the-shelf document
retrieval models: Splade, Plaid, Plaid-X, SimCSE, Contriever, OpenAI ADA and
Gemma2 chosen to determine their performance on the Czech retrieval dataset
DaReCzech. The primary objective of our experiments is to estimate the quality
of modern retrieval approaches in the Czech language. Our analyses include
retrieval quality, speed, and memory footprint. Secondly, we analyze whether it
is better to use the model directly in Czech text, or to use machine
translation into English, followed by retrieval in English. Our experiments
identify the most effective option for Czech information retrieval. The
findings revealed notable performance differences among the models, with
Gemma22 achieving the highest precision and recall, while Contriever performing
poorly. Conclusively, SPLADE and PLAID models offered a balance of efficiency
and performance.","cs.IR, cs.AI",cs.IR,http://arxiv.org/abs/2411.12921v1
"TopoCode: Topologically Informed Error Detection and Correction in
  Communication Systems",Hongzhi Guo,2024-11-19T19:22:24Z,"Traditional error detection and correction codes focus on bit-level fidelity,
which is insufficient for emerging technologies like eXtended Reality (XR) and
holographic communications requiring high-data-rate, low-latency systems.
Bit-level metrics cannot comprehensively evaluate Quality-of-Service (QoS) in
these scenarios. This letter proposes TopoCode which leverages Topological Data
Analysis (TDA) and persistent homology to encode topological information for
message-level error detection and correction. It introduces minimal redundancy
while enabling effective data reconstruction, especially in low Signal-to-Noise
Ratio (SNR) conditions. TopoCode offers a promising approach to meet the
demands of next-generation communication systems prioritizing semantic accuracy
and message-level integrity.",cs.MM,cs.MM,http://arxiv.org/abs/2411.12825v1
WIA-SZZ: Work Item Aware SZZ,"Salomé Perez-Rosero, Robert Dyer, Samuel W. Flint, Shane McIntosh, Witawas Srisa-an",2024-11-19T18:59:14Z,"Many software engineering maintenance tasks require linking a commit that
induced a bug with the commit that later fixed that bug. Several existing SZZ
algorithms provide a way to identify the potential commit that induced a bug
when given a fixing commit as input. Prior work introduced the notion of a
""work item"", a logical grouping of commits that could be a single unit of work.
Our key insight in this work is to recognize that a bug-inducing commit and the
fix(es) for that bug together represent a ""work item."" It is not currently
understood how these work items, which are logical groups of revisions
addressing a single issue or feature, could impact the performance of
algorithms such as SZZ. In this paper, we propose a heuristic that, given an
input commit, uses information about changed methods to identify related
commits that form a work item with the input commit. We hypothesize that given
such a work item identifying heuristic, we can identify bug-inducing commits
more accurately than existing SZZ approaches. We then build a new variant of
SZZ that we call Work Item Aware SZZ (WIA-SZZ), that leverages our work item
detecting heuristic to first suggest bug-inducing commits. If our heuristic
fails to find any candidates, we then fall back to baseline variants of SZZ. We
conduct a manual evaluation to assess the accuracy of our heuristic to identify
work items. Our evaluation reveals the heuristic is 64% accurate in finding
work items, but most importantly it is able to find many bug-inducing commits.
We then evaluate our approach on 821 repositories that have been previously
used to study the performance of SZZ, comparing our work against six SZZ
variants. That evaluation shows an improvement in F1 scores ranging from 2% to
9%, or when looking only at the subset of cases that found work item improved
3% to 14%.",cs.SE,cs.SE,http://arxiv.org/abs/2411.12740v1
Generative Timelines for Instructed Visual Assembly,"Alejandro Pardo, Jui-Hsien Wang, Bernard Ghanem, Josef Sivic, Bryan Russell, Fabian Caba Heilbron",2024-11-19T07:26:30Z,"The objective of this work is to manipulate visual timelines (e.g. a video)
through natural language instructions, making complex timeline editing tasks
accessible to non-expert or potentially even disabled users. We call this task
Instructed visual assembly. This task is challenging as it requires (i)
identifying relevant visual content in the input timeline as well as retrieving
relevant visual content in a given input (video) collection, (ii) understanding
the input natural language instruction, and (iii) performing the desired edits
of the input visual timeline to produce an output timeline. To address these
challenges, we propose the Timeline Assembler, a generative model trained to
perform instructed visual assembly tasks. The contributions of this work are
three-fold. First, we develop a large multimodal language model, which is
designed to process visual content, compactly represent timelines and
accurately interpret timeline editing instructions. Second, we introduce a
novel method for automatically generating datasets for visual assembly tasks,
enabling efficient training of our model without the need for human-labeled
data. Third, we validate our approach by creating two novel datasets for image
and video assembly, demonstrating that the Timeline Assembler substantially
outperforms established baseline models, including the recent GPT-4o, in
accurately executing complex assembly instructions across various real-world
inspired scenarios.","cs.CV, cs.HC, cs.MM",cs.CV,http://arxiv.org/abs/2411.12293v1
"GLOVER: Generalizable Open-Vocabulary Affordance Reasoning for
  Task-Oriented Grasping","Teli Ma, Zifan Wang, Jiaming Zhou, Mengmeng Wang, Junwei Liang",2024-11-19T07:12:48Z,"Inferring affordable (i.e., graspable) parts of arbitrary objects based on
human specifications is essential for robots advancing toward open-vocabulary
manipulation. Current grasp planners, however, are hindered by limited
vision-language comprehension and time-consuming 3D radiance modeling,
restricting real-time, open-vocabulary interactions with objects. To address
these limitations, we propose GLOVER, a unified Generalizable Open-Vocabulary
Affordance Reasoning framework, which fine-tunes the Large Language Models
(LLMs) to predict visual affordance of graspable object parts within RGB
feature space. We compile a dataset of over 10,000 images from human-object
interactions, annotated with unified visual and linguistic affordance labels,
to enable multi-modal fine-tuning. GLOVER inherits world knowledge and
common-sense reasoning from LLMs, facilitating more fine-grained object
understanding and sophisticated tool-use reasoning. To enable effective
real-world deployment, we present Affordance-Aware Grasping Estimation (AGE), a
non-parametric grasp planner that aligns the gripper pose with a superquadric
surface derived from affordance data. In evaluations across 30 real-world
scenes, GLOVER achieves success rates of 86.0% in part identification and 76.3%
in grasping, with speeds approximately 330 times faster in affordance reasoning
and 40 times faster in grasping pose estimation than the previous
state-of-the-art.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.12286v1
"Building Trust: Foundations of Security, Safety and Transparency in AI","Huzaifa Sidhpurwala, Garth Mollett, Emily Fox, Mark Bestavros, Huamin Chen",2024-11-19T06:55:57Z,"This paper explores the rapidly evolving ecosystem of publicly available AI
models, and their potential implications on the security and safety landscape.
As AI models become increasingly prevalent, understanding their potential risks
and vulnerabilities is crucial. We review the current security and safety
scenarios while highlighting challenges such as tracking issues, remediation,
and the apparent absence of AI model lifecycle and ownership processes.
Comprehensive strategies to enhance security and safety for both model
developers and end-users are proposed. This paper aims to provide some of the
foundational pieces for more standardized security, safety, and transparency in
the development and operation of AI models and the larger open ecosystems and
communities forming around them.","cs.CY, cs.AI, cs.CL",cs.CY,http://arxiv.org/abs/2411.12275v1
"Error-Feedback Model for Output Correction in Bilateral Control-Based
  Imitation Learning","Hiroshi Sato, Masashi Konosu, Sho Sakaino, Toshiaki Tsuji",2024-11-19T06:09:09Z,"In recent years, imitation learning using neural networks has enabled robots
to perform flexible tasks. However, since neural networks operate in a
feedforward structure, they do not possess a mechanism to compensate for output
errors. To address this limitation, we developed a feedback mechanism to
correct these errors. By employing a hierarchical structure for neural networks
comprising lower and upper layers, the lower layer was controlled to follow the
upper layer. Additionally, using a multi-layer perceptron in the lower layer,
which lacks an internal state, enhanced the error feedback. In the
character-writing task, this model demonstrated improved accuracy in writing
previously untrained characters. In the character-writing task, this model
demonstrated improved accuracy in writing previously untrained characters.
Through autonomous control with error feedback, we confirmed that the lower
layer could effectively track the output of the upper layer. This study
represents a promising step toward integrating neural networks with control
theories.","cs.RO, cs.AI, cs.LG",cs.RO,http://arxiv.org/abs/2411.12255v1
Neuro-3D: Towards 3D Visual Decoding from EEG Signals,"Zhanqiang Guo, Jiamin Wu, Yonghao Song, Weijian Mai, Qihao Zheng, Wanli Ouyang, Chunfeng Song",2024-11-19T05:52:17Z,"Human's perception of the visual world is shaped by the stereo processing of
3D information. Understanding how the brain perceives and processes 3D visual
stimuli in the real world has been a longstanding endeavor in neuroscience.
Towards this goal, we introduce a new neuroscience task: decoding 3D visual
perception from EEG signals, a neuroimaging technique that enables real-time
monitoring of neural dynamics enriched with complex visual cues. To provide the
essential benchmark, we first present EEG-3D, a pioneering dataset featuring
multimodal analysis data and extensive EEG recordings from 12 subjects viewing
72 categories of 3D objects rendered in both videos and images. Furthermore, we
propose Neuro-3D, a 3D visual decoding framework based on EEG signals. This
framework adaptively integrates EEG features derived from static and dynamic
stimuli to learn complementary and robust neural representations, which are
subsequently utilized to recover both the shape and color of 3D objects through
the proposed diffusion-based colored point cloud decoder. To the best of our
knowledge, we are the first to explore EEG-based 3D visual decoding.
Experiments indicate that Neuro-3D not only reconstructs colored 3D objects
with high fidelity, but also learns effective neural representations that
enable insightful brain region analysis. The dataset and associated code will
be made publicly available.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12248v1
"BoolQuestions: Does Dense Retrieval Understand Boolean Logic in
  Language?","Zongmeng Zhang, Jinhua Zhu, Wengang Zhou, Xiang Qi, Peng Zhang, Houqiang Li",2024-11-19T05:19:53Z,"Dense retrieval, which aims to encode the semantic information of arbitrary
text into dense vector representations or embeddings, has emerged as an
effective and efficient paradigm for text retrieval, consequently becoming an
essential component in various natural language processing systems. These
systems typically focus on optimizing the embedding space by attending to the
relevance of text pairs, while overlooking the Boolean logic inherent in
language, which may not be captured by current training objectives. In this
work, we first investigate whether current retrieval systems can comprehend the
Boolean logic implied in language. To answer this question, we formulate the
task of Boolean Dense Retrieval and collect a benchmark dataset, BoolQuestions,
which covers complex queries containing basic Boolean logic and corresponding
annotated passages. Through extensive experimental results on the proposed task
and benchmark dataset, we draw the conclusion that current dense retrieval
systems do not fully understand Boolean logic in language, and there is a long
way to go to improve our dense retrieval systems. Furthermore, to promote
further research on enhancing the understanding of Boolean logic for language
models, we explore Boolean operation on decomposed query and propose a
contrastive continual training method that serves as a strong baseline for the
research community.","cs.IR, cs.CL",cs.IR,http://arxiv.org/abs/2411.12235v1
"Revisiting Fake News Detection: Towards Temporality-aware Evaluation by
  Leveraging Engagement Earliness","Junghoon Kim, Junmo Lee, Yeonjun In, Kanghoon Yoon, Chanyoung Park",2024-11-19T05:08:00Z,"Social graph-based fake news detection aims to identify news articles
containing false information by utilizing social contexts, e.g., user
information, tweets and comments. However, conventional methods are evaluated
under less realistic scenarios, where the model has access to future knowledge
on article-related and context-related data during training. In this work, we
newly formalize a more realistic evaluation scheme that mimics real-world
scenarios, where the data is temporality-aware and the detection model can only
be trained on data collected up to a certain point in time. We show that the
discriminative capabilities of conventional methods decrease sharply under this
new setting, and further propose DAWN, a method more applicable to such
scenarios. Our empirical findings indicate that later engagements (e.g.,
consuming or reposting news) contribute more to noisy edges that link real
news-fake news pairs in the social graph. Motivated by this, we utilize feature
representations of engagement earliness to guide an edge weight estimator to
suppress the weights of such noisy edges, thereby enhancing the detection
performance of DAWN. Through extensive experiments, we demonstrate that DAWN
outperforms existing fake news detection methods under real-world environments.
The source code is available at https://github.com/LeeJunmo/DAWN.","cs.SI, cs.AI, cs.CL",cs.SI,http://arxiv.org/abs/2411.12775v1
"Perception of Digital Privacy Protection: An Empirical Study using GDPR
  Framework","Hamoud Alhazmi, Ahmed Imran, Mohammad Abu Alsheikh",2024-11-19T04:36:31Z,"Perception of privacy is a contested concept, which is also evolving along
with the rapid proliferation and expansion of technological advancements.
Information systems (IS) applications incorporate various sensing
infrastructures, high-speed networks, and computing components that enable
pervasive data collection about people. Any digital privacy breach within such
systems can result in harmful and far-reaching impacts on individuals and
societies. Accordingly, IS organisations have a legal and ethical
responsibility to respect and protect individuals digital privacy rights. This
study investigates people perception of digital privacy protection of
government data using the General Data Protection Regulation (GDPR) framework.
Findings suggest a dichotomy of perception in protecting people privacy rights.
For example, people perceive the right to be informed as the most respected and
protected in Information Technology (IT) systems. On the contrary, the right to
object by granting and with-drawing consent is perceived as the least
protected. Second, the study shows evidence of a social dilemma in people
perception of digital privacy based on their context and culture.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12223v1
"DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in
  Federated Learning","Kichang Lee, Yujin Shin, Jonghyuk Yun, Jun Han, JeongGil Ko",2024-11-19T04:12:14Z,"Federated Learning (FL) enables collaborative model training across
distributed devices while preserving local data privacy, making it ideal for
mobile and embedded systems. However, the decentralized nature of FL also opens
vulnerabilities to model poisoning attacks, particularly backdoor attacks,
where adversaries implant trigger patterns to manipulate model predictions. In
this paper, we propose DeTrigger, a scalable and efficient backdoor-robust
federated learning framework that leverages insights from adversarial attack
methodologies. By employing gradient analysis with temperature scaling,
DeTrigger detects and isolates backdoor triggers, allowing for precise model
weight pruning of backdoor activations without sacrificing benign model
knowledge. Extensive evaluations across four widely used datasets demonstrate
that DeTrigger achieves up to 251x faster detection than traditional methods
and mitigates backdoor attacks by up to 98.9%, with minimal impact on global
model accuracy. Our findings establish DeTrigger as a robust and scalable
solution to protect federated learning environments against sophisticated
backdoor threats.","cs.LG, cs.AI, cs.CR, 68T07, I.2.11",cs.LG,http://arxiv.org/abs/2411.12220v1
"RoSIS: Robust Framework for Text-Promptable Surgical Instrument
  Segmentation Using Vision-Language Fusion","Tae-Min Choi, Juyoun Park",2024-11-19T03:30:44Z,"Surgical instrument segmentation (SIS) is an essential task in
computer-assisted surgeries, with deep learning-based research improving
accuracy in complex environments. Recently, text-promptable segmentation
methods have been introduced to generate masks based on text prompts describing
target objects. However, these methods assume that the object described by a
given text prompt exists in the scene. This results in mask generation whenever
a related text prompt is provided, even if the object is absent from the image.
Existing methods handle this by using prompts only for objects known to be
present in the image, which introduces inaccessible information in a
vision-based method setting and results in unfair comparisons. For fair
comparison, we redefine existing text-promptable SIS settings to robust
conditions, called Robust text-promptable SIS (R-SIS), designed to forward
prompts of all classes and determine the existence of an object from a given
text prompt for the fair comparison. Furthermore, we propose a novel framework,
Robust Surgical Instrument Segmentation (RoSIS), which combines visual and
language features for promptable segmentation in the R-SIS setting. RoSIS
employs an encoder-decoder architecture with a Multi-Modal Fusion Block (MMFB)
and a Selective Gate Block (SGB) to achieve balanced integration of vision and
language features. Additionally, we introduce an iterative inference strategy
that refines segmentation masks in two steps: an initial pass using name-based
prompts, followed by a refinement step using location prompts. Experiments on
various datasets and settings demonstrate that RoSIS outperforms existing
vision-based and promptable methods under robust conditions.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12199v1
"CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled
  Colonoscopy Image Synthesis","Yifan Xie, Jingge Wang, Tao Feng, Fei Ma, Yang Li",2024-11-19T03:30:06Z,"Colonoscopy is crucial for identifying adenomatous polyps and preventing
colorectal cancer. However, developing robust models for polyp detection is
challenging by the limited size and accessibility of existing colonoscopy
datasets. While previous efforts have attempted to synthesize colonoscopy
images, current methods suffer from instability and insufficient data
diversity. Moreover, these approaches lack precise control over the generation
process, resulting in images that fail to meet clinical quality standards. To
address these challenges, we propose CCIS-DIFF, a Controlled generative model
for high-quality Colonoscopy Image Synthesis based on a Diffusion architecture.
Our method offers precise control over both the spatial attributes (polyp
location and shape) and clinical characteristics of polyps that align with
clinical descriptions. Specifically, we introduce a blur mask weighting
strategy to seamlessly blend synthesized polyps with the colonic mucosa, and a
text-aware attention mechanism to guide the generated images to reflect
clinical characteristics. Notably, to achieve this, we construct a new
multi-modal colonoscopy dataset that integrates images, mask annotations, and
corresponding clinical text descriptions. Experimental results demonstrate that
our method generates high-quality, diverse colonoscopy images with fine control
over both spatial constraints and clinical consistency, offering valuable
support for downstream segmentation and diagnostic tasks.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12198v1
"MTFusion: Reconstructing Any 3D Object from Single Image Using
  Multi-word Textual Inversion","Yu Liu, Ruowei Wang, Jiaqi Li, Zixiang Xu, Qijun Zhao",2024-11-19T03:29:18Z,"Reconstructing 3D models from single-view images is a long-standing problem
in computer vision. The latest advances for single-image 3D reconstruction
extract a textual description from the input image and further utilize it to
synthesize 3D models. However, existing methods focus on capturing a single key
attribute of the image (e.g., object type, artistic style) and fail to consider
the multi-perspective information required for accurate 3D reconstruction, such
as object shape and material properties. Besides, the reliance on Neural
Radiance Fields hinders their ability to reconstruct intricate surfaces and
texture details. In this work, we propose MTFusion, which leverages both image
data and textual descriptions for high-fidelity 3D reconstruction. Our approach
consists of two stages. First, we adopt a novel multi-word textual inversion
technique to extract a detailed text description capturing the image's
characteristics. Then, we use this description and the image to generate a 3D
model with FlexiCubes. Additionally, MTFusion enhances FlexiCubes by employing
a special decoder network for Signed Distance Functions, leading to faster
training and finer surface representation. Extensive evaluations demonstrate
that our MTFusion surpasses existing image-to-3D methods on a wide range of
synthetic and real-world images. Furthermore, the ablation study proves the
effectiveness of our network designs.","cs.CV, cs.MM",cs.CV,http://arxiv.org/abs/2411.12197v1
"A More Advanced Group Polarization Measurement Approach Based on
  LLM-Based Agents and Graphs","Zixin Liu, Ji Zhang, Yiran Ding",2024-11-19T03:29:17Z,"Group polarization is an important research direction in social media content
analysis, attracting many researchers to explore this field. Therefore, how to
effectively measure group polarization has become a critical topic. Measuring
group polarization on social media presents several challenges that have not
yet been addressed by existing solutions. First, social media group
polarization measurement involves processing vast amounts of text, which poses
a significant challenge for information extraction. Second, social media texts
often contain hard-to-understand content, including sarcasm, memes, and
internet slang. Additionally, group polarization research focuses on holistic
analysis, while texts is typically fragmented. To address these challenges, we
designed a solution based on a multi-agent system and used a graph-structured
Community Sentiment Network (CSN) to represent polarization states.
Furthermore, we developed a metric called Community Opposition Index (COI)
based on the CSN to quantify polarization. Finally, we tested our multi-agent
system through a zero-shot stance detection task and achieved outstanding
results. In summary, the proposed approach has significant value in terms of
usability, accuracy, and interpretability.","cs.CY, cs.AI",cs.CY,http://arxiv.org/abs/2411.12196v1
"Tool Compensation and User Strategy during Human-Robot Teleoperation are
  Impacted by System Dynamics and Kinesthetic Feedback","Jacob D. Carducci, Jeremy D. Brown",2024-11-19T03:19:18Z,"Manipulating an environment remotely with a robotic teleoperator introduces
novel electromechanical (EM) dynamics between the user and environment. While
considerable effort has focused on minimizing these dynamics, there is limited
research into understanding their impact on a user's internal model and
resulting motor control strategy. Here we investigate to what degree the
dynamics and kinesthetic feedback of the teleoperator influence task behavior
and tool compensation.
  Our teleoperator testbed features a leader port controlled by user input via
wrist rotation, a follower port connected to a virtual environment rendered by
rotary motor, and three distinct transmissions (Rigid, Unilateral EM, Bilateral
EM) in-between that can be engaged independently. 30 adult participants rotated
a disk in a visco-elastic virtual environment through counterbalanced
presentation of each transmission. Users tracked targets oscillating at 7
pre-defined random frequencies between 0.55 and 2.35 Hz. After session
completion, trajectories of the target, leader, and follower were decomposed
into components of gain and phase error for all frequencies. We found that
while tracking performance at the follower port was similar across
transmissions, users' adjustment at the leader port differed between Rigid and
EM transmissions. Users applied different pinch forces between Rigid and
Unilateral transmissions, suggesting that tracking strategy does change between
dynamics and feedback. However, the users' ability to compensate dynamics
diminished significantly as task speed got faster and more difficult.
Therefore, there are limits to pursuit tracking at the human wrist when
compensating teleoperator dynamics.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12194v1
"LiV-GS: LiDAR-Vision Integration for 3D Gaussian Splatting SLAM in
  Outdoor Environments","Renxiang Xiao, Wei Liu, Yushuai Chen, Liang Hu",2024-11-19T02:56:51Z,"We present LiV-GS, a LiDAR-visual SLAM system in outdoor environments that
leverages 3D Gaussian as a differentiable spatial representation. Notably,
LiV-GS is the first method that directly aligns discrete and sparse LiDAR data
with continuous differentiable Gaussian maps in large-scale outdoor scenes,
overcoming the limitation of fixed resolution in traditional LiDAR mapping. The
system aligns point clouds with Gaussian maps using shared covariance
attributes for front-end tracking and integrates the normal orientation into
the loss function to refines the Gaussian map. To reliably and stably update
Gaussians outside the LiDAR field of view, we introduce a novel conditional
Gaussian constraint that aligns these Gaussians closely with the nearest
reliable ones. The targeted adjustment enables LiV-GS to achieve fast and
accurate mapping with novel view synthesis at a rate of 7.98 FPS. Extensive
comparative experiments demonstrate LiV-GS's superior performance in SLAM,
image rendering and mapping. The successful cross-modal radar-LiDAR
localization highlights the potential of LiV-GS for applications in cross-modal
semantic positioning and object segmentation with Gaussian maps.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12185v1
"AsynEIO: Asynchronous Monocular Event-Inertial Odometry Using Gaussian
  Process Regression","Zhixiang Wang, Xudong Li, Yizhai Zhang, Fan Zhang, Panfeng",2024-11-19T02:39:57Z,"Event cameras, when combined with inertial sensors, show significant
potential for motion estimation in challenging scenarios, such as high-speed
maneuvers and low-light environments. There are many methods for producing such
estimations, but most boil down to a synchronous discrete-time fusion problem.
However, the asynchronous nature of event cameras and their unique fusion
mechanism with inertial sensors remain underexplored. In this paper, we
introduce a monocular event-inertial odometry method called AsynEIO, designed
to fuse asynchronous event and inertial data within a unified Gaussian Process
(GP) regression framework. Our approach incorporates an event-driven frontend
that tracks feature trajectories directly from raw event streams at a high
temporal resolution. These tracked feature trajectories, along with various
inertial factors, are integrated into the same GP regression framework to
enable asynchronous fusion. With deriving analytical residual Jacobians and
noise models, our method constructs a factor graph that is iteratively
optimized and pruned using a sliding-window optimizer. Comparative assessments
highlight the performance of different inertial fusion strategies, suggesting
optimal choices for varying conditions. Experimental results on both public
datasets and our own event-inertial sequences indicate that AsynEIO outperforms
existing methods, especially in high-speed and low-illumination scenarios.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.12175v1
"Just KIDDIN: Knowledge Infusion and Distillation for Detection of
  INdecent Memes","Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ugur Kursuncu, Ponnurangam Kumaraguru",2024-11-19T02:39:28Z,"Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.","cs.LG, cs.CL, cs.CV",cs.LG,http://arxiv.org/abs/2411.12174v1
"HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation
  in Crowded and Constrained Environments","Shuijing Liu, Haochen Xia, Fatemeh Cheraghi Pouria, Kaiwen Hong, Neeloy Chakraborty, Katherine Driggs-Campbell",2024-11-19T00:56:35Z,"We study the problem of robot navigation in dense and interactive crowds with
environmental constraints such as corridors and furniture. Previous methods
fail to consider all types of interactions among agents and obstacles, leading
to unsafe and inefficient robot paths. In this article, we leverage a
graph-based representation of crowded and constrained scenarios and propose a
structured framework to learn robot navigation policies with deep reinforcement
learning. We first split the representations of different components in the
environment and propose a heterogeneous spatio-temporal (st) graph to model
distinct interactions among humans, robots, and obstacles. Based on the
heterogeneous st-graph, we propose HEIGHT, a novel navigation policy network
architecture with different components to capture heterogeneous interactions
among entities through space and time. HEIGHT utilizes attention mechanisms to
prioritize important interactions and a recurrent network to track changes in
the dynamic scene over time, encouraging the robot to avoid collisions
adaptively. Through extensive simulation and real-world experiments, we
demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of
success and efficiency in challenging navigation scenarios. Furthermore, we
demonstrate that our pipeline achieves better zero-shot generalization
capability than previous works when the densities of humans and obstacles
change. More videos are available at
https://sites.google.com/view/crowdnav-height/home.","cs.RO, cs.AI, cs.LG",cs.RO,http://arxiv.org/abs/2411.12150v1
"Towards Understanding the Impact of Data Bugs on Deep Learning Models in
  Software Engineering","Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh",2024-11-19T00:28:20Z,"Deep learning (DL) techniques have achieved significant success in various
software engineering tasks (e.g., code completion by Copilot). However, DL
systems are prone to bugs from many sources, including training data. Existing
literature suggests that bugs in training data are highly prevalent, but little
research has focused on understanding their impacts on the models used in
software engineering tasks. In this paper, we address this research gap through
a comprehensive empirical investigation focused on three types of data
prevalent in software engineering tasks: code-based, text-based, and
metric-based. Using state-of-the-art baselines, we compare the models trained
on clean datasets with those trained on datasets with quality issues and
without proper preprocessing. By analysing the gradients, weights, and biases
from neural networks under training, we identify the symptoms of data quality
and preprocessing issues. Our analysis reveals that quality issues in code data
cause biased learning and gradient instability, whereas problems in text data
lead to overfitting and poor generalisation of models. On the other hand,
quality issues in metric data result in exploding gradients and model
overfitting, and inadequate preprocessing exacerbates these effects across all
three data types. Finally, we demonstrate the validity and generalizability of
our findings using six new datasets. Our research provides a better
understanding of the impact and symptoms of data bugs in software engineering
datasets. Practitioners and researchers can leverage these findings to develop
better monitoring systems and data-cleaning methods to help detect and resolve
data bugs in deep learning systems.",cs.SE,cs.SE,http://arxiv.org/abs/2411.12137v1
BALI: Learning Neural Networks via Bayesian Layerwise Inference,"Richard Kurle, Alexej Klushyn, Ralf Herbrich",2024-11-18T22:18:34Z,"We introduce a new method for learning Bayesian neural networks, treating
them as a stack of multivariate Bayesian linear regression models. The main
idea is to infer the layerwise posterior exactly if we know the target outputs
of each layer. We define these pseudo-targets as the layer outputs from the
forward pass, updated by the backpropagated gradients of the objective
function. The resulting layerwise posterior is a matrix-normal distribution
with a Kronecker-factorized covariance matrix, which can be efficiently
inverted. Our method extends to the stochastic mini-batch setting using an
exponential moving average over natural-parameter terms, thus gradually
forgetting older data. The method converges in few iterations and performs as
well as or better than leading Bayesian neural network methods on various
regression, classification, and out-of-distribution detection benchmarks.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.12102v1
"FruitNinja: 3D Object Interior Texture Generation with Gaussian
  Splatting","Fangyu Wu, Yuhao Chen",2024-11-18T22:00:19Z,"In the real world, objects reveal internal textures when sliced or cut, yet
this behavior is not well-studied in 3D generation tasks today. For example,
slicing a virtual 3D watermelon should reveal flesh and seeds. Given that no
available dataset captures an object's full internal structure and collecting
data from all slices is impractical, generative methods become the obvious
approach. However, current 3D generation and inpainting methods often focus on
visible appearance and overlook internal textures. To bridge this gap, we
introduce FruitNinja, the first method to generate internal textures for 3D
objects undergoing geometric and topological changes. Our approach produces
objects via 3D Gaussian Splatting (3DGS) with both surface and interior
textures synthesized, enabling real-time slicing and rendering without
additional optimization. FruitNinja leverages a pre-trained diffusion model to
progressively inpaint cross-sectional views and applies voxel-grid-based
smoothing to achieve cohesive textures throughout the object. Our OpaqueAtom GS
strategy overcomes 3DGS limitations by employing densely distributed opaque
Gaussians, avoiding biases toward larger particles that destabilize training
and sharp color transitions for fine-grained textures. Experimental results
show that FruitNinja substantially outperforms existing approaches, showcasing
unmatched visual quality in real-time rendered internal views across arbitrary
geometry manipulations.","cs.CV, cs.GR, cs.HC",cs.CV,http://arxiv.org/abs/2411.12089v1
Mitigating Gender Bias in Contextual Word Embeddings,"Navya Yarrabelly, Vinay Damodaran, Feng-Guang Su",2024-11-18T21:36:44Z,"Word embeddings have been shown to produce remarkable results in tackling a
vast majority of NLP related tasks. Unfortunately, word embeddings also capture
the stereotypical biases that are prevalent in society, affecting the
predictive performance of the embeddings when used in downstream tasks. While
various techniques have been proposed \cite{bolukbasi2016man, zhao2018learning}
and criticized\cite{gonen2019lipstick} for static embeddings, very little work
has focused on mitigating bias in contextual embeddings. In this paper, we
propose a novel objective function for MLM(Masked-Language Modeling) which
largely mitigates the gender bias in contextual embeddings and also preserves
the performance for downstream tasks. Since previous works on measuring bias in
contextual embeddings lack in normative reasoning, we also propose novel
evaluation metrics that are straight-forward and aligned with our motivations
in debiasing. We also propose new methods for debiasing static embeddings and
provide empirical proof via extensive analysis and experiments, as to why the
main source of bias in static embeddings stems from the presence of
stereotypical names rather than gendered words themselves. All experiments and
embeddings studied are in English, unless otherwise
specified.\citep{bender2011achieving}.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.12074v1
"Autoassociative Learning of Structural Representations for Modeling and
  Classification in Medical Imaging","Zuzanna Buchnajzer, Kacper Dobek, Stanisław Hapke, Daniel Jankowski, Krzysztof Krawiec",2024-11-18T21:29:50Z,"Deep learning architectures based on convolutional neural networks tend to
rely on continuous, smooth features. While this characteristics provides
significant robustness and proves useful in many real-world tasks, it is
strikingly incompatible with the physical characteristic of the world, which,
at the scale in which humans operate, comprises crisp objects, typically
representing well-defined categories. This study proposes a class of
neurosymbolic systems that learn by reconstructing the observed images in terms
of visual primitives and are thus forced to form high-level, structural
explanations of them. When applied to the task of diagnosing abnormalities in
histological imaging, the method proved superior to a conventional deep
learning architecture in terms of classification accuracy, while being more
transparent.","cs.CV, cs.LG, 68T05, I.2; I.2.6; I.2.10",cs.CV,http://arxiv.org/abs/2411.12070v1
"TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear
  Travelling Salesman Model","Weixian Waylon Li, Yftah Ziser, Yifei Xie, Shay B. Cohen, Tiejun Ma",2024-11-18T21:10:14Z,"Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods
like RankNet and LambdaMART, often fall short by solely focusing on pairwise
comparisons, leading to sub-optimal global rankings. Conversely, deep learning
based listwise methods, while aiming to optimise entire lists, require complex
tuning and yield only marginal improvements over robust pairwise models. To
overcome these limitations, we introduce Travelling Salesman Problem Rank
(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the
ranking problem as a Travelling Salesman Problem (TSP), a well-known
combinatorial optimisation challenge that has been extensively studied for its
numerous solution algorithms and applications. This approach enables the
modelling of pairwise relationships and leverages combinatorial optimisation to
determine the listwise ranking. This approach can be directly integrated as an
additional component into embeddings generated by existing backbone models to
enhance ranking performance. Our extensive experiments across three backbone
models on diverse tasks, including stock ranking, information retrieval, and
historical events ordering, demonstrate that TSPRank significantly outperforms
both pure pairwise and listwise methods. Our qualitative analysis reveals that
TSPRank's main advantage over existing methods is its ability to harness global
information better while ranking. TSPRank's robustness and superior performance
across different domains highlight its potential as a versatile and effective
LETOR solution. The code and preprocessed data are available at
https://github.com/waylonli/TSPRank-KDD2025.","cs.AI, cs.IR",cs.AI,http://arxiv.org/abs/2411.12064v1
"Fingerprinting and Tracing Shadows: The Development and Impact of
  Browser Fingerprinting on Digital Privacy",Alexander Lawall,2024-11-18T20:32:31Z,"Browser fingerprinting is a growing technique for identifying and tracking
users online without traditional methods like cookies. This paper gives an
overview by examining the various fingerprinting techniques and analyzes the
entropy and uniqueness of the collected data. The analysis highlights that
browser fingerprinting poses a complex challenge from both technical and
privacy perspectives, as users often have no control over the collection and
use of their data. In addition, it raises significant privacy concerns as users
are often tracked without their knowledge or consent.","cs.CR, cs.AI, cs.CY",cs.CR,http://arxiv.org/abs/2411.12045v1
"ITACLIP: Boosting Training-Free Semantic Segmentation with Image, Text,
  and Architectural Enhancements","M. Arda Aydın, Efe Mert Çırpar, Elvin Abdinli, Gozde Unal, Yusuf H. Sahin",2024-11-18T20:31:38Z,"Recent advances in foundational Vision Language Models (VLMs) have reshaped
the evaluation paradigm in computer vision tasks. These foundational models,
especially CLIP, have accelerated research in open-vocabulary computer vision
tasks, including Open-Vocabulary Semantic Segmentation (OVSS). Although the
initial results are promising, the dense prediction capabilities of VLMs still
require further improvement. In this study, we enhance the semantic
segmentation performance of CLIP by introducing new modules and modifications:
1) architectural changes in the last layer of ViT and the incorporation of
attention maps from the middle layers with the last layer, 2) Image
Engineering: applying data augmentations to enrich input image representations,
and 3) using Large Language Models (LLMs) to generate definitions and synonyms
for each class name to leverage CLIP's open-vocabulary capabilities. Our
training-free method, ITACLIP, outperforms current state-of-the-art approaches
on segmentation benchmarks such as COCO-Stuff, COCO-Object, Pascal Context, and
Pascal VOC. Our code is available at https://github.com/m-arda-aydn/ITACLIP.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12044v1
"Scaling Deep Learning Research with Kubernetes on the NRP Nautilus
  HyperCluster","J. Alex Hurt, Anes Ouadou, Mariam Alshehri, Grant J. Scott",2024-11-18T20:19:49Z,"Throughout the scientific computing space, deep learning algorithms have
shown excellent performance in a wide range of applications. As these deep
neural networks (DNNs) continue to mature, the necessary compute required to
train them has continued to grow. Today, modern DNNs require millions of FLOPs
and days to weeks of training to generate a well-trained model. The training
times required for DNNs are oftentimes a bottleneck in DNN research for a
variety of deep learning applications, and as such, accelerating and scaling
DNN training enables more robust and accelerated research. To that end, in this
work, we explore utilizing the NRP Nautilus HyperCluster to automate and scale
deep learning model training for three separate applications of DNNs, including
overhead object detection, burned area segmentation, and deforestation
detection. In total, 234 deep neural models are trained on Nautilus, for a
total time of 4,040 hours","cs.LG, cs.AI, cs.DC",cs.LG,http://arxiv.org/abs/2411.12038v1
"In-Situ Melt Pool Characterization via Thermal Imaging for Defect
  Detection in Directed Energy Deposition Using Vision Transformers","Israt Zarin Era, Fan Zhou, Ahmed Shoyeb Raihan, Imtiaz Ahmed, Alan Abul-Haj, James Craig, Srinjoy Das, Zhichao Liu",2024-11-18T20:03:49Z,"Directed Energy Deposition (DED) offers significant potential for
manufacturing complex and multi-material parts. However, internal defects such
as porosity and cracks can compromise mechanical properties and overall
performance. This study focuses on in-situ monitoring and characterization of
melt pools associated with porosity, aiming to improve defect detection and
quality control in DED-printed parts. Traditional machine learning approaches
for defect identification rely on extensive labeled datasets, often scarce and
expensive to generate in real-world manufacturing. To address this, our
framework employs self-supervised learning on unlabeled melt pool data using a
Vision Transformer-based Masked Autoencoder (MAE) to produce highly
representative embeddings. These fine-tuned embeddings are leveraged via
transfer learning to train classifiers on a limited labeled dataset, enabling
the effective identification of melt pool anomalies. We evaluate two
classifiers: (1) a Vision Transformer (ViT) classifier utilizing the fine-tuned
MAE Encoder's parameters and (2) the fine-tuned MAE Encoder combined with an
MLP classifier head. Our framework achieves overall accuracy ranging from
95.44% to 99.17% and an average F1 score exceeding 80%, with the ViT Classifier
slightly outperforming the MAE Encoder Classifier. This demonstrates the
scalability and cost-effectiveness of our approach for automated quality
control in DED, effectively detecting defects with minimal labeled data.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12028v1
On-the-Go Path Planning and Repair in Static and Dynamic Scenarios,Daniel Ajeleye,2024-11-18T19:55:43Z,"Autonomous systems, including robots and drones, face significant challenges
when navigating through dynamic environments, particularly within urban
settings where obstacles, fluctuating traffic, and pedestrian activity are
constantly shifting. Although, traditional motion planning algorithms like the
wavefront planner and gradient descent planner, which use potential functions,
work well in static environments, they fall short in situations where the
environment is continuously changing. This work proposes a dynamic, real-time
path planning approach specifically designed for autonomous systems, allowing
them to effectively avoid static and dynamic obstacles, thereby enhancing their
overall adaptability. The approach integrates the efficiency of conventional
planners with the ability to make rapid adjustments in response to moving
obstacles and environmental changes. The simulation results discussed in this
article demonstrate the effectiveness of the proposed method, demonstrating its
suitability for robotic path planning in both known and unknown environments,
including those involving mobile objects, agents, or potential threats.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.12014v1
"HPA-MPC: Hybrid Perception-Aware Nonlinear Model Predictive Control for
  Quadrotors with Suspended Loads","Mrunal Sarvaiya, Guanrui Li, Giuseppe Loianno",2024-11-18T19:13:06Z,"Quadrotors equipped with cable-suspended loads represent a versatile,
low-cost, and energy efficient solution for aerial transportation,
construction, and manipulation tasks. However, their real-world deployment is
hindered by several challenges. The system is difficult to control because it
is nonlinear, underactuated, involves hybrid dynamics due to slack-taut cable
modes, and evolves on complex configuration spaces. Additionally, it is crucial
to estimate the full state and the cable's mode transitions in real-time using
on-board sensors and computation. To address these challenges, we present a
novel Hybrid Perception-Aware Nonlinear Model Predictive Control (HPA-MPC)
control approach for quadrotors with suspended loads. Our method considers the
complete hybrid system dynamics and includes a perception-aware cost to ensure
the payload remains visible in the robot's camera during navigation.
Furthermore, the full state and hybrid dynamics' transitions are estimated
using onboard sensors. Experimental results demonstrate that our approach
enables stable load tracking control, even during slack-taut transitions, and
operates entirely onboard. The experiments also show that the perception-aware
term effectively keeps the payload in the robot's camera field of view when a
human operator interacts with the load.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11982v1
RoboGSim: A Real2Sim2Real Robotic Gaussian Splatting Simulator,"Xinhai Li, Jialin Li, Ziheng Zhang, Rui Zhang, Fan Jia, Tiancai Wang, Haoqiang Fan, Kuo-Kun Tseng, Ruiping Wang",2024-11-18T18:58:03Z,"Efficient acquisition of real-world embodied data has been increasingly
critical. However, large-scale demonstrations captured by remote operation tend
to take extremely high costs and fail to scale up the data size in an efficient
manner. Sampling the episodes under a simulated environment is a promising way
for large-scale collection while existing simulators fail to high-fidelity
modeling on texture and physics. To address these limitations, we introduce the
RoboGSim, a real2sim2real robotic simulator, powered by 3D Gaussian Splatting
and the physics engine. RoboGSim mainly includes four parts: Gaussian
Reconstructor, Digital Twins Builder, Scene Composer, and Interactive Engine.
It can synthesize the simulated data with novel views, objects, trajectories,
and scenes. RoboGSim also provides an online, reproducible, and safe evaluation
for different manipulation policies. The real2sim and sim2real transfer
experiments show a high consistency in the texture and physics. Moreover, the
effectiveness of synthetic data is validated under the real-world manipulated
tasks. We hope RoboGSim serves as a closed-loop simulator for fair comparison
on policy learning. More information can be found on our project page
https://robogsim.github.io/ .","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.11839v1
"Describe Now: User-Driven Audio Description for Blind and Low Vision
  Individuals","Maryam Cheema, Hasti Seifi, Pooyan Fazli",2024-11-18T18:53:57Z,"Audio descriptions (AD) make videos accessible for blind and low vision (BLV)
users by describing visual elements that cannot be understood from the main
audio track. AD created by professionals or novice describers is time-consuming
and lacks scalability while offering little control to BLV viewers on
description length and content and when they receive it. To address this gap,
we explore user-driven AI-generated descriptions, where the BLV viewer controls
when they receive descriptions. In a study, 20 BLV participants activated audio
descriptions for seven different video genres with two levels of detail:
concise and detailed. Our results show differences in AD frequency and level of
detail BLV users wanted for different videos, their sense of control with this
style of AD delivery, its limitations, and variations among BLV users in their
AD needs and perception of AI-generated descriptions. We discuss the
implications of our findings for future AI-based AD tools.",cs.HC,cs.HC,http://arxiv.org/abs/2411.11835v1
"LightFFDNets: Lightweight Convolutional Neural Networks for Rapid Facial
  Forgery Detection","Günel Jabbarlı, Murat Kurt",2024-11-18T18:44:10Z,"Accurate and fast recognition of forgeries is an issue of great importance in
the fields of artificial intelligence, image processing and object detection.
Recognition of forgeries of facial imagery is the process of classifying and
defining the faces in it by analyzing real-world facial images. This process is
usually accomplished by extracting features from an image, using classifier
algorithms, and correctly interpreting the results. Recognizing forgeries of
facial imagery correctly can encounter many different challenges. For example,
factors such as changing lighting conditions, viewing faces from different
angles can affect recognition performance, and background complexity and
perspective changes in facial images can make accurate recognition difficult.
Despite these difficulties, significant progress has been made in the field of
forgery detection. Deep learning algorithms, especially Convolutional Neural
Networks (CNNs), have significantly improved forgery detection performance.
  This study focuses on image processing-based forgery detection using
Fake-Vs-Real-Faces (Hard) [10] and 140k Real and Fake Faces [61] data sets.
Both data sets consist of two classes containing real and fake facial images.
In our study, two lightweight deep learning models are proposed to conduct
forgery detection using these images. Additionally, 8 different pretrained CNN
architectures were tested on both data sets and the results were compared with
newly developed lightweight CNN models. It's shown that the proposed
lightweight deep learning models have minimum number of layers. It's also shown
that the proposed lightweight deep learning models detect forgeries of facial
imagery accurately, and computationally efficiently. Although the data set
consists only of face images, the developed models can also be used in other
two-class object recognition problems.","cs.CV, cs.AI, I.4.9; I.2.10",cs.CV,http://arxiv.org/abs/2411.11826v1
The Lambda Calculus is Quantifiable,"Valentin Maestracci, Paolo Pistone",2024-11-18T18:23:03Z,"In this paper we introduce several quantitative methods for the
lambda-calculus based on partial metrics, a well-studied variant of standard
metric spaces that have been used to metrize non-Hausdorff topologies, like
those arising from Scott domains. First, we study quantitative variants, based
on program distances, of sensible equational theories for the
$\lambda$-calculus, like those arising from B\""ohm trees and from the
contextual preorder. Then, we introduce applicative distances capturing
higher-order Scott topologies, including reflexive objects like the $D_\infty$
model. Finally, we provide a quantitative insight on the well-known connection
between the B\""ohm tree of a $\lambda$-term and its Taylor expansion, by
showing that the latter can be presented as an isometric transformation.","cs.LO, cs.PL, math.LO, F.4.1; F.3.2",cs.LO,http://arxiv.org/abs/2411.11809v1
"Enabling steep slope walking on Husky using reduced order modeling and
  quadratic programming","Kaushik Venkatesh Krishnamurthy, Eric Sihite, Chenghao Wang, Shreyansh Pitroda, Adarsh Salagame, Alireza Ramezani, Morteza Gharib",2024-11-18T18:03:49Z,"Wing-assisted inclined running (WAIR) observed in some young birds, is an
attractive maneuver that can be extended to legged aerial systems. This study
proposes a control method using a modified Variable Length Inverted Pendulum
(VLIP) by assuming a fixed zero moment point and thruster forces collocated at
the center of mass of the pendulum. A QP MPC is used to find the optimal ground
reaction forces and thruster forces to track a reference position and velocity
trajectory. Simulation results of this VLIP model on a slope of 40 degrees is
maintained and shows thruster forces that can be obtained through posture
manipulation. The simulation also provides insight to how the combined efforts
of the thrusters and the tractive forces from the legs make WAIR possible in
thruster-assisted legged systems.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.11788v1
"LLM-IE: A Python Package for Generative Information Extraction with
  Large Language Models","Enshuo Hsu, Kirk Roberts",2024-11-18T17:56:13Z,"Objectives: Despite the recent adoption of large language models (LLMs) for
biomedical information extraction, challenges in prompt engineering and
algorithms persist, with no dedicated software available. To address this, we
developed LLM-IE: a Python package for building complete information extraction
pipelines. Our key innovation is an interactive LLM agent to support schema
definition and prompt design.
  Materials and Methods: The LLM-IE supports named entity recognition, entity
attribute extraction, and relation extraction tasks. We benchmarked on the i2b2
datasets and conducted a system evaluation.
  Results: The sentence-based prompting algorithm resulted in the best
performance while requiring a longer inference time. System evaluation provided
intuitive visualization.
  Discussion: LLM-IE was designed from practical NLP experience in healthcare
and has been adopted in internal projects. It should hold great value to the
biomedical NLP community.
  Conclusion: We developed a Python package, LLM-IE, that provides building
blocks for robust information extraction pipeline construction.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11779v1
"Freezing of Gait Detection Using Gramian Angular Fields and Federated
  Learning from Wearable Sensors","Shovito Barua Soumma, S M Raihanul Alam, Rudmila Rahman, Umme Niraj Mahi, Abdullah Mamun, Sayyed Mostafa Mostafavi, Hassan Ghasemzadeh",2024-11-18T17:43:43Z,"Freezing of gait (FOG) is a debilitating symptom of Parkinson's disease (PD)
that impairs mobility and safety. Traditional detection methods face challenges
due to intra and inter-patient variability, and most systems are tested in
controlled settings, limiting their real-world applicability. Addressing these
gaps, we present FOGSense, a novel FOG detection system designed for
uncontrolled, free-living conditions. It uses Gramian Angular Field (GAF)
transformations and federated deep learning to capture temporal and spatial
gait patterns missed by traditional methods. We evaluated our FOGSense system
using a public PD dataset, 'tdcsfog'. FOGSense improves accuracy by 10.4% over
a single-axis accelerometer, reduces failure points compared to multi-sensor
systems, and demonstrates robustness to missing values. The federated
architecture allows personalized model adaptation and efficient smartphone
synchronization during off-peak hours, making it effective for long-term
monitoring as symptoms evolve. Overall, FOGSense achieves a 22.2% improvement
in F1-score compared to state-of-the-art methods, along with enhanced
sensitivity for FOG episode detection. Code is available:
https://github.com/shovito66/FOGSense.","cs.LG, eess.SP",cs.LG,http://arxiv.org/abs/2411.11764v2
"High-Speed Cornering Control and Real-Vehicle Deployment for Autonomous
  Electric Vehicles","Shiyue Zhao, Junzhi Zhang, Neda Masoud, Yuhong Jiang, Heye Huang, Tao Liu",2024-11-18T17:40:43Z,"Executing drift maneuvers during high-speed cornering presents significant
challenges for autonomous vehicles, yet offers the potential to minimize
turning time and enhance driving dynamics. While reinforcement learning (RL)
has shown promising results in simulated environments, discrepancies between
simulations and real-world conditions have limited its practical deployment.
This study introduces an innovative control framework that integrates
trajectory optimization with drift maneuvers, aiming to improve the algorithm's
adaptability for real-vehicle implementation. We leveraged Bezier-based
pre-trajectory optimization to enhance rewards and optimize the controller
through Twin Delayed Deep Deterministic Policy Gradient (TD3) in a simulated
environment. For real-world deployment, we implement a hybrid RL-MPC fusion
mechanism, , where TD3-derived maneuvers serve as primary inputs for a Model
Predictive Controller (MPC). This integration enables precise real-time
tracking of the optimal trajectory, with MPC providing corrective inputs to
bridge the gap between simulation and reality. The efficacy of this method is
validated through real-vehicle tests on consumer-grade electric vehicles,
focusing on drift U-turns and drift right-angle turns. The control outcomes of
these real-vehicle tests are thoroughly documented in the paper, supported by
supplementary video evidence (https://youtu.be/5wp67FcpfL8). Notably, this
study is the first to deploy and apply an RL-based transient drift cornering
algorithm on consumer-grade electric vehicles.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.11762v1
"sMoRe: Enhancing Object Manipulation and Organization in Mixed Reality
  Spaces with LLMs and Generative AI","Yunhao Xing, Que Liu, Jingwu Wang, Diego Gomez-Zara",2024-11-18T17:27:56Z,"In mixed reality (MR) environments, understanding space and creating virtual
objects is crucial to providing an intuitive and rich user experience. This
paper introduces sMoRe (Spatial Mapping and Object Rendering Environment), an
MR application that combines Generative AI (GenAI) with large language models
(LLMs) to assist users in creating, placing, and managing virtual objects
within physical spaces. sMoRe allows users to use voice or typed text commands
to create and place virtual objects using GenAI while specifying spatial
constraints. The system leverages LLMs to interpret users' commands, analyze
the current scene, and identify optimal locations. Additionally, sMoRe
integrates text-to-3D generative AI to dynamically create 3D objects based on
users' descriptions. Our user study demonstrates the effectiveness of sMoRe in
enhancing user comprehension, interaction, and organization of the MR
environment.",cs.HC,cs.HC,http://arxiv.org/abs/2411.11752v1
QARM: Quantitative Alignment Multi-Modal Recommendation at Kuaishou,"Xinchen Luo, Jiangxia Cao, Tianyu Sun, Jinkai Yu, Rui Huang, Wei Yuan, Hezheng Lin, Yichen Zheng, Shiyao Wang, Qigen Hu, Changqing Qiu, Jiaqi Zhang, Xu Zhang, Zhiheng Yan, Jingming Zhang, Simin Zhang, Mingxing Wen, Zhaojie Liu, Kun Gai, Guorui Zhou",2024-11-18T17:08:35Z,"In recent years, with the significant evolution of multi-modal large models,
many recommender researchers realized the potential of multi-modal information
for user interest modeling. In industry, a wide-used modeling architecture is a
cascading paradigm: (1) first pre-training a multi-modal model to provide
omnipotent representations for downstream services; (2) The downstream
recommendation model takes the multi-modal representation as additional input
to fit real user-item behaviours. Although such paradigm achieves remarkable
improvements, however, there still exist two problems that limit model
performance: (1) Representation Unmatching: The pre-trained multi-modal model
is always supervised by the classic NLP/CV tasks, while the recommendation
models are supervised by real user-item interaction. As a result, the two
fundamentally different tasks' goals were relatively separate, and there was a
lack of consistent objective on their representations; (2) Representation
Unlearning: The generated multi-modal representations are always stored in
cache store and serve as extra fixed input of recommendation model, thus could
not be updated by recommendation model gradient, further unfriendly for
downstream training. Inspired by the two difficulties challenges in downstream
tasks usage, we introduce a quantitative multi-modal framework to customize the
specialized and trainable multi-modal information for different downstream
models.","cs.IR, cs.AI, N/A",cs.IR,http://arxiv.org/abs/2411.11739v1
"WoodYOLO: A Novel Object Detector for Wood Species Detection in
  Microscopic Images","Lars Nieradzik, Henrike Stephani, Jördis Sieburg-Rockel, Stephanie Helmling, Andrea Olbrich, Stephanie Wrage, Janis Keuper",2024-11-18T17:07:37Z,"Wood species identification plays a crucial role in various industries, from
ensuring the legality of timber products to advancing ecological conservation
efforts. This paper introduces WoodYOLO, a novel object detection algorithm
specifically designed for microscopic wood fiber analysis. Our approach adapts
the YOLO architecture to address the challenges posed by large, high-resolution
microscopy images and the need for high recall in localization of the cell type
of interest (vessel elements). Our results show that WoodYOLO significantly
outperforms state-of-the-art models, achieving performance gains of 12.9% and
6.5% in F2 score over YOLOv10 and YOLOv7, respectively. This improvement in
automated wood cell type localization capabilities contributes to enhancing
regulatory compliance, supporting sustainable forestry practices, and promoting
biodiversity conservation efforts globally.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11738v1
"Advacheck at GenAI Detection Task 1: AI Detection Powered by
  Domain-Aware Multi-Tasking","German Gritsai, Anastasia Voznyuk, Ildar Khabutdinov, Andrey Grabovoy",2024-11-18T17:03:30Z,"The paper describes a system designed by Advacheck team to recognise
machine-generated and human-written texts in the monolingual subtask of GenAI
Detection Task 1 competition. Our developed system is a multi-task architecture
with shared Transformer Encoder between several classification heads. One head
is responsible for binary classification between human-written and
machine-generated texts, while the other heads are auxiliary multiclass
classifiers for texts of different domains from particular datasets. As
multiclass heads were trained to distinguish the domains presented in the data,
they provide a better understanding of the samples. This approach led us to
achieve the first place in the official ranking with 83.07% macro F1-score on
the test set and bypass the baseline by 10%. We further study obtained system
through ablation, error and representation analyses, finding that multi-task
learning outperforms single-task mode and simultaneous tasks form a cluster
structure in embeddings space.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11736v1
Joint-Space Control of a Structurally Elastic Humanoid Robot,"Connor W. Herron, Christian Runyon, Isaac Pressgrove, Benjamin C. Beiter, Bhaben Kalita, Alexander Leonessa",2024-11-18T17:02:15Z,"In this work, the joint-control strategy is presented for the humanoid robot,
PANDORA, whose structural components are designed to be compliant. As opposed
to contemporary approaches which design the elasticity internal to the actuator
housing, PANDORA's structural components are designed to be compliant under
load or, in other words, structurally elastic. To maintain the rapid design
benefit of additive manufacturing, this joint control strategy employs a
disturbance observer (DOB) modeled from an ideal elastic actuator. This robust
controller treats the model variation from the structurally elastic components
as a disturbance and eliminates the need for system identification of the 3D
printed parts. This enables mechanical design engineers to iterate on the 3D
printed linkages without requiring consistent tuning from the joint controller.
Two sets of hardware results are presented for validating the controller. The
first set of results are conducted on an ideal elastic actuator testbed that
drives an unmodeled, 1 DoF weighted pendulum with a 10 kg mass. The results
support the claim that the DOB can handle significant model variation. The
second set of results is from a robust balancing experiment conducted on the 12
DoF lower body of PANDORA. The robot maintains balance while an operator
applies 50 N pushes to the pelvis, where the actuator tracking results are
presented for the left leg.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11734v1
"Integrating Active Sensing and Rearrangement Planning for Efficient
  Object Retrieval from Unknown, Confined, Cluttered Environments","Junyong Kim, Hanwen Ren, Ahmed H. Qureshi",2024-11-18T17:00:52Z,"Retrieving target objects from unknown, confined spaces remains a challenging
task that requires integrated, task-driven active sensing and rearrangement
planning. Previous approaches have independently addressed active sensing and
rearrangement planning, limiting their practicality in real-world scenarios.
This paper presents a new, integrated heuristic-based active sensing and
Monte-Carlo Tree Search (MCTS)-based retrieval planning approach. These
components provide feedback to one another to actively sense critical,
unobserved areas suitable for the retrieval planner to plan a sequence for
relocating path-blocking obstacles and a collision-free trajectory for
retrieving the target object. We demonstrate the effectiveness of our approach
using a robot arm equipped with an in-hand camera in both simulated and
real-world confined, cluttered scenarios. Our framework is compared against
various state-of-the-art methods. The results indicate that our proposed
approach outperforms baseline methods by a significant margin in terms of the
success rate, the object rearrangement planning time consumption and the number
of planning trials before successfully retrieving the target. Videos can be
found at https://youtu.be/tea7I-3RtV0.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11733v1
"Lifted Model Construction without Normalisation: A Vectorised Approach
  to Exploit Symmetries in Factor Graphs","Malte Luttermann, Ralf Möller, Marcel Gehrke",2024-11-18T16:59:44Z,"Lifted probabilistic inference exploits symmetries in a probabilistic model
to allow for tractable probabilistic inference with respect to domain sizes of
logical variables. We found that the current state-of-the-art algorithm to
construct a lifted representation in form of a parametric factor graph misses
symmetries between factors that are exchangeable but scaled differently,
thereby leading to a less compact representation. In this paper, we propose a
generalisation of the advanced colour passing (ACP) algorithm, which is the
state of the art to construct a parametric factor graph. Our proposed algorithm
allows for potentials of factors to be scaled arbitrarily and efficiently
detects more symmetries than the original ACP algorithm. By detecting strictly
more symmetries than ACP, our algorithm significantly reduces online query
times for probabilistic inference when the resulting model is applied, which we
also confirm in our experiments.","cs.AI, cs.LG",cs.AI,http://arxiv.org/abs/2411.11730v2
Aligning Few-Step Diffusion Models with Dense Reward Difference Learning,"Ziyi Zhang, Li Shen, Sen Zhang, Deheng Ye, Yong Luo, Miaojing Shi, Bo Du, Dacheng Tao",2024-11-18T16:57:41Z,"Aligning diffusion models with downstream objectives is essential for their
practical applications. However, standard alignment methods often struggle with
step generalization when directly applied to few-step diffusion models, leading
to inconsistent performance across different denoising step scenarios. To
address this, we introduce Stepwise Diffusion Policy Optimization (SDPO), a
novel alignment method tailored for few-step diffusion models. Unlike prior
approaches that rely on a single sparse reward from only the final step of each
denoising trajectory for trajectory-level optimization, SDPO incorporates dense
reward feedback at every intermediate step. By learning the differences in
dense rewards between paired samples, SDPO facilitates stepwise optimization of
few-step diffusion models, ensuring consistent alignment across all denoising
steps. To promote stable and efficient training, SDPO introduces an online
reinforcement learning framework featuring several novel strategies designed to
effectively exploit the stepwise granularity of dense rewards. Experimental
results demonstrate that SDPO consistently outperforms prior methods in
reward-based alignment across diverse step configurations, underscoring its
robust step generalization capabilities. Code is avaliable at
https://github.com/ZiyiZhang27/sdpo.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.11727v1
"Fair Distillation: Teaching Fairness from Biased Teachers in Medical
  Imaging","Milad Masroor, Tahir Hassan, Yu Tian, Kevin Wells, David Rosewarne, Thanh-Toan Do, Gustavo Carneiro",2024-11-18T16:50:34Z,"Deep learning has achieved remarkable success in image classification and
segmentation tasks. However, fairness concerns persist, as models often exhibit
biases that disproportionately affect demographic groups defined by sensitive
attributes such as race, gender, or age. Existing bias-mitigation techniques,
including Subgroup Re-balancing, Adversarial Training, and Domain
Generalization, aim to balance accuracy across demographic groups, but often
fail to simultaneously improve overall accuracy, group-specific accuracy, and
fairness due to conflicts among these interdependent objectives. We propose the
Fair Distillation (FairDi) method, a novel fairness approach that decomposes
these objectives by leveraging biased ``teacher'' models, each optimized for a
specific demographic group. These teacher models then guide the training of a
unified ``student'' model, which distills their knowledge to maximize overall
and group-specific accuracies, while minimizing inter-group disparities.
Experiments on medical imaging datasets show that FairDi achieves significant
gains in both overall and group-specific accuracy, along with improved
fairness, compared to existing methods. FairDi is adaptable to various medical
tasks, such as classification and segmentation, and provides an effective
solution for equitable model performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11939v1
"Exploring Eye Tracking to Detect Cognitive Load in Complex Virtual
  Reality Training","Mahsa Nasri, Mehmet Kosa, Leanne Chukoskie, Mohsen Moghaddam, Casper Harteveld",2024-11-18T16:44:19Z,"Virtual Reality (VR) has been a beneficial training tool in fields such as
advanced manufacturing. However, users may experience a high cognitive load due
to various factors, such as the use of VR hardware or tasks within the VR
environment. Studies have shown that eye-tracking has the potential to detect
cognitive load, but in the context of VR and complex spatiotemporal tasks
(e.g., assembly and disassembly), it remains relatively unexplored. Here, we
present an ongoing study to detect users' cognitive load using an
eye-tracking-based machine learning approach. We developed a VR training system
for cold spray and tested it with 22 participants, obtaining 19 valid
eye-tracking datasets and NASA-TLX scores. We applied Multi-Layer Perceptron
(MLP) and Random Forest (RF) models to compare the accuracy of predicting
cognitive load (i.e., NASA-TLX) using pupil dilation and fixation duration. Our
preliminary analysis demonstrates the feasibility of using eye tracking to
detect cognitive load in complex spatiotemporal VR experiences and motivates
further exploration.","cs.HC, cs.LG",cs.HC,http://arxiv.org/abs/2411.12771v1
"TrojanRobot: Backdoor Attacks Against Robotic Manipulation in the
  Physical World","Xianlong Wang, Hewen Pan, Hangtao Zhang, Minghui Li, Shengshan Hu, Ziqi Zhou, Lulu Xue, Peijin Guo, Yichen Wang, Wei Wan, Aishan Liu, Leo Yu Zhang",2024-11-18T16:09:26Z,"Robotic manipulation refers to the autonomous handling and interaction of
robots with objects using advanced techniques in robotics and artificial
intelligence. The advent of powerful tools such as large language models (LLMs)
and large vision-language models (LVLMs) has significantly enhanced the
capabilities of these robots in environmental perception and decision-making.
However, the introduction of these intelligent agents has led to security
threats such as jailbreak attacks and adversarial attacks.
  In this research, we take a further step by proposing a backdoor attack
specifically targeting robotic manipulation and, for the first time,
implementing backdoor attack in the physical world. By embedding a backdoor
visual language model into the visual perception module within the robotic
system, we successfully mislead the robotic arm's operation in the physical
world, given the presence of common items as triggers. Experimental evaluations
in the physical world demonstrate the effectiveness of the proposed backdoor
attack.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.11683v1
"Dissecting Misalignment of Multimodal Large Language Models via
  Influence Function","Lijie Hu, Chenyang Ren, Huanyi Xie, Khouloud Saadi, Shu Yang, Jingfeng Zhang, Di Wang",2024-11-18T15:45:41Z,"Multi-modal Large Language models (MLLMs) are always trained on data from
diverse and unreliable sources, which may contain misaligned or mislabeled
text-image pairs. This frequently causes robustness issues and hallucinations,
leading to performance degradation. Data valuation is an efficient way to
detect and trace these misalignments. Nevertheless, existing methods are
computationally expensive for MLLMs. While computationally efficient, the
classical influence functions are inadequate for contrastive learning models
because they were originally designed for pointwise loss. Additionally,
contrastive learning involves minimizing the distance between the modalities of
positive samples and maximizing the distance between the modalities of negative
samples. This requires us to evaluate the influence of samples from both
perspectives. To tackle these challenges, we introduce the Extended Influence
Function for Contrastive Loss (ECIF), an influence function crafted for
contrastive loss. ECIF considers both positive and negative samples and
provides a closed-form approximation of contrastive learning models,
eliminating the need for retraining. Building upon ECIF, we develop a series of
algorithms for data evaluation in MLLM, misalignment detection, and
misprediction trace-back tasks. Experimental results demonstrate our ECIF
advances the transparency and interpretability of MLLMs by offering a more
accurate assessment of data impact and model alignment compared to traditional
baseline methods.","cs.LG, cs.AI, cs.CV",cs.LG,http://arxiv.org/abs/2411.11667v1
"Improving Data Curation of Software Vulnerability Patches through
  Uncertainty Quantification","Hui Chen, Yunhua Zhao, Kostadin Damevski",2024-11-18T15:37:28Z,"The changesets (or patches) that fix open source software vulnerabilities
form critical datasets for various machine learning security-enhancing
applications, such as automated vulnerability patching and silent fix
detection. These patch datasets are derived from extensive collections of
historical vulnerability fixes, maintained in databases like the Common
Vulnerabilities and Exposures list and the National Vulnerability Database.
However, since these databases focus on rapid notification to the security
community, they contain significant inaccuracies and omissions that have a
negative impact on downstream software security quality assurance tasks.
  In this paper, we propose an approach employing Uncertainty Quantification
(UQ) to curate datasets of publicly-available software vulnerability patches.
Our methodology leverages machine learning models that incorporate UQ to
differentiate between patches based on their potential utility. We begin by
evaluating a number of popular UQ techniques, including Vanilla, Monte Carlo
Dropout, and Model Ensemble, as well as homoscedastic and heteroscedastic
models of noise. Our findings indicate that Model Ensemble and heteroscedastic
models are the best choices for vulnerability patch datasets. Based on these UQ
modeling choices, we propose a heuristic that uses UQ to filter out lower
quality instances and select instances with high utility value from the
vulnerability dataset. Using our approach, we observe an improvement in
predictive performance and significant reduction of model training time (i.e.,
energy consumption) for a state-of-the-art vulnerability prediction model.",cs.SE,cs.SE,http://arxiv.org/abs/2411.11659v1
"Introducing IHARDS-CNN: A Cutting-Edge Deep Learning Method for Human
  Activity Recognition Using Wearable Sensors","Nazanin Sedaghati, Masoud Kargar, Sina Abbaskhani",2024-11-18T15:36:00Z,"Human activity recognition, facilitated by smart devices, has recently
garnered significant attention. Deep learning algorithms have become pivotal in
daily activities, sports, and healthcare. Nevertheless, addressing the
challenge of extracting features from sensor data processing necessitates the
utilization of diverse algorithms in isolation, subsequently transforming them
into a standard mode. This research introduces a novel approach called
IHARDS-CNN, amalgamating data from three distinct datasets (UCI-HAR, WISDM, and
KU-HAR) for human activity recognition. The data collected from sensors
embedded in smartwatches or smartphones encompass five daily activity classes.
This study initially outlines the dataset integration approach, follows with a
comprehensive statistical analysis, and assesses dataset accuracy. The proposed
methodology employs a one-dimensional deep convolutional neural network for
classification. Compared to extant activity recognition methods, this approach
stands out for its high speed, reduced detection steps, and absence of the need
to aggregate classified results. Despite fewer detection steps, empirical
results demonstrate an impressive accuracy of nearly 100%, marking it the
highest among existing methods. Evaluation outcomes further highlight superior
classification performance when compared to analogous architectures.",cs.HC,cs.HC,http://arxiv.org/abs/2411.11658v1
Can Highlighting Help GitHub Maintainers Track Security Fixes?,"Xueqing Liu, Yuchen Xiong, Qiushi Liu, Jiangrui Zheng",2024-11-18T15:23:51Z,"In recent years, the rapid growth of security vulnerabilities poses great
challenges to tracing and managing them. For example, it was reported that the
NVD database experienced significant delays due to the shortage of maintainers.
Such delay creates challenges for third-party security personnel (e.g.,
administrators) to trace the information related to the CVE. To help security
personnel trace a vulnerability patch, we build a retrieval system that
automatically retrieves the patch in the repository.
  Inspired by existing work on explainable machine learning, we ask the
following research question: can explanations help security maintainers make
decisions in patch tracing? First, we investigate using LIME (a widely used
explainable machine learning method) to highlight the rationale tokens in the
commit message and code. In addition, we propose an explanation method called
TfIdf-Highlight, which leverages the Tf-Idf statistics to select the most
informative words in the repository and the dataset. We evaluate the
effectiveness of highlighting using two experiments. First, we compare LIME and
TfIdf-Highlight using a faithfulness score (i.e., sufficiency and
comprehensiveness) defined for ranking. We find that TfIdf-Highlight
significantly outperforms LIME's sufficiency scores by 15\% and slightly
outperforms the comprehensiveness scores. Second, we conduct a blind human
labeling experiment by asking the annotators to guess the patch under 3
settings (TfIdf-Highlight, LIME, and no highlight). We find that the
helpfulness score for TfIdf-Highlight is higher than LIME while the labeling
accuracies of LIME and TfIdf-Highlight are similar. Nevertheless, highlighting
does not improve the accuracy over non-highlighting.","cs.CR, cs.SE",cs.CR,http://arxiv.org/abs/2411.11646v1
"TSINR: Capturing Temporal Continuity via Implicit Neural Representations
  for Time Series Anomaly Detection","Mengxuan Li, Ke Liu, Hongyang Chen, Jiajun Bu, Hongwei Wang, Haishuai Wang",2024-11-18T15:19:54Z,"Time series anomaly detection aims to identify unusual patterns in data or
deviations from systems' expected behavior. The reconstruction-based methods
are the mainstream in this task, which learn point-wise representation via
unsupervised learning. However, the unlabeled anomaly points in training data
may cause these reconstruction-based methods to learn and reconstruct anomalous
data, resulting in the challenge of capturing normal patterns. In this paper,
we propose a time series anomaly detection method based on implicit neural
representation (INR) reconstruction, named TSINR, to address this challenge.
Due to the property of spectral bias, TSINR enables prioritizing low-frequency
signals and exhibiting poorer performance on high-frequency abnormal data.
Specifically, we adopt INR to parameterize time series data as a continuous
function and employ a transformer-based architecture to predict the INR of
given data. As a result, the proposed TSINR method achieves the advantage of
capturing the temporal continuity and thus is more sensitive to discontinuous
anomaly data. In addition, we further design a novel form of INR continuous
function to learn inter- and intra-channel information, and leverage a
pre-trained large language model to amplify the intense fluctuations in
anomalies. Extensive experiments demonstrate that TSINR achieves superior
overall performance on both univariate and multivariate time series anomaly
detection benchmarks compared to other state-of-the-art reconstruction-based
methods. Our codes are available.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11641v2
Teapot: Efficiently Uncovering Spectre Gadgets in COTS Binaries,"Fangzheng Lin, Zhongfa Wang, Hiroshi Sasaki",2024-11-18T14:56:56Z,"Speculative execution is crucial in enhancing modern processor performance
but can introduce Spectre-type vulnerabilities that may leak sensitive
information. Detecting Spectre gadgets from programs has been a research focus
to enhance the analysis and understanding of Spectre attacks. However, one of
the problems of existing approaches is that they rely on the presence of source
code (or are impractical in terms of run-time performance and gadget detection
ability).
  This paper presents Teapot, the first Spectre gadget scanner that works on
COTS binaries with comparable performance to compiler-based alternatives. As
its core principle, we introduce Speculation Shadows, a novel approach that
separates the binary code for normal execution and speculation simulation in
order to improve run-time efficiency.
  Teapot is based on static binary rewriting. It instruments the program to
simulate the effects of speculative execution and also adds integrity checks to
detect Spectre gadgets at run time. By leveraging fuzzing, Teapot succeeds in
efficiently detecting Spectre gadgets. Evaluations show that Teapot outperforms
both performance (more than 20x performant) and gadget detection ability than a
previously proposed binary-based approach.","cs.CR, cs.AR",cs.CR,http://arxiv.org/abs/2411.11624v1
"VLN-Game: Vision-Language Equilibrium Search for Zero-Shot Semantic
  Navigation","Bangguo Yu, Yuzhen Liu, Lei Han, Hamidreza Kasaei, Tingguang Li, Ming Cao",2024-11-18T14:30:46Z,"Following human instructions to explore and search for a specified target in
an unfamiliar environment is a crucial skill for mobile service robots. Most of
the previous works on object goal navigation have typically focused on a single
input modality as the target, which may lead to limited consideration of
language descriptions containing detailed attributes and spatial relationships.
To address this limitation, we propose VLN-Game, a novel zero-shot framework
for visual target navigation that can process object names and descriptive
language targets effectively. To be more precise, our approach constructs a 3D
object-centric spatial map by integrating pre-trained visual-language features
with a 3D reconstruction of the physical environment. Then, the framework
identifies the most promising areas to explore in search of potential target
candidates. A game-theoretic vision language model is employed to determine
which target best matches the given language description. Experiments conducted
on the Habitat-Matterport 3D (HM3D) dataset demonstrate that the proposed
framework achieves state-of-the-art performance in both object goal navigation
and language-based navigation tasks. Moreover, we show that VLN-Game can be
easily deployed on real-world robots. The success of VLN-Game highlights the
promising potential of using game-theoretic methods with compact
vision-language models to advance decision-making capabilities in robotic
systems. The supplementary video and code can be accessed via the following
link: https://sites.google.com/view/vln-game.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11609v1
Feature Selection for Network Intrusion Detection,"Charles Westphal, Stephen Hailes, Mirco Musolesi",2024-11-18T14:25:55Z,"Network Intrusion Detection (NID) remains a key area of research within the
information security community, while also being relevant to Machine Learning
(ML) practitioners. The latter generally aim to detect attacks using network
features, which have been extracted from raw network data typically using
dimensionality reduction methods, such as principal component analysis (PCA).
However, PCA is not able to assess the relevance of features for the task at
hand. Consequently, the features available are of varying quality, with some
being entirely non-informative. From this, two major drawbacks arise. Firstly,
trained and deployed models have to process large amounts of unnecessary data,
therefore draining potentially costly resources. Secondly, the noise caused by
the presence of irrelevant features can, in some cases, impede a model's
ability to detect an attack. In order to deal with these challenges, we present
Feature Selection for Network Intrusion Detection (FSNID) a novel
information-theoretic method that facilitates the exclusion of non-informative
features when detecting network intrusions. The proposed method is based on
function approximation using a neural network, which enables a version of our
approach that incorporates a recurrent layer. Consequently, this version
uniquely enables the integration of temporal dependencies. Through an extensive
set of experiments, we demonstrate that the proposed method selects a
significantly reduced feature set, while maintaining NID performance. Code will
be made available upon publication.","cs.LG, cs.CR",cs.LG,http://arxiv.org/abs/2411.11603v1
"Simple But Not Secure: An Empirical Security Analysis of Two-factor
  Authentication Systems","Zhi Wang, Xin Yang, Du Chen, Han Gao, Meiqi Tian, Yan Jia, Wanpeng Li",2024-11-18T13:08:56Z,"To protect users from data breaches and phishing attacks, service providers
typically implement two-factor authentication (2FA) to add an extra layer of
security against suspicious login attempts. However, since 2FA can sometimes
hinder user experience by introducing additional steps, many websites aim to
reduce inconvenience by minimizing the frequency of 2FA prompts. One approach
to achieve this is by storing the user's ``Remember the Device'' preference in
a cookie. As a result, users are only prompted for 2FA when this cookie expires
or if they log in from a new device.
  To understand and improve the security of 2FA systems in real-world settings,
we propose SE2FA, a vulnerability evaluation framework designed to detect
vulnerabilities in 2FA systems. This framework enables us to analyze the
security of 407 2FA systems across popular websites from the Tranco Top 10,000
list. Our analysis and evaluation found three zero-day vulnerabilities on three
service providers that could allow an attacker to access a victim's account
without possessing the victim's second authentication factor, thereby bypassing
2FA protections entirely. A further investigation found that these
vulnerabilities stem from design choices aimed at simplifying 2FA for users but
that unintentionally reduce its security effectiveness. We have disclosed these
findings to the affected websites and assisted them in mitigating the risks.
Based on the insights from this research, we provide practical recommendations
for countermeasures to strengthen 2FA security and address these newly
identified threats.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11551v1
The Complexity Landscape of Dynamic Distributed Subgraph Finding,"Yi-Jun Chang, Lyuting Chen, Yanyu Chen, Gopinath Mishra, Mingyang Yang",2024-11-18T13:02:16Z,"Bonne and Censor-Hillel (ICALP 2019) initiated the study of distributed
subgraph finding in dynamic networks of limited bandwidth. For the case where
the target subgraph is a clique, they determined the tight bandwidth complexity
bounds in nearly all settings. However, several open questions remain, and very
little is known about finding subgraphs beyond cliques. In this work, we
consider these questions and explore subgraphs beyond cliques.
  For finding cliques, we establish an $\Omega(\log \log n)$ bandwidth lower
bound for one-round membership-detection under edge insertions only and an
$\Omega(\log \log \log n)$ bandwidth lower bound for one-round detection under
both edge insertions and node insertions. Moreover, we demonstrate new
algorithms to show that our lower bounds are tight in bounded-degree networks
when the target subgraph is a triangle. Prior to our work, no lower bounds were
known for these problems.
  For finding subgraphs beyond cliques, we present a complete characterization
of the bandwidth complexity of the membership-listing problem for every target
subgraph, every number of rounds, and every type of topological change: node
insertions, node deletions, edge insertions, and edge deletions. We also show
partial characterizations for one-round membership-detection and listing.",cs.DS,cs.DS,http://arxiv.org/abs/2411.11544v1
"Hierarchical-Graph-Structured Edge Partition Models for Learning
  Evolving Community Structure","Xincan Yu, Sikun Yang",2024-11-18T12:48:15Z,"We propose a novel dynamic network model to capture evolving latent
communities within temporal networks. To achieve this, we decompose each
observed dynamic edge between vertices using a Poisson-gamma edge partition
model, assigning each vertex to one or more latent communities through
\emph{nonnegative} vertex-community memberships. Specifically, hierarchical
transition kernels are employed to model the interactions between these latent
communities in the observed temporal network. A hierarchical graph prior is
placed on the transition structure of the latent communities, allowing us to
model how they evolve and interact over time. Consequently, our dynamic network
enables the inferred community structure to merge, split, and interact with one
another, providing a comprehensive understanding of complex network dynamics.
Experiments on various real-world network datasets demonstrate that the
proposed model not only effectively uncovers interpretable latent structures
but also surpasses other state-of-the art dynamic network models in the tasks
of link prediction and community detection.","cs.SI, cs.LG",cs.SI,http://arxiv.org/abs/2411.11536v1
"A Code Knowledge Graph-Enhanced System for LLM-Based Fuzz Driver
  Generation","Hanxiang Xu, Wei Ma, Ting Zhou, Yanjie Zhao, Kai Chen, Qiang Hu, Yang Liu, Haoyu Wang",2024-11-18T12:41:16Z,"The rapid development of large language models (LLMs) with advanced
programming capabilities has paved the way for innovative approaches in
software testing. Fuzz testing, a cornerstone for improving software
reliability and detecting vulnerabilities, often relies on manually written
fuzz drivers, limiting scalability and efficiency. To address this challenge,
we propose CodeGraphGPT, a novel system that integrates code knowledge graphs
with an LLM-powered intelligent agent to automate the fuzz driver generation
process. By framing fuzz driver creation as a code generation task,
CodeGraphGPT leverages program analysis to construct a knowledge graph of code
repositories, where nodes represent code entities, such as functions or files,
and edges capture their relationships. This enables the system to generate
tailored fuzz drivers and input seeds, resolve compilation errors, and analyze
crash reports, all while adapting to specific API usage scenarios.
Additionally, querying the knowledge graph helps identify precise testing
targets and contextualize the purpose of each fuzz driver within the fuzzing
loop. We evaluated CodeGraphGPT on eight open-source software projects,
achieving an average improvement of 8.73\% in code coverage compared to
state-of-the-art methods. Moreover, it reduced the manual workload in crash
case analysis by 84.4\% and identified 11 real-world bugs, including nine
previously unreported ones. This work highlights how integrating LLMs with code
knowledge graphs enhances fuzz driver generation, offering an efficient
solution for vulnerability detection and software quality improvement.","cs.SE, cs.CR",cs.SE,http://arxiv.org/abs/2411.11532v1
"Reliable Poisoned Sample Detection against Backdoor Attacks Enhanced by
  Sharpness Aware Minimization","Mingda Zhang, Mingli Zhu, Zihao Zhu, Baoyuan Wu",2024-11-18T12:35:08Z,"Backdoor attack has been considered as a serious security threat to deep
neural networks (DNNs). Poisoned sample detection (PSD) that aims at filtering
out poisoned samples from an untrustworthy training dataset has shown very
promising performance for defending against data poisoning based backdoor
attacks. However, we observe that the detection performance of many advanced
methods is likely to be unstable when facing weak backdoor attacks, such as low
poisoning ratio or weak trigger strength. To further verify this observation,
we make a statistical investigation among various backdoor attacks and poisoned
sample detections, showing a positive correlation between backdoor effect and
detection performance. It inspires us to strengthen the backdoor effect to
enhance detection performance. Since we cannot achieve that goal via directly
manipulating poisoning ratio or trigger strength, we propose to train one model
using the Sharpness-Aware Minimization (SAM) algorithm, rather than the vanilla
training algorithm. We also provide both empirical and theoretical analysis
about how SAM training strengthens the backdoor effect. Then, this SAM trained
model can be seamlessly integrated with any off-the-shelf PSD method that
extracts discriminative features from the trained model for detection, called
SAM-enhanced PSD. Extensive experiments on several benchmark datasets show the
reliable detection performance of the proposed method against both weak and
strong backdoor attacks, with significant improvements against various attacks
($+34.38\%$ TPR on average), over the conventional PSD methods (i.e., without
SAM enhancement). Overall, this work provides new insights about PSD and
proposes a novel approach that can complement existing detection methods, which
may inspire more in-depth explorations in this field.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11525v1
"Learning a Neural Association Network for Self-supervised Multi-Object
  Tracking","Shuai Li, Michael Burke, Subramanian Ramamoorthy, Juergen Gall",2024-11-18T12:22:29Z,"This paper introduces a novel framework to learn data association for
multi-object tracking in a self-supervised manner. Fully-supervised learning
methods are known to achieve excellent tracking performances, but acquiring
identity-level annotations is tedious and time-consuming. Motivated by the fact
that in real-world scenarios object motion can be usually represented by a
Markov process, we present a novel expectation maximization (EM) algorithm that
trains a neural network to associate detections for tracking, without requiring
prior knowledge of their temporal correspondences. At the core of our method
lies a neural Kalman filter, with an observation model conditioned on
associations of detections parameterized by a neural network. Given a batch of
frames as input, data associations between detections from adjacent frames are
predicted by a neural network followed by a Sinkhorn normalization that
determines the assignment probabilities of detections to states. Kalman
smoothing is then used to obtain the marginal probability of observations given
the inferred states, producing a training objective to maximize this marginal
probability using gradient descent. The proposed framework is fully
differentiable, allowing the underlying neural model to be trained end-to-end.
We evaluate our approach on the challenging MOT17 and MOT20 datasets and
achieve state-of-the-art results in comparison to self-supervised trackers
using public detections. We furthermore demonstrate the capability of the
learned model to generalize across datasets.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11514v1
"LSRAM: A Lightweight Autoscaling and SLO Resource Allocation Framework
  for Microservices Based on Gradient Descent","Kan Hu, Minxian Xu, Kejiang Ye, Chengzhong Xu",2024-11-18T11:55:23Z,"Microservices architecture has become the dominant architecture in cloud
computing paradigm with its advantages of facilitating development, deployment,
modularity and scalability. The workflow of microservices architecture is
transparent to the users, who are concerned with the quality of service (QoS).
Taking Service Level Objective (SLO) as an important indicator of system
resource scaling can effectively ensure user's QoS, but how to quickly allocate
end-to-end SLOs to each microservice in a complete service so that it can
obtain the optimal SLO resource allocation scheme is still a challenging
problem. Existing microservice autoscaling frameworks based on SLO resources
often have heavy and complex models that demand substantial time and
computational resources to get a suitable resource allocation scheme. Moreover,
when the system environment or microservice application changes, these methods
require significant time and resources for model retraining. In this paper, we
propose LSRAM, a lightweight SLO resource allocation management framework based
on the gradient descent method to overcome the limitation of existing methods
in terms of heavy model, time-consuming, poor scalability, and difficulty in
retraining. LSRAM has two stages: at stage one, the lightweight SLO resource
allocation model from LSRAM can quickly compute the appropriate SLO resources
for each microservice; at stage two, LSRAM's SLO resource update model enables
the entire framework to quickly adapt to changes in the cluster environment
(e.g. load and applications). Additionally, LSRAM can effectively handle bursty
traffic and highly fluctuating load application scenarios. Compared to
state-of-the-art SLO allocation frameworks, LSRAM not only guarantees users'
QoS but also reduces resource usage by 17%.",cs.DC,cs.DC,http://arxiv.org/abs/2411.11493v1
"Exploring Emerging Trends and Research Opportunities in Visual Place
  Recognition","Antonios Gasteratos, Konstantinos A. Tsintotas, Tobias Fischer, Yiannis Aloimonos, Michael Milford",2024-11-18T11:36:17Z,"Visual-based recognition, e.g., image classification, object detection, etc.,
is a long-standing challenge in computer vision and robotics communities.
Concerning the roboticists, since the knowledge of the environment is a
prerequisite for complex navigation tasks, visual place recognition is vital
for most localization implementations or re-localization and loop closure
detection pipelines within simultaneous localization and mapping (SLAM). More
specifically, it corresponds to the system's ability to identify and match a
previously visited location using computer vision tools. Towards developing
novel techniques with enhanced accuracy and robustness, while motivated by the
success presented in natural language processing methods, researchers have
recently turned their attention to vision-language models, which integrate
visual and textual data.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.11481v1
"Quantifying Preferences of Vision-Language Models via Value
  Decomposition in Social Media Contexts","Jingxuan Li, Yuning Yang, Shengqi Yang, Yizhou Zhao, Ying Nian Wu",2024-11-18T11:31:10Z,"The rapid advancement of Vision-Language Models (VLMs) has expanded
multimodal applications, yet evaluations often focus on basic tasks like object
recognition, overlooking abstract aspects such as personalities and values. To
address this gap, we introduce Value-Spectrum, a visual question-answering
benchmark aimed at assessing VLMs based on Schwartz's value dimensions, which
capture core values guiding people's beliefs and actions across cultures. We
constructed a vectorized database of over 50,000 short videos sourced from
TikTok, YouTube Shorts, and Instagram Reels, covering multiple months and a
wide array of topics such as family, health, hobbies, society, and technology.
We also developed a VLM agent pipeline to automate video browsing and analysis.
Benchmarking representative VLMs on Value-Spectrum reveals significant
differences in their responses to value-oriented content, with most models
exhibiting a preference for hedonistic topics. Beyond identifying natural
preferences, we explored the ability of VLM agents to adopt specific personas
when explicitly prompted, revealing insights into the models' adaptability in
role-playing scenarios. These findings highlight the potential of
Value-Spectrum as a comprehensive evaluation set for tracking VLM advancements
in value-based tasks and for developing more sophisticated role-playing AI
agents.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11479v1
SL-YOLO: A Stronger and Lighter Drone Target Detection Model,"Defan Chen, Luchan Zhang",2024-11-18T11:26:11Z,"Detecting small objects in complex scenes, such as those captured by drones,
is a daunting challenge due to the difficulty in capturing the complex features
of small targets. While the YOLO family has achieved great success in large
target detection, its performance is less than satisfactory when faced with
small targets. Because of this, this paper proposes a revolutionary model
SL-YOLO (Stronger and Lighter YOLO) that aims to break the bottleneck of small
target detection. We propose the Hierarchical Extended Path Aggregation Network
(HEPAN), a pioneering cross-scale feature fusion method that can ensure
unparalleled detection accuracy even in the most challenging environments. At
the same time, without sacrificing detection capabilities, we design the C2fDCB
lightweight module and add the SCDown downsampling module to greatly reduce the
model's parameters and computational complexity. Our experimental results on
the VisDrone2019 dataset reveal a significant improvement in performance, with
mAP@0.5 jumping from 43.0% to 46.9% and mAP@0.5:0.95 increasing from 26.0% to
28.9%. At the same time, the model parameters are reduced from 11.1M to 9.6M,
and the FPS can reach 132, making it an ideal solution for real-time small
object detection in resource-constrained environments.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11477v1
"MVLight: Relightable Text-to-3D Generation via Light-conditioned
  Multi-View Diffusion","Dongseok Shim, Yichun Shi, Kejie Li, H. Jin Kim, Peng Wang",2024-11-18T11:22:04Z,"Recent advancements in text-to-3D generation, building on the success of
high-performance text-to-image generative models, have made it possible to
create imaginative and richly textured 3D objects from textual descriptions.
However, a key challenge remains in effectively decoupling light-independent
and lighting-dependent components to enhance the quality of generated 3D models
and their relighting performance. In this paper, we present MVLight, a novel
light-conditioned multi-view diffusion model that explicitly integrates
lighting conditions directly into the generation process. This enables the
model to synthesize high-quality images that faithfully reflect the specified
lighting environment across multiple camera views. By leveraging this
capability to Score Distillation Sampling (SDS), we can effectively synthesize
3D models with improved geometric precision and relighting capabilities. We
validate the effectiveness of MVLight through extensive experiments and a user
study.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11475v1
"$ν$-LPA: Fast GPU-based Label Propagation Algorithm (LPA) for
  Community Detection",Subhajit Sahu,2024-11-18T11:09:14Z,"Community detection is the problem of identifying natural divisions in
networks. Efficient parallel algorithms for identifying such divisions are
critical in a number of applications. This report presents an optimized
implementation of the Label Propagation Algorithm (LPA) for community
detection, featuring an asynchronous LPA with a Pick-Less (PL) method every 4
iterations to handle community swaps, ideal for SIMT hardware like GPUs. It
also introduces a novel per-vertex hashtable with hybrid quadratic-double
probing for collision resolution. On an NVIDIA A100 GPU, our implementation,
$\nu$-LPA, outperforms FLPA, NetworKit LPA, and GVE-LPA by 364x, 62x, and 2.6x,
respectively, on a server with dual 16-core Intel Xeon Gold 6226R processors -
processing 3.0B edges/s on a 2.2B edge graph - and achieves 4.7% higher
modularity than FLPA, but 6.1% and 2.2% lower than NetworKit LPA and GVE-LPA.","cs.DC, cs.SI, G.2.2; I.5.3",cs.DC,http://arxiv.org/abs/2411.11468v1
Relevance-guided Audio Visual Fusion for Video Saliency Prediction,"Li Yu, Xuanzhe Sun, Pan Gao, Moncef Gabbouj",2024-11-18T10:42:27Z,"Audio data, often synchronized with video frames, plays a crucial role in
guiding the audience's visual attention. Incorporating audio information into
video saliency prediction tasks can enhance the prediction of human visual
behavior. However, existing audio-visual saliency prediction methods often
directly fuse audio and visual features, which ignore the possibility of
inconsistency between the two modalities, such as when the audio serves as
background music. To address this issue, we propose a novel relevance-guided
audio-visual saliency prediction network dubbed AVRSP. Specifically, the
Relevance-guided Audio-Visual feature Fusion module (RAVF) dynamically adjusts
the retention of audio features based on the semantic relevance between audio
and visual elements, thereby refining the integration process with visual
features. Furthermore, the Multi-scale feature Synergy (MS) module integrates
visual features from different encoding stages, enhancing the network's ability
to represent objects at various scales. The Multi-scale Regulator Gate (MRG)
could transfer crucial fusion information to visual features, thus optimizing
the utilization of multi-scale visual features. Extensive experiments on six
audio-visual eye movement datasets have demonstrated that our AVRSP network
achieves competitive performance in audio-visual saliency prediction.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11454v1
CLUE-MARK: Watermarking Diffusion Models using CLWE,"Kareem Shehata, Aashish Kolluri, Prateek Saxena",2024-11-18T10:03:01Z,"As AI-generated images become widespread, reliable watermarking is essential
for content verification, copyright enforcement, and combating disinformation.
Existing techniques rely on heuristic approaches and lack formal guarantees of
undetectability, making them vulnerable to steganographic attacks that can
expose or erase the watermark. Additionally, these techniques often degrade
output quality by introducing perceptible changes, which is not only
undesirable but an important barrier to adoption in practice.
  In this work, we introduce CLUE-Mark, the first provably undetectable
watermarking scheme for diffusion models. CLUE-Mark requires no changes to the
model being watermarked, is computationally efficient, and because it is
provably undetectable is guaranteed to have no impact on model output quality.
Our approach leverages the Continuous Learning With Errors (CLWE) problem -- a
cryptographically hard lattice problem -- to embed watermarks in the latent
noise vectors used by diffusion models. By proving undetectability via
reduction to a cryptographically hard problem we ensure not only that the
watermark is imperceptible to human observers or adhoc heuristics, but to
\emph{any} efficient detector that does not have the secret key. CLUE-Mark
allows multiple keys to be embedded, enabling traceability of images to
specific users without altering model parameters. Empirical evaluations on
state-of-the-art diffusion models confirm that CLUE-Mark achieves high
recoverability, preserves image quality, and is robust to minor perturbations
such JPEG compression and brightness adjustments. Uniquely, CLUE-Mark cannot be
detected nor removed by recent steganographic attacks.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11434v1
"Detecting Multi-Parameter Constraint Inconsistencies in Python Data
  Science Libraries","Xiufeng Xu, Fuman Xie, Chenguang Zhu, Guangdong Bai, Sarfraz Khurshid, Yi Li",2024-11-18T09:30:14Z,"Modern AI- and Data-intensive software systems rely heavily on data science
and machine learning libraries that provide essential algorithmic
implementations and computational frameworks. These libraries expose complex
APIs whose correct usage has to follow constraints among multiple
interdependent parameters. Developers using these APIs are expected to learn
about the constraints through the provided documentations and any discrepancy
may lead to unexpected behaviors. However, maintaining correct and consistent
multi-parameter constraints in API documentations remains a significant
challenge for API compatibility and reliability. To address this challenge, we
propose MPDetector, for detecting inconsistencies between code and
documentation, specifically focusing on multi-parameter constraints. MPDetector
identifies these constraints at the code level by exploring execution paths
through symbolic execution and further extracts corresponding constraints from
documentation using large language models (LLMs). We propose a customized fuzzy
constraint logic to reconcile the unpredictability of LLM outputs and detects
logical inconsistencies between the code and documentation constraints. We
collected and constructed two datasets from four popular data science libraries
and evaluated MPDetector on them. The results demonstrate that MPDetector can
effectively detect inconsistency issues with the precision of 92.8%. We further
reported 14 detected inconsistency issues to the library developers, who have
confirmed 11 issues at the time of writing.",cs.SE,cs.SE,http://arxiv.org/abs/2411.11410v2
"IKEA Manuals at Work: 4D Grounding of Assembly Instructions on Internet
  Videos","Yunong Liu, Cristobal Eyzaguirre, Manling Li, Shubh Khanna, Juan Carlos Niebles, Vineeth Ravi, Saumitra Mishra, Weiyu Liu, Jiajun Wu",2024-11-18T09:30:05Z,"Shape assembly is a ubiquitous task in daily life, integral for constructing
complex 3D structures like IKEA furniture. While significant progress has been
made in developing autonomous agents for shape assembly, existing datasets have
not yet tackled the 4D grounding of assembly instructions in videos, essential
for a holistic understanding of assembly in 3D space over time. We introduce
IKEA Video Manuals, a dataset that features 3D models of furniture parts,
instructional manuals, assembly videos from the Internet, and most importantly,
annotations of dense spatio-temporal alignments between these data modalities.
To demonstrate the utility of IKEA Video Manuals, we present five applications
essential for shape assembly: assembly plan generation, part-conditioned
segmentation, part-conditioned pose estimation, video object segmentation, and
furniture assembly based on instructional video manuals. For each application,
we provide evaluation metrics and baseline methods. Through experiments on our
annotated data, we highlight many challenges in grounding assembly instructions
in videos to improve shape assembly, including handling occlusions, varying
viewpoints, and extended assembly sequences.","cs.CV, cs.AI, cs.LG, cs.RO",cs.CV,http://arxiv.org/abs/2411.11409v1
"Stacking Brick by Brick: Aligned Feature Isolation for Incremental Face
  Forgery Detection","Jikang Cheng, Zhiyuan Yan, Ying Zhang, Li Hao, Jiaxin Ai, Qin Zou, Chen Li, Zhongyuan Wang",2024-11-18T09:18:36Z,"The rapid advancement of face forgery techniques has introduced a growing
variety of forgeries. Incremental Face Forgery Detection (IFFD), involving
gradually adding new forgery data to fine-tune the previously trained model,
has been introduced as a promising strategy to deal with evolving forgery
methods. However, a naively trained IFFD model is prone to catastrophic
forgetting when new forgeries are integrated, as treating all forgeries as a
single ''Fake"" class in the Real/Fake classification can cause different
forgery types overriding one another, thereby resulting in the forgetting of
unique characteristics from earlier tasks and limiting the model's
effectiveness in learning forgery specificity and generality. In this paper, we
propose to stack the latent feature distributions of previous and new tasks
brick by brick, $\textit{i.e.}$, achieving $\textbf{aligned feature
isolation}$. In this manner, we aim to preserve learned forgery information and
accumulate new knowledge by minimizing distribution overriding, thereby
mitigating catastrophic forgetting. To achieve this, we first introduce Sparse
Uniform Replay (SUR) to obtain the representative subsets that could be treated
as the uniformly sparse versions of the previous global distributions. We then
propose a Latent-space Incremental Detector (LID) that leverages SUR data to
isolate and align distributions. For evaluation, we construct a more advanced
and comprehensive benchmark tailored for IFFD. The leading experimental results
validate the superiority of our method.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11396v2
"Adapting to Cyber Threats: A Phishing Evolution Network (PEN) Framework
  for Phishing Generation and Analyzing Evolution Patterns using Large Language
  Models","Fengchao Chen, Tingmin Wu, Van Nguyen, Shuo Wang, Hongsheng Hu, Alsharif Abuadbba, Carsten Rudolph",2024-11-18T09:03:51Z,"Phishing remains a pervasive cyber threat, as attackers craft deceptive
emails to lure victims into revealing sensitive information. While Artificial
Intelligence (AI), particularly deep learning, has become a key component in
defending against phishing attacks, these approaches face critical limitations.
The scarcity of publicly available, diverse, and updated data, largely due to
privacy concerns, constrains their effectiveness. As phishing tactics evolve
rapidly, models trained on limited, outdated data struggle to detect new,
sophisticated deception strategies, leaving systems vulnerable to an
ever-growing array of attacks. Addressing this gap is essential to
strengthening defenses in an increasingly hostile cyber landscape. To address
this gap, we propose the Phishing Evolution Network (PEN), a framework
leveraging large language models (LLMs) and adversarial training mechanisms to
continuously generate high quality and realistic diverse phishing samples, and
analyze features of LLM-provided phishing to understand evolving phishing
patterns. We evaluate the quality and diversity of phishing samples generated
by PEN and find that it produces over 80% realistic phishing samples,
effectively expanding phishing datasets across seven dominant types. These
PEN-generated samples enhance the performance of current phishing detectors,
leading to a 40% improvement in detection accuracy. Additionally, the use of
PEN significantly boosts model robustness, reducing detectors' sensitivity to
perturbations by up to 60%, thereby decreasing attack success rates under
adversarial conditions. When we analyze the phishing patterns that are used in
LLM-generated phishing, the cognitive complexity and the tone of time
limitation are detected with statistically significant differences compared
with existing phishing.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11389v1
"TL-CLIP: A Power-specific Multimodal Pre-trained Visual Foundation Model
  for Transmission Line Defect Recognition","Ke Zhang, Zhaoye Zheng, Yurong Guo, Jiacun Wang, Jiyuan Yang, Yangjie Xiao",2024-11-18T08:32:51Z,"Transmission line defect recognition models have traditionally used general
pre-trained weights as the initial basis for their training. These models often
suffer weak generalization capability due to the lack of domain knowledge in
the pre-training dataset. To address this issue, we propose a two-stage
transmission-line-oriented contrastive language-image pre-training (TL-CLIP)
framework, which lays a more effective foundation for transmission line defect
recognition. The pre-training process employs a novel power-specific multimodal
algorithm assisted with two power-specific pre-training tasks for better
modeling the power-related semantic knowledge contained in the inspection data.
To fine-tune the pre-trained model, we develop a transfer learning strategy,
namely fine-tuning with pre-training objective (FTP), to alleviate the
overfitting problem caused by limited inspection data. Experimental results
demonstrate that the proposed method significantly improves the performance of
transmission line defect recognition in both classification and detection
tasks, indicating clear advantages over traditional pre-trained models in the
scene of transmission line inspection.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11370v1
Scalable Autoregressive Monocular Depth Estimation,"Jinhong Wang, Jian Liu, Dongqi Tang, Weiqiang Wang, Wentong Li, Danny Chen, J intai Chen, Jian Wu",2024-11-18T08:12:54Z,"This paper proposes a new autoregressive model as an effective and scalable
monocular depth estimator. Our idea is simple: We tackle the monocular depth
estimation (MDE) task with an autoregressive prediction paradigm, based on two
core designs. First, our depth autoregressive model (DAR) treats the depth map
of different resolutions as a set of tokens, and conducts the low-to-high
resolution autoregressive objective with a patch-wise casual mask. Second, our
DAR recursively discretizes the entire depth range into more compact intervals,
and attains the coarse-to-fine granularity autoregressive objective in an
ordinal-regression manner. By coupling these two autoregressive objectives, our
DAR establishes new state-of-the-art (SOTA) on KITTI and NYU Depth v2 by clear
margins. Further, our scalable approach allows us to scale the model up to 2.0B
and achieve the best RMSE of 1.799 on the KITTI dataset (5% improvement)
compared to 1.896 by the current SOTA (Depth Anything). DAR further showcases
zero-shot generalization ability on unseen datasets. These results suggest that
DAR yields superior performance with an autoregressive prediction paradigm,
providing a promising approach to equip modern autoregressive large models
(e.g., GPT-4o) with depth estimation capabilities.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11361v1
"CCExpert: Advancing MLLM Capability in Remote Sensing Change Captioning
  with Difference-Aware Integration and a Foundational Dataset","Zhiming Wang, Mingze Wang, Sheng Xu, Yanjing Li, Baochang Zhang",2024-11-18T08:10:49Z,"Remote Sensing Image Change Captioning (RSICC) aims to generate natural
language descriptions of surface changes between multi-temporal remote sensing
images, detailing the categories, locations, and dynamics of changed objects
(e.g., additions or disappearances). Many current methods attempt to leverage
the long-sequence understanding and reasoning capabilities of multimodal large
language models (MLLMs) for this task. However, without comprehensive data
support, these approaches often alter the essential feature transmission
pathways of MLLMs, disrupting the intrinsic knowledge within the models and
limiting their potential in RSICC. In this paper, we propose a novel model,
CCExpert, based on a new, advanced multimodal large model framework. Firstly,
we design a difference-aware integration module to capture multi-scale
differences between bi-temporal images and incorporate them into the original
image context, thereby enhancing the signal-to-noise ratio of differential
features. Secondly, we constructed a high-quality, diversified dataset called
CC-Foundation, containing 200,000 image pairs and 1.2 million captions, to
provide substantial data support for continue pretraining in this domain.
Lastly, we employed a three-stage progressive training process to ensure the
deep integration of the difference-aware integration module with the pretrained
MLLM. CCExpert achieved a notable performance of $S^*_m=81.80$ on the LEVIR-CC
benchmark, significantly surpassing previous state-of-the-art methods. The code
and part of the dataset will soon be open-sourced at
https://github.com/Meize0729/CCExpert.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11360v1
Text-guided Zero-Shot Object Localization,"Jingjing Wang, Xinglin Piao, Zongzhi Gao, Bo Li, Yong Zhang, Baocai Yin",2024-11-18T08:03:11Z,"Object localization is a hot issue in computer vision area, which aims to
identify and determine the precise location of specific objects from image or
video. Most existing object localization methods heavily rely on extensive
labeled data, which are costly to annotate and constrain their applicability.
Therefore, we propose a new Zero-Shot Object Localization (ZSOL) framework for
addressing the aforementioned challenges. In the proposed framework, we
introduce the Contrastive Language Image Pre-training (CLIP) module which could
integrate visual and linguistic information effectively. Furthermore, we design
a Text Self-Similarity Matching (TSSM) module, which could improve the
localization accuracy by enhancing the representation of text features
extracted by CLIP module. Hence, the proposed framework can be guided by prompt
words to identify and locate specific objects in an image in the absence of
labeled samples. The results of extensive experiments demonstrate that the
proposed method could improve the localization performance significantly and
establishes an effective benchmark for further research.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11357v1
"Leveraging MLLM Embeddings and Attribute Smoothing for Compositional
  Zero-Shot Learning","Xudong Yan, Songhe Feng, Yang Zhang, Jian Yang, Yueguan Lin, Haojun Fei",2024-11-18T07:55:54Z,"Compositional zero-shot learning (CZSL) aims to recognize novel compositions
of attributes and objects learned from seen compositions. Previous works
disentangle attribute and object by extracting shared and exclusive parts
between image pairs sharing the same attribute (object), as well as aligning
them with pretrained word embeddings to improve unseen attribute-object
recognition. Despite the significant achievements of existing efforts, they are
hampered by three limitations: (1) the efficacy of disentanglement is
compromised due to the influence of the background and the intricate
entanglement of attribute with object in the same parts. (2) existing word
embeddings fail to capture complex multimodal semantic information. (3)
overconfidence exhibited by existing models in seen compositions hinders their
generalization to novel compositions. Being aware of these, we propose a novel
framework named Multimodal Large Language Model (MLLM) embeddings and attribute
smoothing guided disentanglement (TRIDENT) for CZSL. First, we leverage feature
adaptive aggregation modules to mitigate the impact of background, and utilize
learnable condition masks to capture multigranularity features for
disentanglement. Then, the last hidden states of MLLM are employed as word
embeddings for their superior representation capabilities. Moreover, we propose
attribute smoothing with auxiliary attributes generated by Large Language Model
(LLM) for seen compositions, addressing the issue of overconfidence by
encouraging the model to learn more attributes in one given composition.
Extensive experiments demonstrate that TRIDENT achieves state-of-the-art
performance on three benchmarks.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.12584v1
Pricing Filtering in Dantzig-Wolfe Decomposition,"Abdellah Bulaich Mehamdi, Mathieu Lacroix, Sébastien Martin",2024-11-18T07:10:46Z,"Column generation is used alongside Dantzig-Wolfe Decomposition, especially
for linear programs having a decomposable pricing step requiring to solve
numerous independent pricing subproblems. We propose a filtering method to
detect which pricing subproblems may have improving columns, and only those
subproblems are solved during pricing. This filtering is done by providing
light, computable bounds using dual information from previous iterations of the
column generation. The experiments show a significant impact on different
combinatorial optimization problems.",cs.DM,cs.DM,http://arxiv.org/abs/2411.11338v1
"Intelligent Pooling: Proactive Resource Provisioning in Large-scale
  Cloud Service","Deepak Ravikumar, Alex Yeo, Yiwen Zhu, Aditya Lakra, Harsha Nagulapalli, Santhosh Kumar Ravindran, Steve Suh, Niharika Dutta, Andrew Fogarty, Yoonjae Park, Sumeet Khushalani, Arijit Tarafdar, Kunal Parekh, Subru Krishnan",2024-11-18T06:39:42Z,"The proliferation of big data and analytic workloads has driven the need for
cloud compute and cluster-based job processing. With Apache Spark, users can
process terabytes of data at ease with hundreds of parallel executors. At
Microsoft, we aim at providing a fast and succinct interface for users to run
Spark applications, such as through creating simple notebook ""sessions"" by
abstracting the underlying complexity of the cloud. Providing low latency
access to Spark clusters and sessions is a challenging problem due to the large
overheads of cluster creation and session startup. In this paper, we introduce
Intelligent Pooling, a system for proactively provisioning compute resources to
combat the aforementioned overheads. To reduce the COGS (cost-of-goods-sold),
our system (1) predicts usage patterns using an innovative hybrid Machine
Learning (ML) model with low latency and high accuracy; and (2) optimizes the
pool size dynamically to meet customer demand while reducing extraneous COGS.
  The proposed system auto-tunes its hyper-parameters to balance between
performance and operational cost with minimal to no engineering input.
Evaluated using large-scale production data, Intelligent Pooling achieves up to
43% reduction in cluster idle time compared to static pooling when targeting
99% pool hit rate. Currently deployed in production, Intelligent Pooling is on
track to save tens of million dollars in COGS per year as compared to
traditional pre-provisioned pools.",cs.DB,cs.DB,http://arxiv.org/abs/2411.11326v1
"SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking
  with Motion-Aware Memory","Cheng-Yen Yang, Hsiang-Wei Huang, Wenhao Chai, Zhongyu Jiang, Jenq-Neng Hwang",2024-11-18T05:59:03Z,"The Segment Anything Model 2 (SAM 2) has demonstrated strong performance in
object segmentation tasks but faces challenges in visual object tracking,
particularly when managing crowded scenes with fast-moving or self-occluding
objects. Furthermore, the fixed-window memory approach in the original model
does not consider the quality of memories selected to condition the image
features for the next frame, leading to error propagation in videos. This paper
introduces SAMURAI, an enhanced adaptation of SAM 2 specifically designed for
visual object tracking. By incorporating temporal motion cues with the proposed
motion-aware memory selection mechanism, SAMURAI effectively predicts object
motion and refines mask selection, achieving robust, accurate tracking without
the need for retraining or fine-tuning. SAMURAI operates in real-time and
demonstrates strong zero-shot performance across diverse benchmark datasets,
showcasing its ability to generalize without fine-tuning. In evaluations,
SAMURAI achieves significant improvements in success rate and precision over
existing trackers, with a 7.1% AUC gain on LaSOT$_{\text{ext}}$ and a 3.5% AO
gain on GOT-10k. Moreover, it achieves competitive results compared to fully
supervised methods on LaSOT, underscoring its robustness in complex tracking
scenarios and its potential for real-world applications in dynamic
environments. Code and results are available at
https://github.com/yangchris11/samurai.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11922v1
"DeSiRe-GS: 4D Street Gaussians for Static-Dynamic Decomposition and
  Surface Reconstruction for Urban Driving Scenes","Chensheng Peng, Chengwei Zhang, Yixiao Wang, Chenfeng Xu, Yichen Xie, Wenzhao Zheng, Kurt Keutzer, Masayoshi Tomizuka, Wei Zhan",2024-11-18T05:49:16Z,"We present DeSiRe-GS, a self-supervised gaussian splatting representation,
enabling effective static-dynamic decomposition and high-fidelity surface
reconstruction in complex driving scenarios. Our approach employs a two-stage
optimization pipeline of dynamic street Gaussians. In the first stage, we
extract 2D motion masks based on the observation that 3D Gaussian Splatting
inherently can reconstruct only the static regions in dynamic environments.
These extracted 2D motion priors are then mapped into the Gaussian space in a
differentiable manner, leveraging an efficient formulation of dynamic Gaussians
in the second stage. Combined with the introduced geometric regularizations,
our method are able to address the over-fitting issues caused by data sparsity
in autonomous driving, reconstructing physically plausible Gaussians that align
with object surfaces rather than floating in air. Furthermore, we introduce
temporal cross-view consistency to ensure coherence across time and viewpoints,
resulting in high-quality surface reconstruction. Comprehensive experiments
demonstrate the efficiency and effectiveness of DeSiRe-GS, surpassing prior
self-supervised arts and achieving accuracy comparable to methods relying on
external 3D bounding box annotations. Code is available at
\url{https://github.com/chengweialan/DeSiRe-GS}",cs.CV,cs.CV,http://arxiv.org/abs/2411.11921v1
SADDE: Semi-supervised Anomaly Detection with Dependable Explanations,"Yachao Yuan, Yu Huang, Yali Yuan, Jin Wang",2024-11-18T05:39:00Z,"Semi-supervised learning holds a pivotal position in anomaly detection
applications, yet identifying anomaly patterns with a limited number of labeled
samples poses a significant challenge. Furthermore, the absence of
interpretability poses major obstacles to the practical adoption of
semi-supervised frameworks. The majority of existing interpretation techniques
are tailored for supervised/unsupervised frameworks or non-security domains,
falling short in providing dependable interpretations. In this research paper,
we introduce SADDE, a general framework designed to accomplish two primary
objectives: (1) to render the anomaly detection process interpretable and
enhance the credibility of interpretation outcomes, and (2) to assign
high-confidence pseudo labels to unlabeled samples, thereby boosting the
performance of anomaly detection systems when supervised data is scarce. To
achieve the first objective, we devise a cutting-edge interpretation method
that utilizes both global and local interpreters to furnish trustworthy
explanations. For the second objective, we conceptualize a novel two-stage
semi-supervised learning framework tailored for network anomaly detection,
ensuring that the model predictions of both stages align with specific
constraints. We apply SADDE to two illustrative network anomaly detection tasks
and conduct extensive evaluations in comparison with notable prior works. The
experimental findings underscore that SADDE is capable of delivering precise
detection results alongside dependable interpretations for semi-supervised
network anomaly detection systems. The source code for SADDE is accessible at:
https://github.com/M-Code-Space/SADDE.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11293v1
Massively Parallel Maximum Coverage Revisited,"Thai Bui, Hoa T. Vu",2024-11-18T04:33:34Z,"We study the maximum set coverage problem in the massively parallel model. In
this setting, $m$ sets that are subsets of a universe of $n$ elements are
distributed among $m$ machines. In each round, these machines can communicate
with each other, subject to the memory constraint that no machine may use more
than $\tilde{O}(n)$ memory. The objective is to find the $k$ sets whose
coverage is maximized. We consider the regime where $k = \Omega(m)$, $m =
O(n)$, and each machine has $\tilde{O}(n)$ memory. Maximum coverage is a
special case of the submodular maximization problem subject to a cardinality
constraint. This problem can be approximated to within a $1-1/e$ factor using
the greedy algorithm, but this approach is not directly applicable to parallel
and distributed models. When $k = \Omega(m)$, to obtain a $1-1/e-\epsilon$
approximation, previous work either requires $\tilde{O}(mn)$ memory per machine
which is not interesting compared to the trivial algorithm that sends the
entire input to a single machine, or requires $2^{O(1/\epsilon)} n$ memory per
machine which is prohibitively expensive even for a moderately small value
$\epsilon$. Our result is a randomized $(1-1/e-\epsilon)$-approximation
algorithm that uses $O(1/\epsilon^3 \cdot \log m \cdot (\log (1/\epsilon) +
\log m))$ rounds. Our algorithm involves solving a slightly transformed linear
program of the maximum coverage problem using the multiplicative weights update
method, classic techniques in parallel computing such as parallel prefix, and
various combinatorial arguments.","cs.DS, cs.DC",cs.DS,http://arxiv.org/abs/2411.11277v1
"VL-Uncertainty: Detecting Hallucination in Large Vision-Language Model
  via Uncertainty Estimation","Ruiyang Zhang, Hu Zhang, Zhedong Zheng",2024-11-18T04:06:04Z,"Given the higher information load processed by large vision-language models
(LVLMs) compared to single-modal LLMs, detecting LVLM hallucinations requires
more human and time expense, and thus rise a wider safety concerns. In this
paper, we introduce VL-Uncertainty, the first uncertainty-based framework for
detecting hallucinations in LVLMs. Different from most existing methods that
require ground-truth or pseudo annotations, VL-Uncertainty utilizes uncertainty
as an intrinsic metric. We measure uncertainty by analyzing the prediction
variance across semantically equivalent but perturbed prompts, including visual
and textual data. When LVLMs are highly confident, they provide consistent
responses to semantically equivalent queries. However, when uncertain, the
responses of the target LVLM become more random. Considering semantically
similar answers with different wordings, we cluster LVLM responses based on
their semantic content and then calculate the cluster distribution entropy as
the uncertainty measure to detect hallucination. Our extensive experiments on
10 LVLMs across four benchmarks, covering both free-form and multi-choice
tasks, show that VL-Uncertainty significantly outperforms strong baseline
methods in hallucination detection.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11919v1
"I Blame Apple in Part for My False Expectations: An Autoethnographic
  Study of Apple's Lockdown Mode in iOS","Benedikt Mader, Christian Eichenmüller, Gaston Pugliese, Dennis Eckhardt, Zinaida Benenson",2024-11-20T12:08:08Z,"Lockdown Mode was introduced in 2022 as a hardening setting for Apple's
operating systems, designed to strengthen the protection against ``some of the
most sophisticated digital threats''. However, Apple never explained these
threats further. We present the first academic exploration of Lockdown Mode
based on a 3-month autoethnographic study. We obtained a nuanced understanding
of user experience and identified issues that can be extrapolated to larger
user groups. The lack of information from Apple about the underlying threat
model and details on affected features may hinder adequate assessment of
Lockdown Mode, making informed decisions on its use challenging. Besides
encountering undocumented restrictions, we also experienced both too much and
too little visibility of protection during Lockdown Mode use. Finally, we deem
the paternalistic security approach by Apple's Lockdown Mode harmful, because
without detailed knowledge about technical capabilities and boundaries, at-risk
users may be lulled into a false sense of security.","cs.CR, cs.HC",cs.CR,http://arxiv.org/abs/2411.13249v1
"Using ChatGPT-4 for the Identification of Common UX Factors within a
  Pool of Measurement Items from Established UX Questionnaires","Stefan Graser, Stephan Böhm, Martin Schrepp",2024-11-20T08:26:40Z,"Measuring User Experience (UX) with standardized questionnaires is a widely
used method. A questionnaire is based on different scales that represent UX
factors and items. However, the questionnaires have no common ground concerning
naming different factors and the items used to measure them. This study aims to
identify general UX factors based on the formulation of the measurement items.
Items from a set of 40 established UX questionnaires were analyzed by
Generative AI (GenAI) to identify semantically similar items and to cluster
similar topics. We used the LLM ChatGPT-4 for this analysis. Results show that
ChatGPT-4 can classify items into meaningful topics and thus help to create a
deeper understanding of the structure of the UX research field. In addition, we
show that ChatGPT-4 can filter items related to a predefined UX concept out of
a pool of UX items.",cs.HC,cs.HC,http://arxiv.org/abs/2411.13118v1
"Quadratic Programming Optimization for Bio-Inspired Thruster-Assisted
  Bipedal Locomotion on Inclined Slopes","Shreyansh Pitroda, Eric Sihite, Kaushik Venkatesh Krishnamurthy, Chenghao Wang, Adarsh Salagame, Reza Nemovi, Alireza Ramezani, Morteza Gharib",2024-11-20T01:45:32Z,"Our work aims to make significant strides in understanding unexplored
locomotion control paradigms based on the integration of posture manipulation
and thrust vectoring. These techniques are commonly seen in nature, such as
Chukar birds using their wings to run on a nearly vertical wall. In this work,
we show quadratic programming with contact constraints which is then given to
the whole body controller to map on robot states to produce a thruster-assisted
slope walking controller for our state-of-the-art Harpy platform. Harpy is a
bipedal robot capable of legged-aerial locomotion using its legs and thrusters
attached to its main frame. The optimization-based walking controller has been
used for dynamic locomotion such as slope walking, but the addition of
thrusters to perform inclined slope walking has not been extensively explored.
In this work, we derive a thruster-assisted bipedal walking with the quadratic
programming (QP) controller and implement it in simulation to study its
performance.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12968v1
"I Can Tell What I am Doing: Toward Real-World Natural Language Grounding
  of Robot Experiences","Zihan Wang, Brian Liang, Varad Dhat, Zander Brumbaugh, Nick Walker, Ranjay Krishna, Maya Cakmak",2024-11-20T01:27:56Z,"Understanding robot behaviors and experiences through natural language is
crucial for developing intelligent and transparent robotic systems. Recent
advancement in large language models (LLMs) makes it possible to translate
complex, multi-modal robotic experiences into coherent, human-readable
narratives. However, grounding real-world robot experiences into natural
language is challenging due to many reasons, such as multi-modal nature of
data, differing sample rates, and data volume. We introduce RONAR, an LLM-based
system that generates natural language narrations from robot experiences,
aiding in behavior announcement, failure analysis, and human interaction to
recover failure. Evaluated across various scenarios, RONAR outperforms
state-of-the-art methods and improves failure recovery efficiency. Our
contributions include a multi-modal framework for robot experience narration, a
comprehensive real-robot dataset, and empirical evidence of RONAR's
effectiveness in enhancing user experience in system transparency and failure
analysis.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12960v1
Narrative Information Theory,"Lion Schulz, Miguel Patrício, Daan Odijk",2024-11-19T22:51:31Z,"We propose an information-theoretic framework to measure narratives,
providing a formalism to understand pivotal moments, cliffhangers, and plot
twists. This approach offers creatives and AI researchers tools to analyse and
benchmark human- and AI-created stories. We illustrate our method in TV shows,
showing its ability to quantify narrative complexity and emotional dynamics
across genres. We discuss applications in media and in human-in-the-loop
generative AI storytelling.","cs.MM, cs.IT, math.IT",cs.MM,http://arxiv.org/abs/2411.12907v1
"Identifying patterns of proprioception and target matching acuity in
  healthy humans","Jacob Carducci, Jeremy D. Brown",2024-11-19T17:16:47Z,"Traditional approaches to measurement in upper-limb therapy have gaps that
electronic sensing and recording can help fill. We highlight shortcomings in
current kinematic recording devices, and we introduce a wrist sensing device
that performs multimodal sensing during single-axis rotation. Our goal is to
characterize normative kinesthetic perception and real-world performance as a
multimodal sensory ""fingerprint"" that can serve as a reference point for
identifying deficit in persons affected by stroke, and then as a jumping point
for later neuroscientific interrogation. We present an experiment involving
psychophysical measurements of passive stimuli discrimination, matching
adjustment acuity, and ADL performance in 11 neurologically-intact persons. We
found that passive velocity sense and active position sense of healthy
controls, measured by velocity discrimination and position matching
respectively, correlated in rank with each other, but other score comparisons
of acuity or task performance had no statistically significant correlations. We
also found that participants differed in acuity between passive and active
velocity sense, which supports current understanding about muscle spindle
activation being modulated by conscious motor command. The potential for our
null correlation results to reveal dissociable aspects of deficit is discussed,
as well as implications for future neuroscientific study with more kinematic
measures and larger datasets.",cs.RO,cs.RO,http://arxiv.org/abs/2411.12664v1
"Do LLMs Understand Ambiguity in Text? A Case Study in Open-world
  Question Answering","Aryan Keluskar, Amrita Bhattacharjee, Huan Liu",2024-11-19T10:27:26Z,"Ambiguity in natural language poses significant challenges to Large Language
Models (LLMs) used for open-domain question answering. LLMs often struggle with
the inherent uncertainties of human communication, leading to
misinterpretations, miscommunications, hallucinations, and biased responses.
This significantly weakens their ability to be used for tasks like
fact-checking, question answering, feature extraction, and sentiment analysis.
Using open-domain question answering as a test case, we compare off-the-shelf
and few-shot LLM performance, focusing on measuring the impact of explicit
disambiguation strategies. We demonstrate how simple, training-free,
token-level disambiguation methods may be effectively used to improve LLM
performance for ambiguous question answering tasks. We empirically show our
findings and discuss best practices and broader impacts regarding ambiguity in
LLMs.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12395v1
"CUE-M: Contextual Understanding and Enhanced Search with Multimodal
  Large Language Model","Dongyoung Go, Taesun Whang, Chanhee Lee, Hwayeon Kim, Sunghoon Park, Seunghwan Ji, Dongchan Kim, Young-Bum Kim",2024-11-19T07:16:48Z,"The integration of Retrieval-Augmented Generation (RAG) with Multimodal Large
Language Models (MLLMs) has expanded the scope of multimodal query resolution.
However, current systems struggle with intent understanding, information
retrieval, and safety filtering, limiting their effectiveness. This paper
introduces Contextual Understanding and Enhanced Search with MLLM (CUE-M), a
novel multimodal search pipeline that addresses these challenges through a
multi-stage framework comprising image context enrichment, intent refinement,
contextual query generation, external API integration, and relevance-based
filtering. CUE-M incorporates a robust safety framework combining image-based,
text-based, and multimodal classifiers, dynamically adapting to instance- and
category-specific risks. Evaluations on a multimodal Q&A dataset and a public
safety benchmark demonstrate that CUE-M outperforms baselines in accuracy,
knowledge integration, and safety, advancing the capabilities of multimodal
retrieval systems.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12287v1
"Predicting User Intents and Musical Attributes from Music Discovery
  Conversations","Daeyong Kwon, SeungHeon Doh, Juhan Nam",2024-11-19T05:58:22Z,"Intent classification is a text understanding task that identifies user needs
from input text queries. While intent classification has been extensively
studied in various domains, it has not received much attention in the music
domain. In this paper, we investigate intent classification models for music
discovery conversation, focusing on pre-trained language models. Rather than
only predicting functional needs: intent classification, we also include a task
for classifying musical needs: musical attribute classification. Additionally,
we propose a method of concatenating previous chat history with just
single-turn user queries in the input text, allowing the model to understand
the overall conversation context better. Our proposed model significantly
improves the F1 score for both user intent and musical attribute
classification, and surpasses the zero-shot and few-shot performance of the
pretrained Llama 3 model.","cs.CL, cs.LG, cs.SD, eess.AS",cs.CL,http://arxiv.org/abs/2411.12254v2
"ADV2E: Bridging the Gap Between Analogue Circuit and Discrete Frames in
  the Video-to-Events Simulator","Xiao Jiang, Fei Zhou, Jiongzhi Lin",2024-11-19T05:52:51Z,"Event cameras operate fundamentally differently from traditional Active Pixel
Sensor (APS) cameras, offering significant advantages. Recent research has
developed simulators to convert video frames into events, addressing the
shortage of real event datasets. Current simulators primarily focus on the
logical behavior of event cameras. However, the fundamental analogue properties
of pixel circuits are seldom considered in simulator design. The gap between
analogue pixel circuit and discrete video frames causes the degeneration of
synthetic events, particularly in high-contrast scenes. In this paper, we
propose a novel method of generating reliable event data based on a detailed
analysis of the pixel circuitry in event cameras. We incorporate the analogue
properties of event camera pixel circuits into the simulator design: (1)
analogue filtering of signals from light intensity to events, and (2) a cutoff
frequency that is independent of video frame rate. Experimental results on two
relevant tasks, including semantic segmentation and image reconstruction,
validate the reliability of simulated event data, even in high-contrast scenes.
This demonstrates that deep neural networks exhibit strong generalization from
simulated to real event data, confirming that the synthetic events generated by
the proposed method are both realistic and well-suited for effective training.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.12250v1
Characterizing Data Scientists in the Real World,"Paula Pereira, Jácome Cunha, João P. Fernandes",2024-11-19T04:43:15Z,"Data collection is pervasively bound to our digital lifestyle. A recent study
by the IDC reports that the growth of the data created and replicated in 2020
was even higher than in the previous years due to pandemic-related confinements
to an astonishing global amount of 64.2 zettabytes of data. While not all the
produced data is meant to be analyzed, there are numerous companies whose
services/products rely heavily on data analysis. That is to say that mining the
produced data has already revealed great value for businesses in different
sectors. But to be able to fully realize this value, companies need to be able
to hire professionals that are capable of gleaning insights and extracting
value from the available data. We hypothesize that people nowadays conducting
data-science-related tasks in practice may not have adequate training or
formation. So in order to be able to fully support them in being productive in
their duties, e.g. by building appropriate tools that increase their
productivity, we first need to characterize the current generation of data
scientists. To contribute towards this characterization, we conducted a public
survey to fully understand who is doing data science, how they work, what are
the skills they hold and lack, and which tools they use and need.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12225v1
"A Survey of Medical Vision-and-Language Applications and Their
  Techniques","Qi Chen, Ruoshan Zhao, Sinuo Wang, Vu Minh Hieu Phan, Anton van den Hengel, Johan Verjans, Zhibin Liao, Minh-Son To, Yong Xia, Jian Chen, Yutong Xie, Qi Wu",2024-11-19T03:27:05Z,"Medical vision-and-language models (MVLMs) have attracted substantial
interest due to their capability to offer a natural language interface for
interpreting complex medical data. Their applications are versatile and have
the potential to improve diagnostic accuracy and decision-making for individual
patients while also contributing to enhanced public health monitoring, disease
surveillance, and policy-making through more efficient analysis of large data
sets. MVLMS integrate natural language processing with medical images to enable
a more comprehensive and contextual understanding of medical images alongside
their corresponding textual information. Unlike general vision-and-language
models trained on diverse, non-specialized datasets, MVLMs are purpose-built
for the medical domain, automatically extracting and interpreting critical
information from medical images and textual reports to support clinical
decision-making. Popular clinical applications of MVLMs include automated
medical report generation, medical visual question answering, medical
multimodal segmentation, diagnosis and prognosis and medical image-text
retrieval. Here, we provide a comprehensive overview of MVLMs and the various
medical tasks to which they have been applied. We conduct a detailed analysis
of various vision-and-language model architectures, focusing on their distinct
strategies for cross-modal integration/exploitation of medical visual and
textual features. We also examine the datasets used for these tasks and compare
the performance of different models based on standardized evaluation metrics.
Furthermore, we highlight potential challenges and summarize future research
trends and directions. The full collection of papers and codes is available at:
https://github.com/YtongXie/Medical-Vision-and-Language-Tasks-and-Methodologies-A-Survey.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12195v1
"Diffusion-Inspired Cold Start with Sufficient Prior in Computerized
  Adaptive Testing","Haiping Ma, Aoqing Xia, Changqian Wang, Hai Wang, Xingyi Zhang",2024-11-19T02:48:58Z,"Computerized Adaptive Testing (CAT) aims to select the most appropriate
questions based on the examinee's ability and is widely used in online
education. However, existing CAT systems often lack initial understanding of
the examinee's ability, requiring random probing questions. This can lead to
poorly matched questions, extending the test duration and negatively impacting
the examinee's mindset, a phenomenon referred to as the Cold Start with
Insufficient Prior (CSIP) task. This issue occurs because CAT systems do not
effectively utilize the abundant prior information about the examinee available
from other courses on online platforms. These response records, due to the
commonality of cognitive states across different knowledge domains, can provide
valuable prior information for the target domain. However, no prior work has
explored solutions for the CSIP task. In response to this gap, we propose
Diffusion Cognitive States TransfeR Framework (DCSR), a novel domain transfer
framework based on Diffusion Models (DMs) to address the CSIP task.
Specifically, we construct a cognitive state transition bridge between domains,
guided by the common cognitive states of examinees, encouraging the model to
reconstruct the initial ability state in the target domain. To enrich the
expressive power of the generated data, we analyze the causal relationships in
the generation process from a causal perspective. Redundant and extraneous
cognitive states can lead to limited transfer and negative transfer effects.
Our DCSR can seamlessly apply the generated initial ability states in the
target domain to existing question selection algorithms, thus improving the
cold start performance of the CAT system. Extensive experiments conducted on
five real-world datasets demonstrate that DCSR significantly outperforms
existing baseline methods in addressing the CSIP task.","cs.LG, cs.AI, cs.CY",cs.LG,http://arxiv.org/abs/2411.12182v1
"Robust 3D Semantic Occupancy Prediction with Calibration-free Spatial
  Transformation","Zhuangwei Zhuang, Ziyin Wang, Sitao Chen, Lizhao Liu, Hui Luo, Mingkui Tan",2024-11-19T02:40:42Z,"3D semantic occupancy prediction, which seeks to provide accurate and
comprehensive representations of environment scenes, is important to autonomous
driving systems. For autonomous cars equipped with multi-camera and LiDAR, it
is critical to aggregate multi-sensor information into a unified 3D space for
accurate and robust predictions. Recent methods are mainly built on the
2D-to-3D transformation that relies on sensor calibration to project the 2D
image information into the 3D space. These methods, however, suffer from two
major limitations: First, they rely on accurate sensor calibration and are
sensitive to the calibration noise, which limits their application in real
complex environments. Second, the spatial transformation layers are
computationally expensive and limit their running on an autonomous vehicle. In
this work, we attempt to exploit a Robust and Efficient 3D semantic Occupancy
(REO) prediction scheme. To this end, we propose a calibration-free spatial
transformation based on vanilla attention to implicitly model the spatial
correspondence. In this way, we robustly project the 2D features to a
predefined BEV plane without using sensor calibration as input. Then, we
introduce 2D and 3D auxiliary training tasks to enhance the discrimination
power of 2D backbones on spatial, semantic, and texture features. Last, we
propose a query-based prediction scheme to efficiently generate large-scale
fine-grained occupancy predictions. By fusing point clouds that provide
complementary spatial information, our REO surpasses the existing methods by a
large margin on three benchmarks, including OpenOccupancy, Occ3D-nuScenes, and
SemanticKITTI Scene Completion. For instance, our REO achieves 19.8$\times$
speedup compared to Co-Occ, with 1.1 improvements in geometry IoU on
OpenOccupancy. Our code will be available at https://github.com/ICEORY/REO.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12177v1
"SkillTree: Explainable Skill-Based Deep Reinforcement Learning for
  Long-Horizon Control Tasks","Yongyan Wen, Siyuan Li, Rongchang Zuo, Lei Yuan, Hangyu Mao, Peng Liu",2024-11-19T02:35:14Z,"Deep reinforcement learning (DRL) has achieved remarkable success in various
research domains. However, its reliance on neural networks results in a lack of
transparency, which limits its practical applications. To achieve
explainability, decision trees have emerged as a popular and promising
alternative to neural networks. Nonetheless, due to their limited
expressiveness, traditional decision trees struggle with high-dimensional
long-horizon continuous control tasks. In this paper, we proposes SkillTree, a
novel framework that reduces complex continuous action spaces into discrete
skill spaces. Our hierarchical approach integrates a differentiable decision
tree within the high-level policy to generate skill embeddings, which
subsequently guide the low-level policy in executing skills. By making skill
decisions explainable, we achieve skill-level explainability, enhancing the
understanding of the decision-making process in complex tasks. Experimental
results demonstrate that our method achieves performance comparable to
skill-based neural networks in complex robotic arm control domains.
Furthermore, SkillTree offers explanations at the skill level, thereby
increasing the transparency of the decision-making process.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12173v1
"UrbanDiT: A Foundation Model for Open-World Urban Spatio-Temporal
  Learning","Yuan Yuan, Chonghua Han, Jingtao Ding, Depeng Jin, Yong Li",2024-11-19T02:01:07Z,"The urban environment is characterized by complex spatio-temporal dynamics
arising from diverse human activities and interactions. Effectively modeling
these dynamics is essential for understanding and optimizing urban systems In
this work, we introduce UrbanDiT, a foundation model for open-world urban
spatio-temporal learning that successfully scale up diffusion transformers in
this field. UrbanDiT pioneers a unified model that integrates diverse
spatio-temporal data sources and types while learning universal spatio-temporal
patterns across different cities and scenarios. This allows the model to unify
both multi-data and multi-task learning, and effectively support a wide range
of spatio-temporal applications. Its key innovation lies in the elaborated
prompt learning framework, which adaptively generates both data-driven and
task-specific prompts, guiding the model to deliver superior performance across
various urban applications. UrbanDiT offers three primary advantages: 1) It
unifies diverse data types, such as grid-based and graph-based data, into a
sequential format, allowing to capture spatio-temporal dynamics across diverse
scenarios of different cities; 2) With masking strategies and task-specific
prompts, it supports a wide range of tasks, including bi-directional
spatio-temporal prediction, temporal interpolation, spatial extrapolation, and
spatio-temporal imputation; and 3) It generalizes effectively to open-world
scenarios, with its powerful zero-shot capabilities outperforming nearly all
baselines with training data. These features allow UrbanDiT to achieves
state-of-the-art performance in different domains such as transportation
traffic, crowd flows, taxi demand, bike usage, and cellular traffic, across
multiple cities and tasks. UrbanDiT sets up a new benchmark for foundation
models in the urban spatio-temporal domain.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12164v1
"A Combined Encoder and Transformer Approach for Coherent and
  High-Quality Text Generation","Jiajing Chen, Shuo Wang, Zhen Qi, Zhenhong Zhang, Chihang Wang, Hongye Zheng",2024-11-19T01:41:56Z,"This research introduces a novel text generation model that combines BERT's
semantic interpretation strengths with GPT-4's generative capabilities,
establishing a high standard in generating coherent, contextually accurate
language. Through the combined architecture, the model enhances semantic depth
and maintains smooth, human-like text flow, overcoming limitations seen in
prior models. Experimental benchmarks reveal that BERT-GPT-4 surpasses
traditional models, including GPT-3, T5, BART, Transformer-XL, and CTRL, in key
metrics like Perplexity and BLEU, showcasing its superior natural language
generation performance. By fully utilizing contextual information, this hybrid
model generates text that is not only logically coherent but also aligns
closely with human language patterns, providing an advanced solution for text
generation tasks. This research highlights the potential of integrating
semantic understanding with advanced generative models, contributing new
insights for NLP, and setting a foundation for broader applications of
large-scale generative architectures in areas such as automated writing,
question-answer systems, and adaptive conversational agents.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12157v1
"HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning
  with Hard Negatives","Wenxiao Liu, Zihong Yang, Chaozhuo Li, Zijin Hong, Jianfeng Ma, Zhiquan Liu, Litian Zhang, Feiran Huang",2024-11-19T01:26:20Z,"Unsupervised sentence representation learning remains a critical challenge in
modern natural language processing (NLP) research. Recently, contrastive
learning techniques have achieved significant success in addressing this issue
by effectively capturing textual semantics. Many such approaches prioritize the
optimization using negative samples. In fields such as computer vision, hard
negative samples (samples that are close to the decision boundary and thus more
difficult to distinguish) have been shown to enhance representation learning.
However, adapting hard negatives to contrastive sentence learning is complex
due to the intricate syntactic and semantic details of text. To address this
problem, we propose HNCSE, a novel contrastive learning framework that extends
the leading SimCSE approach. The hallmark of HNCSE is its innovative use of
hard negative samples to enhance the learning of both positive and negative
samples, thereby achieving a deeper semantic understanding. Empirical tests on
semantic textual similarity and transfer task datasets validate the superiority
of HNCSE.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12156v1
"Reinforcement Learning with Action Sequence for Data-Efficient Robot
  Learning","Younggyo Seo, Pieter Abbeel",2024-11-19T01:23:52Z,"Training reinforcement learning (RL) agents on robotic tasks typically
requires a large number of training samples. This is because training data
often consists of noisy trajectories, whether from exploration or
human-collected demonstrations, making it difficult to learn value functions
that understand the effect of taking each action. On the other hand, recent
behavior-cloning (BC) approaches have shown that predicting a sequence of
actions enables policies to effectively approximate noisy, multi-modal
distributions of expert demonstrations. Can we use a similar idea for improving
RL on robotic tasks? In this paper, we introduce a novel RL algorithm that
learns a critic network that outputs Q-values over a sequence of actions. By
explicitly training the value functions to learn the consequence of executing a
series of current and future actions, our algorithm allows for learning useful
value functions from noisy trajectories. We study our algorithm across various
setups with sparse and dense rewards, and with or without demonstrations,
spanning mobile bi-manual manipulation, whole-body control, and tabletop
manipulation tasks from BiGym, HumanoidBench, and RLBench. We find that, by
learning the critic network with action sequences, our algorithm outperforms
various RL and BC baselines, in particular on challenging humanoid control
tasks.","cs.LG, cs.AI, cs.RO",cs.LG,http://arxiv.org/abs/2411.12155v1
"A Computational Method for Measuring ""Open Codes"" in Qualitative
  Analysis","John Chen, Alexandros Lotsos, Lexie Zhao, Jessica Hullman, Bruce Sherin, Uri Wilensky, Michael Horn",2024-11-19T00:44:56Z,"Qualitative analysis is critical to understanding human datasets in many
social science disciplines. Open coding is an inductive qualitative process
that identifies and interprets ""open codes"" from datasets. Yet, meeting
methodological expectations (such as ""as exhaustive as possible"") can be
challenging. While many machine learning (ML)/generative AI (GAI) studies have
attempted to support open coding, few have systematically measured or evaluated
GAI outcomes, increasing potential bias risks. Building on Grounded Theory and
Thematic Analysis theories, we present a computational method to measure and
identify potential biases from ""open codes"" systematically. Instead of
operationalizing human expert results as the ""ground truth,"" our method is
built upon a team-based approach between human and machine coders. We
experiment with two HCI datasets to establish this method's reliability by 1)
comparing it with human analysis, and 2) analyzing its output stability. We
present evidence-based suggestions and example workflows for ML/GAI to support
open coding.","cs.CL, cs.AI, cs.HC, cs.LG",cs.CL,http://arxiv.org/abs/2411.12142v1
"Mechanism and Emergence of Stacked Attention Heads in Multi-Layer
  Transformers",Tiberiu Musat,2024-11-18T23:12:13Z,"In this paper, I introduce the retrieval problem, a simple reasoning task
that can be solved only by transformers with a minimum number of layers. The
task has an adjustable difficulty that can further increase the required number
of layers to any arbitrary value. I demonstrate that large language models can
solve the task under different prompting formulations without any fine-tuning.
To understand how transformers solve the retrieval problem, I train several
transformers on a minimal formulation. I find that successful learning occurs
only under the presence of an implicit curriculum. I uncover the learned
mechanisms by studying the attention maps in the trained transformers. I also
study the training process, uncovering that attention heads always emerge in a
specific sequence.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.12118v1
Extended-Use Designs on Very Large Online Platforms,"Yixin Chen, Yue Fu, Zeya Chen, Jenny Radesky, Alexis Hiniker",2024-11-18T21:47:51Z,"In the attention economy, online platforms are incentivized to maximize user
engagement through extended-use designs (EUDs), even when such practices
conflict with users' best interests. We conducted a structured content analysis
of all Very Large Online Platforms (VLOPs) to identify the EUDs these
influential apps and sites use. We conducted this analysis posing as a teenager
to understand the EUDs that young people are exposed to. We find that VLOPs use
four strategies to promote extended use: pressuring, enticing, trapping, and
lulling users. We report on a hierarchical taxonomy organizing the 63 designs
that fall under these categories. Applying this taxonomy to all 17 VLOPs, we
identify 583 instances of EUDs, with social media platforms using twice as many
EUDs as other VLOPs. We present three vignettes illustrating how these designs
reinforce one another in practice. We further contribute a graphical dataset of
videos illustrating these features in the wild.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12083v1
"Interpretation of High-Dimensional Regression Coefficients by Comparison
  with Linearized Compressing Features","Joachim Schaeffer, Jinwook Rhyu, Robin Droop, Rolf Findeisen, Richard Braatz",2024-11-18T20:59:38Z,"Linear regression is often deemed inherently interpretable; however,
challenges arise for high-dimensional data. We focus on further understanding
how linear regression approximates nonlinear responses from high-dimensional
functional data, motivated by predicting cycle life for lithium-ion batteries.
We develop a linearization method to derive feature coefficients, which we
compare with the closest regression coefficients of the path of regression
solutions. We showcase the methods on battery data case studies where a single
nonlinear compressing feature, $g\colon \mathbb{R}^p \to \mathbb{R}$, is used
to construct a synthetic response, $\mathbf{y} \in \mathbb{R}$. This unifying
view of linear regression and compressing features for high-dimensional
functional data helps to understand (1) how regression coefficients are shaped
in the highly regularized domain and how they relate to linearized feature
coefficients and (2) how the shape of regression coefficients changes as a
function of regularization to approximate nonlinear responses by exploiting
local structures.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.12060v1
Vision Language Models Are Few-Shot Audio Spectrogram Classifiers,"Satvik Dixit, Laurie M. Heller, Chris Donahue",2024-11-18T20:56:44Z,"We demonstrate that vision language models (VLMs) are capable of recognizing
the content in audio recordings when given corresponding spectrogram images.
Specifically, we instruct VLMs to perform audio classification tasks in a
few-shot setting by prompting them to classify a spectrogram image given
example spectrogram images of each class. By carefully designing the
spectrogram image representation and selecting good few-shot examples, we show
that GPT-4o can achieve 59.00% cross-validated accuracy on the ESC-10
environmental sound classification dataset. Moreover, we demonstrate that VLMs
currently outperform the only available commercial audio language model with
audio understanding capabilities (Gemini-1.5) on the equivalent audio
classification task (59.00% vs. 49.62%), and even perform slightly better than
human experts on visual spectrogram classification (73.75% vs. 72.50% on first
fold). We envision two potential use cases for these findings: (1) combining
the spectrogram and language understanding capabilities of VLMs for audio
caption augmentation, and (2) posing visual spectrogram classification as a
challenge task for VLMs.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.12058v1
The Generalization Error of Machine Learning Algorithms,"Samir M. Perlaza, Xinying Zou",2024-11-18T20:05:51Z,"In this paper, the method of gaps, a technique for deriving closed-form
expressions in terms of information measures for the generalization error of
machine learning algorithms is introduced. The method relies on two central
observations: $(a)$~The generalization error is an average of the variation of
the expected empirical risk with respect to changes on the probability measure
(used for expectation); and~$(b)$~these variations, also referred to as gaps,
exhibit closed-form expressions in terms of information measures. The
expectation of the empirical risk can be either with respect to a measure on
the models (with a fixed dataset) or with respect to a measure on the datasets
(with a fixed model), which results in two variants of the method of gaps. The
first variant, which focuses on the gaps of the expected empirical risk with
respect to a measure on the models, appears to be the most general, as no
assumptions are made on the distribution of the datasets. The second variant
develops under the assumption that datasets are made of independent and
identically distributed data points. All existing exact expressions for the
generalization error of machine learning algorithms can be obtained with the
proposed method. Also, this method allows obtaining numerous new exact
expressions, which improves the understanding of the generalization error;
establish connections with other areas in statistics, e.g., hypothesis testing;
and potentially, might guide algorithm designs.","cs.LG, cs.IT, math.IT",cs.LG,http://arxiv.org/abs/2411.12030v1
NeuMaDiff: Neural Material Synthesis via Hyperdiffusion,"Chenliang Zhou, Zheyuan Hu, Alejandro Sztrajman, Yancheng Cai, Yaru Liu, Cengiz Oztirel",2024-11-18T19:56:54Z,"High-quality material synthesis is essential for replicating complex surface
properties to create realistic digital scenes. However, existing methods often
suffer from inefficiencies in time and memory, require domain expertise, or
demand extensive training data, with high-dimensional material data further
constraining performance. Additionally, most approaches lack multi-modal
guidance capabilities and standardized evaluation metrics, limiting control and
comparability in synthesis tasks. To address these limitations, we propose
NeuMaDiff, a novel neural material synthesis framework utilizing
hyperdiffusion. Our method employs neural fields as a low-dimensional
representation and incorporates a multi-modal conditional hyperdiffusion model
to learn the distribution over material weights. This enables flexible guidance
through inputs such as material type, text descriptions, or reference images,
providing greater control over synthesis. To support future research, we
contribute two new material datasets and introduce two BRDF distributional
metrics for more rigorous evaluation. We demonstrate the effectiveness of
NeuMaDiff through extensive experiments, including a novel statistics-based
constrained synthesis approach, which enables the generation of materials of
desired categories.",cs.GR,cs.GR,http://arxiv.org/abs/2411.12015v1
Compression of Higher Order Ambisonics with Multichannel RVQGAN,"Toni Hirvonen, Mahmoud Namazi",2024-11-18T19:48:18Z,"A multichannel extension to the RVQGAN neural coding method is proposed, and
realized for data-driven compression of third-order Ambisonics audio. The
input- and output layers of the generator and discriminator models are modified
to accept multiple (16) channels without increasing the model bitrate. We also
propose a loss function for accounting for spatial perception in immersive
reproduction, and transfer learning from single-channel models. Listening test
results with 7.1.4 immersive playback show that the proposed extension is
suitable for coding scene-based, 16-channel Ambisonics content with good
quality at 16 kbit/s.","cs.SD, cs.LG, cs.MM, eess.AS",cs.SD,http://arxiv.org/abs/2411.12008v1
Understanding Chain-of-Thought in LLMs through Information Theory,"Jean-Francois Ton, Muhammad Faaiz Taufiq, Yang Liu",2024-11-18T19:14:36Z,"Large Language Models (LLMs) have shown impressive performance in complex
reasoning tasks through Chain-of-Thought (CoT) reasoning, allowing models to
break down problems into manageable sub-tasks. However, existing CoT evaluation
techniques either require annotated CoT data or fall short in accurately
assessing intermediate reasoning steps, leading to high rates of false
positives. In this paper, we formalize CoT reasoning in LLMs through an
information-theoretic lens. Specifically, our framework quantifies the
`information gain' at each reasoning step, enabling the identification of
failure modes in LLMs without the need for expensive annotated datasets. We
demonstrate the efficacy of our approach through extensive experiments on toy
and GSM-8K data, where it significantly outperforms existing outcome-based
methods by providing more accurate insights into model performance on
individual tasks.","cs.CL, cs.AI, cs.LG",cs.CL,http://arxiv.org/abs/2411.11984v1
Generative World Explorer,"Taiming Lu, Tianmin Shu, Alan Yuille, Daniel Khashabi, Jieneng Chen",2024-11-18T18:59:31Z,"Planning with partial observation is a central challenge in embodied AI. A
majority of prior works have tackled this challenge by developing agents that
physically explore their environment to update their beliefs about the world
state. In contrast, humans can $\textit{imagine}$ unseen parts of the world
through a mental exploration and $\textit{revise}$ their beliefs with imagined
observations. Such updated beliefs can allow them to make more informed
decisions, without necessitating the physical exploration of the world at all
times. To achieve this human-like ability, we introduce the $\textit{Generative
World Explorer (Genex)}$, an egocentric world exploration framework that allows
an agent to mentally explore a large-scale 3D world (e.g., urban scenes) and
acquire imagined observations to update its belief. This updated belief will
then help the agent to make a more informed decision at the current step. To
train $\textit{Genex}$, we create a synthetic urban scene dataset, Genex-DB.
Our experimental results demonstrate that (1) $\textit{Genex}$ can generate
high-quality and consistent observations during long-horizon exploration of a
large virtual physical world and (2) the beliefs updated with the generated
observations can inform an existing decision-making model (e.g., an LLM agent)
to make better plans.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.11844v2
"Exploring the Requirements of Clinicians for Explainable AI Decision
  Support Systems in Intensive Care","Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez",2024-11-18T17:53:07Z,"There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.11774v1
"Mapping out the Space of Human Feedback for Reinforcement Learning: A
  Conceptual Framework","Yannick Metz, David Lindner, Raphaël Baur, Mennatallah El-Assady",2024-11-18T17:40:42Z,"Reinforcement Learning from Human feedback (RLHF) has become a powerful tool
to fine-tune or train agentic machine learning models. Similar to how humans
interact in social contexts, we can use many types of feedback to communicate
our preferences, intentions, and knowledge to an RL agent. However,
applications of human feedback in RL are often limited in scope and disregard
human factors. In this work, we bridge the gap between machine learning and
human-computer interaction efforts by developing a shared understanding of
human feedback in interactive learning scenarios. We first introduce a taxonomy
of feedback types for reward-based learning from human feedback based on nine
key dimensions. Our taxonomy allows for unifying human-centered,
interface-centered, and model-centered aspects. In addition, we identify seven
quality metrics of human feedback influencing both the human ability to express
feedback and the agent's ability to learn from the feedback. Based on the
feedback taxonomy and quality criteria, we derive requirements and design
choices for systems learning from human feedback. We relate these requirements
and design choices to existing work in interactive machine learning. In the
process, we identify gaps in existing work and future research opportunities.
We call for interdisciplinary collaboration to harness the full potential of
reinforcement learning with data-driven co-adaptive modeling and varied
interaction mechanics.","cs.LG, cs.HC",cs.LG,http://arxiv.org/abs/2411.11761v1
"TimeFormer: Capturing Temporal Relationships of Deformable 3D Gaussians
  for Robust Reconstruction","DaDong Jiang, Zhihui Ke, Xiaobo Zhou, Zhi Hou, Xianghui Yang, Wenbo Hu, Tie Qiu, Chunchao Guo",2024-11-18T17:11:11Z,"Dynamic scene reconstruction is a long-term challenge in 3D vision. Recent
methods extend 3D Gaussian Splatting to dynamic scenes via additional
deformation fields and apply explicit constraints like motion flow to guide the
deformation. However, they learn motion changes from individual timestamps
independently, making it challenging to reconstruct complex scenes,
particularly when dealing with violent movement, extreme-shaped geometries, or
reflective surfaces. To address the above issue, we design a plug-and-play
module called TimeFormer to enable existing deformable 3D Gaussians
reconstruction methods with the ability to implicitly model motion patterns
from a learning perspective. Specifically, TimeFormer includes a Cross-Temporal
Transformer Encoder, which adaptively learns the temporal relationships of
deformable 3D Gaussians. Furthermore, we propose a two-stream optimization
strategy that transfers the motion knowledge learned from TimeFormer to the
base stream during the training phase. This allows us to remove TimeFormer
during inference, thereby preserving the original rendering speed. Extensive
experiments in the multi-view and monocular dynamic scenes validate qualitative
and quantitative improvement brought by TimeFormer. Project Page:
https://patrickddj.github.io/TimeFormer/",cs.CV,cs.CV,http://arxiv.org/abs/2411.11941v1
"Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via
  Skill Library and Tactile Representation","Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang",2024-11-18T16:42:07Z,"Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a ""task graph"" and a ""scene graph"" to represent task and scene
semantic information, respectively. We introduce a ""state graph"" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.11714v1
MC-LLaVA: Multi-Concept Personalized Vision-Language Model,"Ruichuan An, Sihan Yang, Ming Lu, Kai Zeng, Yulin Luo, Ying Chen, Jiajun Cao, Hao Liang, Qi She, Shanghang Zhang, Wentao Zhang",2024-11-18T16:33:52Z,"Current vision-language models (VLMs) show exceptional abilities across
diverse tasks including visual question answering. To enhance user experience
in practical applications, recent studies investigate VLM personalization to
understand user-provided concepts. However, existing studies mainly focus on
single-concept personalization, neglecting the existence and interplay of
multiple concepts, which limits the real-world applicability of personalized
VLMs. In this paper, we propose the first multi-concept personalization method
named MC-LLaVA along with a high-quality multi-concept personalization dataset.
Specifically, MC-LLaVA uses a joint training strategy incorporating multiple
concepts in a single training step, allowing VLMs to perform accurately in
multi-concept personalization. To reduce the cost of joint training, MC-LLaVA
leverages visual token information for concept token initialization, yielding
improved concept representation and accelerating joint training. To advance
multi-concept personalization research, we further contribute a high-quality
dataset. We carefully collect images from various movies that contain multiple
characters and manually generate the multi-concept question-answer samples. Our
dataset features diverse movie types and question-answer types. We conduct
comprehensive qualitative and quantitative experiments to demonstrate that
MC-LLaVA can achieve impressive multi-concept personalized responses, paving
the way for VLMs to become better user-specific assistants. The code and
dataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11706v1
Newclid: A User-Friendly Replacement for AlphaGeometry,"Vladmir Sicca, Tianxiang Xia, Mathïs Fédérico, Philip John Gorinski, Simon Frieder, Shangling Jui",2024-11-18T16:24:21Z,"We introduce a new symbolic solver for geometry, called Newclid, which is
based on AlphaGeometry. Newclid contains a symbolic solver called DDARN
(derived from DDAR-Newclid), which is a significant refactoring and upgrade of
AlphaGeometry's DDAR symbolic solver by being more user-friendly - both for the
end user as well as for a programmer wishing to extend the codebase. For the
programmer, improvements include a modularized codebase and new debugging and
visualization tools. For the user, Newclid contains a new command line
interface (CLI) that provides interfaces for agents to guide DDARN. DDARN is
flexible with respect to its internal reasoning, which can be steered by
agents. Further, we support input from GeoGebra to make Newclid accessible for
educational contexts. Further, the scope of problems that Newclid can solve has
been expanded to include the ability to have an improved understanding of
metric geometry concepts (length, angle) and to use theorems such as the
Pythagorean theorem in proofs. Bugs have been fixed, and reproducibility has
been improved. Lastly, we re-evaluated the five remaining problems from the
original AG-30 dataset that AlphaGeometry was not able to solve and contrasted
them with the abilities of DDARN, running in breadth-first-search agentic mode
(which corresponds to how DDARN runs by default), finding that DDARN solves an
additional problem. We have open-sourced our code under:
https://github.com/LMCRC/Newclid","cs.GR, cs.AI",cs.GR,http://arxiv.org/abs/2411.11938v1
Towards Degradation-Robust Reconstruction in Generalizable NeRF,"Chan Ho Park, Ka Leong Cheng, Zhicheng Wang, Qifeng Chen",2024-11-18T16:13:47Z,"Generalizable Neural Radiance Field (GNeRF) across scenes has been proven to
be an effective way to avoid per-scene optimization by representing a scene
with deep image features of source images. However, despite its potential for
real-world applications, there has been limited research on the robustness of
GNeRFs to different types of degradation present in the source images. The lack
of such research is primarily attributed to the absence of a large-scale
dataset fit for training a degradation-robust generalizable NeRF model. To
address this gap and facilitate investigations into the degradation robustness
of 3D reconstruction tasks, we construct the Objaverse Blur Dataset, comprising
50,000 images from over 1000 settings featuring multiple levels of blur
degradation. In addition, we design a simple and model-agnostic module for
enhancing the degradation robustness of GNeRFs. Specifically, by extracting
3D-aware features through a lightweight depth estimator and denoiser, the
proposed module shows improvement on different popular methods in GNeRFs in
terms of both quantitative and visual quality over varying degradation types
and levels. Our dataset and code will be made publicly available.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11691v1
"Efficient and Robust Continual Graph Learning for Graph Classification
  in Biology","Ding Zhang, Jane Downer, Can Chen, Ren Wang",2024-11-18T15:47:37Z,"Graph classification is essential for understanding complex biological
systems, where molecular structures and interactions are naturally represented
as graphs. Traditional graph neural networks (GNNs) perform well on static
tasks but struggle in dynamic settings due to catastrophic forgetting. We
present Perturbed and Sparsified Continual Graph Learning (PSCGL), a robust and
efficient continual graph learning framework for graph data classification,
specifically targeting biological datasets. We introduce a perturbed sampling
strategy to identify critical data points that contribute to model learning and
a motif-based graph sparsification technique to reduce storage needs while
maintaining performance. Additionally, our PSCGL framework inherently defends
against graph backdoor attacks, which is crucial for applications in sensitive
biological contexts. Extensive experiments on biological datasets demonstrate
that PSCGL not only retains knowledge across tasks but also enhances the
efficiency and robustness of graph classification models in biology.","cs.LG, q-bio.QM",cs.LG,http://arxiv.org/abs/2411.11668v1
"Calibrated and Efficient Sampling-Free Confidence Estimation for LiDAR
  Scene Semantic Segmentation","Hanieh Shojaei Miandashti, Qianqian Zou, Claus Brenner",2024-11-18T15:13:20Z,"Reliable deep learning models require not only accurate predictions but also
well-calibrated confidence estimates to ensure dependable uncertainty
estimation. This is crucial in safety-critical applications like autonomous
driving, which depend on rapid and precise semantic segmentation of LiDAR point
clouds for real-time 3D scene understanding. In this work, we introduce a
sampling-free approach for estimating well-calibrated confidence values for
classification tasks, achieving alignment with true classification accuracy and
significantly reducing inference time compared to sampling-based methods. Our
evaluation using the Adaptive Calibration Error (ACE) metric for LiDAR semantic
segmentation shows that our approach maintains well-calibrated confidence
values while achieving increased processing speed compared to a sampling
baseline. Additionally, reliability diagrams reveal that our method produces
underconfidence rather than overconfident predictions, an advantage for
safety-critical applications. Our sampling-free approach offers well-calibrated
and time-efficient predictions for LiDAR scene semantic segmentation.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.11935v1
"SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular
  Input","Zhen Lv, Yangqi Long, Congzhentao Huang, Cao Li, Chengfei Lv, Hao Ren, Dian Zheng",2024-11-18T15:12:59Z,"Stereo video synthesis from a monocular input is a demanding task in the
fields of spatial computing and virtual reality. The main challenges of this
task lie on the insufficiency of high-quality paired stereo videos for training
and the difficulty of maintaining the spatio-temporal consistency between
frames. Existing methods primarily address these issues by directly applying
novel view synthesis (NVS) techniques to video, while facing limitations such
as the inability to effectively represent dynamic scenes and the requirement
for large amounts of training data. In this paper, we introduce a novel
self-supervised stereo video synthesis paradigm via a video diffusion model,
termed SpatialDreamer, which meets the challenges head-on. Firstly, to address
the stereo video data insufficiency, we propose a Depth based Video Generation
module DVG, which employs a forward-backward rendering mechanism to generate
paired videos with geometric and temporal priors. Leveraging data generated by
DVG, we propose RefinerNet along with a self-supervised synthetic framework
designed to facilitate efficient and dedicated training. More importantly, we
devise a consistency control module, which consists of a metric of stereo
deviation strength and a Temporal Interaction Learning module TIL for geometric
and temporal consistency ensurance respectively. We evaluated the proposed
method against various benchmark methods, with the results showcasing its
superior performance.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11934v1
SignEye: Traffic Sign Interpretation from Vehicle First-Person View,"Chuang Yang, Xu Han, Tao Han, Yuejiao SU, Junyu Gao, Hongyuan Zhang, Yi Wang, Lap-Pui Chau",2024-11-18T12:12:33Z,"Traffic signs play a key role in assisting autonomous driving systems (ADS)
by enabling the assessment of vehicle behavior in compliance with traffic
regulations and providing navigation instructions. However, current works are
limited to basic sign understanding without considering the egocentric
vehicle's spatial position, which fails to support further regulation
assessment and direction navigation. Following the above issues, we introduce a
new task: traffic sign interpretation from the vehicle's first-person view,
referred to as TSI-FPV. Meanwhile, we develop a traffic guidance assistant
(TGA) scenario application to re-explore the role of traffic signs in ADS as a
complement to popular autonomous technologies (such as obstacle perception).
Notably, TGA is not a replacement for electronic map navigation; rather, TGA
can be an automatic tool for updating it and complementing it in situations
such as offline conditions or temporary sign adjustments. Lastly, a spatial and
semantic logic-aware stepwise reasoning pipeline (SignEye) is constructed to
achieve the TSI-FPV and TGA, and an application-specific dataset (Traffic-CN)
is built. Experiments show that TSI-FPV and TGA are achievable via our SignEye
trained on Traffic-CN. The results also demonstrate that the TGA can provide
complementary information to ADS beyond existing popular autonomous
technologies.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11507v1
All-domain Moveline Evolution Network for Click-Through Rate Prediction,"Chen Gao, Zixin Zhao, Lv Shao, Tong Liu",2024-11-18T12:02:24Z,"E-commerce app users exhibit behaviors that are inherently logically
consistent. A series of multi-scenario user behaviors interconnect to form the
scene-level all-domain user moveline, which ultimately reveals the user's true
intention. Traditional CTR prediction methods typically focus on the item-level
interaction between the target item and the historically interacted items.
However, the scene-level interaction between the target item and the user
moveline remains underexplored. There are two challenges when modeling the
interaction with preceding all-domain user moveline: (i) Heterogeneity between
items and scenes: Unlike traditional user behavior sequences that utilize items
as carriers, the user moveline utilizes scenes as carriers. The heterogeneity
between items and scenes complicates the process of aligning interactions
within a unified representation space. (ii) Temporal misalignment of linked
scene-level and item-level behaviors: In the preceding user moveline with a
fixed sampling length, certain critical scene-level behaviors are closely
linked to subsequent item-level behaviors. However, it is impossible to
establish a complete temporal alignment that clearly identifies which specific
scene-level behaviors correspond to which item-level behaviors. To address
these challenges and pioneer modeling user intent from the perspective of the
all-domain moveline, we propose All-domain Moveline Evolution Network (AMEN).
AMEN not only transfers interactions between items and scenes to homogeneous
representation spaces, but also introduces a Temporal Sequential Pairwise (TSP)
mechanism to understand the nuanced associations between scene-level and
item-level behaviors, ensuring that the all-domain user moveline differentially
influences CTR predictions for user's favored and unfavored items. Online A/B
testing demonstrates that our method achieves a +11.6% increase in CTCVR.",cs.IR,cs.IR,http://arxiv.org/abs/2411.11502v1
"Physics meets Topology: Physics-informed topological neural networks for
  learning rigid body dynamics","Amaury Wei, Olga Fink",2024-11-18T11:03:15Z,"Rigid body interactions are fundamental to numerous scientific disciplines,
but remain challenging to simulate due to their abrupt nonlinear nature and
sensitivity to complex, often unknown environmental factors. These challenges
call for adaptable learning-based methods capable of capturing complex
interactions beyond explicit physical models and simulations. While graph
neural networks can handle simple scenarios, they struggle with complex scenes
and long-term predictions. We introduce a novel framework for modeling rigid
body dynamics and learning collision interactions, addressing key limitations
of existing graph-based methods. Our approach extends the traditional
representation of meshes by incorporating higher-order topology complexes,
offering a physically consistent representation. Additionally, we propose a
physics-informed message-passing neural architecture, embedding physical laws
directly in the model. Our method demonstrates superior accuracy, even during
long rollouts, and exhibits strong generalization to unseen scenarios.
Importantly, this work addresses the challenge of multi-entity dynamic
interactions, with applications spanning diverse scientific and engineering
domains.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11467v1
MGNiceNet: Unified Monocular Geometric Scene Understanding,"Markus Schön, Michael Buchholz, Klaus Dietmayer",2024-11-18T11:01:25Z,"Monocular geometric scene understanding combines panoptic segmentation and
self-supervised depth estimation, focusing on real-time application in
autonomous vehicles. We introduce MGNiceNet, a unified approach that uses a
linked kernel formulation for panoptic segmentation and self-supervised depth
estimation. MGNiceNet is based on the state-of-the-art real-time panoptic
segmentation method RT-K-Net and extends the architecture to cover both
panoptic segmentation and self-supervised monocular depth estimation. To this
end, we introduce a tightly coupled self-supervised depth estimation predictor
that explicitly uses information from the panoptic path for depth prediction.
Furthermore, we introduce a panoptic-guided motion masking method to improve
depth estimation without relying on video panoptic segmentation annotations. We
evaluate our method on two popular autonomous driving datasets, Cityscapes and
KITTI. Our model shows state-of-the-art results compared to other real-time
methods and closes the gap to computationally more demanding methods. Source
code and trained models are available at
https://github.com/markusschoen/MGNiceNet.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11466v1
ChatHTTPFuzz: Large Language Model-Assisted IoT HTTP Fuzzing,"Zhe Yang, Hao Peng, Yanling Jiang, Xingwei Li, Haohua Du, Shuhai Wang, Jianwei Liu",2024-11-18T10:48:53Z,"Internet of Things (IoT) devices offer convenience through web interfaces,
web VPNs, and other web-based services, all relying on the HTTP protocol.
However, these externally exposed HTTP services resent significant security
risks. Although fuzzing has shown some effectiveness in identifying
vulnerabilities in IoT HTTP services, most state-of-the-art tools still rely on
random mutation trategies, leading to difficulties in accurately understanding
the HTTP protocol's structure and generating many invalid test cases.
Furthermore, These fuzzers rely on a limited set of initial seeds for testing.
While this approach initiates testing, the limited number and diversity of
seeds hinder comprehensive coverage of complex scenarios in IoT HTTP services.
In this paper, we investigate and find that large language models (LLMs) excel
in parsing HTTP protocol data and analyzing code logic. Based on these
findings, we propose a novel LLM-guided IoT HTTP fuzzing method, ChatHTTPFuzz,
which automatically parses protocol fields and analyzes service code logic to
generate protocol-compliant test cases. Specifically, we use LLMs to label
fields in HTTP protocol data, creating seed templates. Second, The LLM analyzes
service code to guide the generation of additional packets aligned with the
code logic, enriching the seed templates and their field values. Finally, we
design an enhanced Thompson sampling algorithm based on the exploration balance
factor and mutation potential factor to schedule seed templates. We evaluate
ChatHTTPFuzz on 14 different real-world IoT devices. It finds more
vulnerabilities than SNIPUZZ, BOOFUZZ, and MUTINY. ChatHTTPFuzz has discovered
103 vulnerabilities, of which 68 are unique, and 23 have been assigned CVEs.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11929v1
"The ADUULM-360 Dataset -- A Multi-Modal Dataset for Depth Estimation in
  Adverse Weather","Markus Schön, Jona Ruof, Thomas Wodtko, Michael Buchholz, Klaus Dietmayer",2024-11-18T10:42:53Z,"Depth estimation is an essential task toward full scene understanding since
it allows the projection of rich semantic information captured by cameras into
3D space. While the field has gained much attention recently, datasets for
depth estimation lack scene diversity or sensor modalities. This work presents
the ADUULM-360 dataset, a novel multi-modal dataset for depth estimation. The
ADUULM-360 dataset covers all established autonomous driving sensor modalities,
cameras, lidars, and radars. It covers a frontal-facing stereo setup, six
surround cameras covering the full 360-degree, two high-resolution long-range
lidar sensors, and five long-range radar sensors. It is also the first depth
estimation dataset that contains diverse scenes in good and adverse weather
conditions. We conduct extensive experiments using state-of-the-art
self-supervised depth estimation methods under different training tasks, such
as monocular training, stereo training, and full surround training. Discussing
these results, we demonstrate common limitations of state-of-the-art methods,
especially in adverse weather conditions, which hopefully will inspire future
research in this area. Our dataset, development kit, and trained baselines are
available at https://github.com/uulm-mrm/aduulm_360_dataset.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11455v1
Fluid Antenna-Aided Rate-Splitting Multiple Access,"Farshad Rostami Ghadi, Kai-Kit Wong, F. Javier Lopez-Martinez, Lajos Hanzo, Chan-Byoung Chae",2024-11-18T10:41:40Z,"This letter considers a fluid antenna system (FAS)-aided rate-splitting
multiple access (RSMA) approach for downlink transmission. In particular, a
base station (BS) equipped with a single traditional antenna system (TAS) uses
RSMA signaling to send information to several mobile users (MUs) each equipped
with FAS. To understand the achievable performance, we first present the
distribution of the equivalent channel gain based on the joint multivariate
t-distribution and then derive a compact analytical expression for the outage
probability (OP). Moreover, we obtain the asymptotic OP in the high
signal-to-noise ratio (SNR) regime. Numerical results show that combining FAS
with RSMA significantly outperforms TAS and conventional multiple access
schemes, such as non-orthogonal multiple access (NOMA), in terms of OP. The
results also indicate that FAS can be the tool that greatly improves the
practicality of RSMA.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.11453v1
"Deliberative XAI: How Explanations Impact Understanding and
  Decision-Making of AI Novices in Collective and Individual Settings","Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek",2024-11-18T10:31:24Z,"XAI research often focuses on settings where people learn about and assess
algorithmic systems individually. However, as more public AI systems are
deployed, it becomes essential for XAI to facilitate collective understanding
and deliberation. We conducted a task-based interview study involving 8 focus
groups and 12 individual interviews to explore how explanations can support AI
novices in understanding and forming opinions about AI systems. Participants
received a collection of explanations organized into four information
categories to solve tasks and decide about a system's deployment. These
explanations improved or calibrated participants' self-reported understanding
and decision confidence and facilitated group discussions. Participants valued
both technical and contextual information and the self-directed and modular
explanation structure. Our contributions include an explanation approach that
facilitates both individual and collaborative interaction and explanation
design recommendations, including active and controllable exploration,
different levels of information detail and breadth, and adaptations to the
needs of decision subjects.",cs.HC,cs.HC,http://arxiv.org/abs/2411.11449v1
"InstruGen: Automatic Instruction Generation for Vision-and-Language
  Navigation Via Large Multimodal Models","Yu Yan, Rongtao Xu, Jiazhao Zhang, Peiyang Li, Xiaodan Liang, Jianqin Yin",2024-11-18T09:11:48Z,"Recent research on Vision-and-Language Navigation (VLN) indicates that agents
suffer from poor generalization in unseen environments due to the lack of
realistic training environments and high-quality path-instruction pairs. Most
existing methods for constructing realistic navigation scenes have high costs,
and the extension of instructions mainly relies on predefined templates or
rules, lacking adaptability. To alleviate the issue, we propose InstruGen, a
VLN path-instruction pairs generation paradigm. Specifically, we use YouTube
house tour videos as realistic navigation scenes and leverage the powerful
visual understanding and generation abilities of large multimodal models (LMMs)
to automatically generate diverse and high-quality VLN path-instruction pairs.
Our method generates navigation instructions with different granularities and
achieves fine-grained alignment between instructions and visual observations,
which was difficult to achieve with previous methods. Additionally, we design a
multi-stage verification mechanism to reduce hallucinations and inconsistency
of LMMs. Experimental results demonstrate that agents trained with
path-instruction pairs generated by InstruGen achieves state-of-the-art
performance on the R2R and RxR benchmarks, particularly in unseen environments.
Code is available at https://github.com/yanyu0526/InstruGen.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11394v1
"LeC$^2$O-NeRF: Learning Continuous and Compact Large-Scale Occupancy for
  Urban Scenes","Zhenxing Mi, Dan Xu",2024-11-18T08:37:48Z,"In NeRF, a critical problem is to effectively estimate the occupancy to guide
empty-space skipping and point sampling. Grid-based methods work well for
small-scale scenes. However, on large-scale scenes, they are limited by
predefined bounding boxes, grid resolutions, and high memory usage for grid
updates, and thus struggle to speed up training for large-scale, irregularly
bounded and complex urban scenes without sacrificing accuracy. In this paper,
we propose to learn a continuous and compact large-scale occupancy network,
which can classify 3D points as occupied or unoccupied points. We train this
occupancy network end-to-end together with the radiance field in a
self-supervised manner by three designs. First, we propose a novel imbalanced
occupancy loss to regularize the occupancy network. It makes the occupancy
network effectively control the ratio of unoccupied and occupied points,
motivated by the prior that most of 3D scene points are unoccupied. Second, we
design an imbalanced architecture containing a large scene network and a small
empty space network to separately encode occupied and unoccupied points
classified by the occupancy network. This imbalanced structure can effectively
model the imbalanced nature of occupied and unoccupied regions. Third, we
design an explicit density loss to guide the occupancy network, making the
density of unoccupied points smaller. As far as we know, we are the first to
learn a continuous and compact occupancy of large-scale NeRF by a network. In
our experiments, our occupancy network can quickly learn more compact, accurate
and smooth occupancy compared to the occupancy grid. With our learned occupancy
as guidance for empty space skipping on challenging large-scale benchmarks, our
method consistently obtains higher accuracy compared to the occupancy grid, and
our method can speed up state-of-the-art NeRF methods without sacrificing
accuracy.","cs.CV, cs.GR",cs.CV,http://arxiv.org/abs/2411.11374v1
"Rethinking Thinking Tokens: Understanding Why They Underperform in
  Practice","Sreeram Vennam, David Valente, David Herel, Ponnurangam Kumaraguru",2024-11-18T08:34:38Z,"Thinking Tokens (TT) have been proposed as an unsupervised method to
facilitate reasoning in language models. However, despite their conceptual
appeal, our findings show that TTs marginally improves performance and
consistently underperforms compared to Chain-of-Thought (CoT) reasoning across
multiple benchmarks. We hypothesize that this underperformance stems from the
reliance on a single embedding for TTs, which results in inconsistent learning
signals and introduces noisy gradients. This paper provides a comprehensive
empirical analysis to validate this hypothesis and discusses the implications
for future research on unsupervised reasoning in LLMs.","cs.CL, cs.LG, I.2.6",cs.CL,http://arxiv.org/abs/2411.11371v1
"GPS-Gaussian+: Generalizable Pixel-wise 3D Gaussian Splatting for
  Real-Time Human-Scene Rendering from Sparse Views","Boyao Zhou, Shunyuan Zheng, Hanzhang Tu, Ruizhi Shao, Boning Liu, Shengping Zhang, Liqiang Nie, Yebin Liu",2024-11-18T08:18:44Z,"Differentiable rendering techniques have recently shown promising results for
free-viewpoint video synthesis of characters. However, such methods, either
Gaussian Splatting or neural implicit rendering, typically necessitate
per-subject optimization which does not meet the requirement of real-time
rendering in an interactive application. We propose a generalizable Gaussian
Splatting approach for high-resolution image rendering under a sparse-view
camera setting. To this end, we introduce Gaussian parameter maps defined on
the source views and directly regress Gaussian properties for instant novel
view synthesis without any fine-tuning or optimization. We train our Gaussian
parameter regression module on human-only data or human-scene data, jointly
with a depth estimation module to lift 2D parameter maps to 3D space. The
proposed framework is fully differentiable with both depth and rendering
supervision or with only rendering supervision. We further introduce a
regularization term and an epipolar attention mechanism to preserve geometry
consistency between two source views, especially when neglecting depth
supervision. Experiments on several datasets demonstrate that our method
outperforms state-of-the-art methods while achieving an exceeding rendering
speed.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11363v1
"A comprehensive survey of oracle character recognition: challenges,
  benchmarks, and beyond","Jing Li, Xueke Chi, Qiufeng Wang, Dahan Wang, Kaizhu Huang, Yongge Liu, Cheng-lin Liu",2024-11-18T07:50:22Z,"Oracle character recognition-an analysis of ancient Chinese inscriptions
found on oracle bones-has become a pivotal field intersecting archaeology,
paleography, and historical cultural studies. Traditional methods of oracle
character recognition have relied heavily on manual interpretation by experts,
which is not only labor-intensive but also limits broader accessibility to the
general public. With recent breakthroughs in pattern recognition and deep
learning, there is a growing movement towards the automation of oracle
character recognition (OrCR), showing considerable promise in tackling the
challenges inherent to these ancient scripts. However, a comprehensive
understanding of OrCR still remains elusive. Therefore, this paper presents a
systematic and structured survey of the current landscape of OrCR research. We
commence by identifying and analyzing the key challenges of OrCR. Then, we
provide an overview of the primary benchmark datasets and digital resources
available for OrCR. A review of contemporary research methodologies follows, in
which their respective efficacies, limitations, and applicability to the
complex nature of oracle characters are critically highlighted and examined.
Additionally, our review extends to ancillary tasks associated with OrCR across
diverse disciplines, providing a broad-spectrum analysis of its applications.
We conclude with a forward-looking perspective, proposing potential avenues for
future investigations that could yield significant advancements in the field.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11354v1
Lorentz: Learned SKU Recommendation Using Profile Data,"Nicholas Glaze, Tria McNeely, Yiwen Zhu, Matthew Gleeson, Helen Serr, Rajeev Bhopi, Subru Krishnan",2024-11-18T06:35:02Z,"Cloud operators have expanded their service offerings, known as Stock Keeping
Units (SKUs), to accommodate diverse demands, resulting in increased complexity
for customers to select appropriate configurations. In a studied system, only
43% of the resource capacity was correctly chosen. Automated solutions
addressing this issue often require enriched data, such as workload traces,
which are unavailable for new services. However, telemetry from existing users
and customer satisfaction feedback provide valuable insights for understanding
customer needs and improving provisioning recommendations.
  This paper introduces Lorentz, an intelligent SKU recommender for
provisioning compute resources without relying on workload traces. Lorentz uses
customer profile data to forecast resource capacities for new users by
profiling existing ones. It also incorporates a continuous feedback loop to
refine recommendations based on customer performance versus cost preferences
inferred from satisfaction signals. Validated with production data from Azure
PostgreSQL DB, Lorentz achieves over 60% slack reduction without increasing
throttling compared to user selections and existing defaults. Evaluations with
synthetic data demonstrate Lorentz's ability to iteratively learn user
preferences with high accuracy.",cs.DB,cs.DB,http://arxiv.org/abs/2411.11325v1
"Transcending Language Boundaries: Harnessing LLMs for Low-Resource
  Language Translation","Peng Shu, Junhao Chen, Zhengliang Liu, Hui Wang, Zihao Wu, Tianyang Zhong, Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Yifan Zhou, Constance Owl, Xiaoming Zhai, Ninghao Liu, Claudio Saunt, Tianming Liu",2024-11-18T05:41:27Z,"Large Language Models (LLMs) have demonstrated remarkable success across a
wide range of tasks and domains. However, their performance in low-resource
language translation, particularly when translating into these languages,
remains underexplored. This gap poses significant challenges, as linguistic
barriers hinder the cultural preservation and development of minority
communities. To address this issue, this paper introduces a novel
retrieval-based method that enhances translation quality for low-resource
languages by focusing on key terms, which involves translating keywords and
retrieving corresponding examples from existing data. To evaluate the
effectiveness of this method, we conducted experiments translating from English
into three low-resource languages: Cherokee, a critically endangered indigenous
language of North America; Tibetan, a historically and culturally significant
language in Asia; and Manchu, a language with few remaining speakers. Our
comparison with the zero-shot performance of GPT-4o and LLaMA 3.1 405B,
highlights the significant challenges these models face when translating into
low-resource languages. In contrast, our retrieval-based method shows promise
in improving both word-level accuracy and overall semantic understanding by
leveraging existing resources more effectively.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11295v1
"Reducing Label Dependency for Underwater Scene Understanding: A Survey
  of Datasets, Techniques and Applications","Scarlett Raine, Frederic Maire, Niko Suenderhauf, Tobias Fischer",2024-11-18T05:16:09Z,"Underwater surveys provide long-term data for informing management
strategies, monitoring coral reef health, and estimating blue carbon stocks.
Advances in broad-scale survey methods, such as robotic underwater vehicles,
have increased the range of marine surveys but generate large volumes of
imagery requiring analysis. Computer vision methods such as semantic
segmentation aid automated image analysis, but typically rely on fully
supervised training with extensive labelled data. While ground truth label
masks for tasks like street scene segmentation can be quickly and affordably
generated by non-experts through crowdsourcing services like Amazon Mechanical
Turk, ecology presents greater challenges. The complexity of underwater images,
coupled with the specialist expertise needed to accurately identify species at
the pixel level, makes this process costly, time-consuming, and heavily
dependent on domain experts. In recent years, some works have performed
automated analysis of underwater imagery, and a smaller number of studies have
focused on weakly supervised approaches which aim to reduce the expert-provided
labelled data required. This survey focuses on approaches which reduce
dependency on human expert input, while reviewing the prior and related
approaches to position these works in the wider field of underwater perception.
Further, we offer an overview of coastal ecosystems and the challenges of
underwater imagery. We provide background on weakly and self-supervised deep
learning and integrate these elements into a taxonomy that centres on the
intersection of underwater monitoring, computer vision, and deep learning,
while motivating approaches for weakly supervised deep learning with reduced
dependency on domain expert data annotations. Lastly, the survey examines
available datasets and platforms, and identifies gaps, barriers, and
opportunities for automating underwater surveys.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11287v1
Towards Open-Vocabulary Audio-Visual Event Localization,"Jinxing Zhou, Dan Guo, Ruohao Guo, Yuxin Mao, Jingjing Hu, Yiran Zhong, Xiaojun Chang, Meng Wang",2024-11-18T04:35:20Z,"The Audio-Visual Event Localization (AVEL) task aims to temporally locate and
classify video events that are both audible and visible. Most research in this
field assumes a closed-set setting, which restricts these models' ability to
handle test data containing event categories absent (unseen) during training.
Recently, a few studies have explored AVEL in an open-set setting, enabling the
recognition of unseen events as ``unknown'', but without providing
category-specific semantics. In this paper, we advance the field by introducing
the Open-Vocabulary Audio-Visual Event Localization (OV-AVEL) problem, which
requires localizing audio-visual events and predicting explicit categories for
both seen and unseen data at inference. To address this new task, we propose
the OV-AVEBench dataset, comprising 24,800 videos across 67 real-life
audio-visual scenes (seen:unseen = 46:21), each with manual segment-level
annotation. We also establish three evaluation metrics for this task. Moreover,
we investigate two baseline approaches, one training-free and one using a
further fine-tuning paradigm. Specifically, we utilize the unified multimodal
space from the pretrained ImageBind model to extract audio, visual, and textual
(event classes) features. The training-free baseline then determines
predictions by comparing the consistency of audio-text and visual-text feature
similarities. The fine-tuning baseline incorporates lightweight temporal layers
to encode temporal relations within the audio and visual modalities, using
OV-AVEBench training data for model fine-tuning. We evaluate these baselines on
the proposed OV-AVEBench dataset and discuss potential directions for future
work in this new field.","cs.CV, cs.MM",cs.CV,http://arxiv.org/abs/2411.11278v1
"Artificial Intelligence Mangrove Monitoring System Based on Deep
  Learning and Sentinel-2 Satellite Data in the UAE (2017-2024)","Linlin Tan, Haishan Wu",2024-11-18T03:37:33Z,"Mangroves play a crucial role in maintaining coastal ecosystem health and
protecting biodiversity. Therefore, continuous mapping of mangroves is
essential for understanding their dynamics. Earth observation imagery typically
provides a cost-effective way to monitor mangrove dynamics. However, there is a
lack of regional studies on mangrove areas in the UAE. This study utilizes the
UNet++ deep learning model combined with Sentinel-2 multispectral data and
manually annotated labels to monitor the spatiotemporal dynamics of densely
distributed mangroves (coverage greater than 70%) in the UAE from 2017 to 2024,
achieving an mIoU of 87.8% on the validation set. Results show that the total
mangrove area in the UAE in 2024 was approximately 9,142.21 hectares, an
increase of 2,061.33 hectares compared to 2017, with carbon sequestration
increasing by approximately 194,383.42 tons. Abu Dhabi has the largest mangrove
area and plays a dominant role in the UAE's mangrove growth, increasing by
1,855.6 hectares between 2017-2024, while other emirates have also contributed
to mangrove expansion through stable and sustainable growth in mangrove areas.
This comprehensive growth pattern reflects the collective efforts of all
emirates in mangrove restoration.","cs.LG, stat.CO, 86A08 (Primary) 68T45, 65D18, 92C80 (Secondary), J.2; I.2.10; I.2.6; H.2.8",cs.LG,http://arxiv.org/abs/2411.11918v1
"Cross-Patient Pseudo Bags Generation and Curriculum Contrastive Learning
  for Imbalanced Multiclassification of Whole Slide Image","Yonghuang Wu, Xuan Xie, Xinyuan Niu, Chengqian Zhao, Jinhua Yu",2024-11-18T03:35:34Z,"Pathology computing has dramatically improved pathologists' workflow and
diagnostic decision-making processes. Although computer-aided diagnostic
systems have shown considerable value in whole slide image (WSI) analysis, the
problem of multi-classification under sample imbalance remains an intractable
challenge. To address this, we propose learning fine-grained information by
generating sub-bags with feature distributions similar to the original WSIs.
Additionally, we utilize a pseudo-bag generation algorithm to further leverage
the abundant and redundant information in WSIs, allowing efficient training in
unbalanced-sample multi-classification tasks. Furthermore, we introduce an
affinity-based sample selection and curriculum contrastive learning strategy to
enhance the stability of model representation learning. Unlike previous
approaches, our framework transitions from learning bag-level representations
to understanding and exploiting the feature distribution of multi-instance
bags. Our method demonstrates significant performance improvements on three
datasets, including tumor classification and lymph node metastasis. On average,
it achieves a 4.39-point improvement in F1 score compared to the second-best
method across the three tasks, underscoring its superior performance.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11262v1
"DrivingSphere: Building a High-fidelity 4D World for Closed-loop
  Simulation","Tianyi Yan, Dongming Wu, Wencheng Han, Junpeng Jiang, Xia Zhou, Kun Zhan, Cheng-zhong Xu, Jianbing Shen",2024-11-18T03:00:33Z,"Autonomous driving evaluation requires simulation environments that closely
replicate actual road conditions, including real-world sensory data and
responsive feedback loops. However, many existing simulations need to predict
waypoints along fixed routes on public datasets or synthetic photorealistic
data, \ie, open-loop simulation usually lacks the ability to assess dynamic
decision-making. While the recent efforts of closed-loop simulation offer
feedback-driven environments, they cannot process visual sensor inputs or
produce outputs that differ from real-world data. To address these challenges,
we propose DrivingSphere, a realistic and closed-loop simulation framework. Its
core idea is to build 4D world representation and generate real-life and
controllable driving scenarios. In specific, our framework includes a Dynamic
Environment Composition module that constructs a detailed 4D driving world with
a format of occupancy equipping with static backgrounds and dynamic objects,
and a Visual Scene Synthesis module that transforms this data into
high-fidelity, multi-view video outputs, ensuring spatial and temporal
consistency. By providing a dynamic and realistic simulation environment,
DrivingSphere enables comprehensive testing and validation of autonomous
driving algorithms, ultimately advancing the development of more reliable
autonomous cars. The benchmark will be publicly released.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.11252v1
"MEMO-Bench: A Multiple Benchmark for Text-to-Image and Multimodal Large
  Language Models on Human Emotion Analysis","Yingjie Zhou, Zicheng Zhang, Jiezhang Cao, Jun Jia, Yanwei Jiang, Farong Wen, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai",2024-11-18T02:09:48Z,"Artificial Intelligence (AI) has demonstrated significant capabilities in
various fields, and in areas such as human-computer interaction (HCI), embodied
intelligence, and the design and animation of virtual digital humans, both
practitioners and users are increasingly concerned with AI's ability to
understand and express emotion. Consequently, the question of whether AI can
accurately interpret human emotions remains a critical challenge. To date, two
primary classes of AI models have been involved in human emotion analysis:
generative models and Multimodal Large Language Models (MLLMs). To assess the
emotional capabilities of these two classes of models, this study introduces
MEMO-Bench, a comprehensive benchmark consisting of 7,145 portraits, each
depicting one of six different emotions, generated by 12 Text-to-Image (T2I)
models. Unlike previous works, MEMO-Bench provides a framework for evaluating
both T2I models and MLLMs in the context of sentiment analysis. Additionally, a
progressive evaluation approach is employed, moving from coarse-grained to
fine-grained metrics, to offer a more detailed and comprehensive assessment of
the sentiment analysis capabilities of MLLMs. The experimental results
demonstrate that existing T2I models are more effective at generating positive
emotions than negative ones. Meanwhile, although MLLMs show a certain degree of
effectiveness in distinguishing and recognizing human emotions, they fall short
of human-level accuracy, particularly in fine-grained emotion analysis. The
MEMO-Bench will be made publicly available to support further research in this
area.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11235v1
Noise Filtering Benchmark for Neuromorphic Satellites Observations,"Sami Arja, Alexandre Marcireau, Nicholas Owen Ralph, Saeed Afshar, Gregory Cohen",2024-11-18T02:02:24Z,"Event cameras capture sparse, asynchronous brightness changes which offer
high temporal resolution, high dynamic range, low power consumption, and sparse
data output. These advantages make them ideal for Space Situational Awareness,
particularly in detecting resident space objects moving within a telescope's
field of view. However, the output from event cameras often includes
substantial background activity noise, which is known to be more prevalent in
low-light conditions. This noise can overwhelm the sparse events generated by
satellite signals, making detection and tracking more challenging. Existing
noise-filtering algorithms struggle in these scenarios because they are
typically designed for denser scenes, where losing some signal is acceptable.
This limitation hinders the application of event cameras in complex, real-world
environments where signals are extremely sparse. In this paper, we propose new
event-driven noise-filtering algorithms specifically designed for very sparse
scenes. We categorise the algorithms into logical-based and learning-based
approaches and benchmark their performance against 11 state-of-the-art
noise-filtering algorithms, evaluating how effectively they remove noise and
hot pixels while preserving the signal. Their performance was quantified by
measuring signal retention and noise removal accuracy, with results reported
using ROC curves across the parameter space. Additionally, we introduce a new
high-resolution satellite dataset with ground truth from a real-world platform
under various noise conditions, which we have made publicly available. Code,
dataset, and trained weights are available at
\url{https://github.com/samiarja/dvs_sparse_filter}.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.11233v1
The Sound of Water: Inferring Physical Properties from Pouring Liquids,"Piyush Bagad, Makarand Tapaswi, Cees G. M. Snoek, Andrew Zisserman",2024-11-18T01:19:37Z,"We study the connection between audio-visual observations and the underlying
physics of a mundane yet intriguing everyday activity: pouring liquids. Given
only the sound of liquid pouring into a container, our objective is to
automatically infer physical properties such as the liquid level, the shape and
size of the container, the pouring rate and the time to fill. To this end, we:
(i) show in theory that these properties can be determined from the fundamental
frequency (pitch); (ii) train a pitch detection model with supervision from
simulated data and visual data with a physics-inspired objective; (iii)
introduce a new large dataset of real pouring videos for a systematic study;
(iv) show that the trained model can indeed infer these physical properties for
real data; and finally, (v) we demonstrate strong generalization to various
container shapes, other datasets, and in-the-wild YouTube videos. Our work
presents a keen understanding of a narrow yet rich problem at the intersection
of acoustics, physics, and learning. It opens up applications to enhance
multisensory perception in robotic pouring.","cs.CV, cs.MM, cs.SD, eess.AS",cs.CV,http://arxiv.org/abs/2411.11222v1
"Relational Contrastive Learning and Masked Image Modeling for Scene Text
  Recognition","Tiancheng Lin, Jinglei Zhang, Yi Xu, Kai Chen, Rui Zhang, Chang-Wen Chen",2024-11-18T01:11:47Z,"Context-aware methods have achieved remarkable advancements in supervised
scene text recognition by leveraging semantic priors from words. Considering
the heterogeneity of text and background in STR, we propose that such
contextual priors can be reinterpreted as the relations between textual
elements, serving as effective self-supervised labels for representation
learning. However, textual relations are restricted to the finite size of the
dataset due to lexical dependencies, which causes over-fitting problem, thus
compromising the representation quality. To address this, our work introduces a
unified framework of Relational Contrastive Learning and Masked Image Modeling
for STR (RCMSTR), which explicitly models the enriched textual relations. For
the RCL branch, we first introduce the relational rearrangement module to
cultivate new relations on the fly. Based on this, we further conduct
relational contrastive learning to model the intra- and inter-hierarchical
relations for frames, sub-words and words. On the other hand, MIM can naturally
boost the context information via masking, where we find that the block masking
strategy is more effective for STR. For the effective integration of RCL and
MIM, we also introduce a novel decoupling design aimed at mitigating the impact
of masked images on contrastive learning. Additionally, to enhance the
compatibility of MIM with CNNs, we propose the adoption of sparse convolutions
and directly sharing the weights with dense convolutions in training. The
proposed RCMSTR demonstrates superior performance in various evaluation
protocols for different STR-related downstream tasks, outperforming the
existing state-of-the-art self-supervised STR techniques. Ablation studies and
qualitative experimental results further validate the effectiveness of our
method. The code and pre-trained models will be available at
https://github.com/ThunderVVV/RCMSTR .",cs.CV,cs.CV,http://arxiv.org/abs/2411.11219v2
Capturing Sparks of Abstraction for the ARC Challenge,Martin Andrews,2024-11-17T23:40:00Z,"Excellent progress has been made recently in solving ARC Challenge problems.
However, it seems that new techniques may be required to push beyond 60%
accuracy. Even commercial Large Language Models (LLMs) struggle to 'understand'
many of the problems (when given the input and output grids), which makes
discovering solutions by LLM-lead program search somewhat futile.
  In this work, LLM 'understanding' is attempted from a stronger starting
position : An LLM is given complete solutions to tasks in code, and then asked
to explain how the task is being solved at various levels of abstraction.
Specifically, the LLM was given code solutions implemented in arc-dsl-llm (an
LLM-legible version of Hodel's arc-dsl to obtain: (a) commented code; (b) code
refactored into reusable functional chunks; (c) problem solution steps; and (d)
high-level problem-solving tactics.
  We demonstrate that 'Sparks of Abstraction' can be extracted from the LLM
output - in a form that could be used in downstream tasks with Local LLMs
eligible to enter the ARC Prize.
  Both the arc-dsl-llm DSL framework (with the re-engineered solutions) and the
Gemini LLM-generated data (along with the generation code) are made Open
Source.","cs.CL, cs.AI, cs.LG",cs.CL,http://arxiv.org/abs/2411.11206v1
"On-Board Vision-Language Models for Personalized Autonomous Vehicle
  Motion Control: System Design and Real-World Validation","Can Cui, Zichong Yang, Yupeng Zhou, Juntong Peng, Sung-Yeon Park, Cong Zhang, Yunsheng Ma, Xu Cao, Wenqian Ye, Yiheng Feng, Jitesh Panchal, Lingxi Li, Yaobin Chen, Ziran Wang",2024-11-17T23:20:37Z,"Personalized driving refers to an autonomous vehicle's ability to adapt its
driving behavior or control strategies to match individual users' preferences
and driving styles while maintaining safety and comfort standards. However,
existing works either fail to capture every individual preference precisely or
become computationally inefficient as the user base expands. Vision-Language
Models (VLMs) offer promising solutions to this front through their natural
language understanding and scene reasoning capabilities. In this work, we
propose a lightweight yet effective on-board VLM framework that provides
low-latency personalized driving performance while maintaining strong reasoning
capabilities. Our solution incorporates a Retrieval-Augmented Generation
(RAG)-based memory module that enables continuous learning of individual
driving preferences through human feedback. Through comprehensive real-world
vehicle deployment and experiments, our system has demonstrated the ability to
provide safe, comfortable, and personalized driving experiences across various
scenarios and significantly reduce takeover rates by up to 76.9%. To the best
of our knowledge, this work represents the first end-to-end VLM-based motion
control system in real-world autonomous vehicles.","cs.AI, cs.RO",cs.AI,http://arxiv.org/abs/2411.11913v1
PickScan: Object discovery and reconstruction from handheld interactions,"Vincent van der Brugge, Marc Pollefeys, Joshua B. Tenenbaum, Ayush Tewari, Krishna Murthy Jatavallabhula",2024-11-17T23:09:08Z,"Reconstructing compositional 3D representations of scenes, where each object
is represented with its own 3D model, is a highly desirable capability in
robotics and augmented reality. However, most existing methods rely heavily on
strong appearance priors for object discovery, therefore only working on those
classes of objects on which the method has been trained, or do not allow for
object manipulation, which is necessary to scan objects fully and to guide
object discovery in challenging scenarios. We address these limitations with a
novel interaction-guided and class-agnostic method based on object
displacements that allows a user to move around a scene with an RGB-D camera,
hold up objects, and finally outputs one 3D model per held-up object. Our main
contribution to this end is a novel approach to detecting user-object
interactions and extracting the masks of manipulated objects. On a
custom-captured dataset, our pipeline discovers manipulated objects with 78.3%
precision at 100% recall and reconstructs them with a mean chamfer distance of
0.90cm. Compared to Co-Fusion, the only comparable interaction-based and
class-agnostic baseline, this corresponds to a reduction in chamfer distance of
73% while detecting 99% fewer false positives.","cs.CV, cs.AI, cs.GR, cs.LG, cs.RO, I.4.5",cs.CV,http://arxiv.org/abs/2411.11196v1
"SoK: Unifying Cybersecurity and Cybersafety of Multimodal Foundation
  Models with an Information Theory Approach","Ruoxi Sun, Jiamin Chang, Hammond Pearce, Chaowei Xiao, Bo Li, Qi Wu, Surya Nepal, Minhui Xue",2024-11-17T23:06:20Z,"Multimodal foundation models (MFMs) represent a significant advancement in
artificial intelligence, combining diverse data modalities to enhance learning
and understanding across a wide range of applications. However, this
integration also brings unique safety and security challenges. In this paper,
we conceptualize cybersafety and cybersecurity in the context of multimodal
learning and present a comprehensive Systematization of Knowledge (SoK) to
unify these concepts in MFMs, identifying key threats to these models. We
propose a taxonomy framework grounded in information theory, evaluating and
categorizing threats through the concepts of channel capacity, signal, noise,
and bandwidth. This approach provides a novel framework that unifies model
safety and system security in MFMs, offering a more comprehensive and
actionable understanding of the risks involved. We used this to explore
existing defense mechanisms, and identified gaps in current research -
particularly, a lack of protection for alignment between modalities and a need
for more systematic defense methods. Our work contributes to a deeper
understanding of the security and safety landscape in MFMs, providing
researchers and practitioners with valuable insights for improving the
robustness and reliability of these models.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11195v2
Infinite Width Limits of Self Supervised Neural Networks,"Maximilian Fleissner, Gautham Govind Anil, Debarghya Ghoshdastidar",2024-11-17T21:13:57Z,"The NTK is a widely used tool in the theoretical analysis of deep learning,
allowing us to look at supervised deep neural networks through the lenses of
kernel regression. Recently, several works have investigated kernel models for
self-supervised learning, hypothesizing that these also shed light on the
behaviour of wide neural networks by virtue of the NTK. However, it remains an
open question to what extent this connection is mathematically sound -- it is a
commonly encountered misbelief that the kernel behaviour of wide neural
networks emerges irrespective of the loss function it is trained on. In this
paper, we bridge the gap between the NTK and self-supervised learning, focusing
on two-layer neural networks trained under the Barlow Twins loss. We prove that
the NTK of Barlow Twins indeed becomes constant as the width of the network
approaches infinity. Our analysis technique is different from previous works on
the NTK and may be of independent interest. Overall, our work provides a first
rigorous justification for the use of classic kernel theory to understand
self-supervised learning of wide neural networks. Building on this result, we
derive generalization error bounds for kernelized Barlow Twins and connect them
to neural networks of finite width.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11176v1
"Person Segmentation and Action Classification for Multi-Channel
  Hemisphere Field of View LiDAR Sensors","Svetlana Seliunina, Artem Otelepko, Raphael Memmesheimer, Sven Behnke",2024-11-17T18:53:20Z,"Robots need to perceive persons in their surroundings for safety and to
interact with them. In this paper, we present a person segmentation and action
classification approach that operates on 3D scans of hemisphere field of view
LiDAR sensors. We recorded a data set with an Ouster OSDome-64 sensor
consisting of scenes where persons perform three different actions and
annotated it. We propose a method based on a MaskDINO model to detect and
segment persons and to recognize their actions from combined spherical
projected multi-channel representations of the LiDAR data with an additional
positional encoding. Our approach demonstrates good performance for the person
segmentation task and further performs well for the estimation of the person
action states walking, waving, and sitting. An ablation study provides insights
about the individual channel contributions for the person segmentation task.
The trained models, code and dataset are made publicly available.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.11151v1
"A Comprehensive Survey on Visual Question Answering Datasets and
  Algorithms","Raihan Kabir, Naznin Haque, Md Saiful Islam, Marium-E-Jannat",2024-11-17T18:52:06Z,"Visual question answering (VQA) refers to the problem where, given an image
and a natural language question about the image, a correct natural language
answer has to be generated. A VQA model has to demonstrate both the visual
understanding of the image and the semantic understanding of the question,
demonstrating reasoning capability. Since the inception of this field, a
plethora of VQA datasets and models have been published. In this article, we
meticulously analyze the current state of VQA datasets and models, while
cleanly dividing them into distinct categories and then summarizing the
methodologies and characteristics of each category. We divide VQA datasets into
four categories: (1) available datasets that contain a rich collection of
authentic images, (2) synthetic datasets that contain only synthetic images
produced through artificial means, (3) diagnostic datasets that are specially
designed to test model performance in a particular area, e.g., understanding
the scene text, and (4) KB (Knowledge-Based) datasets that are designed to
measure a model's ability to utilize outside knowledge. Concurrently, we
explore six main paradigms of VQA models: fusion, where we discuss different
methods of fusing information between visual and textual modalities; attention,
the technique of using information from one modality to filter information from
another; external knowledge base, where we discuss different models utilizing
outside information; composition or reasoning, where we analyze techniques to
answer advanced questions that require complex reasoning steps; explanation,
which is the process of generating visual and textual descriptions to verify
sound reasoning; and graph models, which encode and manipulate relationships
through nodes in a graph. We also discuss some miscellaneous topics, such as
scene text understanding, counting, and bias reduction.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11150v1
"From 2D Document Interactions into Immersive Information Experience: An
  Example-Based Design by Augmenting Content, Spatializing Placement, Enriching
  Long-Term Interactions, and Simplifying Content Creations",Chen Chen,2024-11-17T18:33:02Z,"Documents serve as a crucial and indispensable medium for everyday workplace
tasks. However, understanding, interacting and creating such documents on
today's planar interfaces without any intelligent support are challenging due
to our natural cognitive constraints on remembering, processing, understanding
and interacting with these information. My doctorate research investigates how
to bring 2D document interactions into immersive information experience using
multiple of today's emergent technologies. With the examples of four specific
types of documents -- medical scans, instruction document, self-report diary
survey, and reference images for visual artists -- my research demonstrates how
to transform such of today's 2D document interactions into an immersive
information experience, by augmenting content with virtual reality,
spatializing document placements with mixed reality, enriching long-term and
continuous interactions with voice assistants, and simplify document creation
workflow with generative AI.","cs.HC, H.5.m",cs.HC,http://arxiv.org/abs/2411.11145v1
Factors in Crowdsourcing for Evaluation of Complex Dialogue Systems,"Annalena Aicher, Stefan Hillmann, Isabel Feustel, Thilo Michael, Sebastian Möller, Wolfgang Minker",2024-11-17T17:53:38Z,"In the last decade, crowdsourcing has become a popular method for conducting
quantitative empirical studies in human-machine interaction. The remote work on
a given task in crowdworking settings suits the character of typical
speech/language-based interactive systems for instance with regard to
argumentative conversations and information retrieval. Thus, crowdworking
promises a valuable opportunity to study and evaluate the usability and user
experience of real humans in interactions with such interactive systems. In
contrast to physical attendance in laboratory studies, crowdsourcing studies
offer much more flexible and easier access to large numbers of heterogeneous
participants with a specific background, e.g., native speakers or domain
expertise. On the other hand, the experimental and environmental conditions as
well as the participant's compliance and reliability (at least better
monitoring of the latter) are much better controllable in a laboratory.
  This paper seeks to present a (self-)critical examination of
crowdsourcing-based studies in the context of complex (spoken) dialogue
systems. It describes and discusses observed issues in crowdsourcing studies
involving complex tasks and suggests solutions to improve and ensure the
quality of the study results. Thereby, our work contributes to a better
understanding and what needs to be considered when designing and evaluating
studies with crowdworkers for complex dialogue systems.",cs.HC,cs.HC,http://arxiv.org/abs/2411.11137v1
"Oscillation Inversion: Understand the structure of Large Flow Model
  through the Lens of Inversion Method","Yan Zheng, Zhenxiao Liang, Xiaoyan Cong, Lanqing guo, Yuehao Wang, Peihao Wang, Zhangyang Wang",2024-11-17T17:45:37Z,"We explore the oscillatory behavior observed in inversion methods applied to
large-scale text-to-image diffusion models, with a focus on the ""Flux"" model.
By employing a fixed-point-inspired iterative approach to invert real-world
images, we observe that the solution does not achieve convergence, instead
oscillating between distinct clusters. Through both toy experiments and
real-world diffusion models, we demonstrate that these oscillating clusters
exhibit notable semantic coherence. We offer theoretical insights, showing that
this behavior arises from oscillatory dynamics in rectified flow models.
Building on this understanding, we introduce a simple and fast distribution
transfer technique that facilitates image enhancement, stroke-based recoloring,
as well as visual prompt-guided image editing. Furthermore, we provide
quantitative results demonstrating the effectiveness of our method for tasks
such as image enhancement, makeup transfer, reconstruction quality, and guided
sampling quality. Higher-quality examples of videos and images are available at
\href{https://yanyanzheng96.github.io/oscillation_inversion/}{this link}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11135v1
"JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of
  Representation and Circuit","Zeqing He, Zhibo Wang, Zhixuan Chu, Huiyu Xu, Rui Zheng, Kui Ren, Chun Chen",2024-11-17T16:08:34Z,"Despite the outstanding performance of Large language models (LLMs) in
diverse tasks, they are vulnerable to jailbreak attacks, wherein adversarial
prompts are crafted to bypass their security mechanisms and elicit unexpected
responses.Although jailbreak attacks are prevalent, the understanding of their
underlying mechanisms remains limited. Recent studies have explain typical
jailbreaking behavior (e.g., the degree to which the model refuses to respond)
of LLMs by analyzing the representation shifts in their latent space caused by
jailbreak prompts or identifying key neurons that contribute to the success of
these attacks. However, these studies neither explore diverse jailbreak
patterns nor provide a fine-grained explanation from the failure of circuit to
the changes of representational, leaving significant gaps in uncovering the
jailbreak mechanism. In this paper, we propose JailbreakLens, an interpretation
framework that analyzes jailbreak mechanisms from both representation (which
reveals how jailbreaks alter the model's harmfulness perception) and circuit
perspectives (which uncovers the causes of these deceptions by identifying key
circuits contributing to the vulnerability), tracking their evolution
throughout the entire response generation process. We then conduct an in-depth
evaluation of jailbreak behavior on four mainstream LLMs under seven jailbreak
strategies. Our evaluation finds that jailbreak prompts amplify components that
reinforce affirmative responses while suppressing those that produce refusal.
Although this manipulation shifts model representations toward safe clusters to
deceive the LLM, leading it to provide detailed responses instead of refusals,
it still produce abnormal activation which can be caught in the circuit
analysis.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11114v1
Multilingual Large Language Models: A Systematic Survey,"Shaolin Zhu, Supryadi, Shaoyang Xu, Haoran Sun, Leiyu Pan, Menglong Cui, Jiangcun Du, Renren Jin, António Branco, Deyi Xiong",2024-11-17T13:21:26Z,"This paper provides a comprehensive survey of the latest research on
multilingual large language models (MLLMs). MLLMs not only are able to
understand and generate language across linguistic boundaries, but also
represent an important advancement in artificial intelligence. We first discuss
the architecture and pre-training objectives of MLLMs, highlighting the key
components and methodologies that contribute to their multilingual
capabilities. We then discuss the construction of multilingual pre-training and
alignment datasets, underscoring the importance of data quality and diversity
in enhancing MLLM performance. An important focus of this survey is on the
evaluation of MLLMs. We present a detailed taxonomy and roadmap covering the
assessment of MLLMs' cross-lingual knowledge, reasoning, alignment with human
values, safety, interpretability and specialized applications. Specifically, we
extensively discuss multilingual evaluation benchmarks and datasets, and
explore the use of LLMs themselves as multilingual evaluators. To enhance MLLMs
from black to white boxes, we also address the interpretability of multilingual
capabilities, cross-lingual transfer and language bias within these models.
Finally, we provide a comprehensive review of real-world applications of MLLMs
across diverse domains, including biology, medicine, computer science,
mathematics and law. We showcase how these models have driven innovation and
improvements in these specialized fields while also highlighting the challenges
and opportunities in deploying MLLMs within diverse language communities and
application scenarios. We listed the paper related in this survey and publicly
available at https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11072v2
"TS-LLaVA: Constructing Visual Tokens through Thumbnail-and-Sampling for
  Training-Free Video Large Language Models","Tingyu Qu, Mingxiao Li, Tinne Tuytelaars, Marie-Francine Moens",2024-11-17T13:08:29Z,"Recent advances in multimodal Large Language Models (LLMs) have shown great
success in understanding multi-modal contents. For video understanding tasks,
training-based video LLMs are difficult to build due to the scarcity of
high-quality, curated video-text paired data. In contrast, paired image-text
data are much easier to obtain, and there is substantial similarity between
images and videos. Consequently, extending image LLMs for video understanding
tasks presents an appealing alternative. Developing effective strategies for
compressing visual tokens from multiple frames is a promising way to leverage
the powerful pre-trained image LLM. In this work, we explore the limitations of
the existing compression strategies for building a training-free video LLM. The
findings lead to our method TS-LLaVA, which constructs visual tokens through a
Thumbnail-and-Sampling strategy. Given a video, we select few equidistant
frames from all input frames to construct a Thumbnail image as a detailed
visual cue, complemented by Sampled visual tokens from all input frames. Our
method establishes the new state-of-the-art performance among training-free
video LLMs on various benchmarks. Notably, our 34B model outperforms GPT-4V on
the MVBench benchmark, and achieves performance comparable to the 72B
training-based video LLM, Video-LLaMA2, on the challenging MLVU benchmark. Code
is available at https://github.com/tingyu215/TS-LLaVA.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11066v1
Patching FPGAs: The Security Implications of Bitstream Modifications,"Endres Puschner, Maik Ender, Steffen Becker, Christof Paar",2024-11-17T12:47:05Z,"Field Programmable Gate Arrays (FPGAs) are known for their reprogrammability
that allows for post-manufacture circuitry changes. Nowadays, they are integral
to a variety of systems including high-security applications such as aerospace
and military systems. However, this reprogrammability also introduces
significant security challenges, as bitstream manipulation can directly alter
hardware circuits. Malicious manipulations may lead to leakage of secret data
and the implementation of hardware Trojans. In this paper, we present a
comprehensive framework for manipulating bitstreams with minimal reverse
engineering, thereby exposing the potential risks associated with inadequate
bitstream protection. Our methodology does not require a complete understanding
of proprietary bitstream formats or a fully reverse-engineered target design.
Instead, it enables precise modifications by inserting pre-synthesized circuits
into existing bitstreams. This novel approach is demonstrated through a
semi-automated framework consisting of five steps: (1) partial bitstream
reverse engineering, (2) designing the modification, (3) placing and (4)
routing the modification into the existing circuit, and (5) merging of the
modification with the original bitstream. We validate our framework through
four practical case studies on the OpenTitan design synthesized for Xilinx
7-Series FPGAs. While current protections such as bitstream authentication and
encryption often fall short, our work highlights and discusses the urgency of
developing effective countermeasures. We recommend using FPGAs as trust anchors
only when bitstream manipulation attacks can be reliably excluded.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11060v1
Reinforcing Competitive Multi-Agents for Playing So Long Sucker,"Medant Sharan, Chandranath Adak",2024-11-17T12:38:13Z,"This paper examines the use of classical deep reinforcement learning (DRL)
algorithms, DQN, DDQN, and Dueling DQN, in the strategy game So Long Sucker
(SLS), a diplomacy-driven game defined by coalition-building and strategic
betrayal. SLS poses unique challenges due to its blend of cooperative and
adversarial dynamics, making it an ideal platform for studying multi-agent
learning and game theory. The study's primary goal is to teach autonomous
agents the game's rules and strategies using classical DRL methods. To support
this effort, the authors developed a novel, publicly available implementation
of SLS, featuring a graphical user interface (GUI) and benchmarking tools for
DRL algorithms. Experimental results reveal that while considered basic by
modern DRL standards, DQN, DDQN, and Dueling DQN agents achieved roughly 50% of
the maximum possible game reward. This suggests a baseline understanding of the
game's mechanics, with agents favoring legal moves over illegal ones. However,
a significant limitation was the extensive training required, around 2000
games, for agents to reach peak performance, compared to human players who
grasp the game within a few rounds. Even after prolonged training, agents
occasionally made illegal moves, highlighting both the potential and
limitations of these classical DRL methods in semi-complex, socially driven
games. The findings establish a foundational benchmark for training agents in
SLS and similar negotiation-based environments while underscoring the need for
advanced or hybrid DRL approaches to improve learning efficiency and
adaptability. Future research could incorporate game-theoretic strategies to
enhance agent decision-making in dynamic multi-agent contexts.",cs.AI,cs.AI,http://arxiv.org/abs/2411.11057v1
BianCang: A Traditional Chinese Medicine Large Language Model,"Sibo Wei, Xueping Peng, Yi-fei Wang, Jiasheng Si, Weiyu Zhang, Wenpeng Lu, Xiaoming Wu, Yinglong Wang",2024-11-17T10:17:01Z,"The rise of large language models (LLMs) has driven significant progress in
medical applications, including traditional Chinese medicine (TCM). However,
current medical LLMs struggle with TCM diagnosis and syndrome differentiation
due to substantial differences between TCM and modern medical theory, and the
scarcity of specialized, high-quality corpora. This paper addresses these
challenges by proposing BianCang, a TCM-specific LLM, using a two-stage
training process that first injects domain-specific knowledge and then aligns
it through targeted stimulation. To enhance diagnostic and differentiation
capabilities, we constructed pre-training corpora, instruction-aligned datasets
based on real hospital records, and the ChP-TCM dataset derived from the
Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and
medical corpora for continuous pre-training and supervised fine-tuning,
building a comprehensive dataset to refine the model's understanding of TCM.
Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the
effectiveness of BianCang, offering valuable insights for future research.
Code, datasets, and models are available at
https://github.com/QLU-NLP/BianCang.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11027v1
"Unveiling the Hidden: Online Vectorized HD Map Construction with
  Clip-Level Token Interaction and Propagation","Nayeon Kim, Hongje Seong, Daehyun Ji, Sujin Jang",2024-11-17T08:38:18Z,"Predicting and constructing road geometric information (e.g., lane lines,
road markers) is a crucial task for safe autonomous driving, while such static
map elements can be repeatedly occluded by various dynamic objects on the road.
Recent studies have shown significantly improved vectorized high-definition
(HD) map construction performance, but there has been insufficient
investigation of temporal information across adjacent input frames (i.e.,
clips), which may lead to inconsistent and suboptimal prediction results. To
tackle this, we introduce a novel paradigm of clip-level vectorized HD map
construction, MapUnveiler, which explicitly unveils the occluded map elements
within a clip input by relating dense image representations with efficient clip
tokens. Additionally, MapUnveiler associates inter-clip information through
clip token propagation, effectively utilizing long-term temporal map
information. MapUnveiler runs efficiently with the proposed clip-level pipeline
by avoiding redundant computation with temporal stride while building a global
map relationship. Our extensive experiments demonstrate that MapUnveiler
achieves state-of-the-art performance on both the nuScenes and Argoverse2
benchmark datasets. We also showcase that MapUnveiler significantly outperforms
state-of-the-art approaches in a challenging setting, achieving +10.7% mAP
improvement in heavily occluded driving road scenes. The project page can be
found at https://mapunveiler.github.io.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11002v1
"SymDPO: Boosting In-Context Learning of Large Multimodal Models with
  Symbol Demonstration Direct Preference Optimization","Hongrui Jia, Chaoya Jiang, Haiyang Xu, Wei Ye, Mengfan Dong, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang",2024-11-17T08:29:14Z,"As language models continue to scale, Large Language Models (LLMs) have
exhibited emerging capabilities in In-Context Learning (ICL), enabling them to
solve language tasks by prefixing a few in-context demonstrations (ICDs) as
context. Inspired by these advancements, researchers have extended these
techniques to develop Large Multimodal Models (LMMs) with ICL capabilities.
However, existing LMMs face a critical issue: they often fail to effectively
leverage the visual context in multimodal demonstrations and instead simply
follow textual patterns. This indicates that LMMs do not achieve effective
alignment between multimodal demonstrations and model outputs. To address this
problem, we propose Symbol Demonstration Direct Preference Optimization
(SymDPO). Specifically, SymDPO aims to break the traditional paradigm of
constructing multimodal demonstrations by using random symbols to replace text
answers within instances. This forces the model to carefully understand the
demonstration images and establish a relationship between the images and the
symbols to answer questions correctly. We validate the effectiveness of this
method on multiple benchmarks, demonstrating that with SymDPO, LMMs can more
effectively understand the multimodal context within examples and utilize this
knowledge to answer questions better.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11909v1
"From Crime to Hypercrime: Evolving Threats and Law Enforcement's New
  Mandate in the AI Age",Francesco Schiliro,2024-11-17T07:58:19Z,"The paper examines the trajectory of crime, tracing its evolution from
traditional forms to digital manifestations in cybercrime, and proposes
""Hypercrime"" as the latest frontier. Leveraging insights from Michael McGuire's
""Hypercrime: The New Geometry of Harm,"" the study calls for a paradigm shift in
law enforcement strategies to meet the challenges posed by AI-driven
hypercrime. Emphasis is placed on understanding hypercrime's complexity,
developing proactive policies, and embracing technological tools to mitigate
risks associated with AI misuse.",cs.CY,cs.CY,http://arxiv.org/abs/2411.10995v1
VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?,"Yunlong Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng, Xinyang Li, Rui Mao, Chao Huang, Jing Bi, Zeliang Zhang, Pooyan Fazli, Chenliang Xu",2024-11-17T06:23:46Z,"The advancement of Multimodal Large Language Models (MLLMs) has enabled
significant progress in multimodal understanding, expanding their capacity to
analyze video content. However, existing evaluation benchmarks for MLLMs
primarily focus on abstract video comprehension, lacking a detailed assessment
of their ability to understand video compositions, the nuanced interpretation
of how visual elements combine and interact within highly compiled video
contexts. We introduce VidComposition, a new benchmark specifically designed to
evaluate the video composition understanding capabilities of MLLMs using
carefully curated compiled videos and cinematic-level annotations.
VidComposition includes 982 videos with 1706 multiple-choice questions,
covering various compositional aspects such as camera movement, angle, shot
size, narrative structure, character actions and emotions, etc. Our
comprehensive evaluation of 33 open-source and proprietary MLLMs reveals a
significant performance gap between human and model capabilities. This
highlights the limitations of current MLLMs in understanding complex, compiled
video compositions and offers insights into areas for further improvement. The
leaderboard and evaluation code are available at
https://yunlong10.github.io/VidComposition/.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10979v2
"Beamforming Design and Multi-User Scheduling in Transmissive RIS Enabled
  Distributed Cooperative ISAC Networks with RSMA","Ziwei Liu, Wen Chen, Qingqing Wu, Zhendong Li, Qiong Wu, Nan Cheng, Jun Li",2024-11-17T04:46:25Z,"In this paper, we propose a novel transmissive reconfigurable intelligent
surface (TRIS) transceiver-empowered distributed cooperative integrated sensing
and communication (ISAC) network to enhance coverage as well as to enhance
wireless environment understanding. Based on the network requirements, the
users are categorized into cooperative users (CUEs) and destination users
(DUEs), and the CUEs utilize their own resources to serve the DUEs. To realize
cooperation, we implement rate-splitting multiple access (RSMA) at the base
station (BS), where the common stream is decoded and reencoded at the CUEs and
forwarded to the DUEs, while the private stream satisfies the CUEs' own
communication requirements. We construct an optimization problem with maximum
minimum radar mutual information (RMI) as the objective function to optimize
the BS beamforming matrix, the CUE beamforming matrices, the common stream rate
vectors, and the user scheduling vectors. Due to the coupling of the
optimization variables and non-convex operation, the proposed problem is a
non-convex optimization problem that cannot be solved directly. To address the
above challenges, we adopt a consensus alternating direction method of
multipliers (ADMM) framework to decouple the optimization variables and solve
it. Specifically, the problem is decoupled into multiple subproblems and solved
by iterative optimization independently until overall convergence is achieved.
Finally, numerical results validate the superiority of the proposed scheme in
terms of improving communication sum-rate and RMI, and greatly reduce the
algorithm complexity.","cs.IT, math.IT",cs.IT,http://arxiv.org/abs/2411.10960v1
"To Adopt or Not to Adopt L4S-compatible Congestion Control?
  Understanding Performance in a Partial L4S Deployment","Fatih Berkay Sarpkaya, Fraida Fund, Shivendra Panwar",2024-11-17T03:37:16Z,"With few exceptions, the path to deployment for any Internet technology
requires that there be some benefit to unilateral adoption of the new
technology. In an Internet where the technology is not fully deployed, is an
individual better off sticking to the status quo, or adopting the new
technology? This question is especially relevant in the context of the Low
Latency, Low Loss, Scalable Throughput (L4S) architecture, where the full
benefit is realized only when compatible protocols (scalable congestion
control, accurate ECN, and flow isolation at queues) are adopted at both
endpoints of a connection and also at the bottleneck router. In this paper, we
consider the perspective of the sender of an L4S flow using scalable congestion
control, without knowing whether the bottleneck router uses an L4S queue, or
whether other flows sharing the bottleneck queue are also using scalable
congestion control. We show that whether the sender uses TCP Prague or BBRv2 as
the scalable congestion control, it cannot be assured that it will not harm or
be harmed by another flow sharing the bottleneck link. We further show that the
harm is not necessarily mitigated when a scalable flow shares a bottleneck with
multiple classic flows. Finally, we evaluate the approach of BBRv3, where
scalable congestion control is used only when the path delay is small, and ECN
feedback is ignored otherwise, and we show that it is not effective for
coexistence in this scenario.",cs.NI,cs.NI,http://arxiv.org/abs/2411.10952v1
"Understanding Multimodal LLMs: the Mechanistic Interpretability of Llava
  in Visual Question Answering","Zeping Yu, Sophia Ananiadou",2024-11-17T03:32:50Z,"Understanding the mechanisms behind Large Language Models (LLMs) is crucial
for designing improved models and strategies. While recent studies have yielded
valuable insights into the mechanisms of textual LLMs, the mechanisms of
Multi-modal Large Language Models (MLLMs) remain underexplored. In this paper,
we apply mechanistic interpretability methods to analyze the visual question
answering (VQA) mechanisms in the first MLLM, Llava. We compare the mechanisms
between VQA and textual QA (TQA) in color answering tasks and find that: a) VQA
exhibits a mechanism similar to the in-context learning mechanism observed in
TQA; b) the visual features exhibit significant interpretability when
projecting the visual embeddings into the embedding space; and c) Llava
enhances the existing capabilities of the corresponding textual LLM Vicuna
during visual instruction tuning. Based on these findings, we develop an
interpretability tool to help users and researchers identify important visual
locations for final predictions, aiding in the understanding of visual
hallucination. Our method demonstrates faster and more effective results
compared to existing interpretability approaches. Code:
\url{https://github.com/zepingyu0512/llava-mechanism}",cs.CL,cs.CL,http://arxiv.org/abs/2411.10950v1
"Anomaly Detection for People with Visual Impairments Using an Egocentric
  360-Degree Camera","Inpyo Song, Sanghyeon Lee, Minjun Joo, Jangwon Lee",2024-11-17T02:52:34Z,"Recent advancements in computer vision have led to a renewed interest in
developing assistive technologies for individuals with visual impairments.
Although extensive research has been conducted in the field of computer
vision-based assistive technologies, most of the focus has been on
understanding contexts in images, rather than addressing their physical safety
and security concerns. To address this challenge, we propose the first step
towards detecting anomalous situations for visually impaired people by
observing their entire surroundings using an egocentric 360-degree camera. We
first introduce a novel egocentric 360-degree video dataset called VIEW360
(Visually Impaired Equipped with Wearable 360-degree camera), which contains
abnormal activities that visually impaired individuals may encounter, such as
shoulder surfing and pickpocketing. Furthermore, we propose a new architecture
called the FDPN (Frame and Direction Prediction Network), which facilitates
frame-level prediction of abnormal events and identifying of their directions.
Finally, we evaluate our approach on our VIEW360 dataset and the publicly
available UCF-Crime and Shanghaitech datasets, demonstrating state-of-the-art
performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10945v1
"A Monocular SLAM-based Multi-User Positioning System with Image
  Occlusion in Augmented Reality","Wei-Hsiang Lien, Benedictus Kent Chandra, Robin Fischer, Ya-Hui Tang, Shiann-Jang Wang, Wei-En Hsu, Li-Chen Fu",2024-11-17T02:39:30Z,"In recent years, with the rapid development of augmented reality (AR)
technology, there is an increasing demand for multi-user collaborative
experiences. Unlike for single-user experiences, ensuring the spatial
localization of every user and maintaining synchronization and consistency of
positioning and orientation across multiple users is a significant challenge.
In this paper, we propose a multi-user localization system based on ORB-SLAM2
using monocular RGB images as a development platform based on the Unity 3D game
engine. This system not only performs user localization but also places a
common virtual object on a planar surface (such as table) in the environment so
that every user holds a proper perspective view of the object. These generated
virtual objects serve as reference points for multi-user position
synchronization. The positioning information is passed among every user's AR
devices via a central server, based on which the relative position and movement
of other users in the space of a specific user are presented via virtual
avatars all with respect to these virtual objects. In addition, we use deep
learning techniques to estimate the depth map of an image from a single RGB
image to solve occlusion problems in AR applications, making virtual objects
appear more natural in AR scenes.","cs.HC, cs.CV",cs.HC,http://arxiv.org/abs/2411.10940v1
"Evaluating Generative AI Systems is a Social Science Measurement
  Challenge","Hanna Wallach, Meera Desai, Nicholas Pangakis, A. Feder Cooper, Angelina Wang, Solon Barocas, Alexandra Chouldechova, Chad Atalla, Su Lin Blodgett, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Alexandra Olteanu, Stefanie Reed, Emily Sheng, Dan Vann, Jennifer Wortman Vaughan, Matthew Vogel, Hannah Washington, Abigail Z. Jacobs",2024-11-17T02:35:30Z,"Across academia, industry, and government, there is an increasing awareness
that the measurement tasks involved in evaluating generative AI (GenAI) systems
are especially difficult. We argue that these measurement tasks are highly
reminiscent of measurement tasks found throughout the social sciences. With
this in mind, we present a framework, grounded in measurement theory from the
social sciences, for measuring concepts related to the capabilities, impacts,
opportunities, and risks of GenAI systems. The framework distinguishes between
four levels: the background concept, the systematized concept, the measurement
instrument(s), and the instance-level measurements themselves. This four-level
approach differs from the way measurement is typically done in ML, where
researchers and practitioners appear to jump straight from background concepts
to measurement instruments, with little to no explicit systematization in
between. As well as surfacing assumptions, thereby making it easier to
understand exactly what the resulting measurements do and do not mean, this
framework has two important implications for evaluating evaluations: First, it
can enable stakeholders from different worlds to participate in conceptual
debates, broadening the expertise involved in evaluating GenAI systems. Second,
it brings rigor to operational debates by offering a set of lenses for
interrogating the validity of measurement instruments and their resulting
measurements.",cs.CY,cs.CY,http://arxiv.org/abs/2411.10939v1
"Memory-Augmented Multimodal LLMs for Surgical VQA via Self-Contained
  Inquiry","Wenjun Hou, Yi Cheng, Kaishuai Xu, Yan Hu, Wenjie Li, Jiang Liu",2024-11-17T02:23:45Z,"Comprehensively understanding surgical scenes in Surgical Visual Question
Answering (Surgical VQA) requires reasoning over multiple objects. Previous
approaches address this task using cross-modal fusion strategies to enhance
reasoning ability. However, these methods often struggle with limited scene
understanding and question comprehension, and some rely on external resources
(e.g., pre-extracted object features), which can introduce errors and
generalize poorly across diverse surgical environments. To address these
challenges, we propose SCAN, a simple yet effective memory-augmented framework
that leverages Multimodal LLMs to improve surgical context comprehension via
Self-Contained Inquiry. SCAN operates autonomously, generating two types of
memory for context augmentation: Direct Memory (DM), which provides multiple
candidates (or hints) to the final answer, and Indirect Memory (IM), which
consists of self-contained question-hint pairs to capture broader scene
context. DM directly assists in answering the question, while IM enhances
understanding of the surgical scene beyond the immediate query. Reasoning over
these object-aware memories enables the model to accurately interpret images
and respond to questions. Extensive experiments on three publicly available
Surgical VQA datasets demonstrate that SCAN achieves state-of-the-art
performance, offering improved accuracy and robustness across various surgical
scenarios.","cs.CV, cs.CL",cs.CV,http://arxiv.org/abs/2411.10937v1
"Multi-Modal Self-Supervised Learning for Surgical Feedback Effectiveness
  Assessment","Arushi Gupta, Rafal Kocielnik, Jiayun Wang, Firdavs Nasriddinov, Cherine Yang, Elyssa Wong, Anima Anandkumar, Andrew Hung",2024-11-17T00:13:00Z,"During surgical training, real-time feedback from trainers to trainees is
important for preventing errors and enhancing long-term skill acquisition.
Accurately predicting the effectiveness of this feedback, specifically whether
it leads to a change in trainee behavior, is crucial for developing methods for
improving surgical training and education. However, relying on human
annotations to assess feedback effectiveness is laborious and prone to biases,
underscoring the need for an automated, scalable, and objective method.
Creating such an automated system poses challenges, as it requires an
understanding of both the verbal feedback delivered by the trainer and the
visual context of the real-time surgical scene. To address this, we propose a
method that integrates information from transcribed verbal feedback and
corresponding surgical video to predict feedback effectiveness. Our findings
show that both transcribed feedback and surgical video are individually
predictive of trainee behavior changes, and their combination achieves an AUROC
of 0.70+/-0.02, improving prediction accuracy by up to 6.6%. Additionally, we
introduce self-supervised fine-tuning as a strategy for enhancing surgical
video representation learning, which is scalable and further enhances
prediction performance. Our results demonstrate the potential of multi-modal
learning to advance the automated assessment of surgical feedback.","cs.LG, cs.AI, cs.CV, 68T07, 68T45, 68U10, 92C50, I.2; I.2.10; I.5.4; I.4.7; J.3; K.3.1",cs.LG,http://arxiv.org/abs/2411.10919v1
"Bias in Large Language Models: Origin, Evaluation, and Mitigation","Yufei Guo, Muzhe Guo, Juntao Su, Zhou Yang, Mengqiu Zhu, Hongfei Li, Mengyang Qiu, Shuo Shuo Liu",2024-11-16T23:54:53Z,"Large Language Models (LLMs) have revolutionized natural language processing,
but their susceptibility to biases poses significant challenges. This
comprehensive review examines the landscape of bias in LLMs, from its origins
to current mitigation strategies. We categorize biases as intrinsic and
extrinsic, analyzing their manifestations in various NLP tasks. The review
critically assesses a range of bias evaluation methods, including data-level,
model-level, and output-level approaches, providing researchers with a robust
toolkit for bias detection. We further explore mitigation strategies,
categorizing them into pre-model, intra-model, and post-model techniques,
highlighting their effectiveness and limitations. Ethical and legal
implications of biased LLMs are discussed, emphasizing potential harms in
real-world applications such as healthcare and criminal justice. By
synthesizing current knowledge on bias in LLMs, this review contributes to the
ongoing effort to develop fair and responsible AI systems. Our work serves as a
comprehensive resource for researchers and practitioners working towards
understanding, evaluating, and mitigating bias in LLMs, fostering the
development of more equitable AI technologies.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.10915v1
"Generating Compositional Scenes via Text-to-image RGBA Instance
  Generation","Alessandro Fontanella, Petru-Daniel Tudosiu, Yongxin Yang, Shifeng Zhang, Sarah Parisot",2024-11-16T23:44:14Z,"Text-to-image diffusion generative models can generate high quality images at
the cost of tedious prompt engineering. Controllability can be improved by
introducing layout conditioning, however existing methods lack layout editing
ability and fine-grained control over object attributes. The concept of
multi-layer generation holds great potential to address these limitations,
however generating image instances concurrently to scene composition limits
control over fine-grained object attributes, relative positioning in 3D space
and scene manipulation abilities. In this work, we propose a novel multi-stage
generation paradigm that is designed for fine-grained control, flexibility and
interactivity. To ensure control over instance attributes, we devise a novel
training paradigm to adapt a diffusion model to generate isolated scene
components as RGBA images with transparency information. To build complex
images, we employ these pre-generated instances and introduce a multi-layer
composite generation process that smoothly assembles components in realistic
scenes. Our experiments show that our RGBA diffusion model is capable of
generating diverse and high quality instances with precise control over object
attributes. Through multi-layer composition, we demonstrate that our approach
allows to build and manipulate images from highly complex prompts with
fine-grained control over object appearance and location, granting a higher
degree of control than competing methods.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10913v1
"An Empirical Investigation on the Challenges in Scientific Workflow
  Systems Development","Khairul Alam, Chanchal Roy, Banani Roy, Kartik Mittal",2024-11-16T21:14:11Z,"Scientific Workflow Systems (SWSs) are advanced software frameworks that
drive modern research by orchestrating complex computational tasks and managing
extensive data pipelines. These systems offer a range of essential features,
including modularity, abstraction, interoperability, workflow composition
tools, resource management, error handling, and comprehensive documentation.
Utilizing these frameworks accelerates the development of scientific computing,
resulting in more efficient and reproducible research outcomes. However,
developing a user-friendly, efficient, and adaptable SWS poses several
challenges. This study explores these challenges through an in-depth analysis
of interactions on Stack Overflow (SO) and GitHub, key platforms where
developers and researchers discuss and resolve issues. In particular, we
leverage topic modeling (BERTopic) to understand the topics SWSs developers
discuss on these platforms. We identified 10 topics developers discuss on SO
(e.g., Workflow Creation and Scheduling, Data Structures and Operations,
Workflow Execution) and found that workflow execution is the most challenging.
By analyzing GitHub issues, we identified 13 topics (e.g., Errors and Bug
Fixing, Documentation, Dependencies) and discovered that data structures and
operations is the most difficult. We also found common topics between SO and
GitHub, such as data structures and operations, task management, and workflow
scheduling. Additionally, we categorized each topic by type (How, Why, What,
and Others). We observed that the How type consistently dominates across all
topics, indicating a need for procedural guidance among developers. The
dominance of the How type is also evident in domains like Chatbots and Mobile
development. Our study will guide future research in proposing tools and
techniques to help the community overcome the challenges developers face when
developing SWSs.","cs.SE, ACM",cs.SE,http://arxiv.org/abs/2411.10890v1
"MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric
  Depth Estimation","Ansh Shah, K Madhava Krishna",2024-11-16T20:59:01Z,"Recovering metric depth from a single image remains a fundamental challenge
in computer vision, requiring both scene understanding and accurate scaling.
While deep learning has advanced monocular depth estimation, current models
often struggle with unfamiliar scenes and layouts, particularly in zero-shot
scenarios and when predicting scale-ergodic metric depth. We present
MetricGold, a novel approach that harnesses generative diffusion model's rich
priors to improve metric depth estimation. Building upon recent advances in
MariGold, DDVM and Depth Anything V2 respectively, our method combines latent
diffusion, log-scaled metric depth representation, and synthetic data training.
MetricGold achieves efficient training on a single RTX 3090 within two days
using photo-realistic synthetic data from HyperSIM, VirtualKitti, and
TartanAir. Our experiments demonstrate robust generalization across diverse
datasets, producing sharper and higher quality metric depth estimates compared
to existing approaches.","cs.CV, cs.AI, cs.GR, cs.RO",cs.CV,http://arxiv.org/abs/2411.10886v1
"Empowering Meta-Analysis: Leveraging Large Language Models for
  Scientific Synthesis","Jawad Ibn Ahad, Rafeed Mohammad Sultan, Abraham Kaikobad, Fuad Rahman, Mohammad Ruhul Amin, Nabeel Mohammed, Shafin Rahman",2024-11-16T20:18:57Z,"This study investigates the automation of meta-analysis in scientific
documents using large language models (LLMs). Meta-analysis is a robust
statistical method that synthesizes the findings of multiple studies support
articles to provide a comprehensive understanding. We know that a meta-article
provides a structured analysis of several articles. However, conducting
meta-analysis by hand is labor-intensive, time-consuming, and susceptible to
human error, highlighting the need for automated pipelines to streamline the
process. Our research introduces a novel approach that fine-tunes the LLM on
extensive scientific datasets to address challenges in big data handling and
structured data extraction. We automate and optimize the meta-analysis process
by integrating Retrieval Augmented Generation (RAG). Tailored through prompt
engineering and a new loss metric, Inverse Cosine Distance (ICD), designed for
fine-tuning on large contextual datasets, LLMs efficiently generate structured
meta-analysis content. Human evaluation then assesses relevance and provides
information on model performance in key metrics. This research demonstrates
that fine-tuned models outperform non-fine-tuned models, with fine-tuned LLMs
generating 87.6% relevant meta-analysis abstracts. The relevance of the
context, based on human evaluation, shows a reduction in irrelevancy from 4.56%
to 1.9%. These experiments were conducted in a low-resource environment,
highlighting the study's contribution to enhancing the efficiency and
reliability of meta-analysis automation.","cs.CL, cs.AI, cs.IR",cs.CL,http://arxiv.org/abs/2411.10878v1
"Examem: Low-Overhead Memory Instrumentation for Intelligent Memory
  Systems","Ashwin Poduval, Hayden Coffey, Michael Swift",2024-11-16T19:24:11Z,"Memory performance is often the main bottleneck in modern computing systems.
In recent years, researchers have attempted to scale the memory wall by
leveraging new technology such as CXL, HBM, and in- and near-memory processing.
Developers optimizing for such hardware need to understand how target
applications perform to fully take advantage of these systems. Existing
software and hardware performance introspection techniques are ill-suited for
this purpose due to one or more of the following factors: coarse-grained
measurement, inability to offer data needed to debug key issues, high runtime
overhead, and hardware dependence. The heightened integration between compute
and memory in many proposed systems offers an opportunity to extend compiler
support for this purpose.
  We have developed Examem, a memory performance introspection framework based
on the LLVM compiler infrastructure. Examem supports developer annotated
regions in code, allowing for targeted instrumentation of kernels. Examem
supports hardware performance counters when available, in addition to software
instrumentation. It statically records information about the instruction mix of
the code and adds dynamic instrumentation to produce estimated memory bandwidth
for an instrumented region at runtime. This combined approach keeps runtime
overhead low while remaining accurate, with a geomean overhead under 10% and a
geomean byte accuracy of 93%. Finally, our instrumentation is performed using
an LLVM IR pass, which is target agnostic, and we have applied it to four ISAs.","cs.PF, cs.AR",cs.PF,http://arxiv.org/abs/2411.12583v1
"Large Language Models (LLMs) as Traffic Control Systems at Urban
  Intersections: A New Paradigm","Sari Masri, Huthaifa I. Ashqar, Mohammed Elhenawy",2024-11-16T19:23:52Z,"This study introduces a novel approach for traffic control systems by using
Large Language Models (LLMs) as traffic controllers. The study utilizes their
logical reasoning, scene understanding, and decision-making capabilities to
optimize throughput and provide feedback based on traffic conditions in
real-time. LLMs centralize traditionally disconnected traffic control processes
and can integrate traffic data from diverse sources to provide context-aware
decisions. LLMs can also deliver tailored outputs using various means such as
wireless signals and visuals to drivers, infrastructures, and autonomous
vehicles. To evaluate LLMs ability as traffic controllers, this study proposed
a four-stage methodology. The methodology includes data creation and
environment initialization, prompt engineering, conflict identification, and
fine-tuning. We simulated multi-lane four-leg intersection scenarios and
generates detailed datasets to enable conflict detection using LLMs and Python
simulation as a ground truth. We used chain-of-thought prompts to lead LLMs in
understanding the context, detecting conflicts, resolving them using traffic
rules, and delivering context-sensitive traffic management solutions. We
evaluated the prformance GPT-mini, Gemini, and Llama as traffic controllers.
Results showed that the fine-tuned GPT-mini achieved 83% accuracy and an
F1-score of 0.84. GPT-mini model exhibited a promising performance in
generating actionable traffic management insights, with high ROUGE-L scores
across conflict identification of 0.95, decision-making of 0.91, priority
assignment of 0.94, and waiting time optimization of 0.92. We demonstrated that
LLMs can offer precise recommendations to drivers in real-time including
yielding, slowing, or stopping based on vehicle dynamics.","cs.CL, cs.CE, cs.CY, cs.HC",cs.CL,http://arxiv.org/abs/2411.10869v1
"ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large
  Multimodal Models","Vipula Rawte, Sarthak Jain, Aarush Sinha, Garv Kaushik, Aman Bansal, Prathiksha Rumale Vishwanath, Samyak Rajesh Jain, Aishwarya Naresh Reganti, Vinija Jain, Aman Chadha, Amit P. Sheth, Amitava Das",2024-11-16T19:23:12Z,"Latest developments in Large Multimodal Models (LMMs) have broadened their
capabilities to include video understanding. Specifically, Text-to-video (T2V)
models have made significant progress in quality, comprehension, and duration,
excelling at creating videos from simple textual prompts. Yet, they still
frequently produce hallucinated content that clearly signals the video is
AI-generated. We introduce ViBe: a large-scale Text-to-Video Benchmark of
hallucinated videos from T2V models. We identify five major types of
hallucination: Vanishing Subject, Numeric Variability, Temporal Dysmorphia,
Omission Error, and Physical Incongruity. Using 10 open-source T2V models, we
developed the first large-scale dataset of hallucinated videos, comprising
3,782 videos annotated by humans into these five categories. ViBe offers a
unique resource for evaluating the reliability of T2V models and provides a
foundation for improving hallucination detection and mitigation in video
generation. We establish classification as a baseline and present various
ensemble classifier configurations, with the TimeSFormer + CNN combination
yielding the best performance, achieving 0.345 accuracy and 0.342 F1 score.
This benchmark aims to drive the development of robust T2V models that produce
videos more accurately aligned with input prompts.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10867v1
Education in the Era of Neurosymbolic AI,"Chris Davis Jaldi, Eleni Ilkou, Noah Schroeder, Cogan Shimizu",2024-11-16T19:18:39Z,"Education is poised for a transformative shift with the advent of
neurosymbolic artificial intelligence (NAI), which will redefine how we support
deeply adaptive and personalized learning experiences. NAI-powered education
systems will be capable of interpreting complex human concepts and contexts
while employing advanced problem-solving strategies, all grounded in
established pedagogical frameworks. This will enable a level of personalization
in learning systems that to date has been largely unattainable at scale,
providing finely tailored curricula that adapt to an individual's learning pace
and accessibility needs, including the diagnosis of student understanding of
subjects at a fine-grained level, identifying gaps in foundational knowledge,
and adjusting instruction accordingly. In this paper, we propose a system that
leverages the unique affordances of pedagogical agents -- embodied characters
designed to enhance learning -- as critical components of a hybrid NAI
architecture. To do so, these agents can thus simulate nuanced discussions,
debates, and problem-solving exercises that push learners beyond rote
memorization toward deep comprehension. We discuss the rationale for our system
design and the preliminary findings of our work. We conclude that education in
the era of NAI will make learning more accessible, equitable, and aligned with
real-world skills. This is an era that will explore a new depth of
understanding in educational tools.","cs.HC, cs.AI, cs.CY",cs.HC,http://arxiv.org/abs/2411.12763v1
Information Anxiety in Large Language Models,"Prasoon Bajpai, Sarah Masud, Tanmoy Chakraborty",2024-11-16T14:28:33Z,"Large Language Models (LLMs) have demonstrated strong performance as
knowledge repositories, enabling models to understand user queries and generate
accurate and context-aware responses. Extensive evaluation setups have
corroborated the positive correlation between the retrieval capability of LLMs
and the frequency of entities in their pretraining corpus. We take the
investigation further by conducting a comprehensive analysis of the internal
reasoning and retrieval mechanisms of LLMs. Our work focuses on three critical
dimensions - the impact of entity popularity, the models' sensitivity to
lexical variations in query formulation, and the progression of hidden state
representations across LLM layers. Our preliminary findings reveal that popular
questions facilitate early convergence of internal states toward the correct
answer. However, as the popularity of a query increases, retrieved attributes
across lexical variations become increasingly dissimilar and less accurate.
Interestingly, we find that LLMs struggle to disentangle facts, grounded in
distinct relations, from their parametric memory when dealing with highly
popular subjects. Through a case study, we explore these latent strains within
LLMs when processing highly popular queries, a phenomenon we term information
anxiety. The emergence of information anxiety in LLMs underscores the
adversarial injection in the form of linguistic variations and calls for a more
holistic evaluation of frequently occurring entities.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10813v1
"Can Generic LLMs Help Analyze Child-adult Interactions Involving
  Children with Autism in Clinical Observation?","Tiantian Feng, Anfeng Xu, Rimita Lahiri, Helen Tager-Flusberg, So Hyun Kim, Somer Bishop, Catherine Lord, Shrikanth Narayanan",2024-11-16T09:36:56Z,"Large Language Models (LLMs) have shown significant potential in
understanding human communication and interaction. However, their performance
in the domain of child-inclusive interactions, including in clinical settings,
remains less explored. In this work, we evaluate generic LLMs' ability to
analyze child-adult dyadic interactions in a clinically relevant context
involving children with ASD. Specifically, we explore LLMs in performing four
tasks: classifying child-adult utterances, predicting engaged activities,
recognizing language skills and understanding traits that are clinically
relevant. Our evaluation shows that generic LLMs are highly capable of
analyzing long and complex conversations in clinical observation sessions,
often surpassing the performance of non-expert human evaluators. The results
show their potential to segment interactions of interest, assist in language
skills evaluation, identify engaged activities, and offer clinical-relevant
context for assessments.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10761v1
"LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed
  Multi-Label Classification and Fairness Challenges","Chin-Wei Huang, Mu-Yi Shen, Kuan-Chang Shih, Shih-Chih Lin, Chi-Yu Chen, Po-Chih Kuo",2024-11-16T08:59:20Z,"Chest X-rays (CXRs) often display various diseases with disparate class
frequencies, leading to a long-tailed, multi-label data distribution. In
response to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a
curated collection derived from the MIMIC-CXR dataset, specifically designed to
represent a long-tailed and multi-label data scenario. We introduce LTCXNet, a
novel framework that integrates the ConvNeXt model, ML-Decoder, and strategic
data augmentation, further enhanced by an ensemble approach. We demonstrate
that LTCXNet improves the performance of CXR interpretation across all classes,
especially enhancing detection in rarer classes like `Pneumoperitoneum' and
`Pneumomediastinum' by 79\% and 48\%, respectively. Beyond performance metrics,
our research extends into evaluating fairness, highlighting that some methods,
while improving model accuracy, could inadvertently affect fairness across
different demographic groups negatively. This work contributes to advancing the
understanding and management of long-tailed, multi-label data distributions in
medical imaging, paving the way for more equitable and effective diagnostic
tools.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10746v1
"Comparison of Multilingual and Bilingual Models for Satirical News
  Detection of Arabic and English","Omar W. Abdalla, Aditya Joshi, Rahat Masood, Salil S. Kanhere",2024-11-16T07:49:15Z,"Satirical news is real news combined with a humorous comment or exaggerated
content, and it often mimics the format and style of real news. However,
satirical news is often misunderstood as misinformation, especially by
individuals from different cultural and social backgrounds. This research
addresses the challenge of distinguishing satire from truthful news by
leveraging multilingual satire detection methods in English and Arabic. We
explore both zero-shot and chain-of-thought (CoT) prompting using two language
models, Jais-chat(13B) and LLaMA-2-chat(7B). Our results show that CoT
prompting offers a significant advantage for the Jais-chat model over the
LLaMA-2-chat model. Specifically, Jais-chat achieved the best performance, with
an F1-score of 80\% in English when using CoT prompting. These results
highlight the importance of structured reasoning in CoT, which enhances
contextual understanding and is vital for complex tasks like satire detection.","cs.CL, cs.CR",cs.CL,http://arxiv.org/abs/2411.10730v1
DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment,"Mangyu Kong, Jaewon Lee, Seongwon Lee, Euntai Kim",2024-11-16T07:02:46Z,"We introduce Dynamic Gaussian Splatting SLAM (DGS-SLAM), the first dynamic
SLAM framework built on the foundation of Gaussian Splatting. While recent
advancements in dense SLAM have leveraged Gaussian Splatting to enhance scene
representation, most approaches assume a static environment, making them
vulnerable to photometric and geometric inconsistencies caused by dynamic
objects. To address these challenges, we integrate Gaussian Splatting SLAM with
a robust filtering process to handle dynamic objects throughout the entire
pipeline, including Gaussian insertion and keyframe selection. Within this
framework, to further improve the accuracy of dynamic object removal, we
introduce a robust mask generation method that enforces photometric consistency
across keyframes, reducing noise from inaccurate segmentation and artifacts
such as shadows. Additionally, we propose the loop-aware window selection
mechanism, which utilizes unique keyframe IDs of 3D Gaussians to detect loops
between the current and past frames, facilitating joint optimization of the
current camera poses and the Gaussian map. DGS-SLAM achieves state-of-the-art
performance in both camera tracking and novel view synthesis on various dynamic
SLAM benchmarks, proving its effectiveness in handling real-world dynamic
scenes.",cs.RO,cs.RO,http://arxiv.org/abs/2411.10722v1
"AllRestorer: All-in-One Transformer for Image Restoration under
  Composite Degradations","Jiawei Mao, Yu Yang, Xuesong Yin, Ling Shao, Hao Tang",2024-11-16T05:30:55Z,"Image restoration models often face the simultaneous interaction of multiple
degradations in real-world scenarios. Existing approaches typically handle
single or composite degradations based on scene descriptors derived from text
or image embeddings. However, due to the varying proportions of different
degradations within an image, these scene descriptors may not accurately
differentiate between degradations, leading to suboptimal restoration in
practical applications. To address this issue, we propose a novel
Transformer-based restoration framework, AllRestorer. In AllRestorer, we enable
the model to adaptively consider all image impairments, thereby avoiding errors
from scene descriptor misdirection. Specifically, we introduce an All-in-One
Transformer Block (AiOTB), which adaptively removes all degradations present in
a given image by modeling the relationships between all degradations and the
image embedding in latent space. To accurately address different variations
potentially present within the same type of degradation and minimize ambiguity,
AiOTB utilizes a composite scene descriptor consisting of both image and text
embeddings to define the degradation. Furthermore, AiOTB includes an adaptive
weight for each degradation, allowing for precise control of the restoration
intensity. By leveraging AiOTB, AllRestorer avoids misdirection caused by
inaccurate scene descriptors, achieving a 5.00 dB increase in PSNR compared to
the baseline on the CDD-11 dataset.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10708v1
EDBooks: AI-Enhanced Interactive Narratives for Programming Education,"Steve Oney, Yue Shen, Fei Wu, Young Suh Hong, Ziang Wang, Yamini Khajekar, Jiacheng Zhang, April Yi Wang",2024-11-16T03:23:50Z,"Large Language Models (LLMs) have shown the potential to be valuable teaching
tools, with the potential of giving every student a personalized tutor.
However, one challenge with using LLMs to learn new concepts is that when
learning a topic in an unfamiliar domain, it can be difficult to know what
questions to ask. Further, language models do not always encourage ""active
learning"" where students can test and assess their understanding. In this
paper, we propose ways to combine large language models with ""traditional""
learning materials (like e-books) to give readers the benefits of working with
LLMs (the ability to ask personally interesting questions and receive
personalized answers) with the benefits of a traditional e-book (having a
structure and content that is pedagogically sound). This work shows one way
that LLMs have the potential to improve learning materials and make
personalized programming education more accessible to a broader audience.",cs.HC,cs.HC,http://arxiv.org/abs/2411.10687v1
"I'm Spartacus, No, I'm Spartacus: Measuring and Understanding LLM
  Identity Confusion","Kun Li, Shichao Zhuang, Yue Zhang, Minghui Xu, Ruoxi Wang, Kaidi Xu, Xinwen Fu, Xiuzhen Cheng",2024-11-16T03:20:39Z,"Large Language Models (LLMs) excel in diverse tasks such as text generation,
data analysis, and software development, making them indispensable across
domains like education, business, and creative industries. However, the rapid
proliferation of LLMs (with over 560 companies developing or deploying them as
of 2024) has raised concerns about their originality and trustworthiness. A
notable issue, termed identity confusion, has emerged, where LLMs misrepresent
their origins or identities. This study systematically examines identity
confusion through three research questions: (1) How prevalent is identity
confusion among LLMs? (2) Does it arise from model reuse, plagiarism, or
hallucination? (3) What are the security and trust-related impacts of identity
confusion? To address these, we developed an automated tool combining
documentation analysis, self-identity recognition testing, and output
similarity comparisons--established methods for LLM fingerprinting--and
conducted a structured survey via Credamo to assess its impact on user trust.
Our analysis of 27 LLMs revealed that 25.93% exhibit identity confusion. Output
similarity analysis confirmed that these issues stem from hallucinations rather
than replication or reuse. Survey results further highlighted that identity
confusion significantly erodes trust, particularly in critical tasks like
education and professional use, with declines exceeding those caused by logical
errors or inconsistencies. Users attributed these failures to design flaws,
incorrect training data, and perceived plagiarism, underscoring the systemic
risks posed by identity confusion to LLM reliability and trustworthiness.",cs.CR,cs.CR,http://arxiv.org/abs/2411.10683v1
"SPDFusion: An Infrared and Visible Image Fusion Network Based on a
  Non-Euclidean Representation of Riemannian Manifolds","Huan Kang, Hui Li, Tianyang Xu, Rui Wang, Xiao-Jun Wu, Josef Kittler",2024-11-16T03:09:49Z,"Euclidean representation learning methods have achieved commendable results
in image fusion tasks, which can be attributed to their clear advantages in
handling with linear space. However, data collected from a realistic scene
usually have a non-Euclidean structure, where Euclidean metric might be limited
in representing the true data relationships, degrading fusion performance. To
address this issue, a novel SPD (symmetric positive definite) manifold learning
framework is proposed for multi-modal image fusion, named SPDFusion, which
extends the image fusion approach from the Euclidean space to the SPD
manifolds. Specifically, we encode images according to the Riemannian geometry
to exploit their intrinsic statistical correlations, thereby aligning with
human visual perception. Actually, the SPD matrix underpins our network
learning, with a cross-modal fusion strategy employed to harness
modality-specific dependencies and augment complementary information.
Subsequently, an attention module is designed to process the learned weight
matrix, facilitating the weighting of spatial global correlation semantics via
SPD matrix multiplication. Based on this, we design an end-to-end fusion
network based on cross-modal manifold learning. Extensive experiments on public
datasets demonstrate that our framework exhibits superior performance compared
to the current state-of-the-art methods.","cs.CV, I.4",cs.CV,http://arxiv.org/abs/2411.10679v1
"Understanding Learning with Sliced-Wasserstein Requires Rethinking
  Informative Slices","Huy Tran, Yikun Bai, Ashkan Shahbazi, John R. Hershey, Soheil Kolouri",2024-11-16T01:18:27Z,"The practical applications of Wasserstein distances (WDs) are constrained by
their sample and computational complexities. Sliced-Wasserstein distances
(SWDs) provide a workaround by projecting distributions onto one-dimensional
subspaces, leveraging the more efficient, closed-form WDs for one-dimensional
distributions. However, in high dimensions, most random projections become
uninformative due to the concentration of measure phenomenon. Although several
SWD variants have been proposed to focus on \textit{informative} slices, they
often introduce additional complexity, numerical instability, and compromise
desirable theoretical (metric) properties of SWD. Amidst the growing literature
that focuses on directly modifying the slicing distribution, which often face
challenges, we revisit the classical Sliced-Wasserstein and propose instead to
rescale the 1D Wasserstein to make all slices equally informative. Importantly,
we show that with an appropriate data assumption and notion of \textit{slice
informativeness}, rescaling for all individual slices simplifies to \textbf{a
single global scaling factor} on the SWD. This, in turn, translates to the
standard learning rate search for gradient-based learning in common machine
learning workflows. We perform extensive experiments across various machine
learning tasks showing that the classical SWD, when properly configured, can
often match or surpass the performance of more complex variants. We then answer
the following question: ""Is Sliced-Wasserstein all you need for common learning
tasks?""","cs.LG, cs.AI, cs.CV, stat.AP, stat.CO, stat.ML",cs.LG,http://arxiv.org/abs/2411.10651v1
MTA: Multimodal Task Alignment for BEV Perception and Captioning,"Yunsheng Ma, Burhaneddin Yaman, Xin Ye, Feng Tao, Abhirup Mallik, Ziran Wang, Liu Ren",2024-11-16T00:14:13Z,"Bird's eye view (BEV)-based 3D perception plays a crucial role in autonomous
driving applications. The rise of large language models has spurred interest in
BEV-based captioning to understand object behavior in the surrounding
environment. However, existing approaches treat perception and captioning as
separate tasks, focusing on the performance of only one of the tasks and
overlooking the potential benefits of multimodal alignment. To bridge this gap
between modalities, we introduce MTA, a novel multimodal task alignment
framework that boosts both BEV perception and captioning. MTA consists of two
key components: (1) BEV-Language Alignment (BLA), a contextual learning
mechanism that aligns the BEV scene representations with ground-truth language
representations, and (2) Detection-Captioning Alignment (DCA), a cross-modal
prompting mechanism that aligns detection and captioning outputs. MTA
integrates into state-of-the-art baselines during training, adding no extra
computational complexity at runtime. Extensive experiments on the nuScenes and
TOD3Cap datasets show that MTA significantly outperforms state-of-the-art
baselines, achieving a 4.9% improvement in perception and a 9.2% improvement in
captioning. These results underscore the effectiveness of unified alignment in
reconciling BEV-based perception and captioning.","cs.CV, cs.AI, cs.CL, cs.LG",cs.CV,http://arxiv.org/abs/2411.10639v1
Quantifying community evolves in temporal networks,"Peijie Zhong, Cheick Ba, Raúl Mondragón, Richard Clegg",2024-11-15T23:31:23Z,"When we detect communities in temporal networks it is important to ask
questions about how they change in time. Normalised Mutual Information (NMI)
has been used to measure the similarity of communities when the nodes on a
network do not change. We propose two extensions namely Union-Normalised Mutual
Information (UNMI) and Intersection-Normalised Mutual Information (INMI). UNMI
and INMI evaluate the similarity of community structure under the condition of
node variation. Experiments show that these methods are effective in dealing
with temporal networks with the changes in the set of nodes, and can capture
the dynamic evolution of community structure in both synthetic and real
temporal networks. This study not only provides a new similarity measurement
method for network analysis but also helps to deepen the understanding of
community change in complex temporal networks.",cs.SI,cs.SI,http://arxiv.org/abs/2411.10632v1
"KAT to KANs: A Review of Kolmogorov-Arnold Networks and the Neural Leap
  Forward","Divesh Basina, Joseph Raj Vishal, Aarya Choudhary, Bharatesh Chakravarthi",2024-11-15T23:02:26Z,"The curse of dimensionality poses a significant challenge to modern
multilayer perceptron-based architectures, often causing performance stagnation
and scalability issues. Addressing this limitation typically requires vast
amounts of data. In contrast, Kolmogorov-Arnold Networks have gained attention
in the machine learning community for their bold claim of being unaffected by
the curse of dimensionality. This paper explores the Kolmogorov-Arnold
representation theorem and the mathematical principles underlying
Kolmogorov-Arnold Networks, which enable their scalability and high performance
in high-dimensional spaces. We begin with an introduction to foundational
concepts necessary to understand Kolmogorov-Arnold Networks, including
interpolation methods and Basis-splines, which form their mathematical
backbone. This is followed by an overview of perceptron architectures and the
Universal approximation theorem, a key principle guiding modern machine
learning. This is followed by an overview of the Kolmogorov-Arnold
representation theorem, including its mathematical formulation and implications
for overcoming dimensionality challenges. Next, we review the architecture and
error-scaling properties of Kolmogorov-Arnold Networks, demonstrating how these
networks achieve true freedom from the curse of dimensionality. Finally, we
discuss the practical viability of Kolmogorov-Arnold Networks, highlighting
scenarios where their unique capabilities position them to excel in real-world
applications. This review aims to offer insights into Kolmogorov-Arnold
Networks' potential to redefine scalability and performance in high-dimensional
learning tasks.","cs.LG, cs.NE, stat.ML",cs.LG,http://arxiv.org/abs/2411.10622v1
"Voxel-Aggergated Feature Synthesis: Efficient Dense Mapping for
  Simulated 3D Reasoning","Owen Burns, Rizwan Qureshi",2024-11-15T22:37:56Z,"We address the issue of the exploding computational requirements of recent
State-of-the-art (SOTA) open set multimodel 3D mapping (dense 3D mapping)
algorithms and present Voxel-Aggregated Feature Synthesis (VAFS), a novel
approach to dense 3D mapping in simulation. Dense 3D mapping involves
segmenting and embedding sequential RGBD frames which are then fused into 3D.
This leads to redundant computation as the differences between frames are small
but all are individually segmented and embedded. This makes dense 3D mapping
impractical for research involving embodied agents in which the environment,
and thus the mapping, must be modified with regularity. VAFS drastically
reduces this computation by using the segmented point cloud computed by a
simulator's physics engine and synthesizing views of each region. This reduces
the number of features to embed from the number of captured RGBD frames to the
number of objects in the scene, effectively allowing a ""ground truth"" semantic
map to be computed an order of magnitude faster than traditional methods. We
test the resulting representation by assessing the IoU scores of semantic
queries for different objects in the simulated scene, and find that VAFS
exceeds the accuracy and speed of prior dense 3D mapping techniques.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10616v1
"ULTra: Unveiling Latent Token Interpretability in Transformer Based
  Understanding","Hesam Hosseini, Ghazal Hosseini Mighan, Amirabbas Afzali, Sajjad Amini, Amir Houmansadr",2024-11-15T19:36:50Z,"Transformers have revolutionized Computer Vision (CV) and Natural Language
Processing (NLP) through self-attention mechanisms. However, due to their
complexity, their latent token representations are often difficult to
interpret. We introduce a novel framework that interprets Transformer
embeddings, uncovering meaningful semantic patterns within them. Based on this
framework, we demonstrate that zero-shot unsupervised semantic segmentation can
be performed effectively without any fine-tuning using a model pre-trained for
tasks other than segmentation. Our method reveals the inherent capacity of
Transformer models for understanding input semantics and achieves
state-of-the-art performance in semantic segmentation, outperforming
traditional segmentation models. Specifically, our approach achieves an
accuracy of 67.2 % and an mIoU of 32.9 % on the COCO-Stuff dataset, as well as
an mIoU of 51.9 % on the PASCAL VOC dataset. Additionally, we validate our
interpretability framework on LLMs for text summarization, demonstrating its
broad applicability and robustness.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12589v1
Efficient Alignment of Large Language Models via Data Sampling,"Amrit Khera, Rajat Ghosh, Debojyoti Dutta",2024-11-15T19:36:15Z,"LLM alignment ensures that large language models behave safely and
effectively by aligning their outputs with human values, goals, and intentions.
Aligning LLMs employ huge amounts of data, computation, and time. Moreover,
curating data with human feedback is expensive and takes time. Recent research
depicts the benefit of data engineering in the fine-tuning and pre-training
paradigms to bring down such costs. However, alignment differs from the
afore-mentioned paradigms and it is unclear if data efficient alignment is
feasible. In this work, we first aim to understand how the performance of LLM
alignment scales with data. We find out that LLM alignment performance follows
an exponential plateau pattern which tapers off post a rapid initial increase.
Based on this, we identify data subsampling as a viable method to reduce
resources required for alignment. Further, we propose an information
theory-based methodology for efficient alignment by identifying a small high
quality subset thereby reducing the computation and time required by alignment.
We evaluate the proposed methodology over multiple datasets and compare the
results. We find that the model aligned using our proposed methodology
outperforms other sampling methods and performs comparable to the model aligned
with the full dataset while using less than 10% data, leading to greater than
90% savings in costs, resources, and faster LLM alignment.","cs.LG, cs.CL",cs.LG,http://arxiv.org/abs/2411.10545v1
Does Prompt Formatting Have Any Impact on LLM Performance?,"Jia He, Mukund Rungta, David Koleczek, Arshdeep Sekhon, Franklin X Wang, Sadid Hasan",2024-11-15T19:26:38Z,"In the realm of Large Language Models (LLMs), prompt optimization is crucial
for model performance. Although previous research has explored aspects like
rephrasing prompt contexts, using various prompting techniques (like in-context
learning and chain-of-thought), and ordering few-shot examples, our
understanding of LLM sensitivity to prompt templates remains limited.
Therefore, this paper examines the impact of different prompt templates on LLM
performance. We formatted the same contexts into various human-readable
templates, including plain text, Markdown, JSON, and YAML, and evaluated their
impact across tasks like natural language reasoning, code generation, and
translation using OpenAI's GPT models. Experiments show that GPT-3.5-turbo's
performance varies by up to 40\% in a code translation task depending on the
prompt template, while larger models like GPT-4 are more robust to these
variations. Our analysis highlights the need to reconsider the use of fixed
prompt templates, as different formats can significantly affect model
performance.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.10541v1
"Advancing Autonomous Driving Perception: Analysis of Sensor Fusion and
  Computer Vision Techniques","Urvishkumar Bharti, Vikram Shahapur",2024-11-15T19:11:58Z,"In autonomous driving, perception systems are piv otal as they interpret
sensory data to understand the envi ronment, which is essential for
decision-making and planning.
  Ensuring the safety of these perception systems is fundamental
  for achieving high-level autonomy, allowing us to confidently
  delegate driving and monitoring tasks to machines. This re port aims to
enhance the safety of perception systems by
  examining and summarizing the latest advancements in vision
  based systems, and metrics for perception tasks in autonomous
  driving. The report also underscores significant achievements and
  recognized challenges faced by current research in this field. This
  project focuses on enhancing the understanding and navigation
  capabilities of self-driving robots through depth based perception
  and computer vision techniques. Specifically, it explores how we
  can perform better navigation into unknown map 2D map with
  existing detection and tracking algorithms and on top of that how
  depth based perception can enhance the navigation capabilities of
  the wheel based bots to improve autonomous driving perception.","cs.RO, cs.CV",cs.RO,http://arxiv.org/abs/2411.10535v1
"""On the goals of linguistic theory"": Revisiting Chomskyan theories in
  the era of AI","Eva Portelance, Masoud Jasbi",2024-11-15T19:09:22Z,"Theoretical linguistics seeks to explain what human language is, and why.
Linguists and cognitive scientists have proposed different theoretical models
of what language is, as well as cognitive factors that shape it, and allow
humans to 'produce', 'understand', and 'acquire' natural languages. However,
humans may no longer be the only ones learning to 'generate', 'parse', and
'learn' natural language: artificial intelligence (AI) models such as large
language models are proving to have impressive linguistic capabilities. Many
are thus questioning what role, if any, such models should play in helping
theoretical linguistics reach its ultimate research goals? In this paper, we
propose to answer this question, by reiterating the tenets of generative
linguistics, a leading school of thought in the field, and by considering how
AI models as theories of language relate to each of these important concepts.
Specifically, we consider three foundational principles, finding roots in the
early works of Noam Chomsky: (1) levels of theoretical adequacy; (2) procedures
for linguistic theory development; (3) language learnability and Universal
Grammar. In our discussions of each principle, we give special attention to two
types of AI models: neural language models and neural grammar induction models.
We will argue that such models, in particular neural grammar induction models,
do have a role to play, but that this role is largely modulated by the stance
one takes regarding each of these three guiding principles.","cs.CL, F.1.1; I.2.7; I.2.6",cs.CL,http://arxiv.org/abs/2411.10533v1
VeriGraph: Scene Graphs for Execution Verifiable Robot Planning,"Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava",2024-11-15T18:59:51Z,"Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.","cs.RO, cs.AI",cs.RO,http://arxiv.org/abs/2411.10446v1
"Llama Guard 3 Vision: Safeguarding Human-AI Image Understanding
  Conversations","Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie Delpierre Coudert, Kartikeya Upasani, Mahesh Pasupuleti",2024-11-15T18:34:07Z,"We introduce Llama Guard 3 Vision, a multimodal LLM-based safeguard for
human-AI conversations that involves image understanding: it can be used to
safeguard content for both multimodal LLM inputs (prompt classification) and
outputs (response classification). Unlike the previous text-only Llama Guard
versions (Inan et al., 2023; Llama Team, 2024b,a), it is specifically designed
to support image reasoning use cases and is optimized to detect harmful
multimodal (text and image) prompts and text responses to these prompts. Llama
Guard 3 Vision is fine-tuned on Llama 3.2-Vision and demonstrates strong
performance on the internal benchmarks using the MLCommons taxonomy. We also
test its robustness against adversarial attacks. We believe that Llama Guard 3
Vision serves as a good starting point to build more capable and robust content
moderation tools for human-AI conversation with multimodal capabilities.","cs.CV, cs.CL",cs.CV,http://arxiv.org/abs/2411.10414v1
Comparing Bills of Materials,"Lucas Tate, Rebecca Jones, Doug Dennis, Tatyana Benko, Jody Askren",2024-11-15T17:47:22Z,"Bills of materials (BOMs) are quickly becoming an effective tool for managing
supply chain risk. As more BOMs enter circulation, the ability to compare them
will be crucial to understanding how products differ and in managing BOMs from
different tools or sources. This paper will describe some of the challenges of
comparing BOMs followed by a discussion of several comparison methods",cs.SE,cs.SE,http://arxiv.org/abs/2411.10384v1
"Unveiling the Skills and Responsibilities of Serverless Practitioners:
  An Empirical Investigation","Muhammad Hamza, Vy Kauppinen, Muhammad Azeem Akbar, Wardah Naeem Awan, Kari Smolander",2024-11-15T16:45:04Z,"Enterprises are increasingly adopting serverless computing to enhance
scalability, reduce costs, and improve efficiency. However, this shift
introduces new responsibilities and necessitates a distinct set of skills for
practitioners. This study aims to identify and organize the industry
requirements for serverless practitioners by conducting a qualitative analysis
of 141 job advertisements from seven countries. We developed comprehensive
taxonomies of roles, responsibilities, and skills, categorizing 19
responsibilities into four themes: software development, infrastructure and
operations, professional development and leadership, and software business.
Additionally, we identified 28 hard skills mapped into seven themes and 32 soft
skills mapped into eight themes, with the six most demanded soft skills being
communication proficiency, continuous learning and adaptability, collaborative
teamwork, problem-solving and analytical skills, leadership excellence, and
project management. Our findings contribute to understanding the organizational
structures and training requirements for effective serverless computing
adoption.",cs.SE,cs.SE,http://arxiv.org/abs/2411.10344v1
Number it: Temporal Grounding Videos like Flipping Manga,"Yongliang Wu, Xinting Hu, Yuyang Sun, Yizhou Zhou, Wenbo Zhu, Fengyun Rao, Bernt Schiele, Xu Yang",2024-11-15T16:32:34Z,"Video Large Language Models (Vid-LLMs) have made remarkable advancements in
comprehending video content for QA dialogue. However, they struggle to extend
this visual understanding to tasks requiring precise temporal localization,
known as Video Temporal Grounding (VTG). To address this gap, we introduce
Number-Prompt (NumPro), a novel method that empowers Vid-LLMs to bridge visual
comprehension with temporal grounding by adding unique numerical identifiers to
each video frame. Treating a video as a sequence of numbered frame images,
NumPro transforms VTG into an intuitive process: flipping through manga panels
in sequence. This allows Vid-LLMs to ""read"" event timelines, accurately linking
visual content with corresponding temporal information. Our experiments
demonstrate that NumPro significantly boosts VTG performance of top-tier
Vid-LLMs without additional computational cost. Furthermore, fine-tuning on a
NumPro-enhanced dataset defines a new state-of-the-art for VTG, surpassing
previous top-performing methods by up to 6.9\% in mIoU for moment retrieval and
8.5\% in mAP for highlight detection. The code will be available at
https://github.com/yongliang-wu/NumPro.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10332v1
"CNN-Based Classification of Persian Miniature Paintings from Five
  Renowned Schools","Mojtaba Shahi, Roozbeh Rajabi, Farnaz Masoumzadeh",2024-11-15T16:29:57Z,"This article addresses the gap in computational painting analysis focused on
Persian miniature painting, a rich cultural and artistic heritage. It
introduces a novel approach using Convolutional Neural Networks (CNN) to
classify Persian miniatures from five schools: Herat, Tabriz-e Avval, Shiraz-e
Avval, Tabriz-e Dovvom, and Qajar. The method achieves an average accuracy of
over 91%. A meticulously curated dataset captures the distinct features of each
school, with a patch-based CNN approach classifying image segments
independently before merging results for enhanced accuracy. This research
contributes significantly to digital art analysis, providing detailed insights
into the dataset, CNN architecture, training, and validation processes. It
highlights the potential for future advancements in automated art analysis,
bridging machine learning, art history, and digital humanities, thereby aiding
the preservation and understanding of Persian cultural heritage.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10330v1
"Moving Forward: A Review of Autonomous Driving Software and Hardware
  Systems","Xu Wang, Mohammad Ali Maleki, Muhammad Waqar Azhar, Pedro Trancoso",2024-11-15T15:48:50Z,"With their potential to significantly reduce traffic accidents, enhance road
safety, optimize traffic flow, and decrease congestion, autonomous driving
systems are a major focus of research and development in recent years. Beyond
these immediate benefits, they offer long-term advantages in promoting
sustainable transportation by reducing emissions and fuel consumption.
Achieving a high level of autonomy across diverse conditions requires a
comprehensive understanding of the environment. This is accomplished by
processing data from sensors such as cameras, radars, and LiDARs through a
software stack that relies heavily on machine learning algorithms. These ML
models demand significant computational resources and involve large-scale data
movement, presenting challenges for hardware to execute them efficiently and at
high speed. In this survey, we first outline and highlight the key components
of self-driving systems, covering input sensors, commonly used datasets,
simulation platforms, and the software architecture. We then explore the
underlying hardware platforms that support the execution of these software
systems. By presenting a comprehensive view of autonomous driving systems and
their increasing demands, particularly for higher levels of autonomy, we
analyze the performance and efficiency of scaled-up off-the-shelf GPU/CPU-based
systems, emphasizing the challenges within the computational components.
Through examples showcasing the diverse computational and memory requirements
in the software stack, we demonstrate how more specialized hardware and
processing closer to memory can enable more efficient execution with lower
latency. Finally, based on current trends and future demands, we conclude by
speculating what a future hardware platform for autonomous driving might look
like.",cs.RO,cs.RO,http://arxiv.org/abs/2411.10291v1
Transformers -- Messages in Disguise,"Joshua H. Tyler, Mohamed K. M. Fadul, Donald R. Reising",2024-11-15T15:42:29Z,"Modern cryptography, such as Rivest Shamir Adleman (RSA) and Secure Hash
Algorithm (SHA), has been designed by humans based on our understanding of
cryptographic methods. Neural Network (NN) based cryptography is being
investigated due to its ability to learn and implement random cryptographic
schemes that may be harder to decipher than human-designed algorithms. NN based
cryptography may create a new cryptographic scheme that is NN specific and that
changes every time the NN is (re)trained. This is attractive since it would
require an adversary to restart its process(es) to learn or break the
cryptographic scheme every time the NN is (re)trained. Current challenges
facing NN-based encryption include additional communication overhead due to
encoding to correct bit errors, quantizing the continuous-valued output of the
NN, and enabling One-Time-Pad encryption. With this in mind, the Random
Adversarial Data Obfuscation Model (RANDOM) Adversarial Neural Cryptography
(ANC) network is introduced. RANDOM is comprised of three new NN layers: the
(i) projection layer, (ii) inverse projection layer, and (iii) dot-product
layer. This results in an ANC network that (i) is computationally efficient,
(ii) ensures the encrypted message is unique to the encryption key, and (iii)
does not induce any communication overhead. RANDOM only requires around 100 KB
to store and can provide up to 2.5 megabytes per second of end-to-end encrypted
communication.","cs.CR, eess.SP",cs.CR,http://arxiv.org/abs/2411.10287v1
"TESGNN: Temporal Equivariant Scene Graph Neural Networks for Efficient
  and Robust Multi-View 3D Scene Understanding","Quang P. M. Pham, Khoi T. N. Nguyen, Lan C. Ngo, Dezhen Song, Truong Do, Truong Son Hy",2024-11-15T15:39:04Z,"Scene graphs have proven to be highly effective for various scene
understanding tasks due to their compact and explicit representation of
relational information. However, current methods often overlook the critical
importance of preserving symmetry when generating scene graphs from 3D point
clouds, which can lead to reduced accuracy and robustness, particularly when
dealing with noisy, multi-view data. This work, to the best of our knowledge,
presents the first implementation of an Equivariant Scene Graph Neural Network
(ESGNN) to generate semantic scene graphs from 3D point clouds, specifically
for enhanced scene understanding. Furthermore, a significant limitation of
prior methods is the absence of temporal modeling to capture time-dependent
relationships among dynamically evolving entities within a scene. To address
this gap, we introduce a novel temporal layer that leverages the
symmetry-preserving properties of ESGNN to fuse scene graphs across multiple
sequences into a unified global representation by an approximate graph-matching
algorithm. Our combined architecture, termed the Temporal Equivariant Scene
Graph Neural Network (TESGNN), not only surpasses existing state-of-the-art
methods in scene estimation accuracy but also achieves faster convergence.
Importantly, TESGNN is computationally efficient and straightforward to
implement using existing frameworks, making it well-suited for real-time
applications in robotics and computer vision. This approach paves the way for
more robust and scalable solutions to complex multi-view scene understanding
challenges. Our source code is publicly available at:
https://github.com/HySonLab/TESGraph","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10509v1
"From Score-Driven to Value-Sharing: Understanding Chinese Family Use of
  AI to Support Decision Making of College Applications","Si Chen, Jingyi Xie, Ge Wang, Haizhou Wang, Haocong Cheng, Yun Huang",2024-11-15T15:36:06Z,"This study investigates how 18-year-old students, parents, and experts in
China utilize artificial intelligence (AI) tools to support decision-making in
college applications during college entrance exam -- a highly competitive,
score-driven, annual national exam. Through 32 interviews, we examine the use
of Quark GaoKao, an AI tool that generates college application lists and
acceptance probabilities based on exam scores, historical data, preferred
locations, etc. Our findings show that AI tools are predominantly used by
parents with limited involvement from students, and often focus on immediate
exam results, failing to address long-term career goals. We also identify
challenges such as misleading AI recommendations, and irresponsible use of AI
by third-party consultant agencies. Finally, we offer design insights to better
support multi-stakeholders' decision-making in families, especially in the
Chinese context, and discuss how emerging AI tools create barriers for families
with fewer resources.",cs.HC,cs.HC,http://arxiv.org/abs/2411.10280v1
Partial Scene Text Retrieval,"Hao Wang, Minghui Liao, Zhouyi Xie, Wenyu Liu, Xiang Bai",2024-11-15T15:08:04Z,"The task of partial scene text retrieval involves localizing and searching
for text instances that are the same or similar to a given query text from an
image gallery. However, existing methods can only handle text-line instances,
leaving the problem of searching for partial patches within these text-line
instances unsolved due to a lack of patch annotations in the training data. To
address this issue, we propose a network that can simultaneously retrieve both
text-line instances and their partial patches. Our method embeds the two types
of data (query text and scene text instances) into a shared feature space and
measures their cross-modal similarities. To handle partial patches, our
proposed approach adopts a Multiple Instance Learning (MIL) approach to learn
their similarities with query text, without requiring extra annotations.
However, constructing bags, which is a standard step of conventional MIL
approaches, can introduce numerous noisy samples for training, and lower
inference speed. To address this issue, we propose a Ranking MIL (RankMIL)
approach to adaptively filter those noisy samples. Additionally, we present a
Dynamic Partial Match Algorithm (DPMA) that can directly search for the target
partial patch from a text-line instance during the inference stage, without
requiring bags. This greatly improves the search efficiency and the performance
of retrieving partial patches. The source code and dataset are available at
https://github.com/lanfeng4659/PSTR.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10261v2
"Visual-Linguistic Agent: Towards Collaborative Contextual Object
  Reasoning","Jingru Yang, Huan Yu, Yang Jingxin, Chentianye Xu, Yin Biao, Yu Sun, Shengfeng He",2024-11-15T15:02:06Z,"Multimodal Large Language Models (MLLMs) excel at descriptive tasks within
images but often struggle with precise object localization, a critical element
for reliable visual interpretation. In contrast, traditional object detection
models provide high localization accuracy but frequently generate detections
lacking contextual coherence due to limited modeling of inter-object
relationships. To address this fundamental limitation, we introduce the
\textbf{Visual-Linguistic Agent (VLA), a collaborative framework that combines
the relational reasoning strengths of MLLMs with the precise localization
capabilities of traditional object detectors. In the VLA paradigm, the MLLM
serves as a central Linguistic Agent, working collaboratively with specialized
Vision Agents for object detection and classification. The Linguistic Agent
evaluates and refines detections by reasoning over spatial and contextual
relationships among objects, while the classification Vision Agent offers
corrective feedback to improve classification accuracy. This collaborative
approach enables VLA to significantly enhance both spatial reasoning and object
localization, addressing key challenges in multimodal understanding. Extensive
evaluations on the COCO dataset demonstrate substantial performance
improvements across multiple detection models, highlighting VLA's potential to
set a new benchmark in accurate and contextually coherent object detection.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10252v1
"Optimally Rewriting Formulas and Database Queries: A Confluence of Term
  Rewriting, Structural Decomposition, and Complexity","Hubie Chen, Stefan Mengel",2024-11-15T14:41:47Z,"A central computational task in database theory, finite model theory, and
computer science at large is the evaluation of a first-order sentence on a
finite structure. In the context of this task, the \emph{width} of a sentence,
defined as the maximum number of free variables over all subformulas, has been
established as a crucial measure, where minimizing width of a sentence (while
retaining logical equivalence) is considered highly desirable. An
undecidability result rules out the possibility of an algorithm that, given a
first-order sentence, returns a logically equivalent sentence of minimum width;
this result motivates the study of width minimization via syntactic rewriting
rules, which is this article's focus. For a number of common rewriting rules
(which are known to preserve logical equivalence), including rules that allow
for the movement of quantifiers, we present an algorithm that, given a positive
first-order sentence $\phi$, outputs the minimum-width sentence obtainable from
$\phi$ via application of these rules. We thus obtain a complete algorithmic
understanding of width minimization up to the studied rules; this result is the
first one -- of which we are aware -- that establishes this type of
understanding in such a general setting. Our result builds on the theory of
term rewriting and establishes an interface among this theory, query
evaluation, and structural decomposition theory.","cs.LO, cs.DB",cs.LO,http://arxiv.org/abs/2411.10229v1
Entropy and type-token ratio in gigaword corpora,"Pablo Rosillo-Rodes, Maxi San Miguel, David Sanchez",2024-11-15T14:40:59Z,"Lexical diversity measures the vocabulary variation in texts. While its
utility is evident for analyses in language change and applied linguistics, it
is not yet clear how to operationalize this concept in a unique way. We here
investigate entropy and text-token ratio, two widely employed metrics for
lexical diversities, in six massive linguistic datasets in English, Spanish,
and Turkish, consisting of books, news articles, and tweets. These gigaword
corpora correspond to languages with distinct morphological features and differ
in registers and genres, thus constituting a diverse testbed for a quantitative
approach to lexical diversity. Strikingly, we find a functional relation
between entropy and text-token ratio that holds across the corpora under
consideration. Further, in the limit of large vocabularies we find an
analytical expression that sheds light on the origin of this relation and its
connection with both Zipf and Heaps laws. Our results then contribute to the
theoretical understanding of text structure and offer practical implications
for fields like natural language processing.","cs.CL, cs.IR, physics.soc-ph",cs.CL,http://arxiv.org/abs/2411.10227v1
"USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction
  and Gaussian Splatting","Kang Chen, Jiyuan Zhang, Zecheng Hao, Yajing Zheng, Tiejun Huang, Zhaofei Yu",2024-11-15T14:15:16Z,"Spike cameras, as an innovative neuromorphic camera that captures scenes with
the 0-1 bit stream at 40 kHz, are increasingly employed for the 3D
reconstruction task via Neural Radiance Fields (NeRF) or 3D Gaussian Splatting
(3DGS). Previous spike-based 3D reconstruction approaches often employ a
casecased pipeline: starting with high-quality image reconstruction from spike
streams based on established spike-to-image reconstruction algorithms, then
progressing to camera pose estimation and 3D reconstruction. However, this
cascaded approach suffers from substantial cumulative errors, where quality
limitations of initial image reconstructions negatively impact pose estimation,
ultimately degrading the fidelity of the 3D reconstruction. To address these
issues, we propose a synergistic optimization framework, \textbf{USP-Gaussian},
that unifies spike-based image reconstruction, pose correction, and Gaussian
splatting into an end-to-end framework. Leveraging the multi-view consistency
afforded by 3DGS and the motion capture capability of the spike camera, our
framework enables a joint iterative optimization that seamlessly integrates
information between the spike-to-image network and 3DGS. Experiments on
synthetic datasets with accurate poses demonstrate that our method surpasses
previous approaches by effectively eliminating cascading errors. Moreover, we
integrate pose optimization to achieve robust 3D reconstruction in real-world
scenarios with inaccurate initial poses, outperforming alternative methods by
effectively reducing noise and preserving fine texture details. Our code, data
and trained models will be available at
\url{https://github.com/chenkang455/USP-Gaussian}.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10504v1
Compound-QA: A Benchmark for Evaluating LLMs on Compound Questions,"Yutao Hou, Yajing Luo, Zhiwen Ruan, Hongru Wang, Weifeng Ge, Yun Chen, Guanhua Chen",2024-11-15T13:12:29Z,"Large language models (LLMs) demonstrate remarkable performance across
various tasks, prompting researchers to develop diverse evaluation benchmarks.
However, existing benchmarks typically measure the ability of LLMs to respond
to individual questions, neglecting the complex interactions in real-world
applications. In this paper, we introduce Compound Question Synthesis (CQ-Syn)
to create the Compound-QA benchmark, focusing on compound questions with
multiple sub-questions. This benchmark is derived from existing QA datasets,
annotated with proprietary LLMs and verified by humans for accuracy. It
encompasses five categories: Factual-Statement, Cause-and-Effect,
Hypothetical-Analysis, Comparison-and-Selection, and Evaluation-and-Suggestion.
It evaluates the LLM capability in terms of three dimensions including
understanding, reasoning, and knowledge. Our assessment of eight open-source
LLMs using Compound-QA reveals distinct patterns in their responses to compound
questions, which are significantly poorer than those to non-compound questions.
Additionally, we investigate various methods to enhance LLMs performance on
compound questions. The results indicate that these approaches significantly
improve the models' comprehension and reasoning abilities on compound
questions.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10163v1
Legal Evalutions and Challenges of Large Language Models,"Jiaqi Wang, Huan Zhao, Zhenyuan Yang, Peng Shu, Junhao Chen, Haobo Sun, Ruixi Liang, Shixin Li, Pengcheng Shi, Longjun Ma, Zongjia Liu, Zhengliang Liu, Tianyang Zhong, Yutong Zhang, Chong Ma, Xin Zhang, Tuo Zhang, Tianli Ding, Yudan Ren, Tianming Liu, Xi Jiang, Shu Zhang",2024-11-15T12:23:12Z,"In this paper, we review legal testing methods based on Large Language Models
(LLMs), using the OPENAI o1 model as a case study to evaluate the performance
of large models in applying legal provisions. We compare current
state-of-the-art LLMs, including open-source, closed-source, and legal-specific
models trained specifically for the legal domain. Systematic tests are
conducted on English and Chinese legal cases, and the results are analyzed in
depth. Through systematic testing of legal cases from common law systems and
China, this paper explores the strengths and weaknesses of LLMs in
understanding and applying legal texts, reasoning through legal issues, and
predicting judgments. The experimental results highlight both the potential and
limitations of LLMs in legal applications, particularly in terms of challenges
related to the interpretation of legal language and the accuracy of legal
reasoning. Finally, the paper provides a comprehensive analysis of the
advantages and disadvantages of various types of models, offering valuable
insights and references for the future application of AI in the legal field.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.10137v1
Efficient Density Control for 3D Gaussian Splatting,"Xiaobin Deng, Changyu Diao, Min Li, Ruohan Yu, Duanqing Xu",2024-11-15T12:12:56Z,"3D Gaussian Splatting (3DGS) excels in novel view synthesis, balancing
advanced rendering quality with real-time performance. However, in trained
scenes, a large number of Gaussians with low opacity significantly increase
rendering costs. This issue arises due to flaws in the split and clone
operations during the densification process, which lead to extensive Gaussian
overlap and subsequent opacity reduction. To enhance the efficiency of Gaussian
utilization, we improve the adaptive density control of 3DGS. First, we
introduce a more efficient long-axis split operation to replace the original
clone and split, which mitigates Gaussian overlap and improves densification
efficiency.Second, we propose a simple adaptive pruning technique to reduce the
number of low-opacity Gaussians. Finally, by dynamically lowering the splitting
threshold and applying importance weighting, the efficiency of Gaussian
utilization is further improved.We evaluate our proposed method on various
challenging real-world datasets. Experimental results show that our Efficient
Density Control (EDC) can enhance both the rendering speed and quality.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10133v1
"Towards Multi-View Consistent Style Transfer with One-Step Diffusion via
  Vision Conditioning","Yushen Zuo, Jun Xiao, Kin-Chung Chan, Rongkang Dong, Cuixin Yang, Zongqi He, Hao Xie, Kin-Man Lam",2024-11-15T12:02:07Z,"The stylization of 3D scenes is an increasingly attractive topic in 3D
vision. Although image style transfer has been extensively researched with
promising results, directly applying 2D style transfer methods to 3D scenes
often fails to preserve the structural and multi-view properties of 3D
environments, resulting in unpleasant distortions in images from different
viewpoints. To address these issues, we leverage the remarkable generative
prior of diffusion-based models and propose a novel style transfer method,
OSDiffST, based on a pre-trained one-step diffusion model (i.e., SD-Turbo) for
rendering diverse styles in multi-view images of 3D scenes. To efficiently
adapt the pre-trained model for multi-view style transfer on small datasets, we
introduce a vision condition module to extract style information from the
reference style image to serve as conditional input for the diffusion model and
employ LoRA in diffusion model for adaptation. Additionally, we consider color
distribution alignment and structural similarity between the stylized and
content images using two specific loss functions. As a result, our method
effectively preserves the structural information and multi-view consistency in
stylized images without any 3D information. Experiments show that our method
surpasses other promising style transfer methods in synthesizing various styles
for multi-view images of 3D scenes. Stylized images from different viewpoints
generated by our method achieve superior visual quality, with better structural
integrity and less distortion. The source code is available at
https://github.com/YushenZuo/OSDiffST.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10130v1
Bounded degree QBF and positional games,Nacim Oijid,2024-11-15T10:38:57Z,"The study of SAT and its variants has provided numerous NP-complete problems,
from which most NP-hardness results were derived. Due to the NP-hardness of
SAT, adding constraints to either specify a more precise NP-complete problem or
to obtain a tractable one helps better understand the complexity class of
several problems. In 1984, Tovey proved that bounded-degree SAT is also
NP-complete, thereby providing a tool for performing NP-hardness reductions
even with bounded parameters, when the size of the reduction gadget is a
function of the variable degree. In this work, we initiate a similar study for
QBF, the quantified version of SAT. We prove that, like SAT, the truth value of
a maximum degree two quantified formula is polynomial-time computable. However,
surprisingly, while the truth value of a 3-regular 3-SAT formula can be decided
in polynomial time, it is PSPACE-complete for a 3-regular QBF formula. A direct
consequence of these results is that Avoider-Enforcer and Client-Waiter
positional games are PSPACE-complete when restricted to bounded-degree
hypergraphs. To complete the study, we also show that Maker-Breaker and
Maker-Maker positional games are PSPACE-complete for bounded-degree
hypergraphs.","cs.CC, cs.DM, math.CO",cs.CC,http://arxiv.org/abs/2411.10093v2
"CorrCLIP: Reconstructing Correlations in CLIP with Off-the-Shelf
  Foundation Models for Open-Vocabulary Semantic Segmentation","Dengke Zhang, Fagui Liu, Quan Tang",2024-11-15T10:14:55Z,"Open-vocabulary semantic segmentation aims to assign semantic labels to each
pixel without relying on a predefined set of categories. Contrastive
Language-Image Pre-training (CLIP) demonstrates outstanding zero-shot
classification capabilities but struggles with the pixel-wise segmentation task
as the captured inter-patch correlations correspond to no specific visual
concepts. Despite previous CLIP-based works improving inter-patch correlations
by self-self attention, they still face the inherent limitation that image
patches tend to have high similarity to outlier ones. In this work, we
introduce CorrCLIP, a training-free approach for open-vocabulary semantic
segmentation, which reconstructs significantly coherent inter-patch
correlations utilizing foundation models. Specifically, it employs the Segment
Anything Model (SAM) to define the scope of patch interactions, ensuring that
patches interact only with semantically similar ones. Furthermore, CorrCLIP
obtains an understanding of an image's semantic layout via self-supervised
models to determine concrete similarity values between image patches, which
addresses the similarity irregularity problem caused by the aforementioned
restricted patch interaction regime. Finally, CorrCLIP reuses the region masks
produced by SAM to update the segmentation map. As a training-free method,
CorrCLIP achieves a notable improvement across eight challenging benchmarks
regarding the averaged mean Intersection over Union, boosting it from 44.4% to
51.0%.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10086v1
Adapting the Biological SSVEP Response to Artificial Neural Networks,"Emirhan Böge, Yasemin Gunindi, Erchan Aptoula, Nihan Alp, Huseyin Ozkan",2024-11-15T10:02:48Z,"Neuron importance assessment is crucial for understanding the inner workings
of artificial neural networks (ANNs) and improving their interpretability and
efficiency. This paper introduces a novel approach to neuron significance
assessment inspired by frequency tagging, a technique from neuroscience. By
applying sinusoidal contrast modulation to image inputs and analyzing resulting
neuron activations, this method enables fine-grained analysis of a network's
decision-making processes. Experiments conducted with a convolutional neural
network for image classification reveal notable harmonics and intermodulations
in neuron-specific responses under part-based frequency tagging. These findings
suggest that ANNs exhibit behavior akin to biological brains in tuning to
flickering frequencies, thereby opening avenues for neuron/filter importance
assessment through frequency tagging. The proposed method holds promise for
applications in network pruning, and model interpretability, contributing to
the advancement of explainable artificial intelligence and addressing the lack
of transparency in neural networks. Future research directions include
developing novel loss functions to encourage biologically plausible behavior in
ANNs.",cs.AI,cs.AI,http://arxiv.org/abs/2411.10084v1
Xmodel-1.5: An 1B-scale Multilingual LLM,"Wang Qun, Liu Yang, Lin Qingquan, Jiang Ling",2024-11-15T10:01:52Z,"We introduce Xmodel-1.5, a novel 1-billion-parameter multilingual large model
pretrained on approximately 2 trillion tokens. The model demonstrates strong
performance across several languages, with particularly notable results in
Thai, Arabic, and French, alongside its effectiveness in Chinese and English.
In addition, we contribute to the research community by releasing a Thai
evaluation dataset, which includes hundreds of questions annotated by students
from Chulalongkorn University's School of Integrated Innovation. While the
results are promising, we acknowledge that there is still room for improvement.
We hope this work advances ongoing efforts in multilingual AI research and
promotes better cross-linguistic understanding in various natural language
processing tasks. Our models and code are publicly available on GitHub at
https://github.com/XiaoduoAILab/XmodelLM.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10083v1
Understanding The Effect Of Temperature On Alignment With Human Opinions,"Maja Pavlovic, Massimo Poesio",2024-11-15T09:50:27Z,"With the increasing capabilities of LLMs, recent studies focus on
understanding whose opinions are represented by them and how to effectively
extract aligned opinion distributions. We conducted an empirical analysis of
three straightforward methods for obtaining distributions and evaluated the
results across a variety of metrics. Our findings suggest that sampling and
log-probability approaches with simple parameter adjustments can return better
aligned outputs in subjective tasks compared to direct prompting. Yet, assuming
models reflect human opinions may be limiting, highlighting the need for
further research on how human subjectivity affects model uncertainty.","cs.CL, cs.CY",cs.CL,http://arxiv.org/abs/2411.10080v1
SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs,"Shirley Kokane, Ming Zhu, Tulika Awalgaonkar, Jianguo Zhang, Thai Hoang, Akshara Prabhakar, Zuxin Liu, Tian Lan, Liangwei Yang, Juntao Tan, Rithesh Murthy, Weiran Yao, Zhiwei Liu, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong, Silivo Savarese",2024-11-20T18:56:22Z,"Evaluating the output of Large Language Models (LLMs) is one of the most
critical aspects of building a performant compound AI system. Since the output
from LLMs propagate to downstream steps, identifying LLM errors is crucial to
system performance. A common task for LLMs in AI systems is tool use. While
there are several benchmark environments for evaluating LLMs on this task, they
typically only give a success rate without any explanation of the failure
cases. To solve this problem, we introduce SpecTool, a new benchmark to
identify error patterns in LLM output on tool-use tasks. Our benchmark data set
comprises of queries from diverse environments that can be used to test for the
presence of seven newly characterized error patterns. Using SPECTOOL , we show
that even the most prominent LLMs exhibit these error patterns in their
outputs. Researchers can use the analysis and insights from SPECTOOL to guide
their error mitigation strategies.","cs.SE, cs.AI",cs.SE,http://arxiv.org/abs/2411.13547v1
"Interaction force estimation for tactile sensor arrays: Toward
  tactile-based interaction control for robotic fingers","Elie Chelly, Andrea Cherubini, Philippe Fraisse, Faiz Ben Amar, Mahdi Khoramshahi",2024-11-20T14:07:33Z,"Accurate estimation of interaction forces is crucial for achieving fine,
dexterous control in robotic systems. Although tactile sensor arrays offer rich
sensing capabilities, their effective use has been limited by challenges such
as calibration complexities, nonlinearities, and deformation. In this paper, we
tackle these issues by presenting a novel method for obtaining 3D force
estimation using tactile sensor arrays. Unlike existing approaches that focus
on specific or decoupled force components, our method estimates full 3D
interaction forces across an array of distributed sensors, providing
comprehensive real-time feedback. Through systematic data collection and model
training, our approach overcomes the limitations of prior methods, achieving
accurate and reliable tactile-based force estimation. Besides, we integrate
this estimation in a real-time control loop, enabling implicit, stable force
regulation that is critical for precise robotic manipulation. Experimental
validation on the Allegro robot hand with uSkin sensors demonstrates the
effectiveness of our approach in real-time control, and its ability to enhance
the robot's adaptability and dexterity.",cs.RO,cs.RO,http://arxiv.org/abs/2411.13335v1
"[Experiments \& Analysis] Hash-Based vs. Sort-Based Group-By-Aggregate:
  A Focused Empirical Study [Extended Version]","Gaurav Vaghasiya, Shiva Jahangiri",2024-11-20T12:03:50Z,"Group-by-aggregate (GBA) queries are integral to data analysis, allowing
users to group data by specific attributes and apply aggregate functions such
as sum, average, and count. Database Management Systems (DBMSs) typically
execute GBA queries using either sort- or hash-based methods, each with unique
advantages and trade-offs. Sort-based approaches are efficient for large
datasets but become computationally expensive due to record comparisons,
especially in cases with a small number of groups. In contrast, hash-based
approaches offer faster performance in general but require significant memory
and can suffer from hash collisions when handling large numbers of groups or
uneven data distributions. This paper presents a focused empirical study
comparing these two approaches, analyzing their strengths and weaknesses across
varying data sizes, datasets, and group counts using Apache AsterixDB. Our
findings indicate that sort-based methods excel in scenarios with large
datasets or when subsequent operations benefit from sorted data, whereas
hash-based methods are advantageous for smaller datasets or scenarios with
fewer groupings. Our results provide insights into the scenarios where each
method excels, offering practical guidance for optimizing GBA query
performance.",cs.DB,cs.DB,http://arxiv.org/abs/2411.13245v1
CF-GKAT: Efficient Validation of Control-Flow Transformations,"Cheng Zhang, Tobias Kappé, David E. Narváez, Nico Naus",2024-11-20T11:28:23Z,"Guarded Kleene Algebra with Tests (GKAT) provides a sound and complete
framework to reason about trace equivalence between simple imperative programs.
However, there are still several notable limitations. First, GKAT is completely
agnostic with respect to the meaning of primitives, to keep equivalence
decidable. Second, GKAT excludes non-local control flow such as goto, break,
and return. To overcome these limitations, we introduce Control-Flow GKAT
(CF-GKAT), a system that allows reasoning about programs that include non-local
control flow as well as hardcoded values. CF-GKAT is able to soundly and
completely verify trace equivalence of a larger class of programs, while
preserving the nearly-linear efficiency of GKAT. This makes CF-GKAT suitable
for the verification of control-flow manipulating procedures, such as
decompilation and goto-elimination. To demonstrate CF-GKAT's abilities, we
validated the output of several highly non-trivial program transformations,
such as Erosa and Hendren's goto-elimination procedure and the output of Ghidra
decompiler. CF-GKAT opens up the application of Kleene Algebra to a wider set
of challenges, and provides an important verification tool that can be applied
to the field of decompilation and control-flow transformation.",cs.PL,cs.PL,http://arxiv.org/abs/2411.13220v1
"Writing Style Matters: An Examination of Bias and Fairness in
  Information Retrieval Systems",Hongliu Cao,2024-11-20T10:17:09Z,"The rapid advancement of Language Model technologies has opened new
opportunities, but also introduced new challenges related to bias and fairness.
This paper explores the uncharted territory of potential biases in
state-of-the-art universal text embedding models towards specific document and
query writing styles within Information Retrieval (IR) systems. Our
investigation reveals that different embedding models exhibit different
preferences of document writing style, while more informal and emotive styles
are less favored by most embedding models. In terms of query writing styles,
many embedding models tend to match the style of the query with the style of
the retrieved documents, but some show a consistent preference for specific
styles. Text embedding models fine-tuned on synthetic data generated by LLMs
display a consistent preference for certain style of generated data. These
biases in text embedding based IR systems can inadvertently silence or
marginalize certain communication styles, thereby posing a significant threat
to fairness in information retrieval. Finally, we also compare the answer
styles of Retrieval Augmented Generation (RAG) systems based on different LLMs
and find out that most text embedding models are biased towards LLM's answer
styles when used as evaluation metrics for answer correctness. This study sheds
light on the critical issue of writing style based bias in IR systems, offering
valuable insights for the development of more fair and robust models.","cs.IR, cs.AI",cs.IR,http://arxiv.org/abs/2411.13173v1
"Towards Specification-Driven LLM-Based Generation of Embedded Automotive
  Software","Minal Suresh Patil, Gustav Ung, Mattias Nyberg",2024-11-20T12:38:17Z,"The paper studies how code generation by LLMs can be combined with formal
verification to produce critical embedded software. The first contribution is a
general framework, spec2code, in which LLMs are combined with different types
of critics that produce feedback for iterative backprompting and fine-tuning.
The second contribution presents a first feasibility study, where a
minimalistic instantiation of spec2code, without iterative backprompting and
fine-tuning, is empirically evaluated using three industrial case studies from
the heavy vehicle manufacturer Scania. The goal is to automatically generate
industrial-quality code from specifications only. Different combinations of
formal ACSL specifications and natural language specifications are explored.
The results indicate that formally correct code can be generated even without
the application of iterative backprompting and fine-tuning.","cs.SE, cs.AI",cs.SE,http://arxiv.org/abs/2411.13269v1
DMQR-RAG: Diverse Multi-Query Rewriting for RAG,"Zhicong Li, Jiahao Wang, Zhishu Jiang, Hangyu Mao, Zhongxia Chen, Jiazhen Du, Yuanxing Zhang, Fuzheng Zhang, Di Zhang, Yong Liu",2024-11-20T09:43:30Z,"Large language models often encounter challenges with static knowledge and
hallucinations, which undermine their reliability. Retrieval-augmented
generation (RAG) mitigates these issues by incorporating external information.
However, user queries frequently contain noise and intent deviations,
necessitating query rewriting to improve the relevance of retrieved documents.
In this paper, we introduce DMQR-RAG, a Diverse Multi-Query Rewriting framework
designed to improve the performance of both document retrieval and final
responses in RAG. Specifically, we investigate how queries with varying
information quantities can retrieve a diverse array of documents, presenting
four rewriting strategies that operate at different levels of information to
enhance the performance of baseline approaches. Additionally, we propose an
adaptive strategy selection method that minimizes the number of rewrites while
optimizing overall performance. Our methods have been rigorously validated
through extensive experiments conducted in both academic and industry settings.","cs.IR, cs.AI",cs.IR,http://arxiv.org/abs/2411.13154v1
"Denotational Semantics of Gradual Typing using Synthetic Guarded Domain
  Theory (Extended Version)","Eric Giovannini, Tingting Ding, Max S. New",2024-11-19T19:18:31Z,"Gradually typed programming languages, which allow for soundly mixing static
and dynamically typed programming styles, present a strong challenge for
metatheorists. Even the simplest sound gradually typed languages feature at
least recursion and errors, with realistic languages featuring furthermore
runtime allocation of memory locations and dynamic type tags. Further, the
desired metatheoretic properties of gradually typed languages have become
increasingly sophisticated: validity of type-based equational reasoning as well
as the relational property known as graduality. Many recent works have tackled
verifying these properties, but the resulting mathematical developments are
highly repetitive and tedious, with few reusable theorems persisting across
different developments.
  In this work, we present a new denotational semantics for gradual typing
developed using guarded domain theory. Guarded domain theory combines the
generality of step-indexed logical relations for modeling advanced programming
features with the modularity and reusability of denotational semantics. We
demonstrate the feasibility of this approach with a model of a simple gradually
typed lambda calculus and prove the validity of beta-eta equality and the
graduality theorem for the denotational model. This model should provide the
basis for a reusable mathematical theory of gradually typed program semantics.
Finally, we have mechanized most of the core theorems of our development in
Guarded Cubical Agda, a recent extension of Agda with support for the guarded
recursive constructions we use.",cs.PL,cs.PL,http://arxiv.org/abs/2411.12822v1
"SparseInfer: Training-free Prediction of Activation Sparsity for Fast
  LLM Inference","Jiho Shin, Hoeseok Yang, Youngmin Yi",2024-11-19T17:59:12Z,"Leveraging sparsity is crucial for optimizing large language model inference.
however, modern LLMs employing SiLU as their activation function exhibit
minimal activation sparsity. Recent research has proposed replacing SiLU with
ReLU to induce significant activation sparsity and showed no downstream task
accuracy degradation through fine tuning. However, taking full advantage of it
required training a predictor to estimate this sparsity. In this paper, we
introduce SparseInfer, a simple, light weight, and training free predictor for
activation sparsity of ReLU field LLMs, in which activation sparsity is
predicted by comparing only the sign bits of inputs and weights. To compensate
for possible prediction inaccuracy, an adaptive tuning of the predictor's
conservativeness is enabled, which can also serve as a control knob for
optimizing LLM inference. The proposed method achieves approximately faster
inference speed over the state of the art, with negligible accuracy loss of
within 1%p.",cs.PF,cs.PF,http://arxiv.org/abs/2411.12692v1
"CodeXEmbed: A Generalist Embedding Model Family for Multiligual and
  Multi-task Code Retrieval","Ye Liu, Rui Meng, Shafiq Jot, Silvio Savarese, Caiming Xiong, Yingbo Zhou, Semih Yavuz",2024-11-19T16:54:45Z,"Despite the success of text retrieval in many NLP tasks, code retrieval
remains a largely underexplored area. Most text retrieval systems are tailored
for natural language queries, often neglecting the specific challenges of
retrieving code. This gap leaves existing models unable to effectively capture
the diversity of programming languages and tasks across different domains,
highlighting the need for more focused research in code retrieval. To address
this, we introduce CodeXEmbed, a family of large-scale code embedding models
ranging from 400M to 7B parameters. Our novel training pipeline unifies
multiple programming languages and transforms various code-related tasks into a
common retrieval framework, enhancing model generalizability and retrieval
performance. Our 7B model sets a new state-of-the-art (SOTA) in code retrieval,
outperforming the previous leading model, Voyage-Code, by over 20% on CoIR
benchmark. In addition to excelling in code retrieval, our models demonstrate
competitive performance on the widely adopted BeIR text retrieval benchmark,
offering versatility across domains. Experimental results demonstrate that
improving retrieval performance significantly enhances end-to-end
Retrieval-Augmented Generation (RAG) performance for code-related tasks.","cs.SE, cs.AI",cs.SE,http://arxiv.org/abs/2411.12644v1
Evaluating the Prompt Steerability of Large Language Models,"Erik Miehling, Michael Desmond, Karthikeyan Natesan Ramamurthy, Elizabeth M. Daly, Pierre Dognin, Jesus Rios, Djallel Bouneffouf, Miao Liu",2024-11-19T10:41:54Z,"Building pluralistic AI requires designing models that are able to be shaped
to represent a wide range of value systems and cultures. Achieving this
requires first being able to evaluate the degree to which a given model is
capable of reflecting various personas. To this end, we propose a benchmark for
evaluating the steerability of model personas as a function of prompting. Our
design is based on a formal definition of prompt steerability, which analyzes
the degree to which a model's joint behavioral distribution can be shifted from
its baseline behavior. By defining steerability indices and inspecting how
these indices change as a function of steering effort, we can estimate the
steerability of a model across various persona dimensions and directions. Our
benchmark reveals that the steerability of many current models is limited --
due to both a skew in their baseline behavior and an asymmetry in their
steerability across many persona dimensions. We release an implementation of
our benchmark at https://github.com/IBM/prompt-steering.","cs.CL, cs.AI, cs.HC",cs.CL,http://arxiv.org/abs/2411.12405v1
Could Humans Outshine AI in Visual Data Analysis?,"Ratanond Koonchanok, Khairi Reda",2024-11-19T07:40:07Z,"People often use visualizations not only to explore a dataset but also to
draw generalizable conclusions about underlying models or phenomena. While
previous research has viewed deviations from rational analysis as problematic,
we hypothesize that human reliance on non-normative heuristics may be
advantageous in certain situations. In this study, we investigate scenarios
where human intuition might outperform idealized statistical rationality. Our
experiment assesses participants' accuracy in characterizing the parameters of
known data-generating models from bivariate visualizations. Our findings show
that, while participants generally demonstrated lower accuracy than statistical
models, they often outperformed Bayesian agents, particularly when dealing with
extreme samples. These results suggest that, even when deviating from
rationality, human gut reactions to visualizations can provide an advantage.
Our findings offer insights into how analyst intuition and statistical models
can be integrated to improve inference and decision-making, with important
implications for the design of visual analytics tools.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12299v1
HouseLLM: LLM-Assisted Two-Phase Text-to-Floorplan Generation,"Ziyang Zong, Zhaohuan Zhan, Guang Tan",2024-11-19T06:57:45Z,"This paper proposes a two-phase text-to-floorplan generation method, which
guides a Large Language Model (LLM) to generate an initial layout (Layout-LLM)
and refines them into the final floorplans through conditional diffusion model.
We incorporate a Chain-of-Thought approach to prompt the LLM based on user text
specifications, enabling a more user-friendly and intuitive house layout
design. This method allows users to describe their needs in natural language,
enhancing accessibility and providing clearer geometric constraints. The final
floorplans generated by Layout-LLM through conditional diffusion refinement are
more accurate and better meet user requirements. Experimental results
demonstrate that our approach achieves state-of-the-art performance across all
metrics, validating its effectiveness in practical home design applications. We
plan to release our code for public use.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12279v2
"Low-resource Machine Translation: what for? who for? An observational
  study on a dedicated Tetun language translation service","Raphael Merx, Hanna Suominen, Adérito José Guterres Correia, Trevor Cohn, Ekaterina Vylomova",2024-11-19T06:21:51Z,"The impact of machine translation (MT) on low-resource languages remains
poorly understood. In particular, observational studies of actual usage
patterns are scarce. Such studies could provide valuable insights into user
needs and behaviours, complementing survey-based methods. Here we present an
observational analysis of real-world MT usage for Tetun, the lingua franca of
Timor-Leste, using server logs from a widely-used MT service with over $70,000$
monthly active users. Our analysis of $100,000$ translation requests reveals
patterns that challenge assumptions based on existing corpora. We find that
users, many of them students on mobile devices, typically translate short texts
into Tetun across diverse domains including science, healthcare, and daily
life. This contrasts sharply with available Tetun corpora, which are dominated
by news articles covering government and social issues. Our results suggest
that MT systems for languages like Tetun should prioritise translating into the
low-resource language, handling brief inputs effectively, and covering a wide
range of domains relevant to educational contexts. More broadly, this study
demonstrates how observational analysis can inform low-resource language
technology development, by grounding research in practical community needs.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12262v1
Restructuring Tractable Probabilistic Circuits,"Honghua Zhang, Benjie Wang, Marcelo Arenas, Guy Van den Broeck",2024-11-19T06:10:22Z,"Probabilistic circuits (PCs) is a unifying representation for probabilistic
models that support tractable inference. Numerous applications of PCs like
controllable text generation depend on the ability to efficiently multiply two
circuits. Existing multiplication algorithms require that the circuits respect
the same structure, i.e. variable scopes decomposes according to the same
vtree. In this work, we propose and study the task of restructuring
structured(-decomposable) PCs, that is, transforming a structured PC such that
it conforms to a target vtree. We propose a generic approach for this problem
and show that it leads to novel polynomial-time algorithms for multiplying
circuits respecting different vtrees, as well as a practical depth-reduction
algorithm that preserves structured decomposibility. Our work opens up new
avenues for tractable PC inference, suggesting the possibility of training with
less restrictive PC structures while enabling efficient inference by changing
their structures at inference time.","cs.AI, cs.LG",cs.AI,http://arxiv.org/abs/2411.12256v1
"Extending the Burrows-Wheeler Transform for Cartesian Tree Matching and
  Constructing It","Eric M. Osterkamp, Dominik Köppl",2024-11-19T05:37:53Z,"Cartesian tree matching is a form of generalized pattern matching where a
substring of the text matches with the pattern if they share the same Cartesian
tree. This form of matching finds application for time series of stock prices
and can be of interest for melody matching between musical scores. For the
indexing problem, the state-of-the-art data structure is a Burrows-Wheeler
transform based solution due to [Kim and Cho, CPM'21], which uses nearly
succinct space and can count the number of substrings that Cartesian tree match
with a pattern in time linear in the pattern length. The authors address the
construction of their data structure with a straight-forward solution that,
however, requires pointer-based data structures, which asymptotically need more
space than compact solutions [Kim and Cho, CPM'21, Section A.4]. We address
this bottleneck by a construction that requires compact space and has a time
complexity linear in the product of the text length with some logarithmic
terms. Additionally, we can extend this index for indexing multiple circular
texts in the spirit of the extended Burrows-Wheeler transform without
sacrificing the time and space complexities. We present this index in a dynamic
variant, where we pay a logarithmic slowdown and need compact space for the
extra functionality that we can incrementally add texts. Our extended setting
is of interest for finding repetitive motifs common in the aforementioned
applications, independent of offsets and scaling.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12241v1
Sketch-guided Cage-based 3D Gaussian Splatting Deformation,"Tianhao Xie, Noam Aigerman, Eugene Belilovsky, Tiberiu Popa",2024-11-19T02:18:19Z,"3D Gaussian Splatting (GS) is one of the most promising novel 3D
representations that has received great interest in computer graphics and
computer vision. While various systems have introduced editing capabilities for
3D GS, such as those guided by text prompts, fine-grained control over
deformation remains an open challenge. In this work, we present a novel
sketch-guided 3D GS deformation system that allows users to intuitively modify
the geometry of a 3D GS model by drawing a silhouette sketch from a single
viewpoint. Our approach introduces a new deformation method that combines
cage-based deformations with a variant of Neural Jacobian Fields, enabling
precise, fine-grained control. Additionally, it leverages large-scale 2D
diffusion priors and ControlNet to ensure the generated deformations are
semantically plausible. Through a series of experiments, we demonstrate the
effectiveness of our method and showcase its ability to animate static 3D GS
models as one of its key applications.","cs.CV, cs.GR",cs.CV,http://arxiv.org/abs/2411.12168v1
"The Role of Accuracy and Validation Effectiveness in Conversational
  Business Analytics",Adem Alparslan,2024-11-18T23:58:24Z,"This study examines conversational business analytics, an approach that
utilizes AI to address the technical competency gaps that hinder end users from
effectively using traditional self-service analytics. By facilitating natural
language interactions, conversational business analytics aims to empower end
users to independently retrieve data and generate insights. The analysis
focuses on Text-to-SQL as a representative technology for translating natural
language requests into SQL statements. Developing theoretical models grounded
in expected utility theory, the study identifies conditions under which
conversational business analytics, through partial or full support, can
outperform delegation to human experts. The results indicate that partial
support, focusing solely on information generation by AI, is viable when the
accuracy of AI-generated SQL queries leads to a profit that surpasses the
performance of a human expert. In contrast, full support includes not only
information generation but also validation through explanations provided by the
AI, and requires sufficiently high validation effectiveness to be reliable.
However, user-based validation presents challenges, such as misjudgment and
rejection of valid SQL queries, which may limit the effectiveness of
conversational business analytics. These challenges underscore the need for
robust validation mechanisms, including improved user support, automated
processes, and methods for assessing quality independently of end users'
technical competencies.","cs.AI, econ.GN, q-fin.EC",cs.AI,http://arxiv.org/abs/2411.12128v2
Sorted Consecutive Occurrence Queries in Substrings,"Waseem Akram, Takuya Mieno",2024-11-18T22:12:14Z,"The string indexing problem is a fundamental computational problem with
numerous applications, including information retrieval and bioinformatics. It
aims to efficiently solve the pattern matching problem: given a text $T$ of
length $n$ for preprocessing and a pattern $P$ of length $m$ as a query, the
goal is to report all occurrences of $P$ as substrings of $T$. Navarro and
Thankachan [CPM 2015, Theor. Comput. Sci. 2016] introduced a variant of this
problem called the gap-bounded consecutive occurrence query, which reports
pairs of consecutive occurrences of $P$ in $T$ such that their gaps (i.e., the
distances between them) lie within a query-specified range $[g_1, g_2]$.
Recently, Bille et al. [FSTTCS 2020, Theor. Comput. Sci. 2022] proposed the
top-$k$ close consecutive occurrence query, which reports the $k$ closest
consecutive occurrences of $P$ in $T$, sorted in non-descending order of
distance. Both problems are optimally solved in query time with $O(n \log
n)$-space data structures.
  In this paper, we generalize these problems to the range query model, which
focuses only on occurrences of $P$ in a specified substring $T[a.. b]$ of $T$.
Our contributions are as follows: (1) We propose an $O(n \log^2 n)$-space data
structure that answers the range top-$k$ consecutive occurrence query in $O(|P|
+ \log\log n + k)$ time. (2) We propose an $O(n \log^{2+\epsilon} n)$-space
data structure that answers the range gap-bounded consecutive occurrence query
in $O(|P| + \log\log n + \mathit{output})$ time, where $\epsilon$ is a positive
constant and $\mathit{output}$ denotes the number of outputs. Additionally, as
by-products, we present algorithms for geometric problems involving weighted
horizontal segments in a 2D plane, which are of independent interest.","cs.DS, cs.CG",cs.DS,http://arxiv.org/abs/2411.12099v2
"Zoomed In, Diffused Out: Towards Local Degradation-Aware Multi-Diffusion
  for Extreme Image Super-Resolution","Brian B. Moser, Stanislav Frolov, Tobias C. Nauen, Federico Raue, Andreas Dengel",2024-11-18T21:32:49Z,"Large-scale, pre-trained Text-to-Image (T2I) diffusion models have gained
significant popularity in image generation tasks and have shown unexpected
potential in image Super-Resolution (SR). However, most existing T2I diffusion
models are trained with a resolution limit of 512x512, making scaling beyond
this resolution an unresolved but necessary challenge for image SR. In this
work, we introduce a novel approach that, for the first time, enables these
models to generate 2K, 4K, and even 8K images without any additional training.
Our method leverages MultiDiffusion, which distributes the generation across
multiple diffusion paths to ensure global coherence at larger scales, and local
degradation-aware prompt extraction, which guides the T2I model to reconstruct
fine local structures according to its low-resolution input. These innovations
unlock higher resolutions, allowing T2I diffusion models to be applied to image
SR tasks without limitation on resolution.","cs.CV, cs.AI, cs.LG, cs.MM",cs.CV,http://arxiv.org/abs/2411.12072v1
"Benchmarking pre-trained text embedding models in aligning built asset
  information","Mehrzad Shahinmoghadam, Ali Motamedi",2024-11-18T20:54:17Z,"Accurate mapping of the built asset information to established data
classification systems and taxonomies is crucial for effective asset
management, whether for compliance at project handover or ad-hoc data
integration scenarios. Due to the complex nature of built asset data, which
predominantly comprises technical text elements, this process remains largely
manual and reliant on domain expert input. Recent breakthroughs in contextual
text representation learning (text embedding), particularly through pre-trained
large language models, offer promising approaches that can facilitate the
automation of cross-mapping of the built asset data. However, no comprehensive
evaluation has yet been conducted to assess these models' ability to
effectively represent the complex semantics specific to built asset technical
terminology. This study presents a comparative benchmark of state-of-the-art
text embedding models to evaluate their effectiveness in aligning built asset
information with domain-specific technical concepts. Our proposed datasets are
derived from two renowned built asset data classification dictionaries. The
results of our benchmarking across six proposed datasets, covering three tasks
of clustering, retrieval, and reranking, highlight the need for future research
on domain adaptation techniques. The benchmarking resources are published as an
open-source library, which will be maintained and extended to support future
evaluations in this field.","cs.CL, cs.AI, cs.IR, cs.LG",cs.CL,http://arxiv.org/abs/2411.12056v1
Parsing Millions of DNS Records per Second,"Jeroen Koekkoek, Daniel Lemire",2024-11-18T20:13:05Z,"The Domain Name System (DNS) plays a critical role in the functioning of the
Internet. It provides a hierarchical name space for locating resources. Data is
typically stored in plain text files, possibly spanning gigabytes. Frequent
parsing of these files to refresh the data is computationally expensive:
processing a zone file can take minutes.
  We propose a novel approach called simdzone to enhance DNS parsing
throughput. We use data parallelism, specifically the Single Instruction
Multiple Data (SIMD) instructions available on commodity processors. We show
that we can multiply the parsing speed compared to state-of-the-art parsers
found in Knot DNS and the NLnet Labs Name Server Daemon (NSD). The resulting
software library replaced the parser in NSD.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12035v1
"ByteScience: Bridging Unstructured Scientific Literature and Structured
  Data with Auto Fine-tuned Large Language Model in Token Granularity","Tong Xie, Hanzhi Zhang, Shaozhou Wang, Yuwei Wan, Imran Razzak, Chunyu Kit, Wenjie Zhangand Bram Hoex",2024-11-18T19:36:26Z,"Natural Language Processing (NLP) is widely used to supply summarization
ability from long context to structured information. However, extracting
structured knowledge from scientific text by NLP models remains a challenge
because of its domain-specific nature to complex data preprocessing and the
granularity of multi-layered device-level information. To address this, we
introduce ByteScience, a non-profit cloud-based auto fine-tuned Large Language
Model (LLM) platform, which is designed to extract structured scientific data
and synthesize new scientific knowledge from vast scientific corpora. The
platform capitalizes on DARWIN, an open-source, fine-tuned LLM dedicated to
natural science. The platform was built on Amazon Web Services (AWS) and
provides an automated, user-friendly workflow for custom model development and
data extraction. The platform achieves remarkable accuracy with only a small
amount of well-annotated articles. This innovative tool streamlines the
transition from the science literature to structured knowledge and data and
benefits the advancements in natural informatics.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12000v1
Medical Video Generation for Disease Progression Simulation,"Xu Cao, Kaizhao Liang, Kuei-Da Liao, Tianren Gao, Wenqian Ye, Jintai Chen, Zhiguang Ding, Jianguo Cao, James M. Rehg, Jimeng Sun",2024-11-18T18:37:09Z,"Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11943v1
"CNMBert: A Model For Hanyu Pinyin Abbreviation to Character Conversion
  Task","Zishuo Feng, Feng Cao",2024-11-18T17:50:34Z,"The task of converting Hanyu Pinyin abbreviations to Chinese characters
represents a significant branch within the domain of Chinese Spelling
Correction (CSC). This task is typically one of text-length alignment, however,
due to the limited informational content in pinyin abbreviations, achieving
accurate conversion is challenging. In this paper, we propose CNMBert which
stands for zh-CN Pinyin Multi-mask Bert Model as a solution to this issue.
CNMBert surpasses few-shot GPT models, achieving a 59.63% MRR on a
10,424-sample Hanyu Pinyin abbreviation test dataset.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11770v1
"FedCoLLM: A Parameter-Efficient Federated Co-tuning Framework for Large
  and Small Language Models","Tao Fan, Yan Kang, Guoqiang Ma, Lixin Fan, Kai Chen, Qiang Yang",2024-11-18T16:34:58Z,"By adapting Large Language Models (LLMs) to domain-specific tasks or
enriching them with domain-specific knowledge, we can fully harness the
capabilities of LLMs. Nonetheless, a gap persists in achieving simultaneous
mutual enhancement between the server's LLM and the downstream clients' Small
Language Models (SLMs). To address this, we propose FedCoLLM, a novel and
parameter-efficient federated framework designed for co-tuning LLMs and SLMs.
This approach is aimed at adaptively transferring server-side LLMs knowledge to
clients' SLMs while simultaneously enriching the LLMs with domain insights from
the clients. To accomplish this, FedCoLLM utilizes lightweight adapters in
conjunction with SLMs, facilitating knowledge exchange between server and
clients in a manner that respects data privacy while also minimizing
computational and communication overhead. Our evaluation of FedCoLLM, utilizing
various public LLMs and SLMs across a range of NLP text generation tasks,
reveals that the performance of clients' SLMs experiences notable improvements
with the assistance of the LLMs. Simultaneously, the LLMs enhanced via FedCoLLM
achieves comparable performance to that obtained through direct fine-tuning on
clients' data.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11707v1
"Bitcoin Under Volatile Block Rewards: How Mempool Statistics Can
  Influence Bitcoin Mining","Roozbeh Sarenche, Alireza Aghabagherloo, Svetla Nikova, Bart Preneel",2024-11-18T16:29:20Z,"As Bitcoin experiences more halving events, the protocol reward converges to
zero, making transaction fees the primary source of miner rewards. This shift
in Bitcoin's incentivization mechanism, which introduces volatility into block
rewards, could lead to the emergence of new security threats or intensify
existing ones. Previous security analyses of Bitcoin have either considered a
fixed block reward model or a highly simplified volatile model, overlooking the
complexities of Bitcoin's mempool behavior.
  In this paper, we present a reinforcement learning-based tool designed to
analyze mining strategies under a more realistic volatile model. Our tool uses
the Asynchronous Advantage Actor-Critic (A3C) algorithm to derive near-optimal
mining strategies while interacting with an environment that models the
complexity of the Bitcoin mempool. This tool enables the analysis of
adversarial mining strategies, such as selfish mining and undercutting, both
before and after difficulty adjustments, providing insights into the effects of
mining attacks in both the short and long term.
  Our analysis reveals that Bitcoin users' trend of offering higher fees to
speed up the inclusion of their transactions in the chain can incentivize
payoff-maximizing miners to deviate from the honest strategy. In the fixed
reward model, a disincentive for the selfish mining attack is the initial loss
period of at least two weeks, during which the attack is not profitable.
However, our analysis shows that once the protocol reward diminishes to zero in
the future, or even currently on days when transaction fees are comparable to
the protocol reward, mining pools might be incentivized to abandon honest
mining to gain an immediate profit.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11702v1
"Chapter 7 Review of Data-Driven Generative AI Models for Knowledge
  Extraction from Scientific Literature in Healthcare","Leon Kopitar, Primoz Kocbek, Lucija Gosak, Gregor Stiglic",2024-11-18T15:13:47Z,"This review examines the development of abstractive NLP-based text
summarization approaches and compares them to existing techniques for
extractive summarization. A brief history of text summarization from the 1950s
to the introduction of pre-trained language models such as Bidirectional
Encoder Representations from Transformer (BERT) and Generative Pre-training
Transformers (GPT) are presented. In total, 60 studies were identified in
PubMed and Web of Science, of which 29 were excluded and 24 were read and
evaluated for eligibility, resulting in the use of seven studies for further
analysis. This chapter also includes a section with examples including an
example of a comparison between GPT-3 and state-of-the-art GPT-4 solutions in
scientific text summarisation. Natural language processing has not yet reached
its full potential in the generation of brief textual summaries. As there are
acknowledged concerns that must be addressed, we can expect gradual
introduction of such models in practise.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11635v1
"Enhancing Vision-Language Model Safety through Progressive
  Concept-Bottleneck-Driven Alignment","Zhendong Liu, Yuanbi Nie, Yingshui Tan, Xiangyu Yue, Qiushi Cui, Chongjun Wang, Xiaoyong Zhu, Bo Zheng",2024-11-18T13:01:57Z,"Benefiting from the powerful capabilities of Large Language Models (LLMs),
pre-trained visual encoder models connected to LLMs form Vision Language Models
(VLMs). However, recent research shows that the visual modality in VLMs is
highly vulnerable, allowing attackers to bypass safety alignment in LLMs
through visually transmitted content, launching harmful attacks. To address
this challenge, we propose a progressive concept-based alignment strategy,
PSA-VLM, which incorporates safety modules as concept bottlenecks to enhance
visual modality safety alignment. By aligning model predictions with specific
safety concepts, we improve defenses against risky images, enhancing
explainability and controllability while minimally impacting general
performance. Our method is obtained through two-stage training. The low
computational cost of the first stage brings very effective performance
improvement, and the fine-tuning of the language model in the second stage
further improves the safety performance. Our method achieves state-of-the-art
results on popular VLM safety benchmark.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11543v1
"Addressing Hallucinations in Language Models with Knowledge Graph
  Embeddings as an Additional Modality","Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov",2024-11-18T12:40:51Z,"In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11531v1
"Preempting Text Sanitization Utility in Resource-Constrained
  Privacy-Preserving LLM Interactions","Robin Carpentier, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Dali Kaafar",2024-11-18T12:31:22Z,"Individuals have been increasingly interacting with online Large Language
Models (LLMs), both in their work and personal lives. These interactions raise
privacy issues as the LLMs are typically hosted by third-parties who can gather
a variety of sensitive information about users and their companies. Text
Sanitization techniques have been proposed in the literature and can be used to
sanitize user prompts before sending them to the LLM. However, sanitization has
an impact on the downstream task performed by the LLM, and often to such an
extent that it leads to unacceptable results for the user. This is not just a
minor annoyance, with clear monetary consequences as LLM services charge on a
per use basis as well as great amount of computing resources wasted. We propose
an architecture leveraging a Small Language Model (SLM) at the user-side to
help estimate the impact of sanitization on a prompt before it is sent to the
LLM, thus preventing resource losses.
  Our evaluation of this architecture revealed a significant problem with text
sanitization based on Differential Privacy, on which we want to draw the
attention of the community for further investigation.","cs.CR, cs.LG",cs.CR,http://arxiv.org/abs/2411.11521v1
"GLDesigner: Leveraging Multi-Modal LLMs as Designer for Enhanced
  Aesthetic Text Glyph Layouts","Junwen He, Yifan Wang, Lijun Wang, Huchuan Lu, Jun-Yan He, Chenyang Li, Hanyuan Chen, Jin-Peng Lan, Bin Luo, Yifeng Geng",2024-11-18T10:04:10Z,"Text logo design heavily relies on the creativity and expertise of
professional designers, in which arranging element layouts is one of the most
important procedures. However, few attention has been paid to this specific
task which needs to take precise textural details and user constraints into
consideration, but only on the broader tasks such as document/poster layout
generation. In this paper, we propose a VLM-based framework that generates
content-aware text logo layouts by integrating multi-modal inputs with user
constraints, supporting a more flexible and stable layout design in real-world
applications. We introduce two model techniques to reduce the computation for
processing multiple glyph images simultaneously, while does not face
performance degradation. To support instruction-tuning of out model, we
construct two extensive text logo datasets, which are 5x more larger than the
existing public dataset. Except for the geometric annotations (e.g. text masks
and character recognition), we also compliment with comprehensive layout
descriptions in natural language format, for more effective training to have
reasoning ability when dealing with complex layouts and custom user
constraints. Experimental studies demonstrate the effectiveness of our proposed
model and datasets, when comparing with previous methods in various benchmarks
to evaluate geometric aesthetics and human preferences. The code and datasets
will be publicly available.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11435v1
"Extended Neural Contractive Dynamical Systems: On Multiple Tasks and
  Riemannian Safety Regions","Hadi Beik Mohammadi, Søren Hauberg, Georgios Arvanitidis, Gerhard Neumann, Leonel Rozo",2024-11-18T09:27:49Z,"Stability guarantees are crucial when ensuring that a fully autonomous robot
does not take undesirable or potentially harmful actions. We recently proposed
the Neural Contractive Dynamical Systems (NCDS), which is a neural network
architecture that guarantees contractive stability. With this,
learning-from-demonstrations approaches can trivially provide stability
guarantees. However, our early work left several unanswered questions, which we
here address. Beyond providing an in-depth explanation of NCDS, this paper
extends the framework with more careful regularization, a conditional variant
of the framework for handling multiple tasks, and an uncertainty-driven
approach to latent obstacle avoidance. Experiments verify that the developed
system has the flexibility of ordinary neural networks while providing the
stability guarantees needed for autonomous robotics.","cs.RO, cs.LG",cs.RO,http://arxiv.org/abs/2411.11405v2
"FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image
  Pre-training","Anjia Cao, Xing Wei, Zhiheng Ma",2024-11-18T09:19:30Z,"Language-image pre-training faces significant challenges due to limited data
in specific formats and the constrained capacities of text encoders. While
prevailing methods attempt to address these issues through data augmentation
and architecture modifications, they continue to struggle with processing
long-form text inputs, and the inherent limitations of traditional CLIP text
encoders lead to suboptimal downstream generalization. In this paper, we
propose FLAME (Frozen Large lAnguage Models Enable data-efficient
language-image pre-training) that leverages frozen large language models as
text encoders, naturally processing long text inputs and demonstrating
impressive multilingual generalization. FLAME comprises two key components: 1)
a multifaceted prompt distillation technique for extracting diverse semantic
representations from long captions, which better aligns with the multifaceted
nature of images, and 2) a facet-decoupled attention mechanism, complemented by
an offline embedding strategy, to ensure efficient computation. Extensive
empirical evaluations demonstrate FLAME's superior performance. When trained on
CC3M, FLAME surpasses the previous state-of-the-art by 4.9\% in ImageNet top-1
accuracy. On YFCC15M, FLAME surpasses the WIT-400M-trained CLIP by 44.4\% in
average image-to-text recall@1 across 36 languages, and by 34.6\% in
text-to-image recall@1 for long-context retrieval on Urban-1k. Code is
available at \url{https://github.com/MIV-XJTU/FLAME}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11927v1
"CROW: Eliminating Backdoors from Large Language Models via Internal
  Consistency Regularization","Nay Myat Min, Long H. Pham, Yige Li, Jun Sun",2024-11-18T07:52:12Z,"Recent studies reveal that Large Language Models (LLMs) are susceptible to
backdoor attacks, where adversaries embed hidden triggers that manipulate model
responses. Existing backdoor defense methods are primarily designed for vision
or classification tasks, and are thus ineffective for text generation tasks,
leaving LLMs vulnerable. We introduce Internal Consistency Regularization
(CROW), a novel defense using consistency regularization finetuning to address
layer-wise inconsistencies caused by backdoor triggers. CROW leverages the
intuition that clean models exhibit smooth, consistent transitions in hidden
representations across layers, whereas backdoored models show noticeable
fluctuation when triggered. By enforcing internal consistency through
adversarial perturbations and regularization, CROW neutralizes backdoor effects
without requiring clean reference models or prior trigger knowledge, relying
only on a small set of clean data. This makes it practical for deployment
across various LLM architectures. Experimental results demonstrate that CROW
consistently achieves a significant reductions in attack success rates across
diverse backdoor strategies and tasks, including negative sentiment, targeted
refusal, and code injection, on models such as Llama-2 (7B, 13B), CodeLlama
(7B, 13B) and Mistral-7B, while preserving the model's generative capabilities.","cs.CL, cs.AI, cs.LG",cs.CL,http://arxiv.org/abs/2411.12768v1
Teaching Video Diffusion Model with Latent Physical Phenomenon Knowledge,"Qinglong Cao, Ding Wang, Xirui Li, Yuntian Chen, Chao Ma, Xiaokang Yang",2024-11-18T07:26:09Z,"Video diffusion models have exhibited tremendous progress in various video
generation tasks. However, existing models struggle to capture latent physical
knowledge, failing to infer physical phenomena that are challenging to
articulate with natural language. Generating videos following the fundamental
physical laws is still an opening challenge. To address this challenge, we
propose a novel method to teach video diffusion models with latent physical
phenomenon knowledge, enabling the accurate generation of physically informed
phenomena. Specifically, we first pretrain Masked Autoencoders (MAE) to
reconstruct the physical phenomena, resulting in output embeddings that
encapsulate latent physical phenomenon knowledge. Leveraging these embeddings,
we could generate the pseudo-language prompt features based on the aligned
spatial relationships between CLIP vision and language encoders. Particularly,
given that diffusion models typically use CLIP's language encoder for text
prompt embeddings, our approach integrates the CLIP visual features informed by
latent physical knowledge into a quaternion hidden space. This enables the
modeling of spatial relationships to produce physical knowledge-informed
pseudo-language prompts. By incorporating these prompt features and fine-tuning
the video diffusion model in a parameter-efficient manner, the physical
knowledge-informed videos are successfully generated. We validate our method
extensively through both numerical simulations and real-world observations of
physical phenomena, demonstrating its remarkable performance across diverse
scenarios.","cs.CV, stat.AP",cs.CV,http://arxiv.org/abs/2411.11343v1
"Large corpora and large language models: a replicable method for
  automating grammatical annotation","Cameron Morin, Matti Marttinen Larsson",2024-11-18T03:29:48Z,"Much linguistic research relies on annotated datasets of features extracted
from text corpora, but the rapid quantitative growth of these corpora has
created practical difficulties for linguists to manually annotate large data
samples. In this paper, we present a replicable, supervised method that
leverages large language models for assisting the linguist in grammatical
annotation through prompt engineering, training, and evaluation. We introduce a
methodological pipeline applied to the case study of formal variation in the
English evaluative verb construction 'consider X (as) (to be) Y', based on the
large language model Claude 3.5 Sonnet and corpus data from Davies' NOW and
EnTenTen21 (SketchEngine). Overall, we reach a model accuracy of over 90% on
our held-out test samples with only a small amount of training data, validating
the method for the annotation of very large quantities of tokens of the
construction in the future. We discuss the generalisability of our results for
a wider range of case studies of grammatical constructions and grammatical
variation and change, underlining the value of AI copilots as tools for future
linguistic research.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11260v1
"ESTVocoder: An Excitation-Spectral-Transformed Neural Vocoder
  Conditioned on Mel Spectrogram","Xiao-Hang Jiang, Hui-Peng Du, Yang Ai, Ye-Xin Lu, Zhen-Hua Ling",2024-11-18T03:22:34Z,"This paper proposes ESTVocoder, a novel excitation-spectral-transformed
neural vocoder within the framework of source-filter theory. The ESTVocoder
transforms the amplitude and phase spectra of the excitation into the
corresponding speech amplitude and phase spectra using a neural filter whose
backbone is ConvNeXt v2 blocks. Finally, the speech waveform is reconstructed
through the inverse short-time Fourier transform (ISTFT). The excitation is
constructed based on the F0: for voiced segments, it contains full harmonic
information, while for unvoiced segments, it is represented by noise. The
excitation provides the filter with prior knowledge of the amplitude and phase
patterns, expecting to reduce the modeling difficulty compared to conventional
neural vocoders. To ensure the fidelity of the synthesized speech, an
adversarial training strategy is applied to ESTVocoder with multi-scale and
multi-resolution discriminators. Analysis-synthesis and text-to-speech
experiments both confirm that our proposed ESTVocoder outperforms or is
comparable to other baseline neural vocoders, e.g., HiFi-GAN, SiFi-GAN, and
Vocos, in terms of synthesized speech quality, with a reasonable model
complexity and generation speed. Additional analysis experiments also
demonstrate that the introduced excitation effectively accelerates the model's
convergence process, thanks to the speech spectral prior information contained
in the excitation.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.11258v1
"From Words to Structured Visuals: A Benchmark and Framework for
  Text-to-Diagram Generation and Editing","Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, Ruifeng Guo",2024-11-18T02:58:37Z,"We introduce the task of text-to-diagram generation, which focuses on
creating structured visual representations directly from textual descriptions.
Existing approaches in text-to-image and text-to-code generation lack the
logical organization and flexibility needed to produce accurate, editable
diagrams, often resulting in outputs that are either unstructured or difficult
to modify. To address this gap, we introduce DiagramGenBenchmark, a
comprehensive evaluation framework encompassing eight distinct diagram
categories, including flowcharts, model architecture diagrams, and mind maps.
Additionally, we present DiagramAgent, an innovative framework with four core
modules-Plan Agent, Code Agent, Check Agent, and Diagram-to-Code Agent-designed
to facilitate both the generation and refinement of complex diagrams. Our
extensive experiments, which combine objective metrics with human evaluations,
demonstrate that DiagramAgent significantly outperforms existing baseline
models in terms of accuracy, structural coherence, and modifiability. This work
not only establishes a foundational benchmark for the text-to-diagram
generation task but also introduces a powerful toolset to advance research and
applications in this emerging area.",cs.DB,cs.DB,http://arxiv.org/abs/2411.11916v1
Efficient Transfer Learning for Video-language Foundation Models,"Haoxing Chen, Zizheng Huang, Yan Hong, Yanshuo Wang, Zhongcai Lyu, Zhuoer Xu, Jun Lan, Zhangxuan Gu",2024-11-18T01:25:58Z,"Pre-trained vision-language models provide a robust foundation for efficient
transfer learning across various downstream tasks. In the field of video action
recognition, mainstream approaches often introduce additional parameter modules
to capture temporal information. While the increased model capacity brought by
these additional parameters helps better fit the video-specific inductive
biases, existing methods require learning a large number of parameters and are
prone to catastrophic forgetting of the original generalizable knowledge. In
this paper, we propose a simple yet effective Multi-modal Spatio-Temporal
Adapter (MSTA) to improve the alignment between representations in the text and
vision branches, achieving a balance between general knowledge and
task-specific knowledge. Furthermore, to mitigate over-fitting and enhance
generalizability, we introduce a spatio-temporal description-guided consistency
constraint. This constraint involves feeding template inputs (i.e., ``a video
of $\{\textbf{cls}\}$'') into the trainable language branch, while
LLM-generated spatio-temporal descriptions are input into the pre-trained
language branch, enforcing consistency between the outputs of the two branches.
This mechanism prevents over-fitting to downstream tasks and improves the
distinguishability of the trainable branch within the spatio-temporal semantic
space. We evaluate the effectiveness of our approach across four tasks:
zero-shot transfer, few-shot learning, base-to-novel generalization, and
fully-supervised learning. Compared to many state-of-the-art methods, our MSTA
achieves outstanding performance across all evaluations, while using only 2-7\%
of the trainable parameters in the original model. Code will be avaliable at
https://github.com/chenhaoxing/ETL4Video.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11223v1
"LLäMmlein: Compact and Competitive German-Only Language Models from
  Scratch","Jan Pfister, Julia Wunderle, Andreas Hotho",2024-11-17T20:44:34Z,"We create two German-only decoder models, LL\""aMmlein 120M and 1B,
transparently from scratch and publish them, along with the training data, for
the German NLP research community to use. The model training involved several
key steps, including extensive data preprocessing, the creation of a custom
German tokenizer, the training itself, as well as the evaluation of the final
models on various benchmarks. Throughout the training process, multiple
checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor
the models' learning dynamics. Compared to state-of-the-art models on the
SuperGLEBer benchmark, both LL\""aMmlein models performed competitively,
consistently matching or surpassing models with similar parameter sizes. The
results show that the models' quality scales with size as expected, but
performance improvements on some tasks plateaued early, offering valuable
insights into resource allocation for future model development.","cs.CL, cs.AI, cs.LG",cs.CL,http://arxiv.org/abs/2411.11171v1
SEFD: Semantic-Enhanced Framework for Detecting LLM-Generated Text,"Weiqing He, Bojian Hou, Tianqi Shang, Davoud Ataee Tarzanagh, Qi Long, Li Shen",2024-11-17T20:13:30Z,"The widespread adoption of large language models (LLMs) has created an urgent
need for robust tools to detect LLM-generated text, especially in light of
\textit{paraphrasing} techniques that often evade existing detection methods.
To address this challenge, we present a novel semantic-enhanced framework for
detecting LLM-generated text (SEFD) that leverages a retrieval-based mechanism
to fully utilize text semantics. Our framework improves upon existing detection
methods by systematically integrating retrieval-based techniques with
traditional detectors, employing a carefully curated retrieval mechanism that
strikes a balance between comprehensive coverage and computational efficiency.
We showcase the effectiveness of our approach in sequential text scenarios
common in real-world applications, such as online forums and Q\&A platforms.
Through comprehensive experiments across various LLM-generated texts and
detection methods, we demonstrate that our framework substantially enhances
detection accuracy in paraphrasing scenarios while maintaining robustness for
standard LLM-generated content.","cs.CL, cs.AI, cs.IR",cs.CL,http://arxiv.org/abs/2411.12764v1
MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records,"Eric Yang, Pengfei Hu, Xiaoxue Han, Yue Ning",2024-11-17T19:43:10Z,"The adoption of digital systems in healthcare has resulted in the
accumulation of vast electronic health records (EHRs), offering valuable data
for machine learning methods to predict patient health outcomes. However,
single-visit records of patients are often neglected in the training process
due to the lack of annotations of next-visit information, thereby limiting the
predictive and expressive power of machine learning models. In this paper, we
present a novel framework MPLite that utilizes Multi-aspect Pretraining with
Lab results through a light-weight neural network to enhance medical concept
representation and predict future health outcomes of individuals. By
incorporating both structured medical data and additional information from lab
results, our approach fully leverages patient admission records. We design a
pretraining module that predicts medical codes based on lab results, ensuring
robust prediction by fusing multiple aspects of features. Our experimental
evaluation using both MIMIC-III and MIMIC-IV datasets demonstrates improvements
over existing models in diagnosis prediction and heart failure prediction
tasks, achieving a higher weighted-F1 and recall with MPLite. This work reveals
the potential of integrating diverse aspects of data to advance predictive
modeling in healthcare.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11161v1
From Primes to Paths: Enabling Fast Multi-Relational Graph Analysis,"Konstantinos Bougiatiotis, Georgios Paliouras",2024-11-17T18:43:01Z,"Multi-relational networks capture intricate relationships in data and have
diverse applications across fields such as biomedical, financial, and social
sciences. As networks derived from increasingly large datasets become more
common, identifying efficient methods for representing and analyzing them
becomes crucial. This work extends the Prime Adjacency Matrices (PAMs)
framework, which employs prime numbers to represent distinct relations within a
network uniquely. This enables a compact representation of a complete
multi-relational graph using a single adjacency matrix, which, in turn,
facilitates quick computation of multi-hop adjacency matrices. In this work, we
enhance the framework by introducing a lossless algorithm for calculating the
multi-hop matrices and propose the Bag of Paths (BoP) representation, a
versatile feature extraction methodology for various graph analytics tasks, at
the node, edge, and graph level. We demonstrate the efficiency of the framework
across various tasks and datasets, showing that simple BoP-based models perform
comparably to or better than commonly used neural models while offering
improved speed and interpretability.","cs.LG, cs.SI",cs.LG,http://arxiv.org/abs/2411.11149v1
"The Promises and Pitfalls of LLM Annotations in Dataset Labeling: a Case
  Study on Media Bias Detection","Tomas Horych, Christoph Mandl, Terry Ruas, Andre Greiner-Petter, Bela Gipp, Akiko Aizawa, Timo Spinde",2024-11-17T14:14:36Z,"High annotation costs from hiring or crowdsourcing complicate the creation of
large, high-quality datasets needed for training reliable text classifiers.
Recent research suggests using Large Language Models (LLMs) to automate the
annotation process, reducing these costs while maintaining data quality. LLMs
have shown promising results in annotating downstream tasks like hate speech
detection and political framing. Building on the success in these areas, this
study investigates whether LLMs are viable for annotating the complex task of
media bias detection and whether a downstream media bias classifier can be
trained on such data. We create annolexical, the first large-scale dataset for
media bias classification with over 48000 synthetically annotated examples. Our
classifier, fine-tuned on this dataset, surpasses all of the annotator LLMs by
5-9 percent in Matthews Correlation Coefficient (MCC) and performs close to or
outperforms the model trained on human-labeled data when evaluated on two media
bias benchmark datasets (BABE and BASIL). This study demonstrates how our
approach significantly reduces the cost of dataset creation in the media bias
domain and, by extension, the development of classifiers, while our subsequent
behavioral stress-testing reveals some of its current limitations and
trade-offs.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11081v1
"Beyond Human-Like Processing: Large Language Models Perform Equivalently
  on Forward and Backward Scientific Text","Xiaoliang Luo, Michael Ramscar, Bradley C. Love",2024-11-17T12:48:24Z,"The impressive performance of large language models (LLMs) has led to their
consideration as models of human language processing. Instead, we suggest that
the success of LLMs arises from the flexibility of the transformer learning
architecture. To evaluate this conjecture, we trained LLMs on scientific texts
that were either in a forward or backward format. Despite backward text being
inconsistent with the structure of human languages, we found that LLMs
performed equally well in either format on a neuroscience benchmark, eclipsing
human expert performance for both forward and backward orders. Our results are
consistent with the success of transformers across diverse domains, such as
weather prediction and protein design. This widespread success is attributable
to LLM's ability to extract predictive patterns from any sufficiently
structured input. Given their generality, we suggest caution in interpreting
LLM's success in linguistic tasks as evidence for human-like mechanisms.","cs.CL, q-bio.NC",cs.CL,http://arxiv.org/abs/2411.11061v1
FastDraft: How to Train Your Draft,"Ofir Zafrir, Igor Margulis, Dorin Shteyman, Guy Boudoukh",2024-11-17T12:32:44Z,"Speculative Decoding has gained popularity as an effective technique for
accelerating the auto-regressive inference process of Large Language Models
(LLMs). However, Speculative Decoding entirely relies on the availability of
efficient draft models, which are often lacking for many existing language
models due to a stringent constraint of vocabulary incompatibility. In this
work we introduce FastDraft, a novel and efficient approach for pre-training
and aligning a draft model to any large language model by incorporating
efficient pre-training, followed by fine-tuning over synthetic datasets
generated by the target model. We demonstrate FastDraft by training two highly
parameter efficient drafts for the popular Phi-3-mini and Llama-3.1-8B models.
Using FastDraft, we were able to produce a draft with approximately 10 billion
tokens on a single server with 8 Intel$^\circledR$ Gaudi$^\circledR$ 2
accelerators in under 24 hours. Our results show that the draft model achieves
impressive results in key metrics of acceptance rate, block efficiency and up
to 3x memory bound speed up when evaluated on code completion and up to 2x in
summarization, text completion and instruction tasks. We validate our
theoretical findings through benchmarking on the latest Intel$^\circledR$
Core$^{\tiny \text{TM}}$ Ultra, achieving a wall-clock time speedup of up to
2x, indicating a significant reduction in runtime. Due to its high quality,
FastDraft unlocks large language models inference on AI-PC and other
edge-devices.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11055v1
Time Step Generating: A Universal Synthesized Deepfake Image Detector,"Ziyue Zeng, Haoyuan Liu, Dingjie Peng, Luoxu Jing, Hiroshi Watanabe",2024-11-17T09:39:50Z,"Currently, high-fidelity text-to-image models are developed in an
accelerating pace. Among them, Diffusion Models have led to a remarkable
improvement in the quality of image generation, making it vary challenging to
distinguish between real and synthesized images. It simultaneously raises
serious concerns regarding privacy and security. Some methods are proposed to
distinguish the diffusion model generated images through reconstructing.
However, the inversion and denoising processes are time-consuming and heavily
reliant on the pre-trained generative model. Consequently, if the pre-trained
generative model meet the problem of out-of-domain, the detection performance
declines. To address this issue, we propose a universal synthetic image
detector Time Step Generating (TSG), which does not rely on pre-trained models'
reconstructing ability, specific datasets, or sampling algorithms. Our method
utilizes a pre-trained diffusion model's network as a feature extractor to
capture fine-grained details, focusing on the subtle differences between real
and synthetic images. By controlling the time step t of the network input, we
can effectively extract these distinguishing detail features. Then, those
features can be passed through a classifier (i.e. Resnet), which efficiently
detects whether an image is synthetic or real. We test the proposed TSG on the
large-scale GenImage benchmark and it achieves significant improvements in both
accuracy and generalizability.","cs.CV, cs.AI, 62H30, 68T07, I.4.9; I.4.7; I.5.2",cs.CV,http://arxiv.org/abs/2411.11016v2
Image-Based RKPM for Accessing Failure Mechanisms in Composite Materials,"Yanran Wang, Yichun Tang, Jing Du, Mike Hillman, J. S. Chen",2024-11-17T08:11:57Z,"Stress distributions and the corresponding fracture patterns and evolutions
in the microstructures strongly influence the load-carrying capabilities of
composite structures. This work introduces an enhanced phase-field fracture
model incorporating interface decohesion to simulate fracture propagation and
interactions at material interfaces and within the constituents of composite
microstructures. The proposed method employs an interface-modified reproducing
kernel (IM-RK) approximation for handling cross-interface discontinuities
constructed from image voxels and guided by Support Vector Machine (SVM)
ma-terial classification. The numerical models are directly generated from
X-ray microtomography image voxels, guided by SVM using voxel color code
information. Additionally, a strain energy-based phase field variable is
introduced, eliminating the need to solve coupled field problems. The
effectiveness of this method is demonstrated in modeling crack growth both
along interfaces and across matrix and inclusion domains and in predicting the
corresponding structural-scale mechanical behavior in composite structures.
Furthermore, the proposed method has been validated against experimentally
observed crack patterns.",cs.CE,cs.CE,http://arxiv.org/abs/2411.10998v1
BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization,"Md. Nazmus Sadat Samin, Jawad Ibn Ahad, Tanjila Ahmed Medha, Fuad Rahman, Mohammad Ruhul Amin, Nabeel Mohammed, Shafin Rahman",2024-11-16T20:20:15Z,"This study focuses on recognizing Bangladeshi dialects and converting diverse
Bengali accents into standardized formal Bengali speech. Dialects, often
referred to as regional languages, are distinctive variations of a language
spoken in a particular location and are identified by their phonetics,
pronunciations, and lexicon. Subtle changes in pronunciation and intonation are
also influenced by geographic location, educational attainment, and
socioeconomic status. Dialect standardization is needed to ensure effective
communication, educational consistency, access to technology, economic
opportunities, and the preservation of linguistic resources while respecting
cultural diversity. Being the fifth most spoken language with around 55
distinct dialects spoken by 160 million people, addressing Bangla dialects is
crucial for developing inclusive communication tools. However, limited research
exists due to a lack of comprehensive datasets and the challenges of handling
diverse dialects. With the advancement in multilingual Large Language Models
(mLLMs), emerging possibilities have been created to address the challenges of
dialectal Automated Speech Recognition (ASR) and Machine Translation (MT). This
study presents an end-to-end pipeline for converting dialectal Noakhali speech
to standard Bangla speech. This investigation includes constructing a
large-scale diverse dataset with dialectal speech signals that tailored the
fine-tuning process in ASR and LLM for transcribing the dialect speech to
dialect text and translating the dialect text to standard Bangla text. Our
experiments demonstrated that fine-tuning the Whisper ASR model achieved a CER
of 0.8% and WER of 1.5%, while the BanglaT5 model attained a BLEU score of
41.6% for dialect-to-standard text translation.","cs.CL, cs.AI, cs.LG, cs.SD, eess.AS",cs.CL,http://arxiv.org/abs/2411.10879v1
"AnimateAnything: Consistent and Controllable Animation for Video
  Generation","Guojun Lei, Chi Wang, Hong Li, Rong Zhang, Yikai Wang, Weiwei Xu",2024-11-16T16:36:49Z,"We present a unified controllable video generation approach AnimateAnything
that facilitates precise and consistent video manipulation across various
conditions, including camera trajectories, text prompts, and user motion
annotations. Specifically, we carefully design a multi-scale control feature
fusion network to construct a common motion representation for different
conditions. It explicitly converts all control information into frame-by-frame
optical flows. Then we incorporate the optical flows as motion priors to guide
final video generation. In addition, to reduce the flickering issues caused by
large-scale motion, we propose a frequency-based stabilization module. It can
enhance temporal coherence by ensuring the video's frequency domain
consistency. Experiments demonstrate that our method outperforms the
state-of-the-art approaches. For more details and videos, please refer to the
webpage: https://yu-shaonian.github.io/Animate_Anything/.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10836v1
GeomCLIP: Contrastive Geometry-Text Pre-training for Molecules,"Teng Xiao, Chao Cui, Huaisheng Zhu, Vasant G. Honavar",2024-11-16T15:15:24Z,"Pretraining molecular representations is crucial for drug and material
discovery. Recent methods focus on learning representations from geometric
structures, effectively capturing 3D position information. Yet, they overlook
the rich information in biomedical texts, which detail molecules' properties
and substructures. With this in mind, we set up a data collection effort for
200K pairs of ground-state geometric structures and biomedical texts, resulting
in a PubChem3D dataset. Based on this dataset, we propose the GeomCLIP
framework to enhance for multi-modal representation learning from molecular
structures and biomedical text. During pre-training, we design two types of
tasks, i.e., multimodal representation alignment and unimodal denoising
pretraining, to align the 3D geometric encoder with textual information and, at
the same time, preserve its original representation power. Experimental results
show the effectiveness of GeomCLIP in various tasks such as molecular property
prediction, zero-shot text-molecule retrieval, and 3D molecule captioning. Our
code and collected dataset are available at
\url{https://github.com/xiaocui3737/GeomCLIP}","cs.LG, q-bio.BM",cs.LG,http://arxiv.org/abs/2411.10821v1
FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations,"Hmrishav Bandyopadhyay, Yi-Zhe Song",2024-11-16T14:53:03Z,"Sketch animations offer a powerful medium for visual storytelling, from
simple flip-book doodles to professional studio productions. While traditional
animation requires teams of skilled artists to draw key frames and in-between
frames, existing automation attempts still demand significant artistic effort
through precise motion paths or keyframe specification. We present FlipSketch,
a system that brings back the magic of flip-book animation -- just draw your
idea and describe how you want it to move! Our approach harnesses motion priors
from text-to-video diffusion models, adapting them to generate sketch
animations through three key innovations: (i) fine-tuning for sketch-style
frame generation, (ii) a reference frame mechanism that preserves visual
integrity of input sketch through noise refinement, and (iii) a dual-attention
composition that enables fluid motion without losing visual consistency. Unlike
constrained vector animations, our raster frames support dynamic sketch
transformations, capturing the expressive freedom of traditional animation. The
result is an intuitive system that makes sketch animation as simple as doodling
and describing, while maintaining the artistic essence of hand-drawn animation.","cs.GR, cs.CV",cs.GR,http://arxiv.org/abs/2411.10818v1
"Multi-Stage Vision Token Dropping: Towards Efficient Multimodal Large
  Language Model","Ting Liu, Liangtao Shi, Richang Hong, Yue Hu, Quanjun Yin, Linfeng Zhang",2024-11-16T13:45:33Z,"The vision tokens in multimodal large language models usually exhibit
significant spatial and temporal redundancy and take up most of the input
tokens, which harms their inference efficiency. To solve this problem, some
recent works were introduced to drop the unimportant tokens during inference
where the importance of each token is decided only by the information in either
the vision encoding stage or the prefilling stage. In this paper, we propose
Multi-stage Token Dropping (MustDrop) to measure the importance of each token
from the whole lifecycle, including the vision encoding stage, prefilling
stage, and decoding stage. Concretely, in the visual encoding stage, MustDrop
merges spatially adjacent tokens with high similarity, and establishes a key
token set to retain the most vision-critical tokens, preventing them from being
discarded in later stages. In the prefilling stage, MustDrop further compresses
vision tokens by the guidance of text semantics, with a dual-attention
filtering strategy. In the decoding stage, an output-aware cache policy is
proposed to further reduce the size of the KV cache. By leveraging tailored
strategies in the multi-stage process, MustDrop can more precisely recognize
the important and redundant tokens, thus achieving an optimal balance between
performance and efficiency. For instance, MustDrop reduces about 88.5\% FLOPs
on LLaVA with a compression ratio of 92.2\% while maintaining comparable
accuracy. Our codes are available at
\url{https://github.com/liuting20/MustDrop}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10803v1
Test-time Conditional Text-to-Image Synthesis Using Diffusion Models,"Tripti Shukla, Srikrishna Karanam, Balaji Vasan Srinivasan",2024-11-16T13:32:18Z,"We consider the problem of conditional text-to-image synthesis with diffusion
models. Most recent works need to either finetune specific parts of the base
diffusion model or introduce new trainable parameters, leading to deployment
inflexibility due to the need for training. To address this gap in the current
literature, we propose our method called TINTIN: Test-time Conditional
Text-to-Image Synthesis using Diffusion Models which is a new training-free
test-time only algorithm to condition text-to-image diffusion model outputs on
conditioning factors such as color palettes and edge maps. In particular, we
propose to interpret noise predictions during denoising as gradients of an
energy-based model, leading to a flexible approach to manipulate the noise by
matching predictions inferred from them to the ground truth conditioning input.
This results in, to the best of our knowledge, the first approach to control
model outputs with input color palettes, which we realize using a novel color
distribution matching loss. We also show this test-time noise manipulation can
be easily extensible to other types of conditioning, e.g., edge maps. We
conduct extensive experiments using a variety of text prompts, color palettes,
and edge maps and demonstrate significant improvement over the current
state-of-the-art, both qualitatively and quantitatively.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10800v1
"Bag of Design Choices for Inference of High-Resolution Masked Generative
  Transformer","Shitong Shao, Zikai Zhou, Tian Ye, Lichen Bai, Zhiqiang Xu, Zeke Xie",2024-11-16T11:51:33Z,"Text-to-image diffusion models (DMs) develop at an unprecedented pace,
supported by thorough theoretical exploration and empirical analysis.
Unfortunately, the discrepancy between DMs and autoregressive models (ARMs)
complicates the path toward achieving the goal of unified vision and language
generation. Recently, the masked generative Transformer (MGT) serves as a
promising intermediary between DM and ARM by predicting randomly masked image
tokens (i.e., masked image modeling), combining the efficiency of DM with the
discrete token nature of ARM. However, we find that the comprehensive analyses
regarding the inference for MGT are virtually non-existent, and thus we aim to
present positive design choices to fill this gap. We modify and re-design a set
of DM-based inference techniques for MGT and further elucidate their
performance on MGT. We also discuss the approach to correcting token's
distribution to enhance inference. Extensive experiments and empirical analyses
lead to concrete and effective design choices, and these design choices can be
merged to achieve further performance gains. For instance, in terms of enhanced
inference, we achieve winning rates of approximately 70% compared to vanilla
sampling on HPS v2 with the recent SOTA MGT Meissonic. Our contributions have
the potential to further enhance the capabilities and future development of
MGTs.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10781v1
"TDSM:Triplet Diffusion for Skeleton-Text Matching in Zero-Shot Action
  Recognition","Jeonghyeok Do, Munchurl Kim",2024-11-16T08:55:18Z,"We firstly present a diffusion-based action recognition with zero-shot
learning for skeleton inputs. In zero-shot skeleton-based action recognition,
aligning skeleton features with the text features of action labels is essential
for accurately predicting unseen actions. Previous methods focus on direct
alignment between skeleton and text latent spaces, but the modality gaps
between these spaces hinder robust generalization learning. Motivated from the
remarkable performance of text-to-image diffusion models, we leverage their
alignment capabilities between different modalities mostly by focusing on the
training process during reverse diffusion rather than using their generative
power. Based on this, our framework is designed as a Triplet Diffusion for
Skeleton-Text Matching (TDSM) method which aligns skeleton features with text
prompts through reverse diffusion, embedding the prompts into the unified
skeleton-text latent space to achieve robust matching. To enhance
discriminative power, we introduce a novel triplet diffusion (TD) loss that
encourages our TDSM to correct skeleton-text matches while pushing apart
incorrect ones. Our TDSM significantly outperforms the very recent
state-of-the-art methods with large margins of 2.36%-point to 13.05%-point,
demonstrating superior accuracy and scalability in zero-shot settings through
effective skeleton-text matching.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10745v1
On-device Anomaly Detection in Conveyor Belt Operations,"Luciano S. Martinez-Rau, Yuxuan Zhang, Bengt Oelmann, Sebastian Bader",2024-11-16T07:46:28Z,"Mining 4.0 leverages advancements in automation, digitalization, and
interconnected technologies from Industry 4.0 to address the unique challenges
of the mining sector, enhancing efficiency, safety, and sustainability.
Conveyor belts are crucial in mining operations by enabling the continuous and
efficient movement of bulk materials over long distances, which directly
impacts productivity. While detecting anomalies in specific conveyor belt
components, such as idlers, pulleys, and belt surfaces, has been widely
studied, identifying the root causes of these failures remains critical due to
factors like changing production conditions and operator errors. Continuous
monitoring of mining conveyor belt work cycles for anomaly detection is still
at an early stage and requires robust solutions. This study proposes two
distinctive pattern recognition approaches for real-time anomaly detection in
the operational cycles of mining conveyor belts, combining feature extraction,
threshold-based cycle detection, and tiny machine-learning classification. Both
approaches outperformed a state-of-the-art technique on two datasets for duty
cycle classification in terms of F1-scores. The first approach, with 97.3% and
80.2% for normal and abnormal cycles, respectively, reaches the highest
performance in the first dataset while the second approach excels on the second
dataset, scoring 91.3% and 67.9%. Implemented on two low-power
microcontrollers, the methods demonstrated efficient, real-time operation with
energy consumption of 13.3 and 20.6 ${\mu}$J during inference. These results
offer valuable insights for detecting mechanical failure sources, supporting
targeted preventive maintenance, and optimizing production cycles.","cs.LG, cs.CE, eess.SP",cs.LG,http://arxiv.org/abs/2411.10729v1
A Regularized LSTM Method for Detecting Fake News Articles,"Tanjina Sultana Camelia, Faizur Rahman Fahim, Md. Musfique Anwar",2024-11-16T05:54:36Z,"Nowadays, the rapid diffusion of fake news poses a significant problem, as it
can spread misinformation and confusion. This paper aims to develop an advanced
machine learning solution for detecting fake news articles. Leveraging a
comprehensive dataset of news articles, including 23,502 fake news articles and
21,417 accurate news articles, we implemented and evaluated three
machine-learning models. Our dataset, curated from diverse sources, provides
rich textual content categorized into title, text, subject, and Date features.
These features are essential for training robust classification models to
distinguish between fake and authentic news articles. The initial model
employed a Long Short-Term Memory (LSTM) network, achieving an accuracy of 94%.
The second model improved upon this by incorporating additional regularization
techniques and fine-tuning hyperparameters, resulting in a 97% accuracy. The
final model combined the strengths of previous architectures with advanced
optimization strategies, achieving a peak accuracy of 98%. These results
demonstrate the effectiveness of our approach in identifying fake news with
high precision. Implementing these models showcases significant advancements in
natural language processing and machine learning techniques, contributing
valuable tools for combating misinformation. Our work highlights the potential
for deploying such models in real-world applications, providing a reliable
method for automated fake news detection and enhancing the credibility of news
dissemination.","cs.LG, cs.CL, cs.CY",cs.LG,http://arxiv.org/abs/2411.10713v1
"Diagnostic Text-guided Representation Learning in Hierarchical
  Classification for Pathological Whole Slide Image","Jiawen Li, Qiehe Sun, Renao Yan, Yizhi Wang, Yuqiu Fu, Yani Wei, Tian Guan, Huijuan Shi, Yonghonghe He, Anjia Han",2024-11-16T05:35:39Z,"With the development of digital imaging in medical microscopy, artificial
intelligent-based analysis of pathological whole slide images (WSIs) provides a
powerful tool for cancer diagnosis. Limited by the expensive cost of
pixel-level annotation, current research primarily focuses on representation
learning with slide-level labels, showing success in various downstream tasks.
However, given the diversity of lesion types and the complex relationships
between each other, these techniques still deserve further exploration in
addressing advanced pathology tasks. To this end, we introduce the concept of
hierarchical pathological image classification and propose a representation
learning called PathTree. PathTree considers the multi-classification of
diseases as a binary tree structure. Each category is represented as a
professional pathological text description, which messages information with a
tree-like encoder. The interactive text features are then used to guide the
aggregation of hierarchical multiple representations. PathTree uses slide-text
similarity to obtain probability scores and introduces two extra tree specific
losses to further constrain the association between texts and slides. Through
extensive experiments on three challenging hierarchical classification
datasets: in-house cryosectioned lung tissue lesion identification, public
prostate cancer grade assessment, and public breast cancer subtyping, our
proposed PathTree is consistently competitive compared to the state-of-the-art
methods and provides a new perspective on the deep learning-assisted solution
for more complex WSI classification.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10709v1
"GeoGround: A Unified Large Vision-Language Model. for Remote Sensing
  Visual Grounding","Yue Zhou, Mengcheng Lan, Xiang Li, Yiping Ke, Xue Jiang, Litong Feng, Wayne Zhang",2024-11-16T05:12:11Z,"Remote sensing (RS) visual grounding aims to use natural language expression
to locate specific objects (in the form of the bounding box or segmentation
mask) in RS images, enhancing human interaction with intelligent RS
interpretation systems. Early research in this area was primarily based on
horizontal bounding boxes (HBBs), but as more diverse RS datasets have become
available, tasks involving oriented bounding boxes (OBBs) and segmentation
masks have emerged. In practical applications, different targets require
different grounding types: HBB can localize an object's position, OBB provides
its orientation, and mask depicts its shape. However, existing specialized
methods are typically tailored to a single type of RS visual grounding task and
are hard to generalize across tasks. In contrast, large vision-language models
(VLMs) exhibit powerful multi-task learning capabilities but struggle to handle
dense prediction tasks like segmentation. This paper proposes GeoGround, a
novel framework that unifies support for HBB, OBB, and mask RS visual grounding
tasks, allowing flexible output selection. Rather than customizing the
architecture of VLM, our work aims to elegantly support pixel-level visual
grounding output through the Text-Mask technique. We define prompt-assisted and
geometry-guided learning to enhance consistency across different signals. To
support model training, we present refGeo, a large-scale RS visual
instruction-following dataset containing 161k image-text pairs. Experimental
results show that GeoGround demonstrates strong performance across four RS
visual grounding tasks, matching or surpassing the performance of specialized
methods on multiple benchmarks. Code available at
https://github.com/zytx121/GeoGround",cs.CV,cs.CV,http://arxiv.org/abs/2411.11904v1
"MaskMedPaint: Masked Medical Image Inpainting with Diffusion Models for
  Mitigation of Spurious Correlations","Qixuan Jin, Walter Gerych, Marzyeh Ghassemi",2024-11-16T03:23:06Z,"Spurious features associated with class labels can lead image classifiers to
rely on shortcuts that don't generalize well to new domains. This is especially
problematic in medical settings, where biased models fail when applied to
different hospitals or systems. In such cases, data-driven methods to reduce
spurious correlations are preferred, as clinicians can directly validate the
modified images. While Denoising Diffusion Probabilistic Models (Diffusion
Models) show promise for natural images, they are impractical for medical use
due to the difficulty of describing spurious medical features. To address this,
we propose Masked Medical Image Inpainting (MaskMedPaint), which uses
text-to-image diffusion models to augment training images by inpainting areas
outside key classification regions to match the target domain. We demonstrate
that MaskMedPaint enhances generalization to target domains across both natural
(Waterbirds, iWildCam) and medical (ISIC 2018, Chest X-ray) datasets, given
limited unlabeled target images.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10686v1
SAM Decoding: Speculative Decoding via Suffix Automaton,"Yuxuan Hu, Ke Wang, Jing Zhang, Cuiping Li, Hong Chen",2024-11-16T02:02:49Z,"Large Language Models (LLMs) have revolutionized natural language processing
by unifying tasks into text generation, yet their large parameter sizes and
autoregressive nature limit inference speed. SAM-Decoding addresses this by
introducing a novel retrieval-based speculative decoding method that uses a
suffix automaton for efficient and accurate draft generation. Unlike n-gram
matching used by the existing method, SAM-Decoding finds the longest suffix
match in generating text and text corpuss, achieving an average time complexity
of $O(1)$ per generation step. SAM-Decoding constructs static and dynamic
suffix automatons for the text corpus and input prompts, respectively, enabling
fast and precise draft generation. Meanwhile, it is designed as an approach
that can be combined with existing methods, allowing SAM-Decoding to adaptively
select a draft generation strategy based on the matching length, thus
increasing the inference speed of the LLM. When combined with Token Recycling,
evaluations show SAM-Decoding outperforms existing model-free methods,
achieving a speedup of $2.27\times$ over autoregressive decoding on Spec-Bench.
When combined with EAGLE2, it reaches a speedup of $2.49\times$, surpassing all
current approaches. Our code is available at
https://github.com/hyx1999/SAM-Decoding.","cs.CL, cs.AI, I.2.7",cs.CL,http://arxiv.org/abs/2411.10666v1
Hardness Results on Characteristics for Elastic-Degenerated Strings,"Dominik Köppl, Jannik Olbrich",2024-11-16T01:19:40Z,"Generalizations of plain strings have been proposed as a compact way to
represent a collection of nearly identical sequences or to express uncertainty
at specific text positions by enumerating all possibilities. While a plain
string stores a character at each of its positions, generalizations consider a
set of characters (indeterminate strings), a set of strings of equal length
(generalized degenerate strings, or shortly GD strings), or a set of strings of
arbitrary lengths (elastic-degenerate strings, or shortly ED strings). These
generalizations are of importance to compactly represent such type of data, and
find applications in bioinformatics for representing and maintaining a set of
genetic sequences of the same taxonomy or a multiple sequence alignment. To be
of use, attention has been drawn to answering various query types such as
pattern matching or measuring similarity of ED strings by generalizing
techniques known to plain strings. However, for some types of queries, it has
been shown that a generalization of a polynomial-time solvable query on classic
strings becomes NP-hard on ED strings, e.g. [Russo et al.,2022]. In that light,
we wonder about other types of queries, which are of particular interest to
bioinformatics: the search for the longest repeating factor, unique substrings,
absent words, anti-powers, and longest previous factors. While we obtain a
polynomial time algorithm for the first problem on ED strings, we show that all
others are NP-hard to compute, some of them even under the restriction that the
input can be modelled as an indeterminate or GD string.","cs.DS, cs.CC",cs.DS,http://arxiv.org/abs/2411.10653v1
Deep Loss Convexification for Learning Iterative Models,"Ziming Zhang, Yuping Shao, Yiqing Zhang, Fangzhou Lin, Haichong Zhang, Elke Rundensteiner",2024-11-16T01:13:04Z,"Iterative methods such as iterative closest point (ICP) for point cloud
registration often suffer from bad local optimality (e.g. saddle points), due
to the nature of nonconvex optimization. To address this fundamental challenge,
in this paper we propose learning to form the loss landscape of a deep
iterative method w.r.t. predictions at test time into a convex-like shape
locally around each ground truth given data, namely Deep Loss Convexification
(DLC), thanks to the overparametrization in neural networks. To this end, we
formulate our learning objective based on adversarial training by manipulating
the ground-truth predictions, rather than input data. In particular, we propose
using star-convexity, a family of structured nonconvex functions that are
unimodal on all lines that pass through a global minimizer, as our geometric
constraint for reshaping loss landscapes, leading to (1) extra novel hinge
losses appended to the original loss and (2) near-optimal predictions. We
demonstrate the state-of-the-art performance using DLC with existing network
architectures for the tasks of training recurrent neural networks (RNNs), 3D
point cloud registration, and multimodel image alignment.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10649v1
"The Sixth Generation of the Perseus Digital Library and a Workflow for
  Open Philology -- DRAFT","Gregory Crane, James Tauber, Alison Babeu, Lisa Cerrato, Charles Pletcher, Clifford Wulfman, Sergiusz Kazmierski, Farnoosh Shamsian",2024-11-15T21:56:49Z,"We report here on the workflow that we needed to develop in order to
integrate the growing range of openly licensed, born-digital and, increasingly,
machine actionable publications. Our developmental work focused upon textual
data for Ancient Greek, Latin, Old English, Classical Arabic and Classical
Persian but the challenges that we have had to address are relevant to sources
in a wide range of languages, ancient and modern. Perseus 6 was designed to be
a publishing workflow that organizes complementary data into an integrated
reading environment. This document focuses on the ways in which we have
organized the data and describes the current state of ATLAS (Aligned Text and
Linguistic Annotation Server) architecture. While this is the sixth version of
the Perseus Digital Library, Perseus 6 represents a major step beyond its
predecessors. Where Perseus 5 (described below) can represent and integrate
digital versions of print editions (e.g., critical editions with interactive
textual notes, links to lexicon and commentary entries), Perseus 6 was designed
to bring together an expandable range of born-digital classes of annotation. An
online ATLAS server with some initial functionality is now online and public
services will expand during the rest of 2024. Most of the ATLAS data is,
however, now available on Github and that data will be the focus on this paper
in its current version.",cs.DL,cs.DL,http://arxiv.org/abs/2411.10604v1
"Debias your Large Multi-Modal Model at Test-Time with Non-Contrastive
  Visual Attribute Steering","Neale Ratzlaff, Matthew Lyle Olson, Musashi Hinck, Estelle Aflalo, Shao-Yen Tseng, Vasudev Lal, Phillip Howard",2024-11-15T20:06:09Z,"Large Multi-Modal Models (LMMs) have demonstrated impressive capabilities as
general-purpose chatbots that can engage in conversations about a provided
input, such as an image. However, their responses are influenced by societal
biases present in their training datasets, leading to undesirable differences
in how the model responds when presented with images depicting people of
different demographics. In this work, we propose a novel debiasing framework
for LMMs that directly removes biased representations during text generation to
decrease outputs related to protected attributes, or even representing them
internally. Our proposed method is training-free; given a single image and a
list of target attributes, we can ablate the corresponding representations with
just one step of gradient descent on the image itself. Our experiments show
that not only can we can minimize the propensity of LMMs to generate text
related to protected attributes, but we can improve sentiment and even simply
use synthetic data to inform the ablation while retaining language modeling
capabilities on real data such as COCO or FACET. Furthermore, we find the
resulting generations from a debiased LMM exhibit similar accuracy as a
baseline biased model, showing that debiasing effects can be achieved without
sacrificing model performance.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.12590v1
Any2Any: Incomplete Multimodal Retrieval with Conformal Prediction,"Po-han Li, Yunhao Yang, Mohammad Omama, Sandeep Chinchali, Ufuk Topcu",2024-11-15T17:44:27Z,"Autonomous agents perceive and interpret their surroundings by integrating
multimodal inputs, such as vision, audio, and LiDAR. These perceptual
modalities support retrieval tasks, such as place recognition in robotics.
However, current multimodal retrieval systems encounter difficulties when parts
of the data are missing due to sensor failures or inaccessibility, such as
silent videos or LiDAR scans lacking RGB information. We propose Any2Any-a
novel retrieval framework that addresses scenarios where both query and
reference instances have incomplete modalities. Unlike previous methods limited
to the imputation of two modalities, Any2Any handles any number of modalities
without training generative models. It calculates pairwise similarities with
cross-modal encoders and employs a two-stage calibration process with conformal
prediction to align the similarities. Any2Any enables effective retrieval
across multimodal datasets, e.g., text-LiDAR and text-time series. It achieves
a Recall@5 of 35% on the KITTI dataset, which is on par with baseline models
with complete modalities.","cs.CV, cs.IR, cs.MM",cs.CV,http://arxiv.org/abs/2411.10513v1
"A Survey of Event Causality Identification: Principles, Taxonomy,
  Challenges, and Assessment","Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu",2024-11-15T17:19:42Z,"Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.10371v1
"Interactive Cycle Model -- The Linkage Combination among Automatic
  Speech Recognition, Large Language Models and Smart Glasses",Libo Wang,2024-11-15T17:11:13Z,"This research proposes the interaction loop model ""ASR-LLM-Smart Glasses"",
which model combines automatic speech recognition, large language model and
smart glasses to facilitate seamless human-computer interaction. And the
methodology of this research involves decomposing the interaction process into
different stages and elements. Speech is captured and processed by ASR, then
analyzed and interpreted by LLM. The results are then transmitted to smart
glasses for display. The feedback loop is complete when the user interacts with
the displayed data. Mathematical formulas are used to quantify the performance
of the model that revolves around core evaluation points: accuracy, coherence,
and latency during ASR speech-to-text conversion. The research results are
provided theoretically to test and evaluate the feasibility and performance of
the model. Although such human-computer interaction products have not yet
appeared in the industry, the performance indicators of this model in enhancing
user experience in fields that rely on human-computer interaction have also
verified its utility as a technology to promote human-computer interaction. In
addition, this research pioneered the idea of integrating cutting-edge
technologies such as generative pre-trained Transformer models into unique
interaction models, LLM provides raw value through powerful evaluation
techniques and innovative use, which provides a new perspective to evaluate and
enhanced human-computer interaction.
  Keywords: Automatic speech recognition, Large Language Model, Smart glasses,
Interaction mechanism",cs.HC,cs.HC,http://arxiv.org/abs/2411.10362v1
Weakly-Supervised Multimodal Learning on MIMIC-CXR,"Andrea Agostini, Daphné Chopard, Yang Meng, Norbert Fortin, Babak Shahbaba, Stephan Mandt, Thomas M. Sutter, Julia E. Vogt",2024-11-15T17:05:33Z,"Multimodal data integration and label scarcity pose significant challenges
for machine learning in medical settings. To address these issues, we conduct
an in-depth evaluation of the newly proposed Multimodal Variational
Mixture-of-Experts (MMVM) VAE on the challenging MIMIC-CXR dataset. Our
analysis demonstrates that the MMVM VAE consistently outperforms other
multimodal VAEs and fully supervised approaches, highlighting its strong
potential for real-world medical applications.",cs.LG,cs.LG,http://arxiv.org/abs/2411.10356v1
Safe Text-to-Image Generation: Simply Sanitize the Prompt Embedding,"Huming Qiu, Guanxu Chen, Mi Zhang, Min Yang",2024-11-15T16:29:02Z,"In recent years, text-to-image (T2I) generation models have made significant
progress in generating high-quality images that align with text descriptions.
However, these models also face the risk of unsafe generation, potentially
producing harmful content that violates usage policies, such as explicit
material. Existing safe generation methods typically focus on suppressing
inappropriate content by erasing undesired concepts from visual
representations, while neglecting to sanitize the textual representation.
Although these methods help mitigate the risk of misuse to certain extent,
their robustness remains insufficient when dealing with adversarial attacks.
  Given that semantic consistency between input text and output image is a
fundamental requirement for T2I models, we identify that textual
representations (i.e., prompt embeddings) are likely the primary source of
unsafe generation. To this end, we propose a vision-agnostic safe generation
framework, Embedding Sanitizer (ES), which focuses on erasing inappropriate
concepts from prompt embeddings and uses the sanitized embeddings to guide the
model for safe generation. ES is applied to the output of the text encoder as a
plug-and-play module, enabling seamless integration with different T2I models
as well as other safeguards. In addition, ES's unique scoring mechanism assigns
a score to each token in the prompt to indicate its potential harmfulness, and
dynamically adjusts the sanitization intensity to balance defensive performance
and generation quality. Through extensive evaluation on five prompt benchmarks,
our approach achieves state-of-the-art robustness by sanitizing the source
(prompt embedding) of unsafe generation compared to nine baseline methods. It
significantly outperforms existing safeguards in terms of interpretability and
controllability while maintaining generation quality.","cs.CR, cs.AI, cs.CL",cs.CR,http://arxiv.org/abs/2411.10329v1
"Emotion Detection in Reddit: Comparative Study of Machine Learning and
  Deep Learning Techniques",Maliheh Alaeddini,2024-11-15T16:28:25Z,"Emotion detection is pivotal in human communication, as it significantly
influences behavior, relationships, and decision-making processes. This study
concentrates on text-based emotion detection by leveraging the GoEmotions
dataset, which annotates Reddit comments with 27 distinct emotions. These
emotions are subsequently mapped to Ekman's six basic categories: joy, anger,
fear, sadness, disgust, and surprise. We employed a range of models for this
task, including six machine learning models, three ensemble models, and a Long
Short-Term Memory (LSTM) model to determine the optimal model for emotion
detection. Results indicate that the Stacking classifier outperforms other
models in accuracy and performance. We also benchmark our models against
EmoBERTa, a pre-trained emotion detection model, with our Stacking classifier
proving more effective. Finally, the Stacking classifier is deployed via a
Streamlit web application, underscoring its potential for real-world
applications in text-based emotion analysis.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10328v1
"SmoothCache: A Universal Inference Acceleration Technique for Diffusion
  Transformers","Joseph Liu, Joshua Geddes, Ziyu Guo, Haomiao Jiang, Mahesh Kumar Nandwana",2024-11-15T16:24:02Z,"Diffusion Transformers (DiT) have emerged as powerful generative models for
various tasks, including image, video, and speech synthesis. However, their
inference process remains computationally expensive due to the repeated
evaluation of resource-intensive attention and feed-forward modules. To address
this, we introduce SmoothCache, a model-agnostic inference acceleration
technique for DiT architectures. SmoothCache leverages the observed high
similarity between layer outputs across adjacent diffusion timesteps. By
analyzing layer-wise representation errors from a small calibration set,
SmoothCache adaptively caches and reuses key features during inference. Our
experiments demonstrate that SmoothCache achieves 8% to 71% speed up while
maintaining or even improving generation quality across diverse modalities. We
showcase its effectiveness on DiT-XL for image generation, Open-Sora for
text-to-video, and Stable Audio Open for text-to-audio, highlighting its
potential to enable real-time applications and broaden the accessibility of
powerful DiT models.",cs.LG,cs.LG,http://arxiv.org/abs/2411.10510v1
"Modification Takes Courage: Seamless Image Stitching via
  Reference-Driven Inpainting","Ziqi Xie, Xiao Lai, Weidong Zhao, Xianhui Liu, Wenlong Hou",2024-11-15T16:05:01Z,"Current image stitching methods often produce noticeable seams in challenging
scenarios such as uneven hue and large parallax. To tackle this problem, we
propose the Reference-Driven Inpainting Stitcher (RDIStitcher), which
reformulates the image fusion and rectangling as a reference-based inpainting
model, incorporating a larger modification fusion area and stronger
modification intensity than previous methods. Furthermore, we introduce a
self-supervised model training method, which enables the implementation of
RDIStitcher without requiring labeled data by fine-tuning a Text-to-Image (T2I)
diffusion model. Recognizing difficulties in assessing the quality of stitched
images, we present the Multimodal Large Language Models (MLLMs)-based metrics,
offering a new perspective on evaluating stitched image quality. Compared to
the state-of-the-art (SOTA) method, extensive experiments demonstrate that our
method significantly enhances content coherence and seamless transitions in the
stitched images. Especially in the zero-shot experiments, our method exhibits
strong generalization capabilities. Code:
https://github.com/yayoyo66/RDIStitcher",cs.CV,cs.CV,http://arxiv.org/abs/2411.10309v1
"Unveiling Topological Structures in Text: A Comprehensive Survey of
  Topological Data Analysis Applications in NLP","Adaku Uchendu, Thai Le",2024-11-15T15:55:05Z,"The surge of data available on the internet has led to the adoption of
various computational methods to analyze and extract valuable insights from
this wealth of information. Among these, the field of Machine Learning (ML) has
thrived by leveraging data to extract meaningful insights. However, ML
techniques face notable challenges when dealing with real-world data, often due
to issues of imbalance, noise, insufficient labeling, and high dimensionality.
To address these limitations, some researchers advocate for the adoption of
Topological Data Analysis (TDA), a statistical approach that discerningly
captures the intrinsic shape of data despite noise. Despite its potential, TDA
has not gained as much traction within the Natural Language Processing (NLP)
domain compared to structurally distinct areas like computer vision.
Nevertheless, a dedicated community of researchers has been exploring the
application of TDA in NLP, yielding 85 papers we comprehensively survey in this
paper. Our findings categorize these efforts into theoretical and
nontheoretical approaches. Theoretical approaches aim to explain linguistic
phenomena from a topological viewpoint, while non-theoretical approaches merge
TDA with ML features, utilizing diverse numerical representation techniques. We
conclude by exploring the challenges and unresolved questions that persist in
this niche field. Resources and a list of papers on this topic can be found at:
https://github.com/AdaUchendu/AwesomeTDA4NLP.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10298v1
"The ParClusterers Benchmark Suite (PCBS): A Fine-Grained Analysis of
  Scalable Graph Clustering","Shangdi Yu, Jessica Shi, Jamison Meindl, David Eisenstat, Xiaoen Ju, Sasan Tavakkol, Laxman Dhulipala, Jakub Łącki, Vahab Mirrokni, Julian Shun",2024-11-15T15:47:32Z,"We introduce the ParClusterers Benchmark Suite (PCBS) -- a collection of
highly scalable parallel graph clustering algorithms and benchmarking tools
that streamline comparing different graph clustering algorithms and
implementations.
  The benchmark includes clustering algorithms that target a wide range of
modern clustering use cases, including community detection, classification, and
dense subgraph mining.
  The benchmark toolkit makes it easy to run and evaluate multiple instances of
different clustering algorithms, which can be useful for fine-tuning the
performance of clustering on a given task, and for comparing different
clustering algorithms based on different metrics of interest, including
clustering quality and running time.
  Using PCBS, we evaluate a broad collection of real-world graph clustering
datasets. Somewhat surprisingly, we find that the best quality results are
obtained by algorithms that not included in many popular graph clustering
toolkits. The PCBS provides a standardized way to evaluate and judge the
quality-performance tradeoffs of the active research area of scalable graph
clustering algorithms. We believe it will help enable fair, accurate, and
nuanced evaluation of graph clustering algorithms in the future.","cs.DC, cs.AI, cs.LG, cs.SI",cs.DC,http://arxiv.org/abs/2411.10290v1
"Multidimensional Byte Pair Encoding: Shortened Sequences for Improved
  Visual Data Generation","Tim Elsner, Paula Usinger, Julius Nehring-Wirxel, Gregor Kobsik, Victor Czech, Yanjiang He, Isaak Lim, Leif Kobbelt",2024-11-15T15:36:48Z,"In language processing, transformers benefit greatly from text being
condensed. This is achieved through a larger vocabulary that captures word
fragments instead of plain characters. This is often done with Byte Pair
Encoding. In the context of images, tokenisation of visual data is usually
limited to regular grids obtained from quantisation methods, without global
content awareness. Our work improves tokenisation of visual data by bringing
Byte Pair Encoding from 1D to multiple dimensions, as a complementary add-on to
existing compression. We achieve this through counting constellations of token
pairs and replacing the most frequent token pair with a newly introduced token.
The multidimensionality only increases the computation time by a factor of 2
for images, making it applicable even to large datasets like ImageNet within
minutes on consumer hardware. This is a lossless preprocessing step. Our
evaluation shows improved training and inference performance of transformers on
visual data achieved by compressing frequent constellations of tokens: The
resulting sequences are shorter, with more uniformly distributed information
content, e.g. condensing empty regions in an image into single tokens. As our
experiments show, these condensed sequences are easier to process. We
additionally introduce a strategy to amplify this compression further by
clustering the vocabulary.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10281v1
"How the interplay between power concentration, competition, and
  propagation affects the resource efficiency of distributed ledgers","Paolo Barucca, Carlo Campajola, Jiahua Xu",2024-11-15T15:00:21Z,"Forks in the Bitcoin network result from the natural competition in the
blockchain's Proof-of-Work consensus protocol. Their frequency is a critical
indicator for the efficiency of a distributed ledger as they can contribute to
resource waste and network insecurity. We introduce a model for the estimation
of natural fork rates in a network of heterogeneous miners as a function of
their number, the distribution of hash rates and the block propagation time
over the peer-to-peer infrastructure. Despite relatively simplistic
assumptions, such as zero propagation delay within mining pools, the model
predicts fork rates which are comparable with the empirical stale blocks rate.
In the past decade, we observe a reduction in the number of mining pools
approximately by a factor 3, and quantify its consequences for the fork rate,
whilst showing the emergence of a truncated power-law distribution in hash
rates, justified by a rich-get-richer effect constrained by global energy
supply limits. We demonstrate, both empirically and with the aid of our
quantitative model, that the ratio between the block propagation time and the
mining time is a sufficiently accurate estimator of the fork rate, but also
quantify its dependence on the heterogeneity of miner activities. We provide
empirical and theoretical evidence that both hash rate concentration and lower
block propagation time reduce fork rates in distributed ledgers. Our work
introduces a robust mathematical setting for investigating power concentration
and competition on a distributed network, for interpreting discrepancies in
fork rates -- for example caused by selfish mining practices and asymmetric
propagation times -- thus providing an effective tool for designing future and
alternative scenarios for existing and new blockchain distributed mining
systems.","cs.DC, cs.SI, physics.soc-ph",cs.DC,http://arxiv.org/abs/2411.10249v1
"Measuring Non-Adversarial Reproduction of Training Data in Large
  Language Models","Michael Aerni, Javier Rando, Edoardo Debenedetti, Nicholas Carlini, Daphne Ippolito, Florian Tramèr",2024-11-15T14:55:01Z,"Large language models memorize parts of their training data. Memorizing short
snippets and facts is required to answer questions about the world and to be
fluent in any language. But models have also been shown to reproduce long
verbatim sequences of memorized text when prompted by a motivated adversary. In
this work, we investigate an intermediate regime of memorization that we call
non-adversarial reproduction, where we quantify the overlap between model
responses and pretraining data when responding to natural and benign prompts.
For a variety of innocuous prompt categories (e.g., writing a letter or a
tutorial), we show that up to 15% of the text output by popular conversational
language models overlaps with snippets from the Internet. In worst cases, we
find generations where 100% of the content can be found exactly online. For the
same tasks, we find that human-written text has far less overlap with Internet
data. We further study whether prompting strategies can close this reproduction
gap between models and humans. While appropriate prompting can reduce
non-adversarial reproduction on average, we find that mitigating worst-case
reproduction of training data requires stronger defenses -- even for benign
interactions.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.10242v1
"Generative AI in Multimodal User Interfaces: Trends, Challenges, and
  Cross-Platform Adaptability","J. Bieniek, M. Rahouti, D. C. Verma",2024-11-15T14:49:58Z,"As the boundaries of human computer interaction expand, Generative AI emerges
as a key driver in reshaping user interfaces, introducing new possibilities for
personalized, multimodal and cross-platform interactions. This integration
reflects a growing demand for more adaptive and intuitive user interfaces that
can accommodate diverse input types such as text, voice and video, and deliver
seamless experiences across devices. This paper explores the integration of
generative AI in modern user interfaces, examining historical developments and
focusing on multimodal interaction, cross-platform adaptability and dynamic
personalization. A central theme is the interface dilemma, which addresses the
challenge of designing effective interactions for multimodal large language
models, assessing the trade-offs between graphical, voice-based and immersive
interfaces. The paper further evaluates lightweight frameworks tailored for
mobile platforms, spotlighting the role of mobile hardware in enabling scalable
multimodal AI. Technical and ethical challenges, including context retention,
privacy concerns and balancing cloud and on-device processing are thoroughly
examined. Finally, the paper outlines future directions such as emotionally
adaptive interfaces, predictive AI driven user interfaces and real-time
collaborative systems, underscoring generative AI's potential to redefine
adaptive user-centric interfaces across platforms.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.10234v1
ColorEdit: Training-free Image-Guided Color editing with diffusion model,"Xingxi Yin, Zhi Li, Jingfeng Zhang, Chenglin Li, Yin Zhang",2024-11-15T14:45:58Z,"Text-to-image (T2I) diffusion models, with their impressive generative
capabilities, have been adopted for image editing tasks, demonstrating
remarkable efficacy. However, due to attention leakage and collision between
the cross-attention map of the object and the new color attribute from the text
prompt, text-guided image editing methods may fail to change the color of an
object, resulting in a misalignment between the resulting image and the text
prompt. In this paper, we conduct an in-depth analysis on the process of
text-guided image synthesizing and what semantic information different
cross-attention blocks have learned. We observe that the visual representation
of an object is determined in the up-block of the diffusion model in the early
stage of the denoising process, and color adjustment can be achieved through
value matrices alignment in the cross-attention layer. Based on our findings,
we propose a straightforward, yet stable, and effective image-guided method to
modify the color of an object without requiring any additional fine-tuning or
training. Lastly, we present a benchmark dataset called COLORBENCH, the first
benchmark to evaluate the performance of color change methods. Extensive
experiments validate the effectiveness of our method in object-level color
editing and surpass the performance of popular text-guided image editing
approaches in both synthesized and real images.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10232v1
"Visual question answering based evaluation metrics for text-to-image
  generation","Mizuki Miyamoto, Ryugo Morita, Jinjia Zhou",2024-11-15T13:32:23Z,"Text-to-image generation and text-guided image manipulation have received
considerable attention in the field of image generation tasks. However, the
mainstream evaluation methods for these tasks have difficulty in evaluating
whether all the information from the input text is accurately reflected in the
generated images, and they mainly focus on evaluating the overall alignment
between the input text and the generated images. This paper proposes new
evaluation metrics that assess the alignment between input text and generated
images for every individual object. Firstly, according to the input text,
chatGPT is utilized to produce questions for the generated images. After that,
we use Visual Question Answering(VQA) to measure the relevance of the generated
images to the input text, which allows for a more detailed evaluation of the
alignment compared to existing methods. In addition, we use Non-Reference Image
Quality Assessment(NR-IQA) to evaluate not only the text-image alignment but
also the quality of the generated images. Experimental results show that our
proposed evaluation approach is the superior metric that can simultaneously
assess finer text-image alignment and image quality while allowing for the
adjustment of these ratios.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10183v1
"Increasing the Accessibility of Causal Domain Knowledge via Causal
  Information Extraction Methods: A Case Study in the Semiconductor
  Manufacturing Industry","Houssam Razouk, Leonie Benischke, Daniel Garber, Roman Kern",2024-11-15T13:18:18Z,"The extraction of causal information from textual data is crucial in the
industry for identifying and mitigating potential failures, enhancing process
efficiency, prompting quality improvements, and addressing various operational
challenges. This paper presents a study on the development of automated methods
for causal information extraction from actual industrial documents in the
semiconductor manufacturing industry. The study proposes two types of causal
information extraction methods, single-stage sequence tagging (SST) and
multi-stage sequence tagging (MST), and evaluates their performance using
existing documents from a semiconductor manufacturing company, including
presentation slides and FMEA (Failure Mode and Effects Analysis) documents. The
study also investigates the effect of representation learning on downstream
tasks. The presented case study showcases that the proposed MST methods for
extracting causal information from industrial documents are suitable for
practical applications, especially for semi structured documents such as FMEAs,
with a 93\% F1 score. Additionally, MST achieves a 73\% F1 score on texts
extracted from presentation slides. Finally, the study highlights the
importance of choosing a language model that is more aligned with the domain
and in-domain fine-tuning.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.10172v1
Evaluating Text-to-Image Diffusion Models for Texturing Synthetic Data,"Thomas Lips, Francis wyffels",2024-11-15T13:12:47Z,"Building generic robotic manipulation systems often requires large amounts of
real-world data, which can be dificult to collect. Synthetic data generation
offers a promising alternative, but limiting the sim-to-real gap requires
significant engineering efforts. To reduce this engineering effort, we
investigate the use of pretrained text-to-image diffusion models for texturing
synthetic images and compare this approach with using random textures, a common
domain randomization technique in synthetic data generation. We focus on
generating object-centric representations, such as keypoints and segmentation
masks, which are important for robotic manipulation and require precise
annotations. We evaluate the efficacy of the texturing methods by training
models on the synthetic data and measuring their performance on real-world
datasets for three object categories: shoes, T-shirts, and mugs. Surprisingly,
we find that texturing using a diffusion model performs on par with random
textures, despite generating seemingly more realistic images. Our results
suggest that, for now, using diffusion models for texturing does not benefit
synthetic data generation for robotics. The code, data and trained models are
available at \url{https://github.com/tlpss/diffusing-synthetic-data.git}.",cs.RO,cs.RO,http://arxiv.org/abs/2411.10164v1
"Mitigating Sycophancy in Decoder-Only Transformer Architectures:
  Synthetic Data Intervention",Libo Wang,2024-11-15T12:59:46Z,"To address the sycophancy problem caused by reinforcement learning from human
feedback in large language models, this research applies synthetic data
intervention technology to the decoder-only transformer architecture. Based on
the research gaps in the existing literature, the researcher designed an
experimental process to reduce the tendency of models to cater by generating
diversified data, and used GPT4o as an experimental tool for verification. The
experiment used 100 true and false questions, and compared the performance of
the model trained with synthetic data intervention and the original untrained
model on multiple indicators. The results show that the SDI training model
supports the technology in terms of accuracy rate and sycophancy rate and has
significant effectiveness in reducing sycophancy phenomena. Notably, the data
set, experimental process, code and data results have been uploaded to Github,
the link is https://github.com/brucewang123456789/GeniusTrail.git.",cs.AI,cs.AI,http://arxiv.org/abs/2411.10156v2
Everything is a Video: Unifying Modalities through Next-Frame Prediction,"G. Thomas Hudson, Dean Slack, Thomas Winterbottom, Jamie Sterling, Chenghao Xiao, Junjie Shentu, Noura Al Moubayed",2024-11-15T12:59:37Z,"Multimodal learning, which involves integrating information from various
modalities such as text, images, audio, and video, is pivotal for numerous
complex tasks like visual question answering, cross-modal retrieval, and
caption generation. Traditional approaches rely on modality-specific encoders
and late fusion techniques, which can hinder scalability and flexibility when
adapting to new tasks or modalities. To address these limitations, we introduce
a novel framework that extends the concept of task reformulation beyond natural
language processing (NLP) to multimodal learning. We propose to reformulate
diverse multimodal tasks into a unified next-frame prediction problem, allowing
a single model to handle different modalities without modality-specific
components. This method treats all inputs and outputs as sequential frames in a
video, enabling seamless integration of modalities and effective knowledge
transfer across tasks. Our approach is evaluated on a range of tasks, including
text-to-text, image-to-text, video-to-video, video-to-text, and audio-to-text,
demonstrating the model's ability to generalize across modalities with minimal
adaptation. We show that task reformulation can significantly simplify
multimodal model design across various tasks, laying the groundwork for more
generalized multimodal foundation models.","cs.CV, cs.CL, cs.LG",cs.CV,http://arxiv.org/abs/2411.10503v1
"An Effective Framework to Help Large Language Models Handle
  Numeric-involved Long-context Tasks",Yijiong Yu,2024-11-15T12:39:02Z,"Large Language Models (LLMs) have demonstrated remarkable capabilities in
handling long texts and have almost perfect performance in traditional
retrieval tasks. However, their performance significantly degrades when it
comes to numerical calculations in the long-context. Numeric-involved
long-context tasks typically cannot be addressed by current LLMs in normal
settings due to their inherent limitations in simultaneously handling complex
and massive information. Some CoT like prompting methods can improve accuracy
but demands massive output tokens, which is costly and slow. To address this
issue, we propose a workflow, which decompose a numeric-involved long-context
task into 4 low-level subtasks: judging, extracting and processing with code
and conclusion. The former 2 subtasks is relatively simple, which allows us to
use smaller models for efficiently processing long context. When numerical
calculations are required, we use code generated by LLMs to avoid the
disadvantage of LLM not being good at calculations. The results in 2
numeric-involved long-context benchmarks demonstrate our workflow can not only
improve accuracy, but also significantly reduce the cost of API calls.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10145v1
"OnlyFlow: Optical Flow based Motion Conditioning for Video Diffusion
  Models","Mathis Koroglu, Hugo Caselles-Dupré, Guillaume Jeanneret Sanmiguel, Matthieu Cord",2024-11-15T11:19:25Z,"We consider the problem of text-to-video generation tasks with precise
control for various applications such as camera movement control and
video-to-video editing. Most methods tacking this problem rely on providing
user-defined controls, such as binary masks or camera movement embeddings. In
our approach we propose OnlyFlow, an approach leveraging the optical flow
firstly extracted from an input video to condition the motion of generated
videos. Using a text prompt and an input video, OnlyFlow allows the user to
generate videos that respect the motion of the input video as well as the text
prompt. This is implemented through an optical flow estimation model applied on
the input video, which is then fed to a trainable optical flow encoder. The
output feature maps are then injected into the text-to-video backbone model. We
perform quantitative, qualitative and user preference studies to show that
OnlyFlow positively compares to state-of-the-art methods on a wide range of
tasks, even though OnlyFlow was not specifically trained for such tasks.
OnlyFlow thus constitutes a versatile, lightweight yet efficient method for
controlling motion in text-to-video generation. Models and code will be made
available on GitHub and HuggingFace.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10501v1
"FitDiT: Advancing the Authentic Garment Details for High-fidelity
  Virtual Try-on","Boyuan Jiang, Xiaobin Hu, Donghao Luo, Qingdong He, Chengming Xu, Jinlong Peng, Jiangning Zhang, Chengjie Wang, Yunsheng Wu, Yanwei Fu",2024-11-15T11:02:23Z,"Although image-based virtual try-on has made considerable progress, emerging
approaches still encounter challenges in producing high-fidelity and robust
fitting images across diverse scenarios. These methods often struggle with
issues such as texture-aware maintenance and size-aware fitting, which hinder
their overall effectiveness. To address these limitations, we propose a novel
garment perception enhancement technique, termed FitDiT, designed for
high-fidelity virtual try-on using Diffusion Transformers (DiT) allocating more
parameters and attention to high-resolution features. First, to further improve
texture-aware maintenance, we introduce a garment texture extractor that
incorporates garment priors evolution to fine-tune garment feature,
facilitating to better capture rich details such as stripes, patterns, and
text. Additionally, we introduce frequency-domain learning by customizing a
frequency distance loss to enhance high-frequency garment details. To tackle
the size-aware fitting issue, we employ a dilated-relaxed mask strategy that
adapts to the correct length of garments, preventing the generation of garments
that fill the entire mask area during cross-category try-on. Equipped with the
above design, FitDiT surpasses all baselines in both qualitative and
quantitative evaluations. It excels in producing well-fitting garments with
photorealistic and intricate details, while also achieving competitive
inference times of 4.57 seconds for a single 1024x768 image after DiT structure
slimming, outperforming existing methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10499v1
Diachronic Document Dataset for Semantic Layout Analysis,"Thibault Clérice, Juliette Janes, Hugo Scheithauer, Sarah Bénière, Florian Cafiero, Laurent Romary, Simon Gabay, Benoît Sagot",2024-11-15T09:33:13Z,"We present a novel, open-access dataset designed for semantic layout
analysis, built to support document recreation workflows through mapping with
the Text Encoding Initiative (TEI) standard. This dataset includes 7,254
annotated pages spanning a large temporal range (1600-2024) of digitised and
born-digital materials across diverse document types (magazines, papers from
sciences and humanities, PhD theses, monographs, plays, administrative reports,
etc.) sorted into modular subsets. By incorporating content from different
periods and genres, it addresses varying layout complexities and historical
changes in document structure. The modular design allows domain-specific
configurations. We evaluate object detection models on this dataset, examining
the impact of input size and subset-based training. Results show that a
1280-pixel input size for YOLO is optimal and that training on subsets
generally benefits from incorporating them into a generic model rather than
fine-tuning pre-trained weights.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10068v1
Federated Domain Generalization via Prompt Learning and Aggregation,"Shuai Gong, Chaoran Cui, Chunyun Zhang, Wenna Wang, Xiushan Nie, Lei Zhu",2024-11-15T09:26:00Z,"Federated domain generalization (FedDG) aims to improve the global model
generalization in unseen domains by addressing data heterogeneity under
privacy-preserving constraints. A common strategy in existing FedDG studies
involves sharing domain-specific knowledge among clients, such as spectrum
information, class prototypes, and data styles. However, this knowledge is
extracted directly from local client samples, and sharing such sensitive
information poses a potential risk of data leakage, which might not fully meet
the requirements of FedDG. In this paper, we introduce prompt learning to adapt
pre-trained vision-language models (VLMs) in the FedDG scenario, and leverage
locally learned prompts as a more secure bridge to facilitate knowledge
transfer among clients. Specifically, we propose a novel FedDG framework
through Prompt Learning and AggregatioN (PLAN), which comprises two training
stages to collaboratively generate local prompts and global prompts at each
federated round. First, each client performs both text and visual prompt
learning using their own data, with local prompts indirectly synchronized by
regarding the global prompts as a common reference. Second, all domain-specific
local prompts are exchanged among clients and selectively aggregated into the
global prompts using lightweight attention-based aggregators. The global
prompts are finally applied to adapt VLMs to unseen target domains. As our PLAN
framework requires training only a limited number of prompts and lightweight
aggregators, it offers notable advantages in computational and communication
efficiency for FedDG. Extensive experiments demonstrate the superior
generalization ability of PLAN across four benchmark datasets.","cs.AI, cs.CV, cs.LG",cs.AI,http://arxiv.org/abs/2411.10063v1
"Hollywood's misrepresentation of death: A comparison of overall and
  by-gender mortality causes in film and the real world","Calla Beauregard, Christopher M. Danforth, Peter Sheridan Dodds",2024-11-15T08:40:18Z,"The common phrase 'representation matters' asserts that media has a
measurable and important impact on civic society's perception of self and
others. The representation of health in media, in particular, may reflect and
perpetuate a society's disease burden. Here, for the top 10 major causes of
death in the United States, we examine how cinematic representation of overall
and by-gender mortality diverges from reality. Using crowd-sourced data on film
deaths from Cinemorgue Wiki, we employ natural language processing (NLP)
techniques to analyze shifts in representation of deaths in movies versus the
2021 National Vital Statistic Survey (NVSS) top ten mortality causes. Overall,
movies strongly overrepresent suicide and, to a lesser degree, accidents. In
terms of gender, movies overrepresent men and underrepresent women for nearly
every major mortality cause, including heart disease and cerebrovascular
disease. The two exceptions for which women are overrepresented are suicide and
accidents. We discuss the implications of under- and over-representing causes
of death overall and by gender, as well as areas of future research.",cs.CY,cs.CY,http://arxiv.org/abs/2411.10040v1
"GSEditPro: 3D Gaussian Splatting Editing with Attention-based
  Progressive Localization","Yanhao Sun, RunZe Tian, Xiao Han, XinYao Liu, Yan Zhang, Kai Xu",2024-11-15T08:25:14Z,"With the emergence of large-scale Text-to-Image(T2I) models and implicit 3D
representations like Neural Radiance Fields (NeRF), many text-driven generative
editing methods based on NeRF have appeared. However, the implicit encoding of
geometric and textural information poses challenges in accurately locating and
controlling objects during editing. Recently, significant advancements have
been made in the editing methods of 3D Gaussian Splatting, a real-time
rendering technology that relies on explicit representation. However, these
methods still suffer from issues including inaccurate localization and limited
manipulation over editing. To tackle these challenges, we propose GSEditPro, a
novel 3D scene editing framework which allows users to perform various creative
and precise editing using text prompts only. Leveraging the explicit nature of
the 3D Gaussian distribution, we introduce an attention-based progressive
localization module to add semantic labels to each Gaussian during rendering.
This enables precise localization on editing areas by classifying Gaussians
based on their relevance to the editing prompts derived from cross-attention
layers of the T2I model. Furthermore, we present an innovative editing
optimization method based on 3D Gaussian Splatting, obtaining stable and
refined editing results through the guidance of Score Distillation Sampling and
pseudo ground truth. We prove the efficacy of our method through extensive
experiments.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10033v1
"VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying
  Misinformation of Short Videos","Weihao Zhong, Yinhao Xiao, Minghui Xu, Xiuzhen Cheng",2024-11-15T08:20:26Z,"Short video platforms have become important channels for news dissemination,
offering a highly engaging and immediate way for users to access current events
and share information. However, these platforms have also emerged as
significant conduits for the rapid spread of misinformation, as fake news and
rumors can leverage the visual appeal and wide reach of short videos to
circulate extensively among audiences. Existing fake news detection methods
mainly rely on single-modal information, such as text or images, or apply only
basic fusion techniques, limiting their ability to handle the complex,
multi-layered information inherent in short videos. To address these
limitations, this paper presents a novel fake news detection method based on
multimodal information, designed to identify misinformation through a
multi-level analysis of video content. This approach effectively utilizes
different modal representations to generate a unified textual description,
which is then fed into a large language model for comprehensive evaluation. The
proposed framework successfully integrates multimodal features within videos,
significantly enhancing the accuracy and reliability of fake news detection.
Experimental results demonstrate that the proposed approach outperforms
existing models in terms of accuracy, robustness, and utilization of multimodal
information, achieving an accuracy of 90.93%, which is significantly higher
than the best baseline model (SV-FEND) at 81.05%. Furthermore, case studies
provide additional evidence of the effectiveness of the approach in accurately
distinguishing between fake news, debunking content, and real incidents,
highlighting its reliability and robustness in real-world applications.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.10032v1
"Toward Robust and Accurate Adversarial Camouflage Generation against
  Vehicle Detectors","Jiawei Zhou, Linye Lyu, Daojing He, Yu Li",2024-11-15T08:17:08Z,"Adversarial camouflage is a widely used physical attack against vehicle
detectors for its superiority in multi-view attack performance. One promising
approach involves using differentiable neural renderers to facilitate
adversarial camouflage optimization through gradient back-propagation. However,
existing methods often struggle to capture environmental characteristics during
the rendering process or produce adversarial textures that can precisely map to
the target vehicle. Moreover, these approaches neglect diverse weather
conditions, reducing the efficacy of generated camouflage across varying
weather scenarios. To tackle these challenges, we propose a robust and accurate
camouflage generation method, namely RAUCA. The core of RAUCA is a novel neural
rendering component, End-to-End Neural Renderer Plus (E2E-NRP), which can
accurately optimize and project vehicle textures and render images with
environmental characteristics such as lighting and weather. In addition, we
integrate a multi-weather dataset for camouflage generation, leveraging the
E2E-NRP to enhance the attack robustness. Experimental results on six popular
object detectors show that RAUCA-final outperforms existing methods in both
simulation and real-world settings.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10029v1
Model Inversion Attacks: A Survey of Approaches and Countermeasures,"Zhanke Zhou, Jianing Zhu, Fengfei Yu, Xuan Li, Xiong Peng, Tongliang Liu, Bo Han",2024-11-15T08:09:28Z,"The success of deep neural networks has driven numerous research studies and
applications from Euclidean to non-Euclidean data. However, there are
increasing concerns about privacy leakage, as these networks rely on processing
private data. Recently, a new type of privacy attack, the model inversion
attacks (MIAs), aims to extract sensitive features of private data for training
by abusing access to a well-trained model. The effectiveness of MIAs has been
demonstrated in various domains, including images, texts, and graphs. These
attacks highlight the vulnerability of neural networks and raise awareness
about the risk of privacy leakage within the research community. Despite the
significance, there is a lack of systematic studies that provide a
comprehensive overview and deeper insights into MIAs across different domains.
This survey aims to summarize up-to-date MIA methods in both attacks and
defenses, highlighting their contributions and limitations, underlying modeling
principles, optimization challenges, and future directions. We hope this survey
bridges the gap in the literature and facilitates future research in this
critical area. Besides, we are maintaining a repository to keep track of
relevant research at
https://github.com/AndrewZhou924/Awesome-model-inversion-attack.",cs.LG,cs.LG,http://arxiv.org/abs/2411.10023v1
"Information Extraction from Clinical Notes: Are We Ready to Switch to
  Large Language Models?","Yan Hu, Xu Zuo, Yujia Zhou, Xueqing Peng, Jimin Huang, Vipina K. Keloth, Vincent J. Zhang, Ruey-Ling Weng, Qingyu Chen, Xiaoqian Jiang, Kirk E. Roberts, Hua Xu",2024-11-15T07:54:19Z,"Backgrounds: Information extraction (IE) is critical in clinical natural
language processing (NLP). While large language models (LLMs) excel on
generative tasks, their performance on extractive tasks remains debated.
Methods: We investigated Named Entity Recognition (NER) and Relation Extraction
(RE) using 1,588 clinical notes from four sources (UT Physicians, MTSamples,
MIMIC-III, and i2b2). We developed an annotated corpus covering 4 clinical
entities and 16 modifiers, and compared instruction-tuned LLaMA-2 and LLaMA-3
against BiomedBERT in terms of performance, generalizability, computational
resources, and throughput to BiomedBERT. Results: LLaMA models outperformed
BiomedBERT across datasets. With sufficient training data, LLaMA showed modest
improvements (1% on NER, 1.5-3.7% on RE); improvements were larger with limited
training data. On unseen i2b2 data, LLaMA-3-70B outperformed BiomedBERT by 7%
(F1) on NER and 4% on RE. However, LLaMA models required more computing
resources and ran up to 28 times slower. We implemented ""Kiwi,"" a clinical IE
package featuring both models, available at https://kiwi.clinicalnlp.org/.
Conclusion: This study is among the first to develop and evaluate a
comprehensive clinical IE system using open-source LLMs. Results indicate that
LLaMA models outperform BiomedBERT for clinical NER and RE but with higher
computational costs and lower throughputs. These findings highlight that
choosing between LLMs and traditional deep learning methods for clinical IE
applications should remain task-specific, taking into account both performance
metrics and practical considerations such as available computing resources and
the intended use case scenarios.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10020v3
"'What did the Robot do in my Absence?' Video Foundation Models to
  Enhance Intermittent Supervision","Kavindie Katuwandeniya, Leimin Tian, Dana Kulić",2024-11-15T07:50:30Z,"This paper investigates the application of Video Foundation Models (ViFMs)
for generating robot data summaries to enhance intermittent human supervision
of robot teams. We propose a novel framework that produces both generic and
query-driven summaries of long-duration robot vision data in three modalities:
storyboards, short videos, and text. Through a user study involving 30
participants, we evaluate the efficacy of these summary methods in allowing
operators to accurately retrieve the observations and actions that occurred
while the robot was operating without supervision over an extended duration (40
min). Our findings reveal that query-driven summaries significantly improve
retrieval accuracy compared to generic summaries or raw data, albeit with
increased task duration. Storyboards are found to be the most effective
presentation modality, especially for object-related queries. This work
represents, to our knowledge, the first zero-shot application of ViFMs for
generating multi-modal robot-to-human communication in intermittent supervision
contexts, demonstrating both the promise and limitations of these models in
human-robot interaction (HRI) scenarios.",cs.RO,cs.RO,http://arxiv.org/abs/2411.10016v1
"Guided Learning: Lubricating End-to-End Modeling for Multi-stage
  Decision-making","Jian Guo, Saizhuo Wang, Yiyan Qi",2024-11-15T06:54:25Z,"Multi-stage decision-making is crucial in various real-world artificial
intelligence applications, including recommendation systems, autonomous
driving, and quantitative investment systems. In quantitative investment, for
example, the process typically involves several sequential stages such as
factor mining, alpha prediction, portfolio optimization, and sometimes order
execution. While state-of-the-art end-to-end modeling aims to unify these
stages into a single global framework, it faces significant challenges: (1)
training such a unified neural network consisting of multiple stages between
initial inputs and final outputs often leads to suboptimal solutions, or even
collapse, and (2) many decision-making scenarios are not easily reducible to
standard prediction problems. To overcome these challenges, we propose Guided
Learning, a novel methodological framework designed to enhance end-to-end
learning in multi-stage decision-making. We introduce the concept of a
``guide'', a function that induces the training of intermediate neural network
layers towards some phased goals, directing gradients away from suboptimal
collapse. For decision scenarios lacking explicit supervisory labels, we
incorporate a utility function that quantifies the ``reward'' of the throughout
decision. Additionally, we explore the connections between Guided Learning and
classic machine learning paradigms such as supervised, unsupervised,
semi-supervised, multi-task, and reinforcement learning. Experiments on
quantitative investment strategy building demonstrate that guided learning
significantly outperforms both traditional stage-wise approaches and existing
end-to-end methods.","cs.LG, cs.AI, q-fin.CP",cs.LG,http://arxiv.org/abs/2411.10496v1
"HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of
  Historical Texts -- A Case Application of Yantie Lun",Yifan Zeng,2024-11-15T06:21:13Z,"This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text ""Yantie Lun"" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in ""Yantie Lun"" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like ""Yantie Lun"" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.",cs.CL,cs.CL,http://arxiv.org/abs/2411.09978v1
"Experiences from Using LLMs for Repository Mining Studies in Empirical
  Software Engineering","Vincenzo de Martino, Joel Castaño, Fabio Palomba, Xavier Franch, Silverio Martínez-Fernández",2024-11-15T06:08:57Z,"Context: The emergence of Large Language Models (LLMs) has significantly
transformed Software Engineering (SE) by providing innovative methods for
analyzing software repositories. Objectives: Our objective is to establish a
practical framework for future SE researchers needing to enhance the data
collection and dataset while conducting software repository mining studies
using LLMs. Method: This experience report shares insights from two previous
repository mining studies, focusing on the methodologies used for creating,
refining, and validating prompts that enhance the output of LLMs, particularly
in the context of data collection in empirical studies. Results: Our research
packages a framework, coined Prompt Refinement and Insights for Mining
Empirical Software repositories (PRIMES), consisting of a checklist that can
improve LLM usage performance, enhance output quality, and minimize errors
through iterative processes and comparisons among different LLMs. We also
emphasize the significance of reproducibility by implementing mechanisms for
tracking model results. Conclusion: Our findings indicate that standardizing
prompt engineering and using PRIMES can enhance the reliability and
reproducibility of studies utilizing LLMs. Ultimately, this work calls for
further research to address challenges like hallucinations, model biases, and
cost-effectiveness in integrating LLMs into workflows.",cs.SE,cs.SE,http://arxiv.org/abs/2411.09974v1
"Explanation for Trajectory Planning using Multi-modal Large Language
  Model for Autonomous Driving","Shota Yamazaki, Chenyu Zhang, Takuya Nanri, Akio Shigekane, Siyuan Wang, Jo Nishiyama, Tao Chu, Kohei Yokosawa",2024-11-15T06:05:33Z,"End-to-end style autonomous driving models have been developed recently.
These models lack interpretability of decision-making process from perception
to control of the ego vehicle, resulting in anxiety for passengers. To
alleviate it, it is effective to build a model which outputs captions
describing future behaviors of the ego vehicle and their reason. However, the
existing approaches generate reasoning text that inadequately reflects the
future plans of the ego vehicle, because they train models to output captions
using momentary control signals as inputs. In this study, we propose a
reasoning model that takes future planning trajectories of the ego vehicle as
inputs to solve this limitation with the dataset newly collected.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.09971v1
"Steering AI-Driven Personalization of Scientific Text for General
  Audiences","Taewook Kim, Dhruv Agarwal, Jordan Ackerman, Manaswi Saha",2024-11-15T05:55:23Z,"Digital media platforms (e.g., social media, science blogs) offer
opportunities to communicate scientific content to general audiences at scale.
However, these audiences vary in their scientific expertise, literacy levels,
and personal backgrounds, making effective science communication challenging.
To address this challenge, we designed TranSlider, an AI-powered tool that
generates personalized translations of scientific text based on individual user
profiles (e.g., hobbies, location, and education). Our tool features an
interactive slider that allows users to steer the degree of personalization
from 0 (weakly relatable) to 100 (strongly relatable), leveraging LLMs to
generate the translations with given degrees. Through an exploratory study with
15 participants, we investigated both the utility of these AI-personalized
translations and how interactive reading features influenced users'
understanding and reading experiences. We found that participants who preferred
higher degrees of personalization appreciated the relatable and contextual
translations, while those who preferred lower degrees valued concise
translations with subtle contextualization. Furthermore, participants reported
the compounding effect of multiple translations on their understanding of
scientific content. Given these findings, we discuss several implications of
AI-personalized translation tools in facilitating communication in
collaborative contexts.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.09969v1
Boundary Attention Constrained Zero-Shot Layout-To-Image Generation,"Huancheng Chen, Jingtao Li, Weiming Zhuang, Haris Vikalo, Lingjuan Lyu",2024-11-15T05:44:45Z,"Recent text-to-image diffusion models excel at generating high-resolution
images from text but struggle with precise control over spatial composition and
object counting. To address these challenges, several studies developed
layout-to-image (L2I) approaches that incorporate layout instructions into
text-to-image models. However, existing L2I methods typically require either
fine-tuning pretrained parameters or training additional control modules for
the diffusion models. In this work, we propose a novel zero-shot L2I approach,
BACON (Boundary Attention Constrained generation), which eliminates the need
for additional modules or fine-tuning. Specifically, we use text-visual
cross-attention feature maps to quantify inconsistencies between the layout of
the generated images and the provided instructions, and then compute loss
functions to optimize latent features during the diffusion reverse process. To
enhance spatial controllability and mitigate semantic failures in complex
layout instructions, we leverage pixel-to-pixel correlations in the
self-attention feature maps to align cross-attention maps and combine three
loss functions constrained by boundary attention to update latent features.
Comprehensive experimental results on both L2I and non-L2I pretrained diffusion
models demonstrate that our method outperforms existing zero-shot L2I
techniuqes both quantitatively and qualitatively in terms of image composition
on the DrawBench and HRS benchmarks.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10495v1
"Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at
  Pixel Level","Andong Deng, Tongjia Chen, Shoubin Yu, Taojiannan Yang, Lincoln Spencer, Yapeng Tian, Ajmal Saeed Mian, Mohit Bansal, Chen Chen",2024-11-15T03:45:09Z,"In this paper, we introduce Motion-Grounded Video Reasoning, a new motion
understanding task that requires generating visual answers (video segmentation
masks) according to the input question, and hence needs implicit spatiotemporal
reasoning and grounding. This task extends existing spatiotemporal grounding
work focusing on explicit action/motion grounding, to a more general format by
enabling implicit reasoning via questions. To facilitate the development of the
new task, we collect a large-scale dataset called GROUNDMORE, which comprises
1,715 video clips, 249K object masks that are deliberately designed with 4
question types (Causal, Sequential, Counterfactual, and Descriptive) for
benchmarking deep and comprehensive motion reasoning abilities. GROUNDMORE
uniquely requires models to generate visual answers, providing a more concrete
and visually interpretable response than plain texts. It evaluates models on
both spatiotemporal grounding and reasoning, fostering to address complex
challenges in motion-related video reasoning, temporal perception, and
pixel-level understanding. Furthermore, we introduce a novel baseline model
named Motion-Grounded Video Reasoning Assistant (MORA). MORA incorporates the
multimodal reasoning ability from the Multimodal LLM, the pixel-level
perception capability from the grounding model (SAM), and the temporal
perception ability from a lightweight localization head. MORA achieves
respectable performance on GROUNDMORE outperforming the best existing visual
grounding baseline model by an average of 21.5% relatively. We hope this novel
and challenging task will pave the way for future advancements in robust and
general motion understanding via video reasoning segmentation","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.09921v1
Memory Proxy Maps for Visual Navigation,"Faith Johnson, Bryan Bo Cao, Ashwin Ashok, Shubham Jain, Kristin Dana",2024-11-15T02:37:14Z,"Visual navigation takes inspiration from humans, who navigate in previously
unseen environments using vision without detailed environment maps. Inspired by
this, we introduce a novel no-RL, no-graph, no-odometry approach to visual
navigation using feudal learning to build a three tiered agent. Key to our
approach is a memory proxy map (MPM), an intermediate representation of the
environment learned in a self-supervised manner by the high-level manager agent
that serves as a simplified memory, approximating what the agent has seen. We
demonstrate that recording observations in this learned latent space is an
effective and efficient memory proxy that can remove the need for graphs and
odometry in visual navigation tasks. For the mid-level manager agent, we
develop a waypoint network (WayNet) that outputs intermediate subgoals, or
waypoints, imitating human waypoint selection during local navigation. For the
low-level worker agent, we learn a classifier over a discrete action space that
avoids local obstacles and moves the agent towards the WayNet waypoint. The
resulting feudal navigation network offers a novel approach with no RL, no
graph, no odometry, and no metric map; all while achieving SOTA results on the
image goal navigation task.",cs.CV,cs.CV,http://arxiv.org/abs/2411.09893v1
"Research on Domain-Specific Chinese Spelling Correction Method Based on
  Plugin Extension Modules","Xiaowu Zhang, Hongfei Zhao, Xuan Chang",2024-11-15T02:08:58Z,"This paper proposes a Chinese spelling correction method based on plugin
extension modules, aimed at addressing the limitations of existing models in
handling domain-specific texts. Traditional Chinese spelling correction models
are typically trained on general-domain datasets, resulting in poor performance
when encountering specialized terminology in domain-specific texts. To address
this issue, we design an extension module that learns the features of
domain-specific terminology, thereby enhancing the model's correction
capabilities within specific domains. This extension module can provide domain
knowledge to the model without compromising its general spelling correction
performance, thus improving its accuracy in specialized fields. Experimental
results demonstrate that after integrating extension modules for medical,
legal, and official document domains, the model's correction performance is
significantly improved compared to the baseline model without any extension
modules.",cs.CL,cs.CL,http://arxiv.org/abs/2411.09884v1
Evaluating Gender Bias in Large Language Models,"Michael Döll, Markus Döhring, Andreas Müller",2024-11-14T22:23:13Z,"Gender bias in artificial intelligence has become an important issue,
particularly in the context of language models used in communication-oriented
applications. This study examines the extent to which Large Language Models
(LLMs) exhibit gender bias in pronoun selection in occupational contexts. The
analysis evaluates the models GPT-4, GPT-4o, PaLM 2 Text Bison and Gemini 1.0
Pro using a self-generated dataset. The jobs considered include a range of
occupations, from those with a significant male presence to those with a
notable female concentration, as well as jobs with a relatively equal gender
distribution. Three different sentence processing methods were used to assess
potential gender bias: masked tokens, unmasked sentences, and sentence
completion. In addition, the LLMs suggested names of individuals in specific
occupations, which were then examined for gender distribution. The results show
a positive correlation between the models' pronoun choices and the gender
distribution present in U.S. labor force data. Female pronouns were more often
associated with female-dominated occupations, while male pronouns were more
often associated with male-dominated occupations. Sentence completion showed
the strongest correlation with actual gender distribution, while name
generation resulted in a more balanced 'politically correct' gender
distribution, albeit with notable variations in predominantly male or female
occupations. Overall, the prompting method had a greater impact on gender
distribution than the model selection itself, highlighting the complexity of
addressing gender bias in LLMs. The findings highlight the importance of
prompting in gender mapping.",cs.CL,cs.CL,http://arxiv.org/abs/2411.09826v1
"Architect: Generating Vivid and Interactive 3D Scenes with Hierarchical
  2D Inpainting","Yian Wang, Xiaowen Qiu, Jiageng Liu, Zhehuan Chen, Jiting Cai, Yufei Wang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan",2024-11-14T22:15:48Z,"Creating large-scale interactive 3D environments is essential for the
development of Robotics and Embodied AI research. Current methods, including
manual design, procedural generation, diffusion-based scene generation, and
large language model (LLM) guided scene design, are hindered by limitations
such as excessive human effort, reliance on predefined rules or training
datasets, and limited 3D spatial reasoning ability. Since pre-trained 2D image
generative models better capture scene and object configuration than LLMs, we
address these challenges by introducing Architect, a generative framework that
creates complex and realistic 3D embodied environments leveraging
diffusion-based 2D image inpainting. In detail, we utilize foundation visual
perception models to obtain each generated object from the image and leverage
pre-trained depth estimation models to lift the generated 2D image to 3D space.
Our pipeline is further extended to a hierarchical and iterative inpainting
process to continuously generate placement of large furniture and small objects
to enrich the scene. This iterative structure brings the flexibility for our
method to generate or refine scenes from various starting points, such as text,
floor plans, or pre-arranged environments.",cs.CV,cs.CV,http://arxiv.org/abs/2411.09823v1
"Research evaluation with ChatGPT: Is it age, country, length, or field
  biased?","Mike Thelwall, Zeyneb Kurt",2024-11-14T19:25:37Z,"Some research now suggests that ChatGPT can estimate the quality of journal
articles from their titles and abstracts. This has created the possibility to
use ChatGPT quality scores, perhaps alongside citation-based formulae, to
support peer review for research evaluation. Nevertheless, ChatGPT's internal
processes are effectively opaque, despite it writing a report to support its
scores, and its biases are unknown. This article investigates whether
publication date and field are biasing factors. Based on submitting a
monodisciplinary journal-balanced set of 117,650 articles from 26 fields
published in the years 2003, 2008, 2013, 2018 and 2023 to ChatGPT 4o-mini, the
results show that average scores increased over time, and this was not due to
author nationality or title and abstract length changes. The results also
varied substantially between fields, and first author countries. In addition,
articles with longer abstracts tended to receive higher scores, but plausibly
due to such articles tending to be better rather than due to ChatGPT analysing
more text. Thus, for the most accurate research quality evaluation results from
ChatGPT, it is important to normalise ChatGPT scores for field and year and
check for anomalies caused by sets of articles with short abstracts.",cs.DL,cs.DL,http://arxiv.org/abs/2411.09768v1
"Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review
  Outcomes Across Multiple Platforms","Mike Thelwall, Abdullah Yaghi",2024-11-14T19:20:33Z,"While previous studies have demonstrated that Large Language Models (LLMs)
can predict peer review outcomes to some extent, this paper builds on that by
introducing two new contexts and employing a more robust method - averaging
multiple ChatGPT scores. The findings that averaging 30 ChatGPT predictions,
based on reviewer guidelines and using only the submitted titles and abstracts,
failed to predict peer review outcomes for F1000Research (Spearman's rho=0.00).
However, it produced mostly weak positive correlations with the quality
dimensions of SciPost Physics (rho=0.25 for validity, rho=0.25 for originality,
rho=0.20 for significance, and rho = 0.08 for clarity) and a moderate positive
correlation for papers from the International Conference on Learning
Representations (ICLR) (rho=0.38). Including the full text of articles
significantly increased the correlation for ICLR (rho=0.46) and slightly
improved it for F1000Research (rho=0.09), while it had variable effects on the
four quality dimension correlations for SciPost LaTeX files. The use of
chain-of-thought system prompts slightly increased the correlation for
F1000Research (rho=0.10), marginally reduced it for ICLR (rho=0.37), and
further decreased it for SciPost Physics (rho=0.16 for validity, rho=0.18 for
originality, rho=0.18 for significance, and rho=0.05 for clarity). Overall, the
results suggest that in some contexts, ChatGPT can produce weak pre-publication
quality assessments. However, the effectiveness of these assessments and the
optimal strategies for employing them vary considerably across different
platforms, journals, and conferences. Additionally, the most suitable inputs
for ChatGPT appear to differ depending on the platform.","cs.DL, cs.CL",cs.DL,http://arxiv.org/abs/2411.09763v1
"Advancing Fine-Grained Visual Understanding with Multi-Scale Alignment
  in Multi-Modal Models","Wei Wang, Zhaowei Li, Qi Xu, Linfeng Li, YiQing Cai, Botian Jiang, Hang Song, Xingcan Hu, Pengyu Wang, Li Xiao",2024-11-14T18:57:07Z,"Multi-modal large language models (MLLMs) have achieved remarkable success in
fine-grained visual understanding across a range of tasks. However, they often
encounter significant challenges due to inadequate alignment for fine-grained
knowledge, which restricts their ability to accurately capture local details
and attain a comprehensive global perception. While recent advancements have
focused on aligning object expressions with grounding information, they
typically lack explicit integration of object images, which contain affluent
information beyond mere texts or coordinates. To bridge this gap, we introduce
a novel fine-grained visual knowledge alignment method that effectively aligns
and integrates multi-scale knowledge of objects, including texts, coordinates,
and images. This innovative method is underpinned by our multi-scale
fine-grained enhancement data synthesis pipeline, which provides over 300K
essential training data to enhance alignment and improve overall performance.
Furthermore, we present TinyGroundingGPT, a series of compact models optimized
for high-level alignments. With a scale of approximately 3B parameters,
TinyGroundingGPT achieves outstanding results in grounding tasks while
delivering performance comparable to larger MLLMs in complex visual scenarios.",cs.CV,cs.CV,http://arxiv.org/abs/2411.09691v1
LLM Hallucination Reasoning with Zero-shot Knowledge Test,"Seongmin Lee, Hsiang Hsu, Chun-Fu Chen",2024-11-14T18:55:26Z,"LLM hallucination, where LLMs occasionally generate unfaithful text, poses
significant challenges for their practical applications. Most existing
detection methods rely on external knowledge, LLM fine-tuning, or
hallucination-labeled datasets, and they do not distinguish between different
types of hallucinations, which are crucial for improving detection performance.
We introduce a new task, Hallucination Reasoning, which classifies
LLM-generated text into one of three categories: aligned, misaligned, and
fabricated. Our novel zero-shot method assesses whether LLM has enough
knowledge about a given prompt and text. Our experiments conducted on new
datasets demonstrate the effectiveness of our method in hallucination reasoning
and underscore its importance for enhancing detection performance.","cs.AI, cs.CL",cs.AI,http://arxiv.org/abs/2411.09689v1
"Towards a Classification of Open-Source ML Models and Datasets for
  Software Engineering","Alexandra González, Xavier Franch, David Lo, Silverio Martínez-Fernández",2024-11-14T18:52:05Z,"Background: Open-Source Pre-Trained Models (PTMs) and datasets provide
extensive resources for various Machine Learning (ML) tasks, yet these
resources lack a classification tailored to Software Engineering (SE) needs.
Aims: We apply an SE-oriented classification to PTMs and datasets on a popular
open-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs
over time. Method: We conducted a repository mining study. We started with a
systematically gathered database of PTMs and datasets from the HF API. Our
selection was refined by analyzing model and dataset cards and metadata, such
as tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are
replicable, with a publicly accessible replication package. Results: The most
common SE task among PTMs and datasets is code generation, with a primary focus
on software development and limited attention to software management. Popular
PTMs and datasets mainly target software development. Among ML tasks, text
generation is the most common in SE PTMs and datasets. There has been a marked
increase in PTMs for SE since 2023 Q2. Conclusions: This study underscores the
need for broader task coverage to enhance the integration of ML within SE
practices.","cs.SE, cs.AI, cs.LG",cs.SE,http://arxiv.org/abs/2411.09683v1
How do Machine Learning Models Change?,"Joel Castaño, Rafael Cabañas, Antonio Salmerón, David Lo, Silverio Martínez-Fernández",2024-11-14T18:14:32Z,"The proliferation of Machine Learning (ML) models and their open-source
implementations has transformed Artificial Intelligence research and
applications. Platforms like Hugging Face (HF) enable the development, sharing,
and deployment of these models, fostering an evolving ecosystem. While previous
studies have examined aspects of models hosted on platforms like HF, a
comprehensive longitudinal study of how these models change remains
underexplored. This study addresses this gap by utilizing both repository
mining and longitudinal analysis methods to examine over 200,000 commits and
1,200 releases from over 50,000 models on HF. We replicate and extend an ML
change taxonomy for classifying commits and utilize Bayesian networks to
uncover patterns in commit and release activities over time. Our findings
indicate that commit activities align with established data science
methodologies, such as CRISP-DM, emphasizing iterative refinement and
continuous improvement. Additionally, release patterns tend to consolidate
significant updates, particularly in documentation, distinguishing between
granular changes and milestone-based releases. Furthermore, projects with
higher popularity prioritize infrastructure enhancements early in their
lifecycle, and those with intensive collaboration practices exhibit improved
documentation standards. These and other insights enhance the understanding of
model changes on community platforms and provide valuable guidance for best
practices in model maintenance.","cs.SE, cs.LG",cs.SE,http://arxiv.org/abs/2411.09645v1
The Moral Foundations Weibo Corpus,"Renjie Cao, Miaoyan Hu, Jiahan Wei, Baha Ihnaini",2024-11-14T17:32:03Z,"Moral sentiments expressed in natural language significantly influence both
online and offline environments, shaping behavioral styles and interaction
patterns, including social media selfpresentation, cyberbullying, adherence to
social norms, and ethical decision-making. To effectively measure moral
sentiments in natural language processing texts, it is crucial to utilize
large, annotated datasets that provide nuanced understanding for accurate
analysis and modeltraining. However, existing corpora, while valuable, often
face linguistic limitations. To address this gap in the Chinese language
domain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of
25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each
comment is manually annotated by at least three systematically trained
annotators based on ten moral categories derived from a grounded theory of
morality. To assess annotator reliability, we present the kappa testresults, a
gold standard for measuring consistency. Additionally, we apply several the
latest large language models to supplement the manual annotations, conducting
analytical experiments to compare their performance and report baseline results
for moral sentiment classification.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.09612v1
LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models,"Zhengyi Wang, Jonathan Lorraine, Yikai Wang, Hang Su, Jun Zhu, Sanja Fidler, Xiaohui Zeng",2024-11-14T17:08:23Z,"This work explores expanding the capabilities of large language models (LLMs)
pretrained on text to generate 3D meshes within a unified model. This offers
key advantages of (1) leveraging spatial knowledge already embedded in LLMs,
derived from textual sources like 3D tutorials, and (2) enabling conversational
3D generation and mesh understanding. A primary challenge is effectively
tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.
To address this, we introduce LLaMA-Mesh, a novel approach that represents the
vertex coordinates and face definitions of 3D meshes as plain text, allowing
direct integration with LLMs without expanding the vocabulary. We construct a
supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate
3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs
as required, and (3) understand and interpret 3D meshes. Our work is the first
to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge
for 3D mesh generation in a text-based format, effectively unifying the 3D and
text modalities. LLaMA-Mesh achieves mesh generation quality on par with models
trained from scratch while maintaining strong text generation performance.","cs.LG, cs.AI, cs.CL, cs.CV, 68T05, I.3.5; I.2.10; I.2.6",cs.LG,http://arxiv.org/abs/2411.09595v1
Spider: Any-to-Many Multimodal LLM,"Jinxiang Lai, Jie Zhang, Jun Liu, Jian Li, Xiaocheng Lu, Song Guo",2024-11-14T16:58:19Z,"Multimodal LLMs (MLLMs) have emerged as an extension of Large Language Models
(LLMs), enabling the integration of various modalities. However, Any-to-Any
MLLMs are limited to generating pairwise modalities 'Text + X' within a single
response, such as Text + {Image or Audio or Video}. To address this limitation,
we introduce Spider, a novel efficient Any-to-Many Modalities Generation (AMMG)
framework, which can generate an arbitrary combination of modalities 'Text +
Xs', such as Text + {Image and Audio and Video}. To achieve efficient AMMG, our
Spider integrates three core components: a Base Model for basic X-to-X (i.e.,
Any-to-Any) modality processing, a novel Efficient Decoders-Controller for
controlling multimodal Decoders to generate Xs (many-modal) contents, and an
Any-to-Many Instruction Template designed for producing Xs signal prompts. To
train Spider, we constructed a novel Text-formatted Many-Modal (TMM) dataset,
which facilitates the learning of the X-to-Xs (i.e., Any-to-Many) capability
necessary for AMMG. Ultimately, the well-trained Spider generates a pseudo
X-to-Xs dataset, the first-ever X-to-Xs many-modal dataset, enhancing the
potential for AMMG task in future research. Overall, this work not only pushes
the boundary of multimodal interaction but also provides rich data support for
advancing the field.",cs.CV,cs.CV,http://arxiv.org/abs/2411.09439v1
Piecing It All Together: Verifying Multi-Hop Multimodal Claims,"Haoran Wang, Aman Rangapur, Xiongxiao Xu, Yueqing Liang, Haroon Gharwi, Carl Yang, Kai Shu",2024-11-14T16:01:33Z,"Existing claim verification datasets often do not require systems to perform
complex reasoning or effectively interpret multimodal evidence. To address
this, we introduce a new task: multi-hop multimodal claim verification. This
task challenges models to reason over multiple pieces of evidence from diverse
sources, including text, images, and tables, and determine whether the combined
multimodal evidence supports or refutes a given claim. To study this task, we
construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired
with multimodal evidence, generated and refined using large language models,
with additional input from human feedback. We show that MMCV is challenging
even for the latest state-of-the-art multimodal large language models,
especially as the number of reasoning hops increases. Additionally, we
establish a human performance benchmark on a subset of MMCV. We hope this
dataset and its evaluation task will encourage future research in multimodal
multi-hop claim verification.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.09547v1
A Practical Guide to Fine-tuning Language Models with Limited Data,"Márton Szép, Daniel Rueckert, Rüdiger von Eisenhart-Rothe, Florian Hinterwimmer",2024-11-14T15:55:37Z,"Employing pre-trained Large Language Models (LLMs) has become the de facto
standard in Natural Language Processing (NLP) despite their extensive data
requirements. Motivated by the recent surge in research focused on training
LLMs with limited data, particularly in low-resource domains and languages,
this paper surveys recent transfer learning approaches to optimize model
performance in downstream tasks where data is scarce. We first address initial
and continued pre-training strategies to better leverage prior knowledge in
unseen domains and languages. We then examine how to maximize the utility of
limited data during fine-tuning and few-shot learning. The final section takes
a task-specific perspective, reviewing models and methods suited for different
levels of data scarcity. Our goal is to provide practitioners with practical
guidelines for overcoming the challenges posed by constrained data while also
highlighting promising directions for future research.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.09539v1
"Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats
  in LLM-Based Agents","Yuyou Gan, Yong Yang, Zhe Ma, Ping He, Rui Zeng, Yiming Wang, Qingming Li, Chunyi Zhou, Songze Li, Ting Wang, Yunjun Gao, Yingcai Wu, Shouling Ji",2024-11-14T15:40:04Z,"With the continuous development of large language models (LLMs),
transformer-based models have made groundbreaking advances in numerous natural
language processing (NLP) tasks, leading to the emergence of a series of agents
that use LLMs as their control hub. While LLMs have achieved success in various
tasks, they face numerous security and privacy threats, which become even more
severe in the agent scenarios. To enhance the reliability of LLM-based
applications, a range of research has emerged to assess and mitigate these
risks from different perspectives.
  To help researchers gain a comprehensive understanding of various risks, this
survey collects and analyzes the different threats faced by these agents. To
address the challenges posed by previous taxonomies in handling cross-module
and cross-stage threats, we propose a novel taxonomy framework based on the
sources and impacts. Additionally, we identify six key features of LLM-based
agents, based on which we summarize the current research progress and analyze
their limitations. Subsequently, we select four representative agents as case
studies to analyze the risks they may face in practical use. Finally, based on
the aforementioned analyses, we propose future research directions from the
perspectives of data, methodology, and policy, respectively.",cs.AI,cs.AI,http://arxiv.org/abs/2411.09523v1
Golden Noise for Diffusion Models: A Learning Framework,"Zikai Zhou, Shitong Shao, Lichen Bai, Zhiqiang Xu, Bo Han, Zeke Xie",2024-11-14T15:13:13Z,"Text-to-image diffusion model is a popular paradigm that synthesizes
personalized images by providing a text prompt and a random Gaussian noise.
While people observe that some noises are ``golden noises'' that can achieve
better text-image alignment and higher human preference than others, we still
lack a machine learning framework to obtain those golden noises. To learn
golden noises for diffusion sampling, we mainly make three contributions in
this paper. First, we identify a new concept termed the \textit{noise prompt},
which aims at turning a random Gaussian noise into a golden noise by adding a
small desirable perturbation derived from the text prompt. Following the
concept, we first formulate the \textit{noise prompt learning} framework that
systematically learns ``prompted'' golden noise associated with a text prompt
for diffusion models. Second, we design a noise prompt data collection pipeline
and collect a large-scale \textit{noise prompt dataset}~(NPD) that contains
100k pairs of random noises and golden noises with the associated text prompts.
With the prepared NPD as the training dataset, we trained a small \textit{noise
prompt network}~(NPNet) that can directly learn to transform a random noise
into a golden noise. The learned golden noise perturbation can be considered as
a kind of prompt for noise, as it is rich in semantic information and tailored
to the given text prompt. Third, our extensive experiments demonstrate the
impressive effectiveness and generalization of NPNet on improving the quality
of synthesized images across various diffusion models, including SDXL,
DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and
efficient controller that acts as a plug-and-play module with very limited
additional inference and computational costs, as it just provides a golden
noise instead of a random noise without accessing the original pipeline.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.09502v1
"The Use of Readability Metrics in Legal Text: A Systematic Literature
  Review","Yu Han, Aaron Ceross, Jeroen H. M. Bergmann",2024-11-14T15:04:17Z,"Understanding the text in legal documents can be challenging due to their
complex structure and the inclusion of domain-specific jargon. Laws and
regulations are often crafted in such a manner that engagement with them
requires formal training, potentially leading to vastly different
interpretations of the same texts. Linguistic complexity is an important
contributor to the difficulties experienced by readers. Simplifying texts could
enhance comprehension across a broader audience, not just among trained
professionals. Various metrics have been developed to measure document
readability. Therefore, we adopted a systematic review approach to examine the
linguistic and readability metrics currently employed for legal and regulatory
texts. A total of 3566 initial papers were screened, with 34 relevant studies
found and further assessed. Our primary objective was to identify which current
metrics were applied for evaluating readability within the legal field. Sixteen
different metrics were identified, with the Flesch-Kincaid Grade Level being
the most frequently used method. The majority of studies (73.5%) were found in
the domain of ""informed consent forms"". From the analysis, it is clear that not
all legal domains are well represented in terms of readability metrics and that
there is a further need to develop more consensus on which metrics should be
applied for legal documents.",cs.CL,cs.CL,http://arxiv.org/abs/2411.09497v1
"MM-Eval: A Hierarchical Benchmark for Modern Mongolian Evaluation in
  LLMs","Mengyuan Zhang, Ruihui Wang, Bo Xia, Yuan Sun, Xiaobing Zhao",2024-11-14T14:58:38Z,"Large language models (LLMs) excel in high-resource languages but face
notable challenges in low-resource languages like Mongolian. This paper
addresses these challenges by categorizing capabilities into language abilities
(syntax and semantics) and cognitive abilities (knowledge and reasoning). To
systematically evaluate these areas, we developed MM-Eval, a specialized
dataset based on Modern Mongolian Language Textbook I and enriched with WebQSP
and MGSM datasets.
  Preliminary experiments on models including Qwen2-7B-Instruct, GLM4-9b-chat,
Llama3.1-8B-Instruct, GPT-4, and DeepseekV2.5 revealed that: 1) all models
performed better on syntactic tasks than semantic tasks, highlighting a gap in
deeper language understanding; and 2) knowledge tasks showed a moderate
decline, suggesting that models can transfer general knowledge from
high-resource to low-resource contexts.
  The release of MM-Eval, comprising 569 syntax, 677 semantics, 344 knowledge,
and 250 reasoning tasks, offers valuable insights for advancing NLP and LLMs in
low-resource languages like Mongolian. The dataset is available at
https://github.com/joenahm/MM-Eval.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.09492v1
"A Layered Architecture for Developing and Enhancing Capabilities in
  Large Language Model-based Software Systems","Dawen Zhang, Xiwei Xu, Chen Wang, Zhenchang Xing, Robert Mao",2024-11-19T09:18:20Z,"Significant efforts has been made to expand the use of Large Language Models
(LLMs) beyond basic language tasks. While the generalizability and versatility
of LLMs have enabled widespread adoption, evolving demands in application
development often exceed their native capabilities. Meeting these demands may
involve a diverse set of methods, such as enhancing creativity through either
inference temperature adjustments or creativity-provoking prompts. Selecting
the right approach is critical, as different methods lead to trade-offs in
engineering complexity, scalability, and operational costs. This paper
introduces a layered architecture that organizes LLM software system
development into distinct layers, each characterized by specific attributes. By
aligning capabilities with these layers, the framework encourages the
systematic implementation of capabilities in effective and efficient ways that
ultimately supports desired functionalities and qualities. Through practical
case studies, we illustrate the utility of the framework. This work offers
developers actionable insights for selecting suitable technologies in LLM-based
software system development, promoting robustness and scalability.","cs.SE, cs.AI, cs.CL, cs.MA",cs.SE,http://arxiv.org/abs/2411.12357v1
"Balancing Accuracy and Efficiency in Multi-Turn Intent Classification
  for LLM-Powered Dialog Systems in Production","Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim",2024-11-19T07:48:35Z,"Accurate multi-turn intent classification is essential for advancing
conversational AI systems. However, challenges such as the scarcity of
comprehensive datasets and the complexity of contextual dependencies across
dialogue turns hinder progress. This paper presents two novel approaches
leveraging Large Language Models (LLMs) to enhance scalability and reduce
latency in production dialogue systems. First, we introduce Symbol Tuning,
which simplifies intent labels to reduce task complexity and improve
performance in multi-turn dialogues. Second, we propose C-LARA
(Consistency-aware, Linguistics Adaptive Retrieval Augmentation), a framework
that employs LLMs for data augmentation and pseudo-labeling to generate
synthetic multi-turn dialogues. These enriched datasets are used to fine-tune a
small, efficient model suitable for deployment. Experiments conducted on
multilingual dialogue datasets demonstrate significant improvements in
classification accuracy and resource efficiency. Our methods enhance multi-turn
intent classification accuracy by 5.09%, reduce annotation costs by 40%, and
enable scalable deployment in low-resource multilingual industrial systems,
highlighting their practicality and impact.","cs.CL, cs.AI, cs.IR",cs.CL,http://arxiv.org/abs/2411.12307v1
"Enhancing UX Research Activities Using GenAI -- Potential Applications
  and Challenges","Stefan Graser, Anastasia Snimshchikova, Martin Schrepp, Stephan Böhm",2024-11-19T07:18:51Z,"User Experience (UX) Research covers various methods for gathering the users'
subjective impressions of a product. For this, practitioners face different
activities and tasks related to the research process. This includes processing
a large amount of data based on qualitative and quantitative data. However,
this can be very laborious in practice. Thus, the application of GenAI can
support UX research activities. This paper provides a practical perspective on
this topic. Based on previous studies, we present different use cases
indicating the potential of GenAI in UX research. Moreover, we provide insights
into an exploratory study using GenAI along an entire UX research process.
Results show that Large Language Models (LLMs) are useful for various tasks.
Thus, the research activities can be carried out more efficiently. However, the
researcher should always review results to ensure quality. In summary, we want
to express the potential of GenAI enhancing UX research",cs.HC,cs.HC,http://arxiv.org/abs/2411.12289v1
"Evaluating Tokenizer Performance of Large Language Models Across
  Official Indian Languages","S. Tamang, D. J. Bora",2024-11-19T05:37:17Z,"Large Language Models (LLMs) based on transformer architectures have
revolutionized a variety of domains, with tokenization playing a pivotal role
in their pre-processing and fine-tuning stages. In multilingual models,
particularly those tailored for Indic languages, effective tokenization is
crucial for optimizing performance. This paper presents a comprehensive
evaluation of tokenizers used by 12 LLMs across all 22 official languages of
India, with a focus on comparing the efficiency of their tokenization
processes. We employed the Normalized Sequence Length (NSL) as a key metric in
our analysis. Our findings reveal that the SUTRA tokenizer outperforms all
other models, including several Indic-specific models, excelling in 14
languages. Notable insights include the SUTRA tokenizer's superior handling of
Indic languages, GPT-4o's advancement over its predecessor GPT-4 in processing
Indian languages, and the limited performance of Project Indus in certain
languages. This study underscores the critical importance of developing
targeted tokenization strategies for multilingual and Indic-centric models,
laying the groundwork for future improvements in tokenizer design to enhance
linguistic coverage and model efficiency.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12240v1
"Zero-Shot Crate Digging: DJ Tool Retrieval Using Speech Activity, Music
  Structure And CLAP Embeddings",Iroro Orife,2024-11-19T03:57:00Z,"In genres like Hip-Hop, RnB, Reggae, Dancehall and just about every
Electronic/Dance/Club style, DJ tools are a special set of audio files curated
to heighten the DJ's musical performance and creative mixing choices. In this
work we demonstrate an approach to discovering DJ tools in personal music
collections. Leveraging open-source libraries for speech/music activity, music
boundary analysis and a Contrastive Language-Audio Pretraining (CLAP) model for
zero-shot audio classification, we demonstrate a novel system designed to
retrieve (or rediscover) compelling DJ tools for use live or in the studio.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.12209v1
"CoMeDi Shared Task: Models as Annotators in Lexical Semantics
  Disagreements","Zhu Liu, Zhen Hu, Ying Liu",2024-11-19T00:50:06Z,"We present the results of our system for the CoMeDi Shared Task, which
predicts majority votes (Subtask 1) and annotator disagreements (Subtask 2).
Our approach combines model ensemble strategies with MLP-based and
threshold-based methods trained on pretrained language models. Treating
individual models as virtual annotators, we simulate the annotation process by
designing aggregation measures that incorporate continuous similarity scores
and discrete classification labels to capture both majority and disagreement.
Additionally, we employ anisotropy removal techniques to enhance performance.
Experimental results demonstrate the effectiveness of our methods, particularly
for Subtask 2. Notably, we find that continuous similarity scores, even within
the same model, align better with human disagreement patterns compared to
aggregated discrete labels.",cs.CL,cs.CL,http://arxiv.org/abs/2411.12147v1
Metamorphic Evaluation of ChatGPT as a Recommender System,"Madhurima Khirbat, Yongli Ren, Pablo Castells, Mark Sanderson",2024-11-18T23:18:55Z,"With the rise of Large Language Models (LLMs) such as ChatGPT, researchers
have been working on how to utilize the LLMs for better recommendations.
However, although LLMs exhibit black-box and probabilistic characteristics
(meaning their internal working is not visible), the evaluation framework used
for assessing these LLM-based recommender systems (RS) are the same as those
used for traditional recommender systems. To address this gap, we introduce the
metamorphic testing for the evaluation of GPT-based RS. This testing technique
involves defining of metamorphic relations (MRs) between the inputs and
checking if the relationship has been satisfied in the outputs. Specifically,
we examined the MRs from both RS and LLMs perspectives, including rating
multiplication/shifting in RS and adding spaces/randomness in the LLMs prompt
via prompt perturbation. Similarity metrics (e.g. Kendall tau and Ranking
Biased Overlap(RBO)) are deployed to measure whether the relationship has been
satisfied in the outputs of MRs. The experiment results on MovieLens dataset
with GPT3.5 show that lower similarity are obtained in terms of Kendall $\tau$
and RBO, which concludes that there is a need of a comprehensive evaluation of
the LLM-based RS in addition to the existing evaluation metrics used for
traditional recommender systems.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12121v1
"Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning
  Methods","Jai Doshi, Asa Cooper Stickland",2024-11-18T22:31:17Z,"Large language model unlearning aims to remove harmful information that LLMs
have learnt to prevent their use for malicious purposes. LLMU and RMU have been
proposed as two methods for LLM unlearning, achieving impressive results on
unlearning benchmarks. We study in detail the efficacy of these methods by
evaluating their impact on general model capabilities on the WMDP benchmark as
well as a biology benchmark we create. Our experiments show that RMU generally
leads to better preservation of model capabilities, for similar or better
unlearning. We further test the robustness of these methods and find that doing
5-shot prompting or rephrasing the question in simple ways can lead to an over
ten-fold increase in accuracy on unlearning benchmarks. Finally, we show that
training on unrelated data can almost completely recover pre-unlearning
performance, demonstrating that these methods fail at truly unlearning. The
code is available at: https://github.com/JaiDoshi/Knowledge-Erasure.","cs.CL, cs.LG",cs.CL,http://arxiv.org/abs/2411.12103v2
Matroid Secretary via Labeling Schemes,"Kristóf Bérczi, Vasilis Livanos, José Soto, Victor Verdugo",2024-11-18T21:27:51Z,"The Matroid Secretary Problem (MSP) is one of the most prominent settings for
online resource allocation and optimal stopping. A decision-maker is presented
with a ground set of elements $E$ revealed sequentially and in random order.
Upon arrival, an irrevocable decision is made in a take-it-or-leave-it fashion,
subject to a feasibility constraint on the set of selected elements captured by
a matroid defined over $E$. The decision-maker only has ordinal access to
compare the elements, and the goal is to design an algorithm that selects every
element of the optimal basis with probability at least $\alpha$ (i.e.,
$\alpha$-probability-competitive). While the existence of a constant
probability-competitive algorithm for MSP remains a major open question, simple
greedy policies are at the core of state-of-the-art algorithms for several
matroid classes.
  We introduce a flexible and general algorithmic framework to analyze
greedy-like algorithms for MSP based on constructing a language associated with
the matroid. Using this language, we establish a lower bound on the
probability-competitiveness of the algorithm by studying a corresponding
Poisson point process that governs the words' distribution in the language.
Using our framework, we break the state-of-the-art guarantee for laminar
matroids by settling the probability-competitiveness of the greedy-improving
algorithm to be exactly $1-\ln(2) \approx 0.3068$. For graphic matroids, we
show a probability-competitiveness of $0.2693$ when the underlying graph has no
parallel edges and a guarantee of $0.2504$ for general graphs, also breaking
the state-of-the-art factor of $0.25$.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12069v1
"Machine Learning Evaluation Metric Discrepancies across Programming
  Languages and Their Components: Need for Standardization","Mohammad R. Salmanpour, Morteza Alizadeh, Ghazal Mousavi, Saba Sadeghi, Sajad Amiri, Mehrdad Oveisi, Arman Rahmim, Ilker Hacihaliloglu",2024-11-18T20:07:31Z,"This study evaluates metrics for tasks such as classification, regression,
clustering, correlation analysis, statistical tests, segmentation, and
image-to-image (I2I) translation. Metrics were compared across Python
libraries, R packages, and Matlab functions to assess their consistency and
highlight discrepancies. The findings underscore the need for a unified roadmap
to standardize metrics, ensuring reliable and reproducible ML evaluations
across platforms. This study examined a wide range of evaluation metrics across
various tasks and found only some to be consistent across platforms, such as
(i) Accuracy, Balanced Accuracy, Cohens Kappa, F-beta Score, MCC, Geometric
Mean, AUC, and Log Loss in binary classification; (ii) Accuracy, Cohens Kappa,
and F-beta Score in multi-class classification; (iii) MAE, MSE, RMSE, MAPE,
Explained Variance, Median AE, MSLE, and Huber in regression; (iv)
Davies-Bouldin Index and Calinski-Harabasz Index in clustering; (v) Pearson,
Spearman, Kendall's Tau, Mutual Information, Distance Correlation, Percbend,
Shepherd, and Partial Correlation in correlation analysis; (vi) Paired t-test,
Chi-Square Test, ANOVA, Kruskal-Wallis Test, Shapiro-Wilk Test, Welchs t-test,
and Bartlett's test in statistical tests; (vii) Accuracy, Precision, and Recall
in 2D segmentation; (viii) Accuracy in 3D segmentation; (ix) MAE, MSE, RMSE,
and R-Squared in 2D-I2I translation; and (x) MAE, MSE, and RMSE in 3D-I2I
translation. Given observation of discrepancies in a number of metrics (e.g.
precision, recall and F1 score in binary classification, WCSS in clustering,
multiple statistical tests, and IoU in segmentation, amongst multiple metrics),
this study concludes that ML evaluation metrics require standardization and
recommends that future research use consistent metrics for different tasks to
effectively compare ML techniques and solutions.","cs.LG, cs.SE, physics.comp-ph",cs.LG,http://arxiv.org/abs/2411.12032v1
Regret-Free Reinforcement Learning for LTL Specifications,"Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani",2024-11-18T20:01:45Z,"Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.","cs.AI, cs.LG",cs.AI,http://arxiv.org/abs/2411.12019v1
Bi-Mamba: Towards Accurate 1-Bit State Space Models,"Shengkun Tang, Liqun Ma, Haonan Li, Mingjie Sun, Zhiqiang Shen",2024-11-18T18:59:15Z,"The typical selective state-space model (SSM) of Mamba addresses several
limitations of Transformers, such as quadratic computational complexity with
sequence length and significant inference-time memory requirements due to the
key-value cache. However, the growing size of Mamba models continues to pose
training and deployment challenges and raises environmental concerns due to
considerable energy consumption. In this work, we introduce Bi-Mamba, a
scalable and powerful 1-bit Mamba architecture designed for more efficient
large language models with multiple sizes across 780M, 1.3B, and 2.7B. Bi-Mamba
models are trained from scratch on data volume as regular LLM pertaining using
an autoregressive distillation loss. Extensive experimental results on language
modeling demonstrate that Bi-Mamba achieves performance comparable to its
full-precision counterparts (e.g., FP16 or BF16) and much better accuracy than
post-training-binarization (PTB) Mamba baselines, while significantly reducing
memory footprint and energy consumption compared to the original Mamba model.
Our study pioneers a new linear computational complexity LLM framework under
low-bit representation and facilitates the future design of specialized
hardware tailored for efficient 1-bit Mamba-based LLMs.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11843v1
Tackling prediction tasks in relational databases with LLMs,"Marek Wydmuch, Łukasz Borchmann, Filip Graliński",2024-11-18T18:48:13Z,"Though large language models (LLMs) have demonstrated exceptional performance
across numerous problems, their application to predictive tasks in relational
databases remains largely unexplored. In this work, we address the notion that
LLMs cannot yield satisfactory results on relational databases due to their
interconnected tables, complex relationships, and heterogeneous data types.
Using the recently introduced RelBench benchmark, we demonstrate that even a
straightforward application of LLMs achieves competitive performance on these
tasks. These findings establish LLMs as a promising new baseline for ML on
relational databases and encourage further research in this direction.","cs.LG, cs.CL, cs.DB",cs.LG,http://arxiv.org/abs/2411.11829v1
Invariant Shape Representation Learning For Image Classification,"Tonmoy Hossain, Jing Ma, Jundong Li, Miaomiao Zhang",2024-11-19T03:39:43Z,"Geometric shape features have been widely used as strong predictors for image
classification. Nevertheless, most existing classifiers such as deep neural
networks (DNNs) directly leverage the statistical correlations between these
shape features and target variables. However, these correlations can often be
spurious and unstable across different environments (e.g., in different age
groups, certain types of brain changes have unstable relations with
neurodegenerative disease); hence leading to biased or inaccurate predictions.
In this paper, we introduce a novel framework that for the first time develops
invariant shape representation learning (ISRL) to further strengthen the
robustness of image classifiers. In contrast to existing approaches that mainly
derive features in the image space, our model ISRL is designed to jointly
capture invariant features in latent shape spaces parameterized by deformable
transformations. To achieve this goal, we develop a new learning paradigm based
on invariant risk minimization (IRM) to learn invariant representations of
image and shape features across multiple training distributions/environments.
By embedding the features that are invariant with regard to target variables in
different environments, our model consistently offers more accurate
predictions. We validate our method by performing classification tasks on both
simulated 2D images, real 3D brain and cine cardiovascular magnetic resonance
images (MRIs). Our code is publicly available at
https://github.com/tonmoy-hossain/ISRL.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12201v1
"Constant Rate Schedule: Constant-Rate Distributional Change for
  Efficient Training and Sampling in Diffusion Models","Shuntaro Okada, Kenji Doi, Ryota Yoshihashi, Hirokatsu Kataoka, Tomohiro Tanaka",2024-11-19T03:02:39Z,"We propose a noise schedule that ensures a constant rate of change in the
probability distribution of diffused data throughout the diffusion process. To
obtain this noise schedule, we measure the rate of change in the probability
distribution of the forward process and use it to determine the noise schedule
before training diffusion models. The functional form of the noise schedule is
automatically determined and tailored to each dataset and type of diffusion
model. We evaluate the effectiveness of our noise schedule on unconditional and
class-conditional image generation tasks using the LSUN
(bedroom/church/cat/horse), ImageNet, and FFHQ datasets. Through extensive
experiments, we confirmed that our noise schedule broadly improves the
performance of the diffusion models regardless of the dataset, sampler, number
of function evaluations, or type of diffusion model.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.12188v1
"Quantifying the Innovativeness of Celebrated Scientists and Their
  Embeddedness in Collaboration Networks","Chaolin Tian, Yurui Huang, Ching Jin, Yifang Ma, Brian Uzzi",2024-11-19T02:48:14Z,"Matthew effects, or the tendency for early achievements in science to lead to
more recognition and opportunities, are a potential source of stratification
and lost innovation when they draw unreasonable attention away from equally
innovative but less celebrated scholars. Here, we analyze whether prizewinners
produce more innovative works before and after being awarded a prize compared
to equivalently impactful non-prizewinning contenders. Our data covers the
careers of prizewinners and their dynamically matched non-prizewinners, a
longitudinal, science-wide sample of 23,562 scholars and 5.7 million
publications. We measured the innovativeness of prizewinners' and
non-prizewinners' publications in terms of their novelty, convergent thinking,
and interdisciplinarity. We find that prizewinners display distinctive forms of
innovativeness relative to their non-prizewinning counterparts in terms of
combining ideas in novel ways, bridging foundational and cutting-edge work on a
topic, and formulating approaches to problems that leverage the strengths of
interdisciplinarity. Further, prizewinners' innovativeness is strongly
predicted by their type of network embeddedness. In contrast to matched
non-prizewinners, prizewinners have shorter-term collaborations, their
collaborators tend to focus their attention on topics that are new to the
prizewinners, and their collaborators' collaborators have minimal overlap.","cs.DL, cs.SI",cs.DL,http://arxiv.org/abs/2411.12180v1
"Self-Supervised Learning in Deep Networks: A Pathway to Robust Few-Shot
  Classification",Yuyang Xiao,2024-11-19T01:01:56Z,"This study aims to optimize the few-shot image classification task and
improve the model's feature extraction and classification performance by
combining self-supervised learning with the deep network model ResNet-101.
During the training process, we first pre-train the model with self-supervision
to enable it to learn common feature expressions on a large amount of unlabeled
data; then fine-tune it on the few-shot dataset Mini-ImageNet to improve the
model's accuracy and generalization ability under limited data. The
experimental results show that compared with traditional convolutional neural
networks, ResNet-50, DenseNet, and other models, our method has achieved
excellent performance of about 95.12% in classification accuracy (ACC) and F1
score, verifying the effectiveness of self-supervised learning in few-shot
classification. This method provides an efficient and reliable solution for the
field of few-shot image classification.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12151v1
Decoupling Training-Free Guided Diffusion by ADMM,"Youyuan Zhang, Zehua Liu, Zenan Li, Zhaoyu Li, James J. Clark, Xujie Si",2024-11-18T23:05:54Z,"In this paper, we consider the conditional generation problem by guiding
off-the-shelf unconditional diffusion models with differentiable loss functions
in a plug-and-play fashion. While previous research has primarily focused on
balancing the unconditional diffusion model and the guided loss through a tuned
weight hyperparameter, we propose a novel framework that distinctly decouples
these two components. Specifically, we introduce two variables ${x}$ and ${z}$,
to represent the generated samples governed by the unconditional generation
model and the guidance function, respectively. This decoupling reformulates
conditional generation into two manageable subproblems, unified by the
constraint ${x} = {z}$. Leveraging this setup, we develop a new algorithm based
on the Alternating Direction Method of Multipliers (ADMM) to adaptively balance
these components. Additionally, we establish the equivalence between the
diffusion reverse step and the proximal operator of ADMM and provide a detailed
convergence analysis of our algorithm under certain mild assumptions. Our
experiments demonstrate that our proposed method ADMMDiff consistently
generates high-quality samples while ensuring strong adherence to the
conditioning criteria. It outperforms existing methods across a range of
conditional generation tasks, including image generation with various guidance
and controllable motion synthesis.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12773v1
"Distill the Best, Ignore the Rest: Improving Dataset Distillation with
  Loss-Value-Based Pruning","Brian B. Moser, Federico Raue, Tobias C. Nauen, Stanislav Frolov, Andreas Dengel",2024-11-18T22:51:44Z,"Dataset distillation has gained significant interest in recent years, yet
existing approaches typically distill from the entire dataset, potentially
including non-beneficial samples. We introduce a novel ""Prune First, Distill
After"" framework that systematically prunes datasets via loss-based sampling
prior to distillation. By leveraging pruning before classical distillation
techniques and generative priors, we create a representative core-set that
leads to enhanced generalization for unseen architectures - a significant
challenge of current distillation methods. More specifically, our proposed
framework significantly boosts distilled quality, achieving up to a 5.2
percentage points accuracy increase even with substantial dataset pruning,
i.e., removing 80% of the original dataset prior to distillation. Overall, our
experimental results highlight the advantages of our easy-sample prioritization
and cross-architecture robustness, paving the way for more effective and
high-quality dataset distillation.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12115v1
"Just Leaf It: Accelerating Diffusion Classifiers with Hierarchical Class
  Pruning","Arundhati S. Shanbhag, Brian B. Moser, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Andreas Dengel",2024-11-18T21:34:05Z,"Diffusion models, known for their generative capabilities, have recently
shown unexpected potential in image classification tasks by using Bayes'
theorem. However, most diffusion classifiers require evaluating all class
labels for a single classification, leading to significant computational costs
that can hinder their application in large-scale scenarios. To address this, we
present a Hierarchical Diffusion Classifier (HDC) that exploits the inherent
hierarchical label structure of a dataset. By progressively pruning irrelevant
high-level categories and refining predictions only within relevant
subcategories, i.e., leaf nodes, HDC reduces the total number of class
evaluations. As a result, HDC can accelerate inference by up to 60% while
maintaining and, in some cases, improving classification accuracy. Our work
enables a new control mechanism of the trade-off between speed and precision,
making diffusion-based classification more viable for real-world applications,
particularly in large-scale image classification tasks.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.12073v1
"Analyzing and Improving the Skin Tone Consistency and Bias in Implicit
  3D Relightable Face Generators","Libing Zeng, Nima Khademi Kalantari",2024-11-18T19:38:34Z,"With the advances in generative adversarial networks (GANs) and neural
rendering, 3D relightable face generation has received significant attention.
Among the existing methods, a particularly successful technique uses an
implicit lighting representation and generates relit images through the product
of synthesized albedo and light-dependent shading images. While this approach
produces high-quality results with intricate shading details, it often has
difficulty producing relit images with consistent skin tones, particularly when
the lighting condition is extracted from images of individuals with dark skin.
Additionally, this technique is biased towards producing albedo images with
lighter skin tones. Our main observation is that this problem is rooted in the
biased spherical harmonics (SH) coefficients, used during training. Following
this observation, we conduct an analysis and demonstrate that the bias appears
not only in band 0 (DC term), but also in the other bands of the estimated SH
coefficients. We then propose a simple, but effective, strategy to mitigate the
problem. Specifically, we normalize the SH coefficients by their DC term to
eliminate the inherent magnitude bias, while statistically align the
coefficients in the other bands to alleviate the directional bias. We also
propose a scaling strategy to match the distribution of illumination magnitude
in the generated images with the training data. Through extensive experiments,
we demonstrate the effectiveness of our solution in increasing the skin tone
consistency and mitigating bias.",cs.CV,cs.CV,http://arxiv.org/abs/2411.12002v1
Coverage-Constrained Human-AI Cooperation with Multiple Experts,"Zheng Zhang, Cuong Nguyen, Kevin Wells, Thanh-Toan Do, Gustavo Carneiro",2024-11-18T19:06:01Z,"Human-AI cooperative classification (HAI-CC) approaches aim to develop hybrid
intelligent systems that enhance decision-making in various high-stakes
real-world scenarios by leveraging both human expertise and AI capabilities.
Current HAI-CC methods primarily focus on learning-to-defer (L2D), where
decisions are deferred to human experts, and learning-to-complement (L2C),
where AI and human experts make predictions cooperatively. However, a notable
research gap remains in effectively exploring both L2D and L2C under diverse
expert knowledge to improve decision-making, particularly when constrained by
the cooperation cost required to achieve a target probability for AI-only
selection (i.e., coverage). In this paper, we address this research gap by
proposing the Coverage-constrained Learning to Defer and Complement with
Specific Experts (CL2DC) method. CL2DC makes final decisions through either AI
prediction alone or by deferring to or complementing a specific expert,
depending on the input data. Furthermore, we propose a coverage-constrained
optimisation to control the cooperation cost, ensuring it approximates a target
probability for AI-only selection. This approach enables an effective
assessment of system performance within a specified budget. Also, CL2DC is
designed to address scenarios where training sets contain multiple noisy-label
annotations without any clean-label references. Comprehensive evaluations on
both synthetic and real-world datasets demonstrate that CL2DC achieves superior
performance compared to state-of-the-art HAI-CC methods.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.11976v1
"UniHands: Unifying Various Wild-Collected Keypoints for Personalized
  Hand Reconstruction","Menghe Zhang, Joonyeoup Kim, Yangwen Liang, Shuangquan Wang, Kee-Bong Song",2024-11-18T18:59:58Z,"Accurate hand motion capture and standardized 3D representation are essential
for various hand-related tasks. Collecting keypoints-only data, while efficient
and cost-effective, results in low-fidelity representations and lacks surface
information. Furthermore, data inconsistencies across sources challenge their
integration and use. We present UniHands, a novel method for creating
standardized yet personalized hand models from wild-collected keypoints from
diverse sources. Unlike existing neural implicit representation methods,
UniHands uses the widely-adopted parametric models MANO and NIMBLE, providing a
more scalable and versatile solution. It also derives unified hand joints from
the meshes, which facilitates seamless integration into various hand-related
tasks. Experiments on the FreiHAND and InterHand2.6M datasets demonstrate its
ability to precisely reconstruct hand mesh vertices and keypoints, effectively
capturing high-degree articulation motions. Empirical studies involving nine
participants show a clear preference for our unified joints over existing
configurations for accuracy and naturalism (p-value 0.016).","cs.CV, cs.HC",cs.CV,http://arxiv.org/abs/2411.11845v1
"The Power of Many: Multi-Agent Multimodal Models for Cultural Image
  Captioning","Longju Bai, Angana Borah, Oana Ignat, Rada Mihalcea",2024-11-18T17:37:10Z,"Large Multimodal Models (LMMs) exhibit impressive performance across various
multimodal tasks. However, their effectiveness in cross-cultural contexts
remains limited due to the predominantly Western-centric nature of most data
and models. Conversely, multi-agent models have shown significant capability in
solving complex tasks. Our study evaluates the collective performance of LMMs
in a multi-agent interaction setting for the novel task of cultural image
captioning. Our contributions are as follows: (1) We introduce MosAIC, a
Multi-Agent framework to enhance cross-cultural Image Captioning using LMMs
with distinct cultural personas; (2) We provide a dataset of culturally
enriched image captions in English for images from China, India, and Romania
across three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable
metric for evaluating cultural information within image captions; and (4) We
show that the multi-agent interaction outperforms single-agent models across
different metrics, and offer valuable insights for future research. Our dataset
and models can be accessed at https://github.com/MichiganNLP/MosAIC.","cs.CV, cs.AI, cs.CL",cs.CV,http://arxiv.org/abs/2411.11758v1
"Revitalizing Electoral Trust: Enhancing Transparency and Efficiency
  through Automated Voter Counting with Machine Learning","Mir Faris, Syeda Aynul Karim, Md. Juniadul Islam",2024-11-18T17:10:14Z,"In order to address issues with manual vote counting during election
procedures, this study intends to examine the viability of using advanced image
processing techniques for automated voter counting. The study aims to shed
light on how automated systems that utilize cutting-edge technologies like
OpenCV, CVZone, and the MOG2 algorithm could greatly increase the effectiveness
and openness of electoral operations. The empirical findings demonstrate how
automated voter counting can enhance voting processes and rebuild public
confidence in election outcomes, particularly in places where trust is low. The
study also emphasizes how rigorous metrics, such as the F1 score, should be
used to systematically compare the accuracy of automated systems against manual
counting methods. This methodology enables a detailed comprehension of the
differences in performance between automated and human counting techniques by
providing a nuanced assessment. The incorporation of said measures serves to
reinforce an extensive assessment structure, guaranteeing the legitimacy and
dependability of automated voting systems inside the electoral sphere.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.11740v1
RAWMamba: Unified sRGB-to-RAW De-rendering With State Space Model,"Hongjun Chen, Wencheng Han, Huan Zheng, Jianbing Shen",2024-11-18T16:45:44Z,"Recent advancements in sRGB-to-RAW de-rendering have increasingly emphasized
metadata-driven approaches to reconstruct RAW data from sRGB images,
supplemented by partial RAW information. In image-based de-rendering, metadata
is commonly obtained through sampling, whereas in video tasks, it is typically
derived from the initial frame. The distinct metadata requirements necessitate
specialized network architectures, leading to architectural incompatibilities
that increase deployment complexity. In this paper, we propose RAWMamba, a
Mamba-based unified framework developed for sRGB-to-RAW de-rendering across
both image and video domains. The core of RAWMamba is the Unified Metadata
Embedding (UME) module, which harmonizes diverse metadata types into a unified
representation. In detail, a multi-perspective affinity modeling method is
proposed to promote the extraction of reference information. In addition, we
introduce the Local Tone-Aware Mamba (LTA-Mamba) module, which captures
long-range dependencies to enable effective global propagation of metadata.
Experimental results demonstrate that the proposed RAWMamba achieves
state-of-the-art performance, yielding high-quality RAW data reconstruction.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11717v1
From Spectra to Geography: Intelligent Mapping of RRUFF Mineral Data,"Francesco Pappone, Federico Califano, Marco Tafani",2024-11-18T16:15:00Z,"Accurately determining the geographic origin of mineral samples is pivotal
for applications in geology, mineralogy, and material science. Leveraging the
comprehensive Raman spectral data from the RRUFF database, this study
introduces a novel machine learning framework aimed at geolocating mineral
specimens at the country level. We employ a one-dimensional ConvNeXt1D neural
network architecture to classify mineral spectra based solely on their spectral
signatures. The processed dataset comprises over 32,900 mineral samples,
predominantly natural, spanning 101 countries. Through five-fold
cross-validation, the ConvNeXt1D model achieved an impressive average
classification accuracy of 93%, demonstrating its efficacy in capturing
geospatial patterns inherent in Raman spectra.","cs.CV, eess.IV, physics.comp-ph",cs.CV,http://arxiv.org/abs/2411.11693v1
Do Captioning Metrics Reflect Music Semantic Alignment?,"Jinwoo Lee, Kyogu Lee",2024-11-18T16:13:49Z,"Music captioning has emerged as a promising task, fueled by the advent of
advanced language generation models. However, the evaluation of music
captioning relies heavily on traditional metrics such as BLEU, METEOR, and
ROUGE which were developed for other domains, without proper justification for
their use in this new field. We present cases where traditional metrics are
vulnerable to syntactic changes, and show they do not correlate well with human
judgments. By addressing these issues, we aim to emphasize the need for a
critical reevaluation of how music captions are assessed.","cs.SD, cs.IR, eess.AS",cs.SD,http://arxiv.org/abs/2411.11692v1
"SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly
  semi-supervised medical image segmentation","Shiman Li, Jiayue Zhao, Shaolei Liu, Xiaokun Dai, Chenxi Zhang, Zhijian Song",2024-11-18T15:14:36Z,"Deep learning-based medical image segmentation helps assist diagnosis and
accelerate the treatment process while the model training usually requires
large-scale dense annotation datasets. Weakly semi-supervised medical image
segmentation is an essential application because it only requires a small
amount of scribbles and a large number of unlabeled data to train the model,
which greatly reduces the clinician's effort to fully annotate images. To
handle the inadequate supervisory information challenge in weakly
semi-supervised segmentation (WSSS), a SuperPixel-Propagated Pseudo-label
(SP${}^3$) learning method is proposed, using the structural information
contained in superpixel for supplemental information. Specifically, the
annotation of scribbles is propagated to superpixels and thus obtains a dense
annotation for supervised training. Since the quality of pseudo-labels is
limited by the low-quality annotation, the beneficial superpixels selected by
dynamic thresholding are used to refine pseudo-labels. Furthermore, aiming to
alleviate the negative impact of noise in pseudo-label, superpixel-level
uncertainty is incorporated to guide the pseudo-label supervision for stable
learning. Our method achieves state-of-the-art performance on both tumor and
organ segmentation datasets under the WSSS setting, using only 3\% of the
annotation workload compared to fully supervised methods and attaining
approximately 80\% Dice score. Additionally, our method outperforms eight
weakly and semi-supervised methods under both weakly supervised and
semi-supervised settings. Results of extensive experiments validate the
effectiveness and annotation efficiency of our weakly semi-supervised
segmentation, which can assist clinicians in achieving automated segmentation
for organs or tumors quickly and ultimately benefit patients.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11636v1
Federated Incremental Named Entity Recognition,"Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dong Yu",2024-11-18T14:53:53Z,"Federated Named Entity Recognition (FNER) boosts model training within each
local client by aggregating the model updates of decentralized local clients,
without sharing their private data. However, existing FNER methods assume fixed
entity types and local clients in advance, leading to their ineffectiveness in
practical applications. In a more realistic scenario, local clients receive new
entity types continuously, while new local clients collecting novel data may
irregularly join the global FNER training. This challenging setup, referred to
here as Federated Incremental NER, renders the global model suffering from
heterogeneous forgetting of old entity types from both intra-client and
inter-client perspectives. To overcome these challenges, we propose a
Local-Global Forgetting Defense (LGFD) model. Specifically, to address
intra-client forgetting, we develop a structural knowledge distillation loss to
retain the latent space's feature structure and a pseudo-label-guided
inter-type contrastive loss to enhance discriminative capability over different
entity types, effectively preserving previously learned knowledge within local
clients. To tackle inter-client forgetting, we propose a task switching monitor
that can automatically identify new entity types under privacy protection and
store the latest old global model for knowledge distillation and
pseudo-labeling. Experiments demonstrate significant improvement of our LGFD
model over comparison methods.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11623v1
"FERT: Real-Time Facial Expression Recognition with Short-Range FMCW
  Radar","Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach",2024-11-18T14:48:06Z,"This study proposes a novel approach for real-time facial expression
recognition utilizing short-range Frequency-Modulated Continuous-Wave (FMCW)
radar equipped with one transmit (Tx), and three receive (Rx) antennas. The
system leverages four distinct modalities simultaneously: Range-Doppler images
(RDIs), micro range-Doppler Images (micro-RDIs), range azimuth images (RAIs),
and range elevation images (REIs). Our innovative architecture integrates
feature extractor blocks, intermediate feature extractor blocks, and a ResNet
block to accurately classify facial expressions into smile, anger, neutral, and
no-face classes. Our model achieves an average classification accuracy of
98.91% on the dataset collected using a 60 GHz short-range FMCW radar. The
proposed solution operates in real-time in a person-independent manner, which
shows the potential use of low-cost FMCW radars for effective facial expression
recognition in various applications.","cs.CV, cs.LG, eess.SP",cs.CV,http://arxiv.org/abs/2411.11619v1
"Leveraging Computational Pathology AI for Noninvasive Optical Imaging
  Analysis Without Retraining","Danny Barash, Emilie Manning, Aidan Van Vleck, Omri Hirsch, Kyi Lei Aye, Jingxi Li, Philip O. Scumpia, Aydogan Ozcan, Sumaira Aasi, Kerri E. Rieger, Kavita Y. Sarin, Oren Freifeld, Yonatan Winetraub",2024-11-18T14:35:01Z,"Noninvasive optical imaging modalities can probe patient's tissue in 3D and
over time generate gigabytes of clinically relevant data per sample. There is a
need for AI models to analyze this data and assist clinical workflow. The lack
of expert labelers and the large dataset required (>100,000 images) for model
training and tuning are the main hurdles in creating foundation models. In this
paper we introduce FoundationShift, a method to apply any AI model from
computational pathology without retraining. We show our method is more accurate
than state of the art models (SAM, MedSAM, SAM-Med2D, CellProfiler, Hover-Net,
PLIP, UNI and ChatGPT), with multiple imaging modalities (OCT and RCM). This is
achieved without the need for model retraining or fine-tuning. Applying our
method to noninvasive in vivo images could enable physicians to readily
incorporate optical imaging modalities into their clinical practice, providing
real time tissue analysis and improving patient care.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11613v2
MSSIDD: A Benchmark for Multi-Sensor Denoising,"Shibin Mei, Hang Wang, Bingbing Ni",2024-11-18T13:32:59Z,"The cameras equipped on mobile terminals employ different sensors in
different photograph modes, and the transferability of raw domain denoising
models between these sensors is significant but remains sufficient exploration.
Industrial solutions either develop distinct training strategies and models for
different sensors or ignore the differences between sensors and simply extend
existing models to new sensors, which leads to tedious training or
unsatisfactory performance. In this paper, we introduce a new benchmark, the
Multi-Sensor SIDD (MSSIDD) dataset, which is the first raw-domain dataset
designed to evaluate the sensor transferability of denoising models. The MSSIDD
dataset consists of 60,000 raw images of six distinct sensors, derived through
the degeneration of sRGB images via different camera sensor parameters.
Furthermore, we propose a sensor consistency training framework that enables
denoising models to learn the sensor-invariant features, thereby facilitating
the generalization of the consistent model to unseen sensors. We evaluate
previous arts on the newly proposed MSSIDD dataset, and the experimental
results validate the effectiveness of our proposed method. Our dataset is
available at https://www.kaggle.com/datasets/sjtuwh/mssidd.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.11562v1
Real-Time Fitness Exercise Classification and Counting from Video Frames,Riccardo Riccio,2024-11-18T13:06:29Z,"This paper introduces a novel method for real-time exercise classification
using a Bidirectional Long Short-Term Memory (BiLSTM) neural network. Existing
exercise recognition approaches often rely on synthetic datasets, raw
coordinate inputs sensitive to user and camera variations, and fail to fully
exploit the temporal dependencies in exercise movements. These issues limit
their generalizability and robustness in real-world conditions, where lighting,
camera angles, and user body types vary.
  To address these challenges, we propose a BiLSTM-based model that leverages
invariant features, such as joint angles, alongside raw coordinates. By using
both angles and (x, y, z) coordinates, the model adapts to changes in
perspective, user positioning, and body differences, improving generalization.
Training on 30-frame sequences enables the BiLSTM to capture the temporal
context of exercises and recognize patterns evolving over time.
  We compiled a dataset combining synthetic data from the InfiniteRep dataset
and real-world videos from Kaggle and other sources. This dataset includes four
common exercises: squat, push-up, shoulder press, and bicep curl. The model was
trained and validated on these diverse datasets, achieving an accuracy of over
99% on the test set. To assess generalizability, the model was tested on 2
separate test sets representative of typical usage conditions. Comparisons with
the previous approach from the literature are present in the result section
showing that the proposed model is the best-performing one.
  The classifier is integrated into a web application providing real-time
exercise classification and repetition counting without manual exercise
selection.
  Demo and datasets are available at the following GitHub Repository:
https://github.com/RiccardoRiccio/Fitness-AI-Trainer-With-Automatic-Exercise-Recognition-and-Counting.","cs.CV, cs.AI, cs.LG",cs.CV,http://arxiv.org/abs/2411.11548v1
"Using voice analysis as an early indicator of risk for depression in
  young adults","Klaus R. Scherer, Felix Burkhardt, Uwe D. Reichel, Florian Eyben, Björn W. Schuller",2024-11-18T12:57:43Z,"Increasingly frequent publications in the literature report voice quality
differences between depressed patients and controls. Here, we examine the
possibility of using voice analysis as an early warning signal for the
development of emotion disturbances in young adults. As part of a major
interdisciplinary European research project in four countries (ECoWeB),
examining the effects of web-based prevention programs to reduce the risk for
depression in young adults, we analyzed a large number of acoustic voice
characteristics in vocal reports of emotions experienced by the participants on
a specific day. We were able to identify a number of significant differences in
acoustic cues, particularly with respect to the energy distribution in the
voice spectrum, encouraging further research efforts to develop promising
non-obtrusive risk indicators in the normal speaking voice. This is
particularly important in the case of young adults who are less likely to
exhibit standard risk factors for depression such as negative life experiences.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.11541v1
"Channel Capacity-Aware Distributed Encoding for Multi-View Sensing and
  Edge Inference","Mingjie Yang, Guangming Liang, Dongzhu Liu, Lei Zhang, Kaibin Huang",2024-11-18T12:52:04Z,"Integrated sensing and communication (ISAC) unifies wireless communication
and sensing by sharing spectrum and hardware, which often incurs trade-offs
between two functions due to limited resources. However, this paper shifts
focus to exploring the synergy between communication and sensing, using WiFi
sensing as an exemplary scenario where communication signals are repurposed to
probe the environment without dedicated sensing waveforms, followed by data
uploading to the edge server for inference. While increased device
participation enhances multi-view sensing data, it also imposes significant
communication overhead between devices and the edge server. To address this
challenge, we aim to maximize the sensing task performance, measured by mutual
information, under the channel capacity constraint. The information-theoretic
optimization problem is solved by the proposed ADE-MI, a novel framework that
employs a two-stage optimization two-stage optimization approach: (1) adaptive
distributed encoding (ADE) at the device, which ensures transmitted bits are
most relevant to sensing tasks, and (2) multi-view Inference (MI) at the edge
server, which orchestrates multi-view data from distributed devices. Our
experimental results highlight the synergy between communication and sensing,
showing that more frequent communication from WiFi access points to edge
devices improves sensing inference accuracy. The proposed ADE-MI achieves 92\%
recognition accuracy with over $10^4$-fold reduction in latency compared to
schemes with raw data communication, achieving both high sensing inference
accuracy and low communication latency simultaneously.","cs.IT, eess.SP, math.IT",cs.IT,http://arxiv.org/abs/2411.11539v1
"Cascaded Diffusion Models for 2D and 3D Microscopy Image Synthesis to
  Enhance Cell Segmentation","Rüveyda Yilmaz, Kaan Keven, Yuli Wu, Johannes Stegmaier",2024-11-18T12:22:37Z,"Automated cell segmentation in microscopy images is essential for biomedical
research, yet conventional methods are labor-intensive and prone to error.
While deep learning-based approaches have proven effective, they often require
large annotated datasets, which are scarce due to the challenges of manual
annotation. To overcome this, we propose a novel framework for synthesizing
densely annotated 2D and 3D cell microscopy images using cascaded diffusion
models. Our method synthesizes 2D and 3D cell masks from sparse 2D annotations
using multi-level diffusion models and NeuS, a 3D surface reconstruction
approach. Following that, a pretrained 2D Stable Diffusion model is finetuned
to generate realistic cell textures and the final outputs are combined to form
cell populations. We show that training a segmentation model with a combination
of our synthetic data and real data improves cell segmentation performance by
up to 9\% across multiple datasets. Additionally, the FID scores indicate that
the synthetic data closely resembles real data. The code for our proposed
approach will be available at
https://github.com/ruveydayilmaz0/cascaded_diffusion.","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.11515v2
LaVin-DiT: Large Vision Diffusion Transformer,"Zhaoqing Wang, Xiaobo Xia, Runnan Chen, Dongdong Yu, Changhu Wang, Mingming Gong, Tongliang Liu",2024-11-18T12:05:27Z,"This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a
scalable and unified foundation model designed to tackle over 20 computer
vision tasks in a generative framework. Unlike existing large vision models
directly adapted from natural language processing architectures, which rely on
less efficient autoregressive techniques and disrupt spatial relationships
essential for vision data, LaVin-DiT introduces key innovations to optimize
generative performance for vision tasks. First, to address the high
dimensionality of visual data, we incorporate a spatial-temporal variational
autoencoder that encodes data into a continuous latent space. Second, for
generative modeling, we develop a joint diffusion transformer that
progressively produces vision outputs. Third, for unified multi-task training,
in-context learning is implemented. Input-target pairs serve as task context,
which guides the diffusion transformer to align outputs with specific tasks
within the latent space. During inference, a task-specific context set and test
data as queries allow LaVin-DiT to generalize across tasks without fine-tuning.
Trained on extensive vision datasets, the model is scaled from 0.1B to 3.4B
parameters, demonstrating substantial scalability and state-of-the-art
performance across diverse vision tasks. This work introduces a novel pathway
for large vision foundation models, underscoring the promising potential of
diffusion transformers. The code and models will be open-sourced.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11505v1
"AtomThink: A Slow Thinking Framework for Multimodal Mathematical
  Reasoning","Kun Xiang, Zhili Liu, Zihao Jiang, Yunshuang Nie, Runhui Huang, Haoxiang Fan, Hanhui Li, Weiran Huang, Yihan Zeng, Jianhua Han, Lanqing Hong, Hang Xu, Xiaodan Liang",2024-11-18T11:54:58Z,"In this paper, we address the challenging task of multimodal mathematical
reasoning by incorporating the ability of ``slow thinking"" into multimodal
large language models (MLLMs). Contrary to existing methods that rely on direct
or fast thinking, our key idea is to construct long chains of thought (CoT)
consisting of atomic actions in a step-by-step manner, guiding MLLMs to perform
complex reasoning. To this end, we design a novel AtomThink framework composed
of three key modules: (i) a CoT annotation engine that automatically generates
high-quality CoT annotations to address the lack of high-quality visual
mathematical data; (ii) an atomic step fine-tuning strategy that jointly
optimizes an MLLM and a policy reward model (PRM) for step-wise reasoning; and
(iii) four different search strategies that can be applied with the PRM to
complete reasoning. Additionally, we propose AtomMATH, a large-scale multimodal
dataset of long CoTs, and an atomic capability evaluation metric for
mathematical tasks. Extensive experimental results show that the proposed
AtomThink significantly improves the performance of baseline MLLMs, achieving
approximately 50\% relative accuracy gains on MathVista and 120\% on MathVerse.
To support the advancement of multimodal slow-thinking models, we will make our
code and dataset publicly available on https://github.com/Quinn777/AtomThink.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11930v1
Look a Group at Once: Multi-Slide Modeling for Survival Prediction,"Xinyang Li, Yi Zhang, Yi Xie, Jianfei Yang, Xi Wang, Hao Chen, Haixian Zhang",2024-11-18T11:48:45Z,"Survival prediction is a critical task in pathology. In clinical practice,
pathologists often examine multiple cases, leveraging a broader spectrum of
cancer phenotypes to enhance pathological assessment. Despite significant
advancements in deep learning, current solutions typically model each slide as
a sample, struggling to effectively capture comparable and slide-agnostic
pathological features. In this paper, we introduce GroupMIL, a novel framework
inspired by the clinical practice of collective analysis, which models multiple
slides as a single sample and organizes groups of patches and slides
sequentially to capture cross-slide prognostic features. We also present
GPAMamba, a model designed to facilitate intra- and inter-slide feature
interactions, effectively capturing local micro-environmental characteristics
within slide-level graphs while uncovering essential prognostic patterns across
an extended patch sequence within the group framework. Furthermore, we develop
a dual-head predictor that delivers comprehensive survival risk and probability
assessments for each patient. Extensive empirical evaluations demonstrate that
our model significantly outperforms state-of-the-art approaches across five
datasets from The Cancer Genome Atlas.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11487v1
"Generalizable Person Re-identification via Balancing Alignment and
  Uniformity","Yoonki Cho, Jaeyoon Kim, Woo Jae Kim, Junsik Jung, Sung-eui Yoon",2024-11-18T11:13:30Z,"Domain generalizable person re-identification (DG re-ID) aims to learn
discriminative representations that are robust to distributional shifts. While
data augmentation is a straightforward solution to improve generalization,
certain augmentations exhibit a polarized effect in this task, enhancing
in-distribution performance while deteriorating out-of-distribution
performance. In this paper, we investigate this phenomenon and reveal that it
leads to sparse representation spaces with reduced uniformity. To address this
issue, we propose a novel framework, Balancing Alignment and Uniformity (BAU),
which effectively mitigates this effect by maintaining a balance between
alignment and uniformity. Specifically, BAU incorporates alignment and
uniformity losses applied to both original and augmented images and integrates
a weighting strategy to assess the reliability of augmented samples, further
improving the alignment loss. Additionally, we introduce a domain-specific
uniformity loss that promotes uniformity within each source domain, thereby
enhancing the learning of domain-invariant features. Extensive experimental
results demonstrate that BAU effectively exploits the advantages of data
augmentation, which previous studies could not fully utilize, and achieves
state-of-the-art performance without requiring complex training procedures. The
code is available at \url{https://github.com/yoonkicho/BAU}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11471v1
Towards fast DBSCAN via Spectrum-Preserving Data Compression,Yongyu Wang,2024-11-18T09:46:45Z,"This paper introduces a novel method to significantly accelerate DBSCAN by
employing spectral data compression. The proposed approach reduces the size of
the data set by a factor of five while preserving the essential clustering
characteristics through an innovative spectral compression technique. This
enables DBSCAN to run substantially faster without any loss of accuracy.
Experiments on real-world data sets, such as USPS, demonstrate the method's
capability to achieve this dramatic reduction in data size while maintaining
clustering performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11421v1
"Temporal and Spatial Reservoir Ensembling Techniques for Liquid State
  Machines","Anmol Biswas, Sharvari Ashok Medhe, Raghav Singhal, Udayan Ganguly",2024-11-18T09:35:22Z,"Reservoir computing (RC), is a class of computational methods such as Echo
State Networks (ESN) and Liquid State Machines (LSM) describe a generic method
to perform pattern recognition and temporal analysis with any non-linear
system. This is enabled by Reservoir Computing being a shallow network model
with only Input, Reservoir, and Readout layers where input and reservoir
weights are not learned (only the readout layer is trained). LSM is a special
case of Reservoir computing inspired by the organization of neurons in the
brain and generally refers to spike-based Reservoir computing approaches. LSMs
have been successfully used to showcase decent performance on some neuromorphic
vision and speech datasets but a common problem associated with LSMs is that
since the model is more-or-less fixed, the main way to improve the performance
is by scaling up the Reservoir size, but that only gives diminishing rewards
despite a tremendous increase in model size and computation. In this paper, we
propose two approaches for effectively ensembling LSM models - Multi-Length
Scale Reservoir Ensemble (MuLRE) and Temporal Excitation Partitioned Reservoir
Ensemble (TEPRE) and benchmark them on Neuromorphic-MNIST (N-MNIST), Spiking
Heidelberg Digits (SHD), and DVSGesture datasets, which are standard
neuromorphic benchmarks. We achieve 98.1% test accuracy on N-MNIST with a
3600-neuron LSM model which is higher than any prior LSM-based approach and
77.8% test accuracy on the SHD dataset which is on par with a standard
Recurrent Spiking Neural Network trained by Backprop Through Time (BPTT). We
also propose receptive field-based input weights to the Reservoir to work
alongside the Multi-Length Scale Reservoir ensemble model for vision tasks.
Thus, we introduce effective means of scaling up the performance of LSM models
and evaluate them against relevant neuromorphic benchmarks","cs.LG, cs.NE",cs.LG,http://arxiv.org/abs/2411.11414v1
"KAN-Mamba FusionNet: Redefining Medical Image Segmentation with
  Non-Linear Modeling","Akansh Agrawal, Akshan Agrawal, Shashwat Gupta, Priyanka Bagade",2024-11-18T09:19:16Z,"Medical image segmentation is crucial in robotic surgeries, disease
diagnosis, and treatment plans. This research presents an innovative
methodology that combines Kolmogorov-Arnold Networks (KAN) with an adapted
Mamba layer for medical image segmentation. The proposed KAN-Mamba FusionNet
framework improves image segmentation by integrating attention-driven
mechanisms with convolutional parallel training and autoregressive deployment,
while preserving interpretability, in contrast to the state-of-the-art
techniques that depend exclusively on Mamba for ailment localization and
accurate diagnosis. We evaluated our proposed KAN-Mamba FusionNet model on
three distinct medical image segmentation datasets, BUSI, Kvasir-Seg and GlaS.
The results indicated that the KAN-Mamba FusionNet consistently yields better
IoU and F1 scores in comparison to the state-of-the-art methods. Further, we
offer insights into the model's behavior via ablation studies, examining the
effects of various components and assessing their contributions to the overall
performance of the proposed model. The findings illustrate the strength and
effectiveness of this methodology for dependable medical image segmentation,
providing a unique approach to address intricate visual data issues in
healthcare.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11926v1
Continuous Speculative Decoding for Autoregressive Image Generation,"Zili Wang, Robert Zhang, Kun Ding, Qi Yang, Fei Li, Shiming Xiang",2024-11-18T09:19:15Z,"Continuous-valued Autoregressive (AR) image generation models have
demonstrated notable superiority over their discrete-token counterparts,
showcasing considerable reconstruction quality and higher generation fidelity.
However, the computational demands of the autoregressive framework result in
significant inference overhead. While speculative decoding has proven effective
in accelerating Large Language Models (LLMs), their adaptation to
continuous-valued visual autoregressive models remains unexplored. This work
generalizes the speculative decoding algorithm from discrete tokens to
continuous space. By analyzing the intrinsic properties of output distribution,
we establish a tailored acceptance criterion for the diffusion distributions
prevalent in such models. To overcome the inconsistency that occurred in
speculative decoding output distributions, we introduce denoising trajectory
alignment and token pre-filling methods. Additionally, we identify the
hard-to-sample distribution in the rejection phase. To mitigate this issue, we
propose a meticulous acceptance-rejection sampling method with a proper upper
bound, thereby circumventing complex integration. Experimental results show
that our continuous speculative decoding achieves a remarkable $2.33\times$
speed-up on off-the-shelf models while maintaining the output distribution.
Codes will be available at https://github.com/MarkXCloud/CSpD",cs.CV,cs.CV,http://arxiv.org/abs/2411.11925v1
"MAIRA-Seg: Enhancing Radiology Report Generation with Segmentation-Aware
  Multimodal Large Language Models","Harshita Sharma, Valentina Salvatelli, Shaury Srivastav, Kenza Bouzid, Shruthi Bannur, Daniel C. Castro, Maximilian Ilse, Sam Bond-Taylor, Mercy Prasanna Ranjit, Fabian Falck, Fernando Pérez-García, Anton Schwaighofer, Hannah Richardson, Maria Teodora Wetscherek, Stephanie L. Hyland, Javier Alvarez-Valle",2024-11-18T08:13:22Z,"There is growing interest in applying AI to radiology report generation,
particularly for chest X-rays (CXRs). This paper investigates whether
incorporating pixel-level information through segmentation masks can improve
fine-grained image interpretation of multimodal large language models (MLLMs)
for radiology report generation. We introduce MAIRA-Seg, a segmentation-aware
MLLM framework designed to utilize semantic segmentation masks alongside CXRs
for generating radiology reports. We train expert segmentation models to obtain
mask pseudolabels for radiology-specific structures in CXRs. Subsequently,
building on the architectures of MAIRA, a CXR-specialised model for report
generation, we integrate a trainable segmentation tokens extractor that
leverages these mask pseudolabels, and employ mask-aware prompting to generate
draft radiology reports. Our experiments on the publicly available MIMIC-CXR
dataset show that MAIRA-Seg outperforms non-segmentation baselines. We also
investigate set-of-marks prompting with MAIRA and find that MAIRA-Seg
consistently demonstrates comparable or superior performance. The results
confirm that using segmentation masks enhances the nuanced reasoning of MLLMs,
potentially contributing to better clinical outcomes.","cs.CV, cs.CL",cs.CV,http://arxiv.org/abs/2411.11362v1
"Superpixel-informed Implicit Neural Representation for Multi-Dimensional
  Data","Jiayi Li, Xile Zhao, Jianli Wang, Chao Wang, Min Wang",2024-11-18T07:57:59Z,"Recently, implicit neural representations (INRs) have attracted increasing
attention for multi-dimensional data recovery. However, INRs simply map
coordinates via a multi-layer perception (MLP) to corresponding values,
ignoring the inherent semantic information of the data. To leverage semantic
priors from the data, we propose a novel Superpixel-informed INR (S-INR).
Specifically, we suggest utilizing generalized superpixel instead of pixel as
an alternative basic unit of INR for multi-dimensional data (e.g., images and
weather data). The coordinates of generalized superpixels are first fed into
exclusive attention-based MLPs, and then the intermediate results interact with
a shared dictionary matrix. The elaborately designed modules in S-INR allow us
to ingenuously exploit the semantic information within and across generalized
superpixels. Extensive experiments on various applications validate the
effectiveness and efficacy of our S-INR compared to state-of-the-art INR
methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11356v1
Visual-Semantic Graph Matching Net for Zero-Shot Learning,"Bowen Duan, Shiming Chen, Yufei Guo, Guo-Sen Xie, Weiping Ding, Yisong Wang",2024-11-18T07:43:12Z,"Zero-shot learning (ZSL) aims to leverage additional semantic information to
recognize unseen classes. To transfer knowledge from seen to unseen classes,
most ZSL methods often learn a shared embedding space by simply aligning visual
embeddings with semantic prototypes. However, methods trained under this
paradigm often struggle to learn robust embedding space because they align the
two modalities in an isolated manner among classes, which ignore the crucial
class relationship during the alignment process. To address the aforementioned
challenges, this paper proposes a Visual-Semantic Graph Matching Net, termed as
VSGMN, which leverages semantic relationships among classes to aid in
visual-semantic embedding. VSGMN employs a Graph Build Network (GBN) and a
Graph Matching Network (GMN) to achieve two-stage visual-semantic alignment.
Specifically, GBN first utilizes an embedding-based approach to build visual
and semantic graphs in the semantic space and align the embedding with its
prototype for first-stage alignment. Additionally, to supplement unseen class
relations in these graphs, GBN also build the unseen class nodes based on
semantic relationships. In the second stage, GMN continuously integrates
neighbor and cross-graph information into the constructed graph nodes, and
aligns the node relationships between the two graphs under the class
relationship constraint. Extensive experiments on three benchmark datasets
demonstrate that VSGMN achieves superior performance in both conventional and
generalized ZSL scenarios. The implementation of our VSGMN and experimental
results are available at github: https://github.com/dbwfd/VSGMN",cs.CV,cs.CV,http://arxiv.org/abs/2411.11351v1
"Video-to-Task Learning via Motion-Guided Attention for Few-Shot Action
  Recognition","Hanyu Guo, Wanchuan Yu, Suzhou Que, Kaiwen Du, Yan Yan, Hanzi Wang",2024-11-18T07:01:59Z,"In recent years, few-shot action recognition has achieved remarkable
performance through spatio-temporal relation modeling. Although a wide range of
spatial and temporal alignment modules have been proposed, they primarily
address spatial or temporal misalignments at the video level, while the
spatio-temporal relationships across different videos at the task level remain
underexplored. Recent studies utilize class prototypes to learn task-specific
features but overlook the spatio-temporal relationships across different videos
at the task level, especially in the spatial dimension, where these
relationships provide rich information. In this paper, we propose a novel Dual
Motion-Guided Attention Learning method (called DMGAL) for few-shot action
recognition, aiming to learn the spatio-temporal relationships from the
video-specific to the task-specific level. To achieve this, we propose a
carefully designed Motion-Guided Attention (MGA) method to identify and
correlate motion-related region features from the video level to the task
level. Specifically, the Self Motion-Guided Attention module (S-MGA) achieves
spatio-temporal relation modeling at the video level by identifying and
correlating motion-related region features between different frames within a
video. The Cross Motion-Guided Attention module (C-MGA) identifies and
correlates motion-related region features between frames of different videos
within a specific task to achieve spatio-temporal relationships at the task
level. This approach enables the model to construct class prototypes that fully
incorporate spatio-temporal relationships from the video-specific level to the
task-specific level. We validate the effectiveness of our DMGAL method by
employing both fully fine-tuning and adapter-tuning paradigms. The models
developed using these paradigms are termed DMGAL-FT and DMGAL-Adapter,
respectively.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11335v1
Color-Oriented Redundancy Reduction in Dataset Distillation,"Bowen Yuan, Zijian Wang, Yadan Luo, Mahsa Baktashmotlagh, Yadan Luo, Zi Huang",2024-11-18T06:48:11Z,"Dataset Distillation (DD) is designed to generate condensed representations
of extensive image datasets, enhancing training efficiency. Despite recent
advances, there remains considerable potential for improvement, particularly in
addressing the notable redundancy within the color space of distilled images.
In this paper, we propose AutoPalette, a framework that minimizes color
redundancy at the individual image and overall dataset levels, respectively. At
the image level, we employ a palette network, a specialized neural network, to
dynamically allocate colors from a reduced color space to each pixel. The
palette network identifies essential areas in synthetic images for model
training and consequently assigns more unique colors to them. At the dataset
level, we develop a color-guided initialization strategy to minimize redundancy
among images. Representative images with the least replicated color patterns
are selected based on the information gain. A comprehensive performance study
involving various datasets and evaluation scenarios is conducted, demonstrating
the superior performance of our proposed color-aware DD compared to existing DD
methods. The code is available at
\url{https://github.com/KeViNYuAn0314/AutoPalette}.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11329v1
Dataset Distillers Are Good Label Denoisers In the Wild,"Lechao Cheng, Kaifeng Chen, Jiyang Li, Shengeng Tang, Shufei Zhang, Meng Wang",2024-11-18T06:26:41Z,"Learning from noisy data has become essential for adapting deep learning
models to real-world applications. Traditional methods often involve first
evaluating the noise and then applying strategies such as discarding noisy
samples, re-weighting, or re-labeling. However, these methods can fall into a
vicious cycle when the initial noise evaluation is inaccurate, leading to
suboptimal performance. To address this, we propose a novel approach that
leverages dataset distillation for noise removal. This method avoids the
feedback loop common in existing techniques and enhances training efficiency,
while also providing strong privacy protection through offline processing. We
rigorously evaluate three representative dataset distillation methods (DATM,
DANCE, and RCIG) under various noise conditions, including symmetric noise,
asymmetric noise, and real-world natural noise. Our empirical findings reveal
that dataset distillation effectively serves as a denoising tool in random
noise scenarios but may struggle with structured asymmetric noise patterns,
which can be absorbed into the distilled samples. Additionally, clean but
challenging samples, such as those from tail classes in imbalanced datasets,
may undergo lossy compression during distillation. Despite these challenges,
our results highlight that dataset distillation holds significant promise for
robust model training, especially in high-privacy environments where noise is
prevalent.","cs.LG, cs.CV",cs.LG,http://arxiv.org/abs/2411.11924v1
Study of the Performance of CEEMDAN in Underdetermined Speech Separation,"Rawad Melhem, Riad Hamadeh, Assef Jafar",2024-11-18T06:13:51Z,"The CEEMDAN algorithm is one of the modern methods used in the analysis of
non-stationary signals. This research presents a study of the effectiveness of
this method in audio source separation to know the limits of its work. It
concluded two conditions related to frequencies and amplitudes of mixed signals
to be separated by CEEMDAN. The performance of the algorithm in separating
noise from speech and separating speech signals from each other is studied. The
research reached a conclusion that CEEMDAN can remove some types of noise from
speech (speech improvement), and it cannot separate speech signals from each
other (cocktail party). Simulation is done using Matlab environment and Noizeus
database.","cs.SD, cs.AI, eess.AS",cs.SD,http://arxiv.org/abs/2411.11312v1
TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation,"Ranmin Wang, Limin Zhuang, Hongkun Chen, Boyan Xu, Ruichu Cai",2024-11-18T06:01:00Z,"The advancement of medical image segmentation techniques has been propelled
by the adoption of deep learning techniques, particularly UNet-based
approaches, which exploit semantic information to improve the accuracy of
segmentations. However, the order of organs in scanned images has been
disregarded by current medical image segmentation approaches based on UNet.
Furthermore, the inherent network structure of UNet does not provide direct
capabilities for integrating temporal information. To efficiently integrate
temporal information, we propose TP-UNet that utilizes temporal prompts,
encompassing organ-construction relationships, to guide the segmentation UNet
model. Specifically, our framework is featured with cross-attention and
semantic alignment based on unsupervised contrastive learning to combine
temporal prompts and image features effectively. Extensive evaluations on two
medical image segmentation datasets demonstrate the state-of-the-art
performance of TP-UNet. Our implementation will be open-sourced after
acceptance.","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11305v2
"Towards Personalized Brain-Computer Interface Application Based on
  Endogenous EEG Paradigms","Heon-Gyu Kwak, Gi-Hwan Shin, Yeon-Woo Choi, Dong-Hoon Lee, Yoo-In Jeon, Jun-Su Kang, Seong-Whan Lee",2024-11-18T05:58:41Z,"In this paper, we propose a conceptual framework for personalized
brain-computer interface (BCI) applications, which can offer an enhanced user
experience by customizing services to individual preferences and needs, based
on endogenous electroencephalography (EEG) paradigms including motor imagery
(MI), speech imagery (SI), and visual imagery. The framework includes two
essential components: user identification and intention classification, which
enable personalized services by identifying individual users and recognizing
their intended actions through EEG signals. We validate the feasibility of our
framework using a private EEG dataset collected from eight subjects, employing
the ShallowConvNet architecture to decode EEG features. The experimental
results demonstrate that user identification achieved an average classification
accuracy of 0.995, while intention classification achieved 0.47 accuracy across
all paradigms, with MI demonstrating the best performance. These findings
indicate that EEG signals can effectively support personalized BCI
applications, offering robust identification and reliable intention decoding,
especially for MI and SI.","cs.HC, cs.AI",cs.HC,http://arxiv.org/abs/2411.11302v1
Performance Evaluation of Geospatial Images based on Zarr and Tiff,"Jaheer Khan, Swarup E, Rakshit Ramesh",2024-11-18T05:34:31Z,"This evaluate the performance of geospatial image processing using two
distinct data storage formats: Zarr and TIFF. Geospatial images, converted to
numerous applications like environmental monitoring, urban planning, and
disaster management. Traditional Tagged Image File Format is mostly used
because it is simple and compatible but may lack by performance limitations
while working on large datasets. Zarr is a new format designed for the cloud
systems,that offers scalability and efficient storage with data chunking and
compression techniques. This study compares the two formats in terms of storage
efficiency, access speed, and computational performance during typical
geospatial processing tasks. Through analysis on a range of geospatial
datasets, this provides details about the practical advantages and limitations
of each format,helping users to select the appropriate format based on their
specific needs and constraints.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11291v1
"Neuron: Learning Context-Aware Evolving Representations for Zero-Shot
  Skeleton Action Recognition","Yang Chen, Jingcai Guo, Song Guo, Dacheng Tao",2024-11-18T05:16:11Z,"Zero-shot skeleton action recognition is a non-trivial task that requires
robust unseen generalization with prior knowledge from only seen classes and
shared semantics. Existing methods typically build the skeleton-semantics
interactions by uncontrollable mappings and conspicuous representations,
thereby can hardly capture the intricate and fine-grained relationship for
effective cross-modal transferability. To address these issues, we propose a
novel dyNamically Evolving dUal skeleton-semantic syneRgistic framework with
the guidance of cOntext-aware side informatioN (dubbed Neuron), to explore more
fine-grained cross-modal correspondence from micro to macro perspectives at
both spatial and temporal levels, respectively. Concretely, 1) we first
construct the spatial-temporal evolving micro-prototypes and integrate dynamic
context-aware side information to capture the intricate and synergistic
skeleton-semantic correlations step-by-step, progressively refining cross-model
alignment; and 2) we introduce the spatial compression and temporal memory
mechanisms to guide the growth of spatial-temporal micro-prototypes, enabling
them to absorb structure-related spatial representations and
regularity-dependent temporal patterns. Notably, such processes are analogous
to the learning and growth of neurons, equipping the framework with the
capacity to generalize to novel unseen action categories. Extensive experiments
on various benchmark datasets demonstrated the superiority of the proposed
method.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11288v1
"Zero-Shot Automatic Annotation and Instance Segmentation using
  LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for
  Deep Learning Model Development","Ranjan Sapkota, Achyut Paudel, Manoj Karkee",2024-11-18T05:11:29Z,"Currently, deep learning-based instance segmentation for various applications
(e.g., Agriculture) is predominantly performed using a labor-intensive process
involving extensive field data collection using sophisticated sensors, followed
by careful manual annotation of images, presenting significant logistical and
financial challenges to researchers and organizations. The process also slows
down the model development and training process. In this study, we presented a
novel method for deep learning-based instance segmentation of apples in
commercial orchards that eliminates the need for labor-intensive field data
collection and manual annotation. Utilizing a Large Language Model (LLM), we
synthetically generated orchard images and automatically annotated them using
the Segment Anything Model (SAM) integrated with a YOLO11 base model. This
method significantly reduces reliance on physical sensors and manual data
processing, presenting a major advancement in ""Agricultural AI"". The synthetic,
auto-annotated dataset was used to train the YOLO11 model for Apple instance
segmentation, which was then validated on real orchard images. The results
showed that the automatically generated annotations achieved a Dice Coefficient
of 0.9513 and an IoU of 0.9303, validating the accuracy and overlap of the mask
annotations. All YOLO11 configurations, trained solely on these synthetic
datasets with automated annotations, accurately recognized and delineated
apples, highlighting the method's efficacy. Specifically, the YOLO11m-seg
configuration achieved a mask precision of 0.902 and a mask mAP@50 of 0.833 on
test images collected from a commercial orchard. Additionally, the YOLO11l-seg
configuration outperformed other models in validation on 40 LLM-generated
images, achieving the highest mask precision and mAP@50 metrics.
  Keywords: YOLO, SAM, SAMv2, YOLO11, YOLOv11, Segment Anything, YOLO-SAM","cs.CV, cs.AI",cs.CV,http://arxiv.org/abs/2411.11285v1
FCC: Fully Connected Correlation for Few-Shot Segmentation,"Seonghyeon Moon, Haein Kong, Muhammad Haris Khan, Yuewei Lin",2024-11-18T03:32:02Z,"Few-shot segmentation (FSS) aims to segment the target object in a query
image using only a small set of support images and masks. Therefore, having
strong prior information for the target object using the support set is
essential for guiding the initial training of FSS, which leads to the success
of few-shot segmentation in challenging cases, such as when the target object
shows considerable variation in appearance, texture, or scale across the
support and query images. Previous methods have tried to obtain prior
information by creating correlation maps from pixel-level correlation on
final-layer or same-layer features. However, we found these approaches can
offer limited and partial information when advanced models like Vision
Transformers are used as the backbone. Vision Transformer encoders have a
multi-layer structure with identical shapes in their intermediate layers.
Leveraging the feature comparison from all layers in the encoder can enhance
the performance of few-shot segmentation. We introduce FCC (Fully Connected
Correlation) to integrate pixel-level correlations between support and query
features, capturing associations that reveal target-specific patterns and
correspondences in both same-layers and cross-layers. FCC captures previously
inaccessible target information, effectively addressing the limitations of
support mask. Our approach consistently demonstrates state-of-the-art
performance on PASCAL, COCO, and domain shift tests. We conducted an ablation
study and cross-layer correlation analysis to validate FCC's core methodology.
These findings reveal the effectiveness of FCC in enhancing prior information
and overall model performance.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11917v1
"Semantic or Covariate? A Study on the Intractable Case of
  Out-of-Distribution Detection","Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen",2024-11-18T03:09:39Z,"The primary goal of out-of-distribution (OOD) detection tasks is to identify
inputs with semantic shifts, i.e., if samples from novel classes are absent in
the in-distribution (ID) dataset used for training, we should reject these OOD
samples rather than misclassifying them into existing ID classes. However, we
find the current definition of ""semantic shift"" is ambiguous, which renders
certain OOD testing protocols intractable for the post-hoc OOD detection
methods based on a classifier trained on the ID dataset. In this paper, we
offer a more precise definition of the Semantic Space and the Covariate Space
for the ID distribution, allowing us to theoretically analyze which types of
OOD distributions make the detection task intractable. To avoid the flaw in the
existing OOD settings, we further define the ""Tractable OOD"" setting which
ensures the distinguishability of OOD and ID distributions for the post-hoc OOD
detection methods. Finally, we conduct several experiments to demonstrate the
necessity of our definitions and validate the correctness of our theorems.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11254v1
"A Stable-Set Bound and Maximal Numbers of Nash Equilibria in Bimatrix
  Games","Constantin Ickstadt, Thorsten Theobald, Bernhard von Stengel",2024-11-19T10:11:46Z,"Quint and Shubik (1997) conjectured that a non-degenerate n-by-n game has at
most 2^n-1 Nash equilibria in mixed strategies. The conjecture is true for n at
most 4 but false for n=6 or larger. We answer it positively for the remaining
case n=5, which had been open since 1999. The problem can be translated to a
combinatorial question about the vertices of a pair of simple n-polytopes with
2n facets. We introduce a novel obstruction based on the index of an
equilibrium, which states that equilibrium vertices belong to two equal-sized
disjoint stable sets of the graph of the polytope. This bound is verified
directly using the known classification of the 159,375 combinatorial types of
dual neighborly polytopes in dimension 5 with 10 facets. Non-neighborly
polytopes are analyzed with additional combinatorial techniques where the bound
is used for their disjoint facets.","cs.GT, 91A05, G.2",cs.GT,http://arxiv.org/abs/2411.12385v1
"Hyper-parameter Optimization for Federated Learning with Step-wise
  Adaptive Mechanism","Yasaman Saadati, M. Hadi Amini",2024-11-19T05:49:00Z,"Federated Learning (FL) is a decentralized learning approach that protects
sensitive information by utilizing local model parameters rather than sharing
clients' raw datasets. While this privacy-preserving method is widely employed
across various applications, it still requires significant development and
optimization. Automated Machine Learning (Auto-ML) has been adapted for
reducing the need for manual adjustments. Previous studies have explored the
integration of AutoML with different FL algorithms to evaluate their
effectiveness in enhancing FL settings. However, Automated FL (Auto-FL) faces
additional challenges due to the involvement of a large cohort of clients and
global training rounds between clients and the server, rendering the tuning
process time-consuming and nearly impossible on resource-constrained edge
devices (e.g., IoT devices). This paper investigates the deployment and
integration of two lightweight Hyper-Parameter Optimization (HPO) tools,
Raytune and Optuna, within the context of FL settings. A step-wise feedback
mechanism has also been designed to accelerate the hyper-parameter tuning
process and coordinate AutoML toolkits with the FL server. To this end, both
local and global feedback mechanisms are integrated to limit the search space
and expedite the HPO process. Further, a novel client selection technique is
introduced to mitigate the straggler effect in Auto-FL. The selected
hyper-parameter tuning tools are evaluated using two benchmark datasets,
FEMNIST, and CIFAR10. Further, the paper discusses the essential properties of
successful HPO tools, the integration mechanism with the FL pipeline, and the
challenges posed by the distributed and heterogeneous nature of FL
environments.","cs.LG, cs.DC, I.2.11",cs.LG,http://arxiv.org/abs/2411.12244v1
"Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time
  Series Node Classification","Mingsen Du, Meng Chen, Yongjian Li, Xiuxin Zhang, Jiahui Gao, Cun Ji, Shoushui Wei",2024-11-19T04:32:41Z,"Multivariate time series (MTS) data is generated through multiple sensors
across various domains such as engineering application, health monitoring, and
the internet of things, characterized by its temporal changes and high
dimensional characteristics. Over the past few years, many studies have
explored the long-range dependencies and similarities in MTS. However,
long-range dependencies are difficult to model due to their temporal changes
and high dimensionality makes it difficult to obtain similarities effectively
and efficiently. Thus, to address these issues, we propose contrast
similarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).
Firstly, to obtain the dynamic similarity of each sample, we initially use
temporal contrast learning module to acquire MTS representations. And then we
construct a similarity matrix between MTS representations using Fast Dynamic
Time Warping (FastDTW). Secondly, we apply the DPMamba to consider the
bidirectional nature of MTS, allowing us to better capture long-range and
short-range dependencies within the data. Finally, we utilize the
Kolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete the
information interaction in the matrix and MTS node classification task. By
comprehensively considering the long-range dependencies and dynamic similarity
features, we achieved precise MTS node classification. We conducted experiments
on multiple University of East Anglia (UEA) MTS datasets, which encompass
diverse application scenarios. Our results demonstrate the superiority of our
method through both supervised and semi-supervised experiments on the MTS
classification task.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12222v1
"Microsegmented Cloud Network Architecture Using Open-Source Tools for a
  Zero Trust Foundation","Sunil Arora, John Hastings",2024-11-19T01:58:40Z,"This paper presents a multi-cloud networking architecture built on zero trust
principles and micro-segmentation to provide secure connectivity with
authentication, authorization, and encryption in transit. The proposed design
includes the multi-cloud network to support a wide range of applications and
workload use cases, compute resources including containers, virtual machines,
and cloud-native services, including IaaS (Infrastructure as a Service (IaaS),
PaaS (Platform as a service). Furthermore, open-source tools provide
flexibility, agility, and independence from locking to one vendor technology.
The paper provides a secure architecture with micro-segmentation and follows
zero trust principles to solve multi-fold security and operational challenges.","cs.CR, cs.DC, cs.NI, cs.SY, eess.SY, K.6.5; D.4.6; C.2.1; C.2.3; C.2.4",cs.CR,http://arxiv.org/abs/2411.12162v1
Visualizing Loss Functions as Topological Landscape Profiles,"Caleb Geniesse, Jiaqing Chen, Tiankai Xie, Ge Shi, Yaoqing Yang, Dmitriy Morozov, Talita Perciano, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber",2024-11-19T00:28:14Z,"In machine learning, a loss function measures the difference between model
predictions and ground-truth (or target) values. For neural network models,
visualizing how this loss changes as model parameters are varied can provide
insights into the local structure of the so-called loss landscape (e.g.,
smoothness) as well as global properties of the underlying model (e.g.,
generalization performance). While various methods for visualizing the loss
landscape have been proposed, many approaches limit sampling to just one or two
directions, ignoring potentially relevant information in this extremely
high-dimensional space. This paper introduces a new representation based on
topological data analysis that enables the visualization of higher-dimensional
loss landscapes. After describing this new topological landscape profile
representation, we show how the shape of loss landscapes can reveal new details
about model performance and learning dynamics, highlighting several use cases,
including image segmentation (e.g., UNet) and scientific machine learning
(e.g., physics-informed neural networks). Through these examples, we provide
new insights into how loss landscapes vary across distinct hyperparameter
spaces: we find that the topology of the loss landscape is simpler for
better-performing models; and we observe greater variation in the shape of loss
landscapes near transitions from low to high model performance.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.12136v1
Fine-Grained Uncertainty Quantification via Collisions,"Jesse Friedbaum, Sudarshan Adiga, Ravi Tandon",2024-11-18T23:41:27Z,"We propose a new approach for fine-grained uncertainty quantification (UQ)
using a collision matrix. For a classification problem involving $K$ classes,
the $K\times K$ collision matrix $S$ measures the inherent (aleatoric)
difficulty in distinguishing between each pair of classes. In contrast to
existing UQ methods, the collision matrix gives a much more detailed picture of
the difficulty of classification. We discuss several possible downstream
applications of the collision matrix, establish its fundamental mathematical
properties, as well as show its relationship with existing UQ methods,
including the Bayes error rate. We also address the new problem of estimating
the collision matrix using one-hot labeled data. We propose a series of
innovative techniques to estimate $S$. First, we learn a contrastive binary
classifier which takes two inputs and determines if they belong to the same
class. We then show that this contrastive classifier (which is PAC learnable)
can be used to reliably estimate the Gramian matrix of $S$, defined as
$G=S^TS$. Finally, we show that under very mild assumptions, $G$ can be used to
uniquely recover $S$, a new result on stochastic matrices which could be of
independent interest. Experimental results are also presented to validate our
methods on several datasets.","cs.LG, cs.IT, math.IT, math.ST, stat.ML, stat.TH",cs.LG,http://arxiv.org/abs/2411.12127v1
"MMBind: Unleashing the Potential of Distributed and Heterogeneous Data
  for Multimodal Learning in IoT","Xiaomin Ouyang, Jason Wu, Tomoyoshi Kimura, Yihan Lin, Gunjan Verma, Tarek Abdelzaher, Mani Srivastava",2024-11-18T23:34:07Z,"Multimodal sensing systems are increasingly prevalent in various real-world
applications. Most existing multimodal learning approaches heavily rely on
training with a large amount of complete multimodal data. However, such a
setting is impractical in real-world IoT sensing applications where data is
typically collected by distributed nodes with heterogeneous data modalities,
and is also rarely labeled. In this paper, we propose MMBind, a new framework
for multimodal learning on distributed and heterogeneous IoT data. The key idea
of MMBind is to construct a pseudo-paired multimodal dataset for model training
by binding data from disparate sources and incomplete modalities through a
sufficiently descriptive shared modality. We demonstrate that data of different
modalities observing similar events, even captured at different times and
locations, can be effectively used for multimodal training. Moreover, we
propose an adaptive multimodal learning architecture capable of training models
with heterogeneous modality combinations, coupled with a weighted contrastive
learning approach to handle domain shifts among disparate data. Evaluations on
ten real-world multimodal datasets highlight that MMBind outperforms
state-of-the-art baselines under varying data incompleteness and domain shift,
and holds promise for advancing multimodal foundation model training in IoT
applications.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12126v1
Federated Contrastive Learning of Graph-Level Representations,"Xiang Li, Gagan Agrawal, Rajiv Ramnath, Ruoming Jin",2024-11-18T22:10:31Z,"Graph-level representations (and clustering/classification based on these
representations) are required in a variety of applications. Examples include
identifying malicious network traffic, prediction of protein properties, and
many others. Often, data has to stay in isolated local systems (i.e., cannot be
centrally shared for analysis) due to a variety of considerations like privacy
concerns, lack of trust between the parties, regulations, or simply because the
data is too large to be shared sufficiently quickly. This points to the need
for federated learning for graph-level representations, a topic that has not
been explored much, especially in an unsupervised setting.
  Addressing this problem, this paper presents a new framework we refer to as
Federated Contrastive Learning of Graph-level Representations (FCLG). As the
name suggests, our approach builds on contrastive learning. However, what is
unique is that we apply contrastive learning at two levels. The first
application is for local unsupervised learning of graph representations. The
second level is to address the challenge associated with data distribution
variation (i.e. the ``Non-IID issue"") when combining local models. Through
extensive experiments on the downstream task of graph-level clustering, we
demonstrate FCLG outperforms baselines (which apply existing federated methods
on existing graph-level clustering methods) with significant margins.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12098v1
Molecule Generation with Fragment Retrieval Augmentation,"Seul Lee, Karsten Kreis, Srimukh Prasad Veccham, Meng Liu, Danny Reidenbach, Saee Paliwal, Arash Vahdat, Weili Nie",2024-11-18T21:43:52Z,"Fragment-based drug discovery, in which molecular fragments are assembled
into new molecules with desirable biochemical properties, has achieved great
success. However, many fragment-based molecule generation methods show limited
exploration beyond the existing fragments in the database as they only
reassemble or slightly modify the given ones. To tackle this problem, we
propose a new fragment-based molecule generation framework with retrieval
augmentation, namely Fragment Retrieval-Augmented Generation (f-RAG). f-RAG is
based on a pre-trained molecular generative model that proposes additional
fragments from input fragments to complete and generate a new molecule. Given a
fragment vocabulary, f-RAG retrieves two types of fragments: (1) hard
fragments, which serve as building blocks that will be explicitly included in
the newly generated molecule, and (2) soft fragments, which serve as reference
to guide the generation of new fragments through a trainable fragment injection
module. To extrapolate beyond the existing fragments, f-RAG updates the
fragment vocabulary with generated fragments via an iterative refinement
process which is further enhanced with post-hoc genetic fragment modification.
f-RAG can achieve an improved exploration-exploitation trade-off by maintaining
a pool of fragments and expanding it with novel and high-quality fragments
through a strong generative prior.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12078v1
"Theoretical Corrections and the Leveraging of Reinforcement Learning to
  Enhance Triangle Attack","Nicole Meng, Caleb Manicke, David Chen, Yingjie Lao, Caiwen Ding, Pengyu Hong, Kaleel Mahmood",2024-11-18T21:31:24Z,"Adversarial examples represent a serious issue for the application of machine
learning models in many sensitive domains. For generating adversarial examples,
decision based black-box attacks are one of the most practical techniques as
they only require query access to the model. One of the most recently proposed
state-of-the-art decision based black-box attacks is Triangle Attack (TA). In
this paper, we offer a high-level description of TA and explain potential
theoretical limitations. We then propose a new decision based black-box attack,
Triangle Attack with Reinforcement Learning (TARL). Our new attack addresses
the limits of TA by leveraging reinforcement learning. This creates an attack
that can achieve similar, if not better, attack accuracy than TA with half as
many queries on state-of-the-art classifiers and defenses across ImageNet and
CIFAR-10.","cs.LG, cs.CR",cs.LG,http://arxiv.org/abs/2411.12071v1
Higher Order Graph Attention Probabilistic Walk Networks,"Thomas Bailie, Yun Sing Koh, Karthik Mukkavilli",2024-11-18T20:46:02Z,"Graphs inherently capture dependencies between nodes or variables through
their topological structure, with paths between any two nodes indicating a
sequential dependency on the nodes traversed. Message Passing Neural Networks
(MPNNs) leverage these latent relationships embedded in graph structures, and
have become widely adopted across diverse applications. However, many existing
methods predominantly rely on local information within the $1$-hop
neighborhood. This approach has notable limitations; for example, $1$-hop
aggregation schemes inherently lose long-distance information, and are limited
in expressive power as defined by the $k$-Weisfeiler-Leman ($k$-WL) isomorphism
test. To address these issues, we propose the Higher Order Graphical Attention
(HoGA) module, which assigns weights to variable-length paths sampled based on
feature-vector diversity, effectively reconstructing the $k$-hop neighborhood.
HoGA represents higher-order relationships as a robust form of self-attention,
applicable to any single-hop attention mechanism. In empirical studies,
applying HoGA to existing attention-based models consistently leads to
significant accuracy improvements on benchmark node classification datasets.
Furthermore, we observe that the performance degradation typically associated
with additional message-passing steps may be mitigated.",cs.LG,cs.LG,http://arxiv.org/abs/2411.12052v1
Fast Convergence of Softmax Policy Mirror Ascent,"Reza Asad, Reza Babanezhad, Issam Laradji, Nicolas Le Roux, Sharan Vaswani",2024-11-18T20:27:13Z,"Natural policy gradient (NPG) is a common policy optimization algorithm and
can be viewed as mirror ascent in the space of probabilities. Recently, Vaswani
et al. [2021] introduced a policy gradient method that corresponds to mirror
ascent in the dual space of logits. We refine this algorithm, removing its need
for a normalization across actions and analyze the resulting method (referred
to as SPMA). For tabular MDPs, we prove that SPMA with a constant step-size
matches the linear convergence of NPG and achieves a faster convergence than
constant step-size (accelerated) softmax policy gradient. To handle large
state-action spaces, we extend SPMA to use a log-linear policy
parameterization. Unlike that for NPG, generalizing SPMA to the linear function
approximation (FA) setting does not require compatible function approximation.
Unlike MDPO, a practical generalization of NPG, SPMA with linear FA only
requires solving convex softmax classification problems. We prove that SPMA
achieves linear convergence to the neighbourhood of the optimal value function.
We extend SPMA to handle non-linear FA and evaluate its empirical performance
on the MuJoCo and Atari benchmarks. Our results demonstrate that SPMA
consistently achieves similar or better performance compared to MDPO, PPO and
TRPO.","cs.LG, cs.AI, cs.RO",cs.LG,http://arxiv.org/abs/2411.12042v1
"Transmission Line Outage Probability Prediction Under Extreme Events
  Using Peter-Clark Bayesian Structural Learning","Xiaolin Chen, Qiuhua Huang, Yuqi Zhou",2024-11-18T19:10:49Z,"Recent years have seen a notable increase in the frequency and intensity of
extreme weather events. With a rising number of power outages caused by these
events, accurate prediction of power line outages is essential for safe and
reliable operation of power grids. The Bayesian network is a probabilistic
model that is very effective for predicting line outages under weather-related
uncertainties. However, most existing studies in this area offer general risk
assessments, but fall short of providing specific outage probabilities. In this
work, we introduce a novel approach for predicting transmission line outage
probabilities using a Bayesian network combined with Peter-Clark (PC)
structural learning. Our approach not only enables precise outage probability
calculations, but also demonstrates better scalability and robust performance,
even with limited data. Case studies using data from BPA and NOAA show the
effectiveness of this approach, while comparisons with several existing methods
further highlight its advantages.","cs.LG, cs.SY, eess.SY",cs.LG,http://arxiv.org/abs/2411.11980v1
Competing Bandits in Decentralized Large Contextual Matching Markets,"Satush Parikh, Soumya Basu, Avishek Ghosh, Abishek Sankararaman",2024-11-18T18:08:05Z,"Sequential learning in a multi-agent resource constrained matching market has
received significant interest in the past few years. We study decentralized
learning in two-sided matching markets where the demand side (aka players or
agents) competes for a `large' supply side (aka arms) with potentially
time-varying preferences, to obtain a stable match. Despite a long line of work
in the recent past, existing learning algorithms such as Explore-Then-Commit or
Upper-Confidence-Bound remain inefficient for this problem. In particular, the
per-agent regret achieved by these algorithms scales linearly with the number
of arms, $K$. Motivated by the linear contextual bandit framework, we assume
that for each agent an arm-mean can be represented by a linear function of a
known feature vector and an unknown (agent-specific) parameter.
  Moreover, our setup captures the essence of a dynamic (non-stationary)
matching market where the preferences over arms change over time. Our proposed
algorithms achieve instance-dependent logarithmic regret, scaling independently
of the number of arms, $K$.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.11794v1
A Potential Game Perspective in Federated Learning,"Kang Liu, Ziqi Wang, Enrique Zuazua",2024-11-18T18:06:44Z,"Federated learning (FL) is an emerging paradigm for training machine learning
models across distributed clients. Traditionally, in FL settings, a central
server assigns training efforts (or strategies) to clients. However, from a
market-oriented perspective, clients may independently choose their training
efforts based on rational self-interest. To explore this, we propose a
potential game framework where each client's payoff is determined by their
individual efforts and the rewards provided by the server. The rewards are
influenced by the collective efforts of all clients and can be modulated
through a reward factor. Our study begins by establishing the existence of Nash
equilibria (NEs), followed by an investigation of uniqueness in homogeneous
settings. We demonstrate a significant improvement in clients' training efforts
at a critical reward factor, identifying it as the optimal choice for the
server. Furthermore, we prove the convergence of the best-response algorithm to
compute NEs for our FL game. Finally, we apply the training efforts derived
from specific NEs to a real-world FL scenario, validating the effectiveness of
the identified optimal reward factor.","cs.LG, 68T01, 90C90, 91A10, 93A16",cs.LG,http://arxiv.org/abs/2411.11793v1
"Assistive Control of Knee Exoskeletons for Human Walking on Granular
  Terrains","Chunchu Zhu, Xunjie Chen, Jingang Yi",2024-11-18T17:54:35Z,"Human walkers traverse diverse environments and demonstrate different gait
locomotion and energy cost on granular terrains compared to solid ground. We
present a stiffness-based model predictive control approach of knee exoskeleton
assistance on sand. The gait and locomotion comparison is first discussed for
human walkers on sand and solid ground. A machine learning-based estimation
scheme is then presented to predict the ground reaction forces (GRFs) for human
walkers on different terrains in real time. Built on the estimated GRFs and
human joint torques, a knee exoskeleton controller is designed to provide
assistive torque through a model predictive stiffness control scheme. We
conduct indoor and outdoor experiments to validate the modeling and control
design and their performance. The experiments demonstrate the major muscle
activation and metabolic reductions by respectively 15% and 3.7% under the
assistive exoskeleton control of human walking on sand.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11777v1
Drowning in Documents: Consequences of Scaling Reranker Inference,"Mathew Jacob, Erik Lindgren, Matei Zaharia, Michael Carbin, Omar Khattab, Andrew Drozdov",2024-11-18T17:46:32Z,"Rerankers, typically cross-encoders, are often used to re-score the documents
retrieved by cheaper initial IR systems. This is because, though expensive,
rerankers are assumed to be more effective. We challenge this assumption by
measuring reranker performance for full retrieval, not just re-scoring
first-stage retrieval. Our experiments reveal a surprising trend: the best
existing rerankers provide diminishing returns when scoring progressively more
documents and actually degrade quality beyond a certain limit. In fact, in this
setting, rerankers can frequently assign high scores to documents with no
lexical or semantic overlap with the query. We hope that our findings will spur
future research to improve reranking.","cs.IR, cs.CL, cs.LG",cs.IR,http://arxiv.org/abs/2411.11767v1
BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration,"Yuzong Chen, Ahmed F. AbouElhamayed, Xilai Dai, Yang Wang, Marta Andronic, George A. Constantinides, Mohamed S. Abdelfattah",2024-11-18T17:16:58Z,"Large language models (LLMs) have demonstrated remarkable performance across
various machine learning tasks. Yet the substantial memory footprint of LLMs
significantly hinders their deployment. In this paper, we improve the
accessibility of LLMs through BitMoD, an algorithm-hardware co-design solution
that enables efficient LLM acceleration at low weight precision. On the
algorithm side, BitMoD introduces fine-grained data type adaptation that uses a
different numerical data type to quantize a group of (e.g., 128) weights.
Through the careful design of these new data types, BitMoD is able to quantize
LLM weights to very low precision (e.g., 4 bits and 3 bits) while maintaining
high accuracy. On the hardware side, BitMoD employs a bit-serial processing
element to easily support multiple numerical precisions and data types; our
hardware design includes two key innovations: First, it employs a unified
representation to process different weight data types, thus reducing the
hardware cost. Second, it adopts a bit-serial dequantization unit to rescale
the per-group partial sum with minimal hardware overhead. Our evaluation on six
representative LLMs demonstrates that BitMoD significantly outperforms
state-of-the-art LLM quantization and acceleration methods. For discriminative
tasks, BitMoD can quantize LLM weights to 4-bit with $<\!0.5\%$ accuracy loss
on average. For generative tasks, BitMoD is able to quantize LLM weights to
3-bit while achieving better perplexity than prior LLM quantization scheme.
Combining the superior model performance with an efficient accelerator design,
BitMoD achieves an average of $1.69\times$ and $1.48\times$ speedups compared
to prior LLM accelerators ANT and OliVe, respectively.","cs.LG, cs.AR",cs.LG,http://arxiv.org/abs/2411.11745v1
Introducing Milabench: Benchmarking Accelerators for AI,"Pierre Delaunay, Xavier Bouthillier, Olivier Breuleux, Satya Ortiz-Gagné, Olexa Bilaniuk, Fabrice Normandin, Arnaud Bergeron, Bruno Carrez, Guillaume Alain, Soline Blanc, Frédéric Osterrath, Joseph Viviano, Roger Creus-Castanyer Darshan Patil, Rabiul Awal, Le Zhang",2024-11-18T17:07:08Z,"AI workloads, particularly those driven by deep learning, are introducing
novel usage patterns to high-performance computing (HPC) systems that are not
comprehensively captured by standard HPC benchmarks. As one of the largest
academic research centers dedicated to deep learning, Mila identified the need
to develop a custom benchmarking suite to address the diverse requirements of
its community, which consists of over 1,000 researchers. This report introduces
Milabench, the resulting benchmarking suite. Its design was informed by an
extensive literature review encompassing 867 papers, as well as surveys
conducted with Mila researchers. This rigorous process led to the selection of
26 primary benchmarks tailored for procurement evaluations, alongside 16
optional benchmarks for in-depth analysis. We detail the design methodology,
the structure of the benchmarking suite, and provide performance evaluations
using GPUs from NVIDIA, AMD, and Intel. The Milabench suite is open source and
can be accessed at github.com/mila-iqia/milabench.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11940v1
"FLMarket: Enabling Privacy-preserved Pre-training Data Pricing for
  Federated Learning","Zhenyu Wen, Wanglei Feng, Di Wu, Haozhen Hu, Chang Xu, Bin Qian, Zhen Hong, Cong Wang, Shouling Ji",2024-11-18T16:37:41Z,"Federated Learning (FL), as a mainstream privacy-preserving machine learning
paradigm, offers promising solutions for privacy-critical domains such as
healthcare and finance. Although extensive efforts have been dedicated from
both academia and industry to improve the vanilla FL, little work focuses on
the data pricing mechanism. In contrast to the straightforward in/post-training
pricing techniques, we study a more difficult problem of pre-training pricing
without direct information from the learning process. We propose FLMarket that
integrates a two-stage, auction-based pricing mechanism with a security
protocol to address the utility-privacy conflict. Through comprehensive
experiments, we show that the client selection according to FLMarket can
achieve more than 10% higher accuracy in subsequent FL training compared to
state-of-the-art methods. In addition, it outperforms the in-training baseline
with more than 2% accuracy increase and 3x run-time speedup.","cs.LG, cs.DC",cs.LG,http://arxiv.org/abs/2411.11713v1
Robust Reinforcement Learning under Diffusion Models for Data with Jumps,"Chenyang Jiang, Donggyu Kim, Alejandra Quintos, Yazhen Wang",2024-11-18T16:17:34Z,"Reinforcement Learning (RL) has proven effective in solving complex
decision-making tasks across various domains, but challenges remain in
continuous-time settings, particularly when state dynamics are governed by
stochastic differential equations (SDEs) with jump components. In this paper,
we address this challenge by introducing the Mean-Square Bipower Variation
Error (MSBVE) algorithm, which enhances robustness and convergence in scenarios
involving significant stochastic noise and jumps. We first revisit the
Mean-Square TD Error (MSTDE) algorithm, commonly used in continuous-time RL,
and highlight its limitations in handling jumps in state dynamics. The proposed
MSBVE algorithm minimizes the mean-square quadratic variation error, offering
improved performance over MSTDE in environments characterized by SDEs with
jumps. Simulations and formal proofs demonstrate that the MSBVE algorithm
reliably estimates the value function in complex settings, surpassing MSTDE's
performance when faced with jump processes. These findings underscore the
importance of alternative error metrics to improve the resilience and
effectiveness of RL algorithms in continuous-time frameworks.","cs.LG, stat.ML",cs.LG,http://arxiv.org/abs/2411.11697v1
"Value Imprint: A Technique for Auditing the Human Values Embedded in
  RLHF Datasets","Ike Obi, Rohan Pant, Srishti Shekhar Agrawal, Maham Ghazanfar, Aaron Basiletti",2024-11-18T16:12:24Z,"LLMs are increasingly fine-tuned using RLHF datasets to align them with human
preferences and values. However, very limited research has investigated which
specific human values are operationalized through these datasets. In this
paper, we introduce Value Imprint, a framework for auditing and classifying the
human values embedded within RLHF datasets. To investigate the viability of
this framework, we conducted three case study experiments by auditing the
Anthropic/hh-rlhf, OpenAI WebGPT Comparisons, and Alpaca GPT-4-LLM datasets to
examine the human values embedded within them. Our analysis involved a
two-phase process. During the first phase, we developed a taxonomy of human
values through an integrated review of prior works from philosophy, axiology,
and ethics. Then, we applied this taxonomy to annotate 6,501 RLHF preferences.
During the second phase, we employed the labels generated from the annotation
as ground truth data for training a transformer-based machine learning model to
audit and classify the three RLHF datasets. Through this approach, we
discovered that information-utility values, including Wisdom/Knowledge and
Information Seeking, were the most dominant human values within all three RLHF
datasets. In contrast, prosocial and democratic values, including Well-being,
Justice, and Human/Animal Rights, were the least represented human values.
These findings have significant implications for developing language models
that align with societal values and norms. We contribute our datasets to
support further research in this area.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11937v1
The weight hierarchy of decreasing norm-trace codes,"Eduardo Camps-Moreno, Hiram H. López, Gretchen L. Matthews, Rodrigo San-José",2024-11-20T14:54:31Z,"The Generalized Hamming weights and their relative version, which generalize
the minimum distance of a linear code, are relevant to numerous applications,
including coding on the wire-tap channel of type II, $t$-resilient functions,
bounding the cardinality of the output in list decoding algorithms, ramp secret
sharing schemes, and quantum error correction. The generalized Hamming weights
have been determined for some families of codes, including Cartesian codes and
Hermitian one-point codes. In this paper, we determine the generalized Hamming
weights of decreasing norm-trace codes, which are linear codes defined by
evaluating monomials that are closed under divisibility on the rational points
of the extended norm-trace curve given by $x^{u} = y^{q^{s - 1}} + y^{q^{s -
2}} + \cdots + y$ over the finite field of cardinality $q^s$, where $u$ is a
positive divisor of $\frac{q^s - 1}{q - 1}$. As a particular case, we obtain
the weight hierarchy of one-point norm-trace codes and recover the result of
Barbero and Munuera (2001) giving the weight hierarchy of one-point Hermitian
codes. We also study the relative generalized Hamming weights for these codes
and use them to construct impure quantum codes with excellent parameters.","cs.IT, math.AC, math.AG, math.IT, 94B05, 11T71, 14G50",cs.IT,http://arxiv.org/abs/2411.13375v1
Reconstructing Graph Signals from Noisy Dynamical Samples,"Akram Aldroubi, Victor Bailey, Ilya Krishtal, Brendan Miller, Armenak Petrosyan",2024-11-19T17:22:05Z,"We investigate the dynamical sampling space-time trade-off problem within a
graph setting. Specifically, we derive necessary and sufficient conditions for
space-time sampling that enable the reconstruction of an initial band-limited
signal on a graph. Additionally, we develop and test numerical algorithms for
approximating the optimal placement of sensors on the graph to minimize the
mean squared error when recovering signals from time-space measurements
corrupted by i.i.d.~additive noise. Our numerical experiments demonstrate that
our approach outperforms previously proposed algorithms for related problems.","cs.IT, math.IT",cs.IT,http://arxiv.org/abs/2411.12670v1
Brief Announcement: Parallel Construction of Bumped Ribbon Retrieval,"Matthias Becht, Hans-Peter Lehmann, Peter Sanders",2024-11-19T09:25:57Z,"A retrieval data structure stores a static function f : S -> {0,1}^r . For
all x in S, it returns the r-bit value f(x), while for other inputs it may
return an arbitrary result. The structure cannot answer membership queries, so
it does not have to encode S. The information theoretic space lower bound for
arbitrary inputs is r|S| bits. Retrieval data structures have widespread
applications. They can be used as an approximate membership filter for S by
storing fingerprints of the keys in S, where they are faster and more space
efficient than Bloom filters. They can also be used as a basic building block
of succinct data structures like perfect hash functions.
  Bumped Ribbon Retrieval (BuRR) [Dillinger et al., SEA'22] is a recently
developed retrieval data structure that is fast to construct with a space
overhead of less than 1%. The idea is to solve a nearly diagonal system of
linear equations to determine a matrix that, multiplied with the hash of each
key, gives the desired output values. During solving, BuRR might bump lines of
the equation system to another layer of the same data structure. While the
paper describes a simple parallel construction based on bumping the keys on
thread boundaries, it does not give an implementation. In this brief
announcement, we now fill this gap.
  Our parallel implementation is transparent to the queries. It achieves a
speedup of 14 on 32 cores for 8-bit filters. The additional space overhead is
105 bytes per thread, or 105 slots. This matches 0.0007% of the total space
consumption when constructing with 1 billion input keys. A large portion of the
construction time is spent on parallel sorting.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12365v1
An Affine Equivalence Algorithm for S-boxes based on Matrix Invariants,"Xincheng Hu, Xiao Zeng, Zhaoqiang Liu, Guowu Yang",2024-11-19T09:19:36Z,"We investigate the affine equivalence (AE) problem of S-boxes. Given two
S-boxes denoted as $S_1$ and $S_2$, we aim to seek two invertible AE
transformations $A,B$ such that $S_1\circ A = B\circ S_2$ holds. Due to
important applications in the analysis and design of block ciphers, the
investigation of AE algorithms has performed growing significance.
  In this paper, we propose zeroization on S-box firstly, and the AE problem
can be transformed into $2^n$ linear equivalence problems by this zeroization
operation. Secondly, we propose standard orthogonal spatial matrix (SOSM), and
the rank of the SOSM is invariant under AE transformations. Finally, based on
the zeroization operation and the SOSM method, we propose a depth first search
(DFS) method for determining AE of S-boxes, named the AE\_SOSM\_DFS algorithm.
Using this matrix invariant, we optimize the temporal complexity of the
algorithm to approximately $\frac{1}{2^n}$ of the complexity without SOSM.
Specifically, the complexity of our algorithm is $O(2^{3n})$. In addition, we
also conducted experiments with non-invertible S-boxes, and the performance is
similar to that of invertible S-boxes. Moreover, our proposed algorithm can
effectively handle S-boxes with low algebraic degree or certain popular S-boxes
such as namely AES and ARIA\_s2, which are difficult to be handled by the
algorithm proposed by Dinur (2018). Using our algorithm, it only takes 5.5
seconds to find out that the seven popular S-boxes namely AES, ARIA\_s2,
Camellia, Chiasmus, DBlock, SEED\_S0, and SMS4 are affine equivalent and the AE
transformations of these S-boxes are provided.","cs.CR, cs.DS",cs.CR,http://arxiv.org/abs/2411.12360v1
HW/SW Implementation of MiRitH on Embedded Platforms,"Maximilian Schöffel, Hiandra Tomasi, Norbert Wehn",2024-11-19T08:30:08Z,"Multi-Party Computation in the Head (MPCitH) algorithms are appealing
candidates in the additional US NIST standardization rounds for Post-Quantum
Cryptography (PQC) with respect to key sizes and mathematical hardness
assumptions. However, their complexity presents a significant challenge for
platforms with limited computational capabilities. To address this issue, we
present, to the best of our knowledge, the first design space exploration of
MiRitH, a promising MPCitH algorithm, for embedded devices. We develop a
library of mixed HW/SW blocks on the Xilinx ZYNQ 7000, and, based on this
library, we explore optimal solutions under runtime or FPGA resource
constraints for a given public key infrastructure. Our results show that MiRitH
is a viable algorithm for embedded devices in terms of runtime and FPGA
resource requirements.",cs.CR,cs.CR,http://arxiv.org/abs/2411.12328v1
"Efficient Training in Multi-Agent Reinforcement Learning: A
  Communication-Free Framework for the Box-Pushing Problem","David Ge, Hao Ji",2024-11-19T05:51:10Z,"Self-organizing systems consist of autonomous agents that can perform complex
tasks and adapt to dynamic environments without a central controller. Prior
research often relies on reinforcement learning to enable agents to gain the
skills needed for task completion, such as in the box-pushing environment.
However, when agents push from opposing directions during exploration, they
tend to exert equal and opposite forces on the box, resulting in minimal
displacement and inefficient training. This paper proposes a model called
Shared Pool of Information (SPI), which enables information to be accessible to
all agents and facilitates coordination, reducing force conflicts among agents
and enhancing exploration efficiency. Through computer simulations, we
demonstrate that SPI not only expedites the training process but also requires
fewer steps per episode, significantly improving the agents' collaborative
effectiveness.",cs.AI,cs.AI,http://arxiv.org/abs/2411.12246v1
"SymphonyQG: Towards Symphonious Integration of Quantization and Graph
  for Approximate Nearest Neighbor Search","Yutong Gou, Jianyang Gao, Yuexuan Xu, Cheng Long",2024-11-19T04:51:08Z,"Approximate nearest neighbor (ANN) search in high-dimensional Euclidean space
has a broad range of applications. Among existing ANN algorithms, graph-based
methods have shown superior performance in terms of the time-accuracy
trade-off. However, they face performance bottlenecks due to the random memory
accesses caused by the searching process on the graph indices and the costs of
computing exact distances to guide the searching process. To relieve the
bottlenecks, a recent method named NGT-QG makes an attempt by integrating
quantization and graph. It (1) replicates and stores the quantization codes of
a vertex's neighbors compactly so that they can be accessed sequentially, and
(2) uses a SIMD-based implementation named FastScan to efficiently estimate
distances based on the quantization codes in batch for guiding the searching
process. While NGT-QG achieves promising improvements over the vanilla
graph-based methods, it has not fully unleashed the potential of integrating
quantization and graph. For instance, it entails a re-ranking step to compute
exact distances at the end, which introduces extra random memory accesses; its
graph structure is not jointly designed considering the in-batch nature of
FastScan, which causes wastes of computation in searching. In this work,
following NGT-QG, we present a new method named SymphonyQG, which achieves more
symphonious integration of quantization and graph (e.g., it avoids the explicit
re-ranking step and refines the graph structure to be more aligned with
FastScan). Based on extensive experiments on real-world datasets, SymphonyQG
establishes the new state-of-the-art in terms of the time-accuracy trade-off.","cs.DB, cs.IR",cs.DB,http://arxiv.org/abs/2411.12229v1
"Adaptive Cache Management for Complex Storage Systems Using
  CNN-LSTM-Based Spatiotemporal Prediction","Xiaoye Wang, Xuan Li, Linji Wang, Tingyi Ruan, Pochun Li",2024-11-19T01:55:26Z,"This paper proposes an intelligent cache management strategy based on
CNN-LSTM to improve the performance and cache hit rate of storage systems.
Through comparative experiments with traditional algorithms (such as LRU and
LFU) and other deep learning models (such as RNN, GRU-RNN and LSTM), the
results show that the CNN-LSTM model has significant advantages in cache demand
prediction. The MSE and MAE values of this model are significantly reduced,
proving its effectiveness under complex data access patterns. This study not
only verifies the potential of deep learning technology in storage system
optimization, but also provides direction and reference for further optimizing
and improving cache management strategies. This intelligent cache management
strategy performs well in complex storage environments. By combining the
spatial feature extraction capabilities of convolutional neural networks and
the time series modeling capabilities of long short-term memory networks, the
CNN-LSTM model can more accurately predict cache needs, thereby Dynamically
optimize cache allocation to improve system response speed and resource
utilization. This research provides theoretical support and practical reference
for cache optimization under large-scale data access modes, and is of great
significance to improving the performance of future storage systems.",cs.DC,cs.DC,http://arxiv.org/abs/2411.12161v1
Space-Efficient Online Computation of String Net Occurrences,"Takuya Mieno, Shunsuke Inenaga",2024-11-19T01:53:37Z,"A substring $u$ of a string $T$ is said to be a repeat if $u$ occurs at least
twice in $T$. An occurrence $[i..j]$ of a repeat $u$ in $T$ is said to be a net
occurrence if each of the substrings $aub = T[i-1..j+1]$, $au = T[i-1..j+1]$,
and $ub = T[i..j+1]$ occurs exactly once in $T$. The occurrence $[i-1..j+1]$ of
$aub$ is said to be an extended net occurrence of $u$. Let $T$ be an input
string of length $n$ over an alphabet of size $\sigma$, and let
$\mathsf{ENO}(T)$ denote the set of extended net occurrences of repeats in $T$.
Guo et al. [SPIRE 2024] presented an online algorithm which can report
$\mathsf{ENO}(T[1..i])$ in $T[1..i]$ in $O(n\sigma^2)$ time, for each prefix
$T[1..i]$ of $T$. Very recently, Inenaga [arXiv 2024] gave a faster online
algorithm that can report $\mathsf{ENO}(T[1..i])$ in optimal
$O(\#\mathsf{ENO}(T[1..i]))$ time for each prefix $T[1..i]$ of $T$, where $\#S$
denotes the cardinality of a set $S$. Both of the aforementioned data
structures can be maintained in $O(n \log \sigma)$ time and occupy $O(n)$
space, where the $O(n)$-space requirement comes from the suffix tree data
structure. In this paper, we propose the two following space-efficient
alternatives: (1) A sliding-window algorithm of $O(d)$ working space that can
report $\mathsf{ENO}(T[i-d+1..i])$ in optimal $O(\#\mathsf{ENO}(T[i-d+1..i]))$
time for each sliding window $T[i-d+1..i]$ of size $d$ in $T$. (2) A
CDAWG-based online algorithm of $O(e)$ working space that can report
$\mathsf{ENO}(T[1..i])$ in optimal $O(\#\mathsf{ENO}(T[1..i]))$ time for each
prefix $T[1..i]$ of $T$, where $e < 2n$ is the number of edges in the CDAWG for
$T$. All of our proposed data structures can be maintained in $O(n \log
\sigma)$ time for the input online string $T$. We also discuss that the
extended net occurrences of repeats in $T$ can be fully characterized in terms
of the minimal unique substrings (MUSs) in $T$.",cs.DS,cs.DS,http://arxiv.org/abs/2411.12160v1
Differentiable GPU-Parallelized Task and Motion Planning,"William Shen, Caelan Garrett, Ankit Goyal, Tucker Hermans, Fabio Ramos",2024-11-18T18:51:57Z,"We present a differentiable optimization-based framework for Task and Motion
Planning (TAMP) that is massively parallelizable on GPUs, enabling thousands of
sampled seeds to be optimized simultaneously. Existing sampling-based
approaches inherently disconnect the parameters by generating samples for each
independently and combining them through composition and rejection, while
optimization-based methods struggle with highly non-convex constraints and
local optima. Our method treats TAMP constraint satisfaction as optimizing a
batch of particles, each representing an assignment to a plan skeleton's
continuous parameters. We represent the plan skeleton's constraints using
differentiable cost functions, enabling us to compute the gradient of each
particle and update it toward satisfying solutions. Our use of GPU parallelism
better covers the parameter space through scale, increasing the likelihood of
finding the global optima by exploring multiple basins through global sampling.
We demonstrate that our algorithm can effectively solve a highly constrained
Tetris packing problem using a Franka arm in simulation and deploy our planner
on a real robot arm. Website: https://williamshen-nz.github.io/gpu-tamp",cs.RO,cs.RO,http://arxiv.org/abs/2411.11833v1
"cHyRRT and cHySST: Two Motion Planning Tools for Hybrid Dynamical
  Systems","Beverly Xu, Nan Wang, Ricardo Sanfelice",2024-11-18T18:27:37Z,"This paper describes two C++/Open Motion Planning Library implementations of
the recently developed motion planning algorithms HyRRT arXiv:2210.15082v1
[cs.RO] and HySST arXiv:2305.18649v1 [cs.RO]. Specifically, cHyRRT, an
implementation of the HyRRT algorithm, is capable of generating a solution to a
motion planning problem for hybrid systems with probabilistically completeness,
while cHySST, an implementation of the asymptotically near-optimal HySST
algorithm, is capable of computing a trajectory to solve the optimal motion
planning problem for hybrid systems. cHyRRT is suitable for motion planning
problems where an optimal solution is not required, whereas cHySST is suitable
for such problems that prefer optimal solutions, within all feasible solutions.
The structure, components, and usage of the two tools are described. Examples
are included to illustrate the main capabilities of the toolbox.","cs.RO, I.2.9",cs.RO,http://arxiv.org/abs/2411.11812v1
Towards Scalable and Practical Batch-Dynamic Connectivity,"Quinten De Man, Laxman Dhulipala, Adam Karczmarz, Jakub Łącki, Julian Shun, Zhongqi Wang",2024-11-18T17:56:44Z,"We study the problem of dynamically maintaining the connected components of
an undirected graph subject to edge insertions and deletions. We give the first
parallel algorithm for the problem which is work-efficient, supports batches of
updates, runs in polylogarithmic depth, and uses only linear total space. The
existing algorithms for the problem either use super-linear space, do not come
with strong theoretical bounds, or are not parallel. On the empirical side, we
provide the first implementation of the cluster forest algorithm, the first
linear-space and poly-logarithmic update time algorithm for dynamic
connectivity. Experimentally, we find that our algorithm uses up to 19.7x less
space and is up to 6.2x faster than the level-set algorithm of HDT, arguably
the most widely-implemented dynamic connectivity algorithm with strong
theoretical guarantees.","cs.DS, cs.DB, cs.DC",cs.DS,http://arxiv.org/abs/2411.11781v1
AdaptLIL: A Gaze-Adaptive Visualization for Ontology Mapping,"Nicholas Chow, Bo Fu",2024-11-18T17:47:54Z,"This paper showcases AdaptLIL, a real-time adaptive link-indented list
ontology mapping visualization that uses eye gaze as the primary input source.
Through a multimodal combination of real-time systems, deep learning, and web
development applications, this system uniquely curtails graphical overlays
(adaptations) to pairwise mappings of link-indented list ontology
visualizations for individual users based solely on their eye gaze.","cs.HC, cs.AI, H.5.2; I.2.4",cs.HC,http://arxiv.org/abs/2411.11768v1
"A Bicriterion Concentration Inequality and Prophet Inequalities for
  $k$-Fold Matroid Unions","Noga Alon, Nick Gravin, Tristan Pollner, Aviad Rubinstein, Hongao Wang, S. Matthew Weinberg, Qianfan Zhang",2024-11-18T17:11:06Z,"We investigate prophet inequalities with competitive ratios approaching $1$,
seeking to generalize $k$-uniform matroids. We first show that large girth does
not suffice: for all $k$, there exists a matroid of girth $\geq k$ and a
prophet inequality instance on that matroid whose optimal competitive ratio is
$\frac{1}{2}$. Next, we show $k$-fold matroid unions do suffice: we provide a
prophet inequality with competitive ratio $1-O(\sqrt{\frac{\log k}{k}})$ for
any $k$-fold matroid union. Our prophet inequality follows from an online
contention resolution scheme.
  The key technical ingredient in our online contention resolution scheme is a
novel bicriterion concentration inequality for arbitrary monotone $1$-Lipschitz
functions over independent items which may be of independent interest. Applied
to our particular setting, our bicriterion concentration inequality yields
""Chernoff-strength"" concentration for a $1$-Lipschitz function that is not
(approximately) self-bounding.","cs.DS, math.PR",cs.DS,http://arxiv.org/abs/2411.11741v2
"Moral Persuasion in Large Language Models: Evaluating Susceptibility and
  Ethical Alignment","Allison Huang, Yulu Niki Pi, Carlos Mougan",2024-11-18T16:59:59Z,"We explore how large language models (LLMs) can be influenced by prompting
them to alter their initial decisions and align them with established ethical
frameworks. Our study is based on two experiments designed to assess the
susceptibility of LLMs to moral persuasion. In the first experiment, we examine
the susceptibility to moral ambiguity by evaluating a Base Agent LLM on morally
ambiguous scenarios and observing how a Persuader Agent attempts to modify the
Base Agent's initial decisions. The second experiment evaluates the
susceptibility of LLMs to align with predefined ethical frameworks by prompting
them to adopt specific value alignments rooted in established philosophical
theories. The results demonstrate that LLMs can indeed be persuaded in morally
charged scenarios, with the success of persuasion depending on factors such as
the model used, the complexity of the scenario, and the conversation length.
Notably, LLMs of distinct sizes but from the same company produced markedly
different outcomes, highlighting the variability in their susceptibility to
ethical persuasion.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11731v1
Distributed Maximum Flow in Planar Graphs,"Yaseen Abd-Elhaleem, Michal Dory, Merav Parter, Oren Weimann",2024-11-18T16:46:30Z,"The dual of a planar graph $G$ is a planar graph $G^*$ that has a vertex for
each face of $G$ and an edge for each pair of adjacent faces of $G$. The
profound relationship between a planar graph and its dual has been the
algorithmic basis for solving numerous (centralized) classical problems on
planar graphs. In the distributed setting however, the only use of planar
duality is for finding a recursive decomposition of $G$ [DISC 2017, STOC 2019].
  We extend the distributed algorithmic toolkit to work on the dual graph
$G^*$. These tools can then facilitate various algorithms on $G$ by solving a
suitable dual problem on $G^*$.
  Given a directed planar graph $G$ with positive and negative edge-lengths and
hop-diameter $D$, our key result is an $\tilde{O}(D^2)$-round algorithm for
Single Source Shortest Paths on $G^*$, which then implies an
$\tilde{O}(D^2)$-round algorithm for Maximum $st$-Flow on $G$. Prior to our
work, no $\tilde{O}(\text{poly}(D))$-round algorithm was known for Maximum
$st$-Flow. We further obtain a $D\cdot n^{o(1)}$-rounds
$(1-\epsilon)$-approximation algorithm for Maximum $st$-Flow on $G$ when $G$ is
undirected and $st$-planar. Finally, we give a near optimal $\tilde O(D)$-round
algorithm for computing the weighted girth of $G$.
  The main challenges in our work are that $G^*$ is not the communication graph
(e.g., a vertex of $G$ is mapped to multiple vertices of $G^*$), and that the
diameter of $G^*$ can be much larger than $D$ (i.e., possibly by a linear
factor). We overcome these challenges by carefully defining and maintaining
subgraphs of the dual graph $G^*$ while applying the recursive decomposition on
the primal graph $G$. The main technical difficulty, is that along the
recursive decomposition, a face of $G$ gets shattered into (disconnected)
components yet we still need to treat it as a dual node.","cs.DC, cs.DS",cs.DC,http://arxiv.org/abs/2411.11718v1
"A New Finite-Horizon Dynamic Programming Analysis of Nonanticipative
  Rate-Distortion Function for Markov Sources","Zixuan He, Charalambos D. Charalambous, Photios A. Stavrou",2024-11-18T16:20:21Z,"This paper deals with the computation of a non-asymptotic lower bound by
means of the nonanticipative rate-distortion function (NRDF) on the
discrete-time zero-delay variable-rate lossy compression problem for discrete
Markov sources with per-stage, single-letter distortion. First, we derive a new
information structure of the NRDF for Markov sources and single-letter
distortions. Second, we derive new convexity results on the NRDF, which
facilitate the use of Lagrange duality theorem to cast the problem as an
unconstrained partially observable finite-time horizon stochastic dynamic
programming (DP) algorithm subject to a probabilistic state (belief state) that
summarizes the past information about the reproduction symbols and takes values
in a continuous state space. Instead of approximating the DP algorithm
directly, we use Karush-Kuhn-Tucker (KKT) conditions to find an implicit
closed-form expression of the optimal control policy of the stochastic DP
(i.e., the minimizing distribution of the NRDF) and approximate the control
policy and the cost-to-go function (a function of the rate) stage-wise, via a
novel dynamic alternating minimization (AM) approach, that is realized by an
offline algorithm operating using backward recursions, with provable
convergence guarantees. We obtain the clean values of the aforementioned
quantities using an online (forward) algorithm operating for any finite-time
horizon. Our methodology provides an approximate solution to the exact NRDF
solution, which becomes near-optimal as the search space of the belief state
becomes sufficiently large at each time stage. We corroborate our theoretical
findings with simulation studies where we apply our algorithms assuming
time-varying and time-invariant binary Markov processes.","cs.IT, cs.SY, eess.SY, math.IT",cs.IT,http://arxiv.org/abs/2411.11698v1
Technical Report: Enhancing LLM Reasoning with Reward-guided Tree Search,"Jinhao Jiang, Zhipeng Chen, Yingqian Min, Jie Chen, Xiaoxue Cheng, Jiapeng Wang, Yiru Tang, Haoxiang Sun, Jia Deng, Wayne Xin Zhao, Zheng Liu, Dong Yan, Jian Xie, Zhongyuan Wang, Ji-Rong Wen",2024-11-18T16:15:17Z,"Recently, test-time scaling has garnered significant attention from the
research community, largely due to the substantial advancements of the o1 model
released by OpenAI. By allocating more computational resources during the
inference phase, large language models~(LLMs) can extensively explore the
solution space by generating more thought tokens or diverse solutions, thereby
producing more accurate responses. However, developing an o1-like reasoning
approach is challenging, and researchers have been making various attempts to
advance this open area of research. In this paper, we present a preliminary
exploration into enhancing the reasoning abilities of LLMs through
reward-guided tree search algorithms. This framework is implemented by
integrating the policy model, reward model, and search algorithm. It is
primarily constructed around a tree search algorithm, where the policy model
navigates a dynamically expanding tree guided by a specially trained reward
model. We thoroughly explore various design considerations necessary for
implementing this framework and provide a detailed report of the technical
aspects. To assess the effectiveness of our approach, we focus on mathematical
reasoning tasks and conduct extensive evaluations on four challenging datasets,
significantly enhancing the reasoning abilities of LLMs.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11694v1
Conceptwm: A Diffusion Model Watermark for Concept Protection,"Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu",2024-11-18T16:11:25Z,"The personalization techniques of diffusion models succeed in generating
specific concepts but also pose threats to copyright protection and illegal
use. Model Watermarking is an effective method to prevent the unauthorized use
of subject-driven or style-driven image generation, safeguarding concept
copyrights. However, under the goal of concept-oriented protection, current
watermarking schemes typically add watermarks to all images rather than
applying them in a refined manner targeted at specific concepts. Additionally,
the personalization techniques of diffusion models can easily remove
watermarks. Existing watermarking methods struggle to achieve fine-grained
watermark embedding with a few images of specific concept and prevent removal
of watermarks through personalized fine-tuning. Therefore, we introduce a novel
concept-oriented watermarking framework that seamlessly embeds imperceptible
watermarks into the concept of diffusion models. We conduct extensive
experiments and ablation studies to verify our framework. Our code is available
at https://anonymous.4open.science/r/Conceptwm-4EB3/.","cs.CR, cs.AI, cs.MM",cs.CR,http://arxiv.org/abs/2411.11688v1
"PSPO*: An Effective Process-supervised Policy Optimization for Reasoning
  Alignment","Jiawei Li, Xinyue Liang, Yizhe Yang, Chong Feng, Yang Gao",2024-11-18T16:03:51Z,"Process supervision enhances the performance of large language models in
reasoning tasks by providing feedback at each step of chain-of-thought
reasoning. However, due to the lack of effective process supervision methods,
even advanced large language models are prone to logical errors and redundant
reasoning. We claim that the effectiveness of process supervision significantly
depends on both the accuracy and the length of reasoning chains. Moreover, we
identify that these factors exhibit a nonlinear relationship with the overall
reward score of the reasoning process. Inspired by these insights, we propose a
novel process supervision paradigm, PSPO*, which systematically outlines the
workflow from reward model training to policy optimization, and highlights the
importance of nonlinear rewards in process supervision. Based on PSPO*, we
develop the PSPO-WRS, which considers the number of reasoning steps in
determining reward scores and utilizes an adjusted Weibull distribution for
nonlinear reward shaping. Experimental results on six mathematical reasoning
datasets demonstrate that PSPO-WRS consistently outperforms current mainstream
models.","cs.AI, cs.LG",cs.AI,http://arxiv.org/abs/2411.11681v1
Artificial Scientific Discovery,Antonio Norelli,2024-11-18T15:51:45Z,"Rooted in the explosion of deep learning over the past decade, this thesis
spans from AlphaGo to ChatGPT to empirically examine the fundamental concepts
needed to realize the vision of an artificial scientist: a machine with the
capacity to autonomously generate original research and contribute to the
expansion of human knowledge. The investigation begins with {\sc Olivaw}, an
AlphaGo Zero-like agent that discovers Othello knowledge from scratch but is
unable to communicate it. This realization leads to the development of the
Explanatory Learning (EL) framework, a formalization of the problem faced by a
scientist when trying to explain a new phenomenon to their peers. The effective
EL prescriptions allow us to crack Zendo, a board game simulating the
scientific endeavor. This success comes with a fundamental insight: an
artificial scientist must develop its own interpretation of the language used
to explain its findings. This perspective then leads us to see modern
multimodal models as interpreters, and to devise a new way to build
interpretable and cost-effective CLIP-like models: by coupling two unimodal
models using little multimodal data and no further training. Finally, we
discuss what ChatGPT and its siblings are still missing to become artificial
scientists, and introduce Odeen, a benchmark about interpreting explanations
that sees LLMs going no further than random chance while being instead fully
solved by humans.","cs.AI, cs.LG, I.2",cs.AI,http://arxiv.org/abs/2411.11672v1
"Multi-Grained Preference Enhanced Transformer for Multi-Behavior
  Sequential Recommendation","Chuan He, Yongchao Liu, Qiang Li, Weiqiang Wang, Xin Fu, Xinyi Fu, Chuntao Hong, Xinwei Yao",2024-11-19T02:45:17Z,"Sequential recommendation (SR) aims to predict the next purchasing item
according to users' dynamic preference learned from their historical user-item
interactions. To improve the performance of recommendation, learning dynamic
heterogeneous cross-type behavior dependencies is indispensable for recommender
system. However, there still exists some challenges in Multi-Behavior
Sequential Recommendation (MBSR). On the one hand, existing methods only model
heterogeneous multi-behavior dependencies at behavior-level or item-level, and
modelling interaction-level dependencies is still a challenge. On the other
hand, the dynamic multi-grained behavior-aware preference is hard to capture in
interaction sequences, which reflects interaction-aware sequential pattern. To
tackle these challenges, we propose a Multi-Grained Preference enhanced
Transformer framework (M-GPT). First, M-GPT constructs a interaction-level
graph of historical cross-typed interactions in a sequence. Then graph
convolution is performed to derive interaction-level multi-behavior dependency
representation repeatedly, in which the complex correlation between historical
cross-typed interactions at specific orders can be well learned. Secondly, a
novel multi-scale transformer architecture equipped with multi-grained user
preference extraction is proposed to encode the interaction-aware sequential
pattern enhanced by capturing temporal behavior-aware multi-grained preference
. Experiments on the real-world datasets indicate that our method M-GPT
consistently outperforms various state-of-the-art recommendation methods.","cs.IR, cs.SI",cs.IR,http://arxiv.org/abs/2411.12179v1
Few-shot Model Extraction Attacks against Sequential Recommender Systems,"Hui Zhang, Fu Liu",2024-11-18T15:57:14Z,"Among adversarial attacks against sequential recommender systems, model
extraction attacks represent a method to attack sequential recommendation
models without prior knowledge. Existing research has primarily concentrated on
the adversary's execution of black-box attacks through data-free model
extraction. However, a significant gap remains in the literature concerning the
development of surrogate models by adversaries with access to few-shot raw data
(10\% even less). That is, the challenge of how to construct a surrogate model
with high functional similarity within the context of few-shot data scenarios
remains an issue that requires resolution.This study addresses this gap by
introducing a novel few-shot model extraction framework against sequential
recommenders, which is designed to construct a superior surrogate model with
the utilization of few-shot data. The proposed few-shot model extraction
framework is comprised of two components: an autoregressive augmentation
generation strategy and a bidirectional repair loss-facilitated model
distillation procedure. Specifically, to generate synthetic data that closely
approximate the distribution of raw data, autoregressive augmentation
generation strategy integrates a probabilistic interaction sampler to extract
inherent dependencies and a synthesis determinant signal module to characterize
user behavioral patterns. Subsequently, bidirectional repair loss, which target
the discrepancies between the recommendation lists, is designed as auxiliary
loss to rectify erroneous predictions from surrogate models, transferring
knowledge from the victim model to the surrogate model effectively. Experiments
on three datasets show that the proposed few-shot model extraction framework
yields superior surrogate models.","cs.LG, cs.CR, cs.IR",cs.LG,http://arxiv.org/abs/2411.11677v1
"METEOR: Evolutionary Journey of Large Language Models from Guidance to
  Self-Growth","Jiawei Li, Chong Feng, Yang Gao",2024-11-18T15:09:50Z,"Model evolution enables learning from feedback to refine experiences and
update skills, transforming models from having no domain knowledge to becoming
domain experts. However, there is currently no unified and effective method for
guiding this evolutionary process. To address this gap, we propose the Meteor
method, which includes three training phases: weak-to-strong data distillation,
iterative training, and self-evolution strategies. Each phase maximizes the
model's inherent domain capabilities, allowing it to autonomously refine its
domain knowledge and enhance performance. Experiments demonstrate that our
approach significantly improves accuracy, completeness, relevance, coherence,
and reliability across domain-specific tasks.","cs.LG, cs.AI, cs.CL",cs.LG,http://arxiv.org/abs/2411.11933v1
"ST-Tree with Interpretability for Multivariate Time Series
  Classification","Mingsen Du, Yanxuan Wei, Yingxia Tang, Xiangwei Zheng, Shoushui Wei, Cun Ji",2024-11-18T14:49:12Z,"Multivariate time series classification is of great importance in practical
applications and is a challenging task. However, deep neural network models
such as Transformers exhibit high accuracy in multivariate time series
classification but lack interpretability and fail to provide insights into the
decision-making process. On the other hand, traditional approaches based on
decision tree classifiers offer clear decision processes but relatively lower
accuracy. Swin Transformer (ST) addresses these issues by leveraging
self-attention mechanisms to capture both fine-grained local patterns and
global patterns. It can also model multi-scale feature representation learning,
thereby providing a more comprehensive representation of time series features.
To tackle the aforementioned challenges, we propose ST-Tree with
interpretability for multivariate time series classification. Specifically, the
ST-Tree model combines ST as the backbone network with an additional neural
tree model. This integration allows us to fully leverage the advantages of ST
in learning time series context while providing interpretable decision
processes through the neural tree. This enables researchers to gain clear
insights into the model's decision-making process and extract meaningful
interpretations. Through experimental evaluations on 10 UEA datasets, we
demonstrate that the ST-Tree model improves accuracy in multivariate time
series classification tasks and provides interpretability through visualizing
the decision-making process across different datasets.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11620v1
"Reviving Dormant Memories: Investigating Catastrophic Forgetting in
  Language Models through Rationale-Guidance Difficulty","Huashan Sun, Yang Gao",2024-11-18T14:28:04Z,"Although substantial efforts have been made to mitigate catastrophic
forgetting in continual learning, the intrinsic mechanisms are not well
understood. In this paper, we discover that when a forgetting model passively
receives an externally provided partial appropriate rationale, its performance
on the forgotten task can be restored. Furthermore, by simply adding a
task-agnostic prefix to the original instruction, the forgetting model can
actively generate an appropriate rationale to reach the correct answer. These
findings suggest that the model does not actually ``forget'' the task
knowledge; instead, the degraded performance can be attributed to the failure
of the original instructions in guiding the model to generate the appropriate
rationales. Based on this insight, we propose the Rationale-Guidance Difficulty
metric to evaluate how effectively a given instruction guides the model in
generating appropriate rationales. We apply this metric to optimize the
allocation of replay data in replay-based continual learning algorithm.
Experimental results demonstrate that our data allocation method effectively
mitigates catastrophic forgetting and maintains better model plasticity
simultaneously across models.","cs.LG, cs.AI, cs.CL",cs.LG,http://arxiv.org/abs/2411.11932v1
"Generative Spatio-temporal GraphNet for Transonic Wing Pressure
  Distribution Forecasting","Gabriele Immordino, Andrea Vaiuso, Andrea Da Ronch, Marcello Righi",2024-11-18T14:10:20Z,"This study presents a framework for predicting unsteady transonic wing
pressure distributions, integrating an autoencoder architecture with graph
convolutional networks and graph-based temporal layers to model time
dependencies. The framework compresses high-dimensional pressure distribution
data into a lower-dimensional latent space using an autoencoder, ensuring
efficient data representation while preserving essential features. Within this
latent space, graph-based temporal layers are employed to predict future wing
pressures based on past data, effectively capturing temporal dependencies and
improving predictive accuracy. This combined approach leverages the strengths
of autoencoders for dimensionality reduction, graph convolutional networks for
handling unstructured grid data, and temporal layers for modeling time-based
sequences. The effectiveness of the proposed framework is validated through its
application to the Benchmark Super Critical Wing test case, achieving accuracy
comparable to computational fluid dynamics, while significantly reducing
prediction time. This framework offers a scalable, computationally efficient
solution for the aerodynamic analysis of unsteady phenomena.","cs.LG, cs.CE",cs.LG,http://arxiv.org/abs/2411.11592v1
"Exploring LLMs for Verifying Technical System Specifications Against
  Requirements","Lasse M. Reinpold, Marvin Schieseck, Lukas P. Wagner, Felix Gehlhoff, Alexander Fay",2024-11-18T13:59:29Z,"Requirements engineering is a knowledge intensive process and crucial for the
success of engineering projects. The field of knowledge-based requirements
engineering (KBRE) aims to support engineers by providing knowledge to assist
in the elicitation, validation, and management of system requirements. The
advent of large language models (LLMs) opens new opportunities in the field of
KBRE. This work experimentally investigates the potential of LLMs in
requirements verification. Therein, LLMs are provided with a set of
requirements and a textual system specification and are prompted to assess
which requirements are fulfilled by the system specification. Different
experimental variables such as system specification complexity, the number of
requirements, and prompting strategies were analyzed. Formal rule-based systems
serve as a benchmark to compare LLM performance to. Requirements and system
specifications are derived from the smart-grid domain. Results show that
advanced LLMs, like GPT-4o and Claude 3.5 Sonnet, achieved f1-scores between 79
% and 94 % in identifying non-fulfilled requirements, indicating potential for
LLMs to be leveraged for requirements verification.","cs.SE, cs.SY, eess.SY",cs.SE,http://arxiv.org/abs/2411.11582v1
Closed-loop multi-step planning with innate physics knowledge,"Giulia Lafratta, Bernd Porr, Christopher Chandler, Alice Miller",2024-11-18T12:15:16Z,"We present a hierarchical framework to solve robot planning as an input
control problem. At the lowest level are temporary closed control loops,
(""tasks""), each representing a behaviour, contingent on a specific sensory
input and therefore temporary. At the highest level, a supervising
""Configurator"" directs task creation and termination. Here resides ""core""
knowledge as a physics engine, where sequences of tasks can be simulated. The
Configurator encodes and interprets simulation results,based on which it can
choose a sequence of tasks as a plan. We implement this framework on a real
robot and test it in an overtaking scenario as proof-of-concept.","cs.RO, cs.AI, cs.ET, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.11510v1
Timescale-agnostic characterisation for collective attention events,"Tristan J. B. Cann, Iain S. Weaver, Hywel T. P. Williams",2024-11-18T12:01:59Z,"Online communications, and in particular social media, are a key component of
how society interacts with and promotes content online. Collective attention on
such content can vary wildly. The majority of breaking topics quickly fade into
obscurity after only a handful of interactions, while the possibility exists
for content to ``go viral'', seeing sustained interaction by large audiences
over long periods. In this paper we investigate the mechanisms behind such
events and introduce a new representation that enables direct comparison of
events over diverse time and volume scales. We find four characteristic
behaviours in the usage of hashtags on Twitter that are indicative of different
patterns of attention to topics. We go on to develop an agent-based model for
generating collective attention events to test the factors affecting emergence
of these phenomena. This model can reproduce the characteristic behaviours seen
in the Twitter dataset using a small set of parameters, and reveal that three
of these behaviours instead represent a continuum determined by model
parameters rather than discrete categories. These insights suggest that
collective attention in social systems develops in line with a set of universal
principles independent of effects inherent to system scale, and the techniques
we introduce here present a valuable opportunity to infer the possible
mechanisms of attention flow in online communications.","cs.SI, cs.CY",cs.SI,http://arxiv.org/abs/2411.11500v1
"Physics Encoded Blocks in Residual Neural Network Architectures for
  Digital Twin Models","Muhammad Saad Zia, Ashiq Anjum, Lu Liu, Anthony Conway, Anasol Pena Rios",2024-11-18T11:58:20Z,"Physics Informed Machine Learning has emerged as a popular approach in
modelling and simulation for digital twins to generate accurate models of
processes and behaviours of real-world systems. However, despite their success
in generating accurate and reliable models, the existing methods either use
simple regularizations in loss functions to offer limited physics integration
or are too specific in architectural definitions to be generalized to a wide
variety of physical systems. This paper presents a generic approach based on a
novel physics-encoded residual neural network architecture to combine
data-driven and physics-based analytical models to address these limitations.
Our method combines physics blocks as mathematical operators from physics-based
models with learning blocks comprising feed-forward layers. Intermediate
residual blocks are incorporated for stable gradient flow as they train on
physical system observation data. This way, the model learns to comply with the
geometric and kinematic aspects of the physical system. Compared to
conventional neural network-based methods, our method improves generalizability
with substantially low data requirements and model complexity in terms of
parameters, especially in scenarios where prior physics knowledge is either
elementary or incomplete. We investigate our approach in two application
domains. The first is a basic robotic motion model using Euler Lagrangian
equations of motion as physics prior. The second application is a complex
scenario of a steering model for a self-driving vehicle in a simulation. In
both applications, our method outperforms both conventional neural network
based approaches as-well as state-of-the-art Physics Informed Machine Learning
methods.","cs.LG, cs.RO",cs.LG,http://arxiv.org/abs/2411.11497v1
"Alien Recombination: Exploring Concept Blends Beyond Human Cognitive
  Availability in Visual Art","Alejandro Hernandez, Levin Brinkmann, Ignacio Serna, Nasim Rahaman, Hassan Abu Alhaija, Hiromu Yakura, Mar Canet Sola, Bernhard Schölkopf, Iyad Rahwan",2024-11-18T11:55:38Z,"While AI models have demonstrated remarkable capabilities in constrained
domains like game strategy, their potential for genuine creativity in
open-ended domains like art remains debated. We explore this question by
examining how AI can transcend human cognitive limitations in visual art
creation. Our research hypothesizes that visual art contains a vast unexplored
space of conceptual combinations, constrained not by inherent incompatibility,
but by cognitive limitations imposed by artists' cultural, temporal,
geographical and social contexts.
  To test this hypothesis, we present the Alien Recombination method, a novel
approach utilizing fine-tuned large language models to identify and generate
concept combinations that lie beyond human cognitive availability. The system
models and deliberately counteracts human availability bias, the tendency to
rely on immediately accessible examples, to discover novel artistic
combinations.
  This system not only produces combinations that have never been attempted
before within our dataset but also identifies and generates combinations that
are cognitively unavailable to all artists in the domain. Furthermore, we
translate these combinations into visual representations, enabling the
exploration of subjective perceptions of novelty. Our findings suggest that
cognitive unavailability is a promising metric for optimizing artistic novelty,
outperforming merely temperature scaling without additional evaluation
criteria. This approach uses generative models to connect previously
unconnected ideas, providing new insight into the potential of framing
AI-driven creativity as a combinatorial problem.","cs.AI, cs.CY, cs.LG",cs.AI,http://arxiv.org/abs/2411.11494v1
"Graph Artificial Intelligence for Quantifying Compatibility Mechanisms
  in Traditional Chinese Medicine","Jingqi Zeng, Xiaobin Jia",2024-11-18T11:16:13Z,"Traditional Chinese Medicine (TCM) involves complex compatibility mechanisms
characterized by multi-component and multi-target interactions, which are
challenging to quantify. To address this challenge, we applied graph artificial
intelligence to develop a TCM multi-dimensional knowledge graph that bridges
traditional TCM theory and modern biomedical science
(https://zenodo.org/records/13763953 ). Using feature engineering and
embedding, we processed key TCM terminology and Chinese herbal pieces (CHP),
introducing medicinal properties as virtual nodes and employing graph neural
networks with attention mechanisms to model and analyze 6,080 Chinese herbal
formulas (CHF). Our method quantitatively assessed the roles of CHP within CHF
and was validated using 215 CHF designed for COVID-19 management. With
interpretable models, open-source data, and code
(https://github.com/ZENGJingqi/GraphAI-for-TCM ), this study provides robust
tools for advancing TCM theory and drug discovery.","cs.LG, q-bio.QM, 92C42 (Systems biology, networks), 68T07 (Artificial intelligence
  and machine learning), I.2.6; I.2.7; J.3",cs.LG,http://arxiv.org/abs/2411.11474v1
"Weak Simplicial Bisimilarity and Minimisation for Polyhedral Model
  Checking","Nick Bezhanishvili, Laura Bussi, Vincenzo Ciancia, David Gabelaia, Mamuka Jibladze, Diego Latella, Mieke Massink, Erik P. de Vink",2024-11-18T09:57:19Z,"The work described in this paper builds on the polyhedral semantics of the
Spatial Logic for Closure Spaces (SLCS) and the geometric spatial model checker
PolyLogicA. Polyhedral models are central in domains that exploit mesh
processing, such as 3D computer graphics. A discrete representation of
polyhedral models is given by cell poset models, which are amenable to
geometric spatial model checking on polyhedral models using the logical
language SLCS$\eta$, a weaker version of SLCS. In this work we show that the
mapping from polyhedral models to cell poset models preserves and reflects
SLCS$\eta$. We also propose weak simplicial bisimilarity on polyhedral models
and weak $\pm$-bisimilarity on cell poset models. Weak $\pm$-bisimilarity leads
to a stronger reduction of models than its counterpart $\pm$-bisimilarity that
was introduced in previous work. We show that the proposed bisimilarities enjoy
the Hennessy-Milner property, i.e. two points are weakly simplicial bisimilar
iff they are logically equivalent for SLCS$\eta$. Similarly, two cells are
weakly $\pm$-bisimilar iff they are logically equivalent in the poset-model
interpretation of SLCS$\eta$. Furthermore we present a procedure, and prove
that it correctly computes the minimal model with respect to weak
$\pm$-bisimilarity, i.e. with respect to logical equivalence of SLCS$\eta$. The
procedure works via an encoding into LTSs and then exploits branching
bisimilarity on those LTSs. This allows one to use in the implementation the
minimization capabilities as included in the mCRL2 toolset. Various experiments
are included to show the effectiveness of the approach.","cs.LO, 68N30 Mathematical aspects of software engineering (specification,
  verification, metrics, requirements, etc.)",cs.LO,http://arxiv.org/abs/2411.11428v1
Membership Inference Attack against Long-Context Large Language Models,"Zixiong Wang, Gaoyang Liu, Yang Yang, Chen Wang",2024-11-18T09:50:54Z,"Recent advances in Large Language Models (LLMs) have enabled them to overcome
their context window limitations, and demonstrate exceptional retrieval and
reasoning capacities on longer context. Quesion-answering systems augmented
with Long-Context Language Models (LCLMs) can automatically search massive
external data and incorporate it into their contexts, enabling faithful
predictions and reducing issues such as hallucinations and knowledge staleness.
Existing studies targeting LCLMs mainly concentrate on addressing the so-called
lost-in-the-middle problem or improving the inference effiencicy, leaving their
privacy risks largely unexplored. In this paper, we aim to bridge this gap and
argue that integrating all information into the long context makes it a
repository of sensitive information, which often contains private data such as
medical records or personal identities. We further investigate the membership
privacy within LCLMs external context, with the aim of determining whether a
given document or sequence is included in the LCLMs context. Our basic idea is
that if a document lies in the context, it will exhibit a low generation loss
or a high degree of semantic similarity to the contents generated by LCLMs. We
for the first time propose six membership inference attack (MIA) strategies
tailored for LCLMs and conduct extensive experiments on various popular models.
Empirical results demonstrate that our attacks can accurately infer membership
status in most cases, e.g., 90.66% attack F1-score on Multi-document QA
datasets with LongChat-7b-v1.5-32k, highlighting significant risks of
membership leakage within LCLMs input contexts. Furthermore, we examine the
underlying reasons why LCLMs are susceptible to revealing such membership
information.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11424v1
Continual Task Learning through Adaptive Policy Self-Composition,"Shengchao Hu, Yuhang Zhou, Ziqing Fan, Jifeng Hu, Li Shen, Ya Zhang, Dacheng Tao",2024-11-18T08:20:21Z,"Training a generalizable agent to continually learn a sequence of tasks from
offline trajectories is a natural requirement for long-lived agents, yet
remains a significant challenge for current offline reinforcement learning (RL)
algorithms. Specifically, an agent must be able to rapidly adapt to new tasks
using newly collected trajectories (plasticity), while retaining knowledge from
previously learned tasks (stability). However, systematic analyses of this
setting are scarce, and it remains unclear whether conventional continual
learning (CL) methods are effective in continual offline RL (CORL) scenarios.
In this study, we develop the Offline Continual World benchmark and demonstrate
that traditional CL methods struggle with catastrophic forgetting, primarily
due to the unique distribution shifts inherent to CORL scenarios. To address
this challenge, we introduce CompoFormer, a structure-based continual
transformer model that adaptively composes previous policies via a meta-policy
network. Upon encountering a new task, CompoFormer leverages semantic
correlations to selectively integrate relevant prior policies alongside newly
trained parameters, thereby enhancing knowledge sharing and accelerating the
learning process. Our experiments reveal that CompoFormer outperforms
conventional CL methods, particularly in longer task sequences, showcasing a
promising balance between plasticity and stability.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11364v1
Zero-Shot Load Forecasting with Large Language Models,"Wenlong Liao, Zhe Yang, Mengshuo Jia, Christian Rehtanz, Jiannong Fang, Fernando Porté-Agel",2024-11-18T07:39:46Z,"Deep learning models have shown strong performance in load forecasting, but
they generally require large amounts of data for model training before being
applied to new scenarios, which limits their effectiveness in data-scarce
scenarios. Inspired by the great success of pre-trained language models (LLMs)
in natural language processing, this paper proposes a zero-shot load
forecasting approach using an advanced LLM framework denoted as the Chronos
model. By utilizing its extensive pre-trained knowledge, the Chronos model
enables accurate load forecasting in data-scarce scenarios without the need for
extensive data-specific training. Simulation results across five real-world
datasets demonstrate that the Chronos model significantly outperforms nine
popular baseline models for both deterministic and probabilistic load
forecasting with various forecast horizons (e.g., 1 to 48 hours), even though
the Chronos model is neither tailored nor fine-tuned to these specific load
datasets. Notably, Chronos reduces root mean squared error (RMSE), continuous
ranked probability score (CRPS), and quantile score (QS) by approximately
7.34%-84.30%, 19.63%-60.06%, and 22.83%-54.49%, respectively, compared to
baseline models. These results highlight the superiority and flexibility of the
Chronos model, positioning it as an effective solution in data-scarce
scenarios.","cs.LG, eess.SP",cs.LG,http://arxiv.org/abs/2411.11350v1
"Mitigating Knowledge Conflicts in Language Model-Driven Question
  Answering","Han Cao, Zhaoyang Zhang, Xiangtian Li, Chufan Wu, Hansong Zhang, Wenqing Zhang",2024-11-18T07:33:10Z,"Knowledge-aware sequence to sequence generation tasks such as document
question answering and abstract summarization typically requires two types of
knowledge: encoded parametric knowledge and retrieved contextual information.
Previous work show improper correlation between parametric knowledge and
answers in the training set could cause the model ignore input information at
test time, resulting in un-desirable model behaviour such as over-stability and
hallucination. In this work, we argue that hallucination could be mitigated via
explicit correlation between input source and generated content. We focus on a
typical example of hallucination, entity-based knowledge conflicts in question
answering, where correlation of entities and their description at training time
hinders model behaviour during inference.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.11344v1
"SayComply: Grounding Field Robotic Tasks in Operational Compliance
  through Retrieval-Based Language Models","Muhammad Fadhil Ginting, Dong-Ki Kim, Sung-Kyun Kim, Bandi Jai Krishna, Mykel J. Kochenderfer, Shayegan Omidshafiei, Ali-akbar Agha-mohammadi",2024-11-18T06:33:05Z,"This paper addresses the problem of task planning for robots that must comply
with operational manuals in real-world settings. Task planning under these
constraints is essential for enabling autonomous robot operation in domains
that require adherence to domain-specific knowledge. Current methods for
generating robot goals and plans rely on common sense knowledge encoded in
large language models. However, these models lack grounding of robot plans to
domain-specific knowledge and are not easily transferable between multiple
sites or customers with different compliance needs. In this work, we present
SayComply, which enables grounding robotic task planning with operational
compliance using retrieval-based language models. We design a hierarchical
database of operational, environment, and robot embodiment manuals and
procedures to enable efficient retrieval of the relevant context under the
limited context length of the LLMs. We then design a task planner using a
tree-based retrieval augmented generation (RAG) technique to generate robot
tasks that follow user instructions while simultaneously complying with the
domain knowledge in the database. We demonstrate the benefits of our approach
through simulations and hardware experiments in real-world scenarios that
require precise context retrieval across various types of context,
outperforming the standard RAG method. Our approach bridges the gap in
deploying robots that consistently adhere to operational protocols, offering a
scalable and edge-deployable solution for ensuring compliance across varied and
complex real-world environments. Project website: saycomply.github.io.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11323v1
On the compressiveness of the Burrows-Wheeler transform,"Hideo Bannai, Tomohiro I, Yuto Nakashima",2024-11-18T05:48:55Z,"The Burrows-Wheeler transform (BWT) is a reversible transform that converts a
string $w$ into another string $\mathsf{BWT}(w)$. The size of the run-length
encoded BWT (RLBWT) can be interpreted as a measure of repetitiveness in the
class of representations called dictionary compression which are essentially
representations based on copy and paste operations. In this paper, we shed new
light on the compressiveness of BWT and the bijective BWT (BBWT). We first
extend previous results on the relations of their run-length compressed sizes
$r$ and $r_B$. We also show that the so-called ``clustering effect'' of BWT and
BBWT can be captured by measures other than empirical entropy or run-length
encoding. In particular, we show that BWT and BBWT do not increase the
repetitiveness of the string with respect to various measures based on
dictionary compression by more than a polylogarithmic factor. Furthermore, we
show that there exists an infinite family of strings that are maximally
incompressible by any dictionary compression measure, but become very
compressible after applying BBWT. An interesting implication of this result is
that it is possible to transcend dictionary compression in some cases by simply
applying BBWT before applying dictionary compression.","cs.DM, cs.DS",cs.DM,http://arxiv.org/abs/2411.11298v1
"Dual-Frequency Filtering Self-aware Graph Neural Networks for Homophilic
  and Heterophilic Graphs","Yachao Yang, Yanfeng Sun, Jipeng Guo, Junbin Gao, Shaofan Wang, Fujiao Ju, Baocai Yin",2024-11-18T04:57:05Z,"Graph Neural Networks (GNNs) have excelled in handling graph-structured data,
attracting significant research interest. However, two primary challenges have
emerged: interference between topology and attributes distorting node
representations, and the low-pass filtering nature of most GNNs leading to the
oversight of valuable high-frequency information in graph signals. These issues
are particularly pronounced in heterophilic graphs. To address these
challenges, we propose Dual-Frequency Filtering Self-aware Graph Neural
Networks (DFGNN). DFGNN integrates low-pass and high-pass filters to extract
smooth and detailed topological features, using frequency-specific constraints
to minimize noise and redundancy in the respective frequency bands. The model
dynamically adjusts filtering ratios to accommodate both homophilic and
heterophilic graphs. Furthermore, DFGNN mitigates interference by aligning
topological and attribute representations through dynamic correspondences
between their respective frequency bands, enhancing overall model performance
and expressiveness. Extensive experiments conducted on benchmark datasets
demonstrate that DFGNN outperforms state-of-the-art methods in classification
performance, highlighting its effectiveness in handling both homophilic and
heterophilic graphs.",cs.LG,cs.LG,http://arxiv.org/abs/2411.11284v1
VersaTune: Fine-Tuning Multi-Ability LLMs Efficiently,"Keer Lu, Keshi Zhao, Zheng Liang, Da Pan, Shusen Zhang, Xin Wu, Weipeng Chen, Zenan Zhou, Guosheng Dong, Bin Cui, Wentao Zhang",2024-11-18T03:45:34Z,"Large Language Models (LLMs) exhibit remarkable capabilities in handling
multiple tasks across domains due to their emergent properties. These
capabilities are further augmented during the Supervised Fine-Tuning (SFT)
phase. Despite their potential, existing work mainly focuses on domain-specific
enhancements during fine-tuning, the challenge of which lies in catastrophic
forgetting of knowledge across other domains. In this study, we introduce
VersaTune, a novel data composition framework designed for enhancing LLMs'
overall multi-ability performances during fine-tuning. We categorize knowledge
into distinct domains including law, medicine, finance, science, code. We begin
with detecting the distribution of domain-specific knowledge within the base
model, followed by the composition of training data that aligns with the
model's existing knowledge distribution. During the fine-tuning process,
weights of different domains are dynamically adjusted based on their learnable
potential and forgetting degree. Experimental results demonstrate that
VersaTune achieves significant improvements in multi-domain performance, with a
35.21% enhancement in comprehensive multi-domain tasks. Additionally, in
scenarios where specific domain optimization is required, VersaTune reduces the
degradation of performance in other domains by 38.77%, without compromising the
target domain's training efficacy.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11266v1
"EXCON: Extreme Instance-based Contrastive Representation Learning of
  Severely Imbalanced Multivariate Time Series for Solar Flare Prediction","Onur Vural, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi",2024-11-18T02:36:19Z,"In heliophysics research, predicting solar flares is crucial due to their
potential to impact both space-based systems and Earth's infrastructure
substantially. Magnetic field data from solar active regions, recorded by solar
imaging observatories, are transformed into multivariate time series to enable
solar flare prediction using temporal window-based analysis. In the realm of
multivariate time series-driven solar flare prediction, addressing severe class
imbalance with effective strategies for multivariate time series representation
learning is key to developing robust predictive models. Traditional methods
often struggle with overfitting to the majority class in prediction tasks where
major solar flares are infrequent. This work presents EXCON, a contrastive
representation learning framework designed to enhance classification
performance amidst such imbalances. EXCON operates through four stages:
obtaining core features from multivariate time series data; selecting
distinctive contrastive representations for each class to maximize inter-class
separation; training a temporal feature embedding module with a custom extreme
reconstruction loss to minimize intra-class variation; and applying a
classifier to the learned embeddings for robust classification. The proposed
method leverages contrastive learning principles to map similar instances
closer in the feature space while distancing dissimilar ones, a strategy not
extensively explored in solar flare prediction tasks. This approach not only
addresses class imbalance but also offers a versatile solution applicable to
univariate and multivariate time series across binary and multiclass
classification problems. Experimental results, including evaluations on the
benchmark solar flare dataset and multiple time series archive datasets with
binary and multiclass labels, demonstrate EXCON's efficacy in enhancing
classification performance.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11249v1
Mirror Descent on Reproducing Kernel Banach Spaces,"Akash Kumar, Mikhail Belkin, Parthe Pandit",2024-11-18T02:18:32Z,"Recent advances in machine learning have led to increased interest in
reproducing kernel Banach spaces (RKBS) as a more general framework that
extends beyond reproducing kernel Hilbert spaces (RKHS). These works have
resulted in the formulation of representer theorems under several regularized
learning schemes. However, little is known about an optimization method that
encompasses these results in this setting. This paper addresses a learning
problem on Banach spaces endowed with a reproducing kernel, focusing on
efficient optimization within RKBS. To tackle this challenge, we propose an
algorithm based on mirror descent (MDA). Our approach involves an iterative
method that employs gradient steps in the dual space of the Banach space using
the reproducing kernel.
  We analyze the convergence properties of our algorithm under various
assumptions and establish two types of results: first, we identify conditions
under which a linear convergence rate is achievable, akin to optimization in
the Euclidean setting, and provide a proof of the linear rate; second, we
demonstrate a standard convergence rate in a constrained setting. Moreover, to
instantiate this algorithm in practice, we introduce a novel family of RKBSs
with $p$-norm ($p \neq 2$), characterized by both an explicit dual map and a
kernel.","cs.LG, math.OC, stat.ML",cs.LG,http://arxiv.org/abs/2411.11242v1
"SAMOS: A Neural MOS Prediction Model Leveraging Semantic Representations
  and Acoustic Features","Yu-Fei Shi, Yang Ai, Ye-Xin Lu, Hui-Peng Du, Zhen-Hua Ling",2024-11-18T01:54:51Z,"Assessing the naturalness of speech using mean opinion score (MOS) prediction
models has positive implications for the automatic evaluation of speech
synthesis systems. Early MOS prediction models took the raw waveform or
amplitude spectrum of speech as input, whereas more advanced methods employed
self-supervised-learning (SSL) based models to extract semantic representations
from speech for MOS prediction. These methods utilized limited aspects of
speech information for MOS prediction, resulting in restricted prediction
accuracy. Therefore, in this paper, we propose SAMOS, a MOS prediction model
that leverages both Semantic and Acoustic information of speech to be assessed.
Specifically, the proposed SAMOS leverages a pretrained wav2vec2 to extract
semantic representations and uses the feature extractor of a pretrained
BiVocoder to extract acoustic features. These two types of features are then
fed into the prediction network, which includes multi-task heads and an
aggregation layer, to obtain the final MOS score. Experimental results
demonstrate that the proposed SAMOS outperforms current state-of-the-art MOS
prediction models on the BVCC dataset and performs comparable performance on
the BC2019 dataset, according to the results of system-level evaluation
metrics.","cs.SD, eess.AS",cs.SD,http://arxiv.org/abs/2411.11232v1
"Investigating the Use of Productive Failure as a Design Paradigm for
  Learning Introductory Python Programming","Hussel Suriyaarachchi, Paul Denny, Suranga Nanayakkara",2024-11-18T01:39:05Z,"Productive Failure (PF) is a learning approach where students initially
tackle novel problems targeting concepts they have not yet learned, followed by
a consolidation phase where these concepts are taught. Recent application in
STEM disciplines suggests that PF can help learners develop more robust
conceptual knowledge. However, empirical validation of PF for programming
education remains under-explored. In this paper, we investigate the use of PF
to teach Python lists to undergraduate students with limited prior programming
experience. We designed a novel PF-based learning activity that incorporated
the unobtrusive collection of real-time heart-rate data from consumer-grade
wearable sensors. This sensor data was used both to make the learning activity
engaging and to infer cognitive load. We evaluated our approach with 20
participants, half of whom were taught Python concepts using Direct Instruction
(DI), and the other half with PF. We found that although there was no
difference in initial learning outcomes between the groups, students who
followed the PF approach showed better knowledge retention and performance on
delayed but similar tasks. In addition, physiological measurements indicated
that these students also exhibited a larger decrease in cognitive load during
their tasks after instruction. Our findings suggest that PF-based approaches
may lead to more robust learning, and that future work should investigate
similar activities at scale across a range of concepts.","cs.CY, cs.HC",cs.CY,http://arxiv.org/abs/2411.11227v1
"Online Item Cold-Start Recommendation with Popularity-Aware
  Meta-Learning","Yunze Luo, Yuezihan Jiang, Yinjie Jiang, Gaode Chen, Jingchi Wang, Kaigui Bian, Peiyi Li, Qi Zhang",2024-11-18T01:30:34Z,"With the rise of e-commerce and short videos, online recommender systems that
can capture users' interests and update new items in real-time play an
increasingly important role. In both online and offline recommendation, the
cold-start problem due to interaction sparsity has been affecting the
recommendation effect of cold-start items, which is also known as the long-tail
problem of item distribution. Many cold-start scheme based on fine-tuning or
knowledge transferring shows excellent performance on offline recommendation.
Yet, these schemes are infeasible for online recommendation on streaming data
pipelines due to different training method, computational overhead and time
constraints.
  Inspired by the above questions, we propose a model-agnostic recommendation
algorithm called Popularity-Aware Meta-learning (PAM), to address the item
cold-start problem under streaming data settings. PAM divides the incoming data
into different meta-learning tasks by predefined item popularity thresholds.
The model can distinguish and reweight behavior-related features and
content-related features in each task based on their different roles in
different popularity levels, thus adapting to recommendations for cold-start
samples. These task-fixing design significantly reduces additional computation
and storage costs compared to offline methods. Furthermore, PAM also introduced
data augmentation and an additional self-supervised loss specifically designed
for low-popularity tasks, leveraging insights from high-popularity samples.
This approach effectively mitigates the issue of inadequate supervision due to
the scarcity of cold-start samples. Experimental results across multiple public
datasets demonstrate the superiority of our approach over other baseline
methods in addressing cold-start challenges in online streaming data scenarios.",cs.IR,cs.IR,http://arxiv.org/abs/2411.11225v1
BVI-CR: A Multi-View Human Dataset for Volumetric Video Compression,"Ge Gao, Adrian Azzarelli, Ho Man Kwan, Nantheera Anantrasirichai, Fan Zhang, Oliver Moolan-Feroze, David Bull",2024-11-17T23:22:48Z,"The advances in immersive technologies and 3D reconstruction have enabled the
creation of digital replicas of real-world objects and environments with fine
details. These processes generate vast amounts of 3D data, requiring more
efficient compression methods to satisfy the memory and bandwidth constraints
associated with data storage and transmission. However, the development and
validation of efficient 3D data compression methods are constrained by the lack
of comprehensive and high-quality volumetric video datasets, which typically
require much more effort to acquire and consume increased resources compared to
2D image and video databases. To bridge this gap, we present an open multi-view
volumetric human dataset, denoted BVI-CR, which contains 18 multi-view RGB-D
captures and their corresponding textured polygonal meshes, depicting a range
of diverse human actions. Each video sequence contains 10 views in 1080p
resolution with durations between 10-15 seconds at 30FPS. Using BVI-CR, we
benchmarked three conventional and neural coordinate-based multi-view video
compression methods, following the MPEG MIV Common Test Conditions, and
reported their rate quality performance based on various quality metrics. The
results show the great potential of neural representation based methods in
volumetric video compression compared to conventional video coding methods
(with an up to 38\% average coding gain in PSNR). This dataset provides a
development and validation platform for a variety of tasks including volumetric
reconstruction, compression, and quality assessment. The database will be
shared publicly at \url{https://github.com/fan-aaron-zhang/bvi-cr}.","cs.CV, eess.IV",cs.CV,http://arxiv.org/abs/2411.11199v1
"Careless Whisper: Exploiting Stealthy End-to-End Leakage in Mobile
  Instant Messengers","Gabriel K. Gegenhuber, Maximilian Günther, Markus Maier, Aljosha Judmayer, Florian Holzbauer, Philipp É. Frenzel, Johanna Ullrich",2024-11-17T22:58:28Z,"With over 3 billion users globally, mobile instant messaging apps have become
indispensable for both personal and professional communication. Besides plain
messaging, many services implement additional features such as delivery and
read receipts informing a user when a message has successfully reached its
target. This paper highlights that delivery receipts can pose significant
privacy risks to users. We use specifically crafted messages that trigger
delivery receipts allowing any user to be pinged without their knowledge or
consent. By using this technique at high frequency, we demonstrate how an
attacker could extract private information such as the online and activity
status of a victim, e.g., screen on/off. Moreover, we can infer the number of
currently active user devices and their operating system, as well as launch
resource exhaustion attacks, such as draining a user's battery or data
allowance, all without generating any notification on the target side. Due to
the widespread adoption of vulnerable messengers (WhatsApp and Signal) and the
fact that any user can be targeted simply by knowing their phone number, we
argue for a design change to address this issue.","cs.CR, cs.NI",cs.CR,http://arxiv.org/abs/2411.11194v2
"RPN 2: On Interdependence Function Learning Towards Unifying and
  Advancing CNN, RNN, GNN, and Transformer",Jiawei Zhang,2024-11-17T19:45:26Z,"This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.","cs.LG, cs.AI, cs.CV, cs.IT, math.IT, stat.ML",cs.LG,http://arxiv.org/abs/2411.11162v1
"TabDeco: A Comprehensive Contrastive Framework for Decoupled
  Representations in Tabular Data","Suiyao Chen, Jing Wu, Yunxiao Wang, Cheng Ji, Tianpei Xie, Daniel Cociorva, Michael Sharps, Cecile Levasseur, Hakan Brunzell",2024-11-17T18:42:46Z,"Representation learning is a fundamental aspect of modern artificial
intelligence, driving substantial improvements across diverse applications.
While selfsupervised contrastive learning has led to significant advancements
in fields like computer vision and natural language processing, its adaptation
to tabular data presents unique challenges. Traditional approaches often
prioritize optimizing model architecture and loss functions but may overlook
the crucial task of constructing meaningful positive and negative sample pairs
from various perspectives like feature interactions, instance-level patterns
and batch-specific contexts. To address these challenges, we introduce TabDeco,
a novel method that leverages attention-based encoding strategies across both
rows and columns and employs contrastive learning framework to effectively
disentangle feature representations at multiple levels, including features,
instances and data batches. With the innovative feature decoupling hierarchies,
TabDeco consistently surpasses existing deep learning methods and leading
gradient boosting algorithms, including XG-Boost, CatBoost, and LightGBM,
across various benchmark tasks, underscoring its effectiveness in advancing
tabular data representation learning.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11148v1
"MolParser: End-to-end Visual Recognition of Molecule Structures in the
  Wild","Xi Fang, Jiankun Wang, Xiaochen Cai, Shangqian Chen, Shuwen Yang, Lin Yao, Linfeng Zhang, Guolin Ke",2024-11-17T15:00:09Z,"In recent decades, chemistry publications and patents have increased rapidly.
A significant portion of key information is embedded in molecular structure
figures, complicating large-scale literature searches and limiting the
application of large language models in fields such as biology, chemistry, and
pharmaceuticals. The automatic extraction of precise chemical structures is of
critical importance. However, the presence of numerous Markush structures in
real-world documents, along with variations in molecular image quality, drawing
styles, and noise, significantly limits the performance of existing optical
chemical structure recognition (OCSR) methods. We present MolParser, a novel
end-to-end OCSR method that efficiently and accurately recognizes chemical
structures from real-world documents, including difficult Markush structure. We
use a extended SMILES encoding rule to annotate our training dataset. Under
this rule, we build MolParser-7M, the largest annotated molecular image dataset
to our knowledge. While utilizing a large amount of synthetic data, we employed
active learning methods to incorporate substantial in-the-wild data,
specifically samples cropped from real patents and scientific literature, into
the training process. We trained an end-to-end molecular image captioning
model, MolParser, using a curriculum learning approach. MolParser significantly
outperforms classical and learning-based methods across most scenarios, with
potential for broader downstream applications. The dataset is publicly
available.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11098v1
"ForPKG-1.0: A Framework for Constructing Forestry Policy Knowledge Graph
  and Application Analysis","Jingyun Sun, Zhongze Luo",2024-11-17T14:45:52Z,"A policy knowledge graph can provide decision support for tasks such as
project compliance, policy analysis, and intelligent question answering, and
can also serve as an external knowledge base to assist the reasoning process of
related large language models. Although there have been many related works on
knowledge graphs, there is currently a lack of research on the construction
methods of policy knowledge graphs. This paper, focusing on the forestry field,
designs a complete policy knowledge graph construction framework, including:
firstly, proposing a fine-grained forestry policy domain ontology; then,
proposing an unsupervised policy information extraction method, and finally,
constructing a complete forestry policy knowledge graph. The experimental
results show that the proposed ontology has good expressiveness and
extensibility, and the policy information extraction method proposed in this
paper achieves better results than other unsupervised methods. Furthermore, by
analyzing the application of the knowledge graph in the
retrieval-augmented-generation task of the large language models, the practical
application value of the knowledge graph in the era of large language models is
confirmed. The knowledge graph resource will be released on an open-source
platform and can serve as the basic knowledge base for forestry policy-related
intelligent systems. It can also be used for academic research. In addition,
this study can provide reference and guidance for the construction of policy
knowledge graphs in other fields.",cs.IR,cs.IR,http://arxiv.org/abs/2411.11090v1
"D-Cube: Exploiting Hyper-Features of Diffusion Model for Robust Medical
  Classification","Minhee Jang, Juheon Son, Thanaporn Viriyasaranon, Junho Kim, Jang-Hwan Choi",2024-11-17T14:30:50Z,"The integration of deep learning technologies in medical imaging aims to
enhance the efficiency and accuracy of cancer diagnosis, particularly for
pancreatic and breast cancers, which present significant diagnostic challenges
due to their high mortality rates and complex imaging characteristics. This
paper introduces Diffusion-Driven Diagnosis (D-Cube), a novel approach that
leverages hyper-features from a diffusion model combined with contrastive
learning to improve cancer diagnosis. D-Cube employs advanced feature selection
techniques that utilize the robust representational capabilities of diffusion
models, enhancing classification performance on medical datasets under
challenging conditions such as data imbalance and limited sample availability.
The feature selection process optimizes the extraction of clinically relevant
features, significantly improving classification accuracy and demonstrating
resilience in imbalanced and limited data scenarios. Experimental results
validate the effectiveness of D-Cube across multiple medical imaging
modalities, including CT, MRI, and X-ray, showing superior performance compared
to existing baseline models. D-Cube represents a new strategy in cancer
detection, employing advanced deep learning techniques to achieve
state-of-the-art diagnostic accuracy and efficiency.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11087v1
Spectral Subspace Clustering for Attributed Graphs,"Xiaoyang Lin, Renchi Yang, Haoran Zheng, Xiangyu Ke",2024-11-17T13:22:15Z,"Subspace clustering seeks to identify subspaces that segment a set of n data
points into k (k<<n) groups, which has emerged as a powerful tool for analyzing
data from various domains, especially images and videos. Recently, several
studies have demonstrated the great potential of subspace clustering models for
partitioning vertices in attributed graphs, referred to as SCAG. However, these
works either demand significant computational overhead for constructing the nxn
self-expressive matrix, or fail to incorporate graph topology and attribute
data into the subspace clustering framework effectively, and thus, compromise
result quality.
  Motivated by this, this paper presents two effective and efficient
algorithms, S2CAG and M-S2CAG, for SCAG computation. Particularly, S2CAG
obtains superb performance through three major contributions. First, we
formulate a new objective function for SCAG with a refined representation model
for vertices and two non-trivial constraints. On top of that, an efficient
linear-time optimization solver is developed based on our theoretically
grounded problem transformation and well-thought-out adaptive strategy. We then
conduct an in-depth analysis to disclose the theoretical connection of S2CAG to
conductance minimization, which further inspires the design of M-S2CAG that
maximizes the modularity. Our extensive experiments, comparing S2CAG and
M-S2CAG against 17 competitors over 8 benchmark datasets, exhibit that our
solutions outperform all baselines in terms of clustering quality measured
against the ground truth while delivering high efficiency","cs.SI, cs.LG",cs.SI,http://arxiv.org/abs/2411.11074v1
"Knowledge-enhanced Transformer for Multivariate Long Sequence
  Time-series Forecasting","Shubham Tanaji Kakde, Rony Mitra, Jasashwi Mandal, Manoj Kumar Tiwari",2024-11-17T11:53:54Z,"Multivariate Long Sequence Time-series Forecasting (LSTF) has been a critical
task across various real-world applications. Recent advancements focus on the
application of transformer architectures attributable to their ability to
capture temporal patterns effectively over extended periods. However, these
approaches often overlook the inherent relationships and interactions between
the input variables that could be drawn from their characteristic properties.
In this paper, we aim to bridge this gap by integrating information-rich
Knowledge Graph Embeddings (KGE) with state-of-the-art transformer-based
architectures. We introduce a novel approach that encapsulates conceptual
relationships among variables within a well-defined knowledge graph, forming
dynamic and learnable KGEs for seamless integration into the transformer
architecture. We investigate the influence of this integration into seminal
architectures such as PatchTST, Autoformer, Informer, and Vanilla Transformer.
Furthermore, we thoroughly investigate the performance of these
knowledge-enhanced architectures along with their original implementations for
long forecasting horizons and demonstrate significant improvement in the
benchmark results. This enhancement empowers transformer-based architectures to
address the inherent structural relation between variables. Our
knowledge-enhanced approach improves the accuracy of multivariate LSTF by
capturing complex temporal and relational dynamics across multiple domains. To
substantiate the validity of our model, we conduct comprehensive experiments
using Weather and Electric Transformer Temperature (ETT) datasets.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11046v1
VeGaS: Video Gaussian Splatting,"Weronika Smolak-Dyżewska, Dawid Malarz, Kornel Howil, Jan Kaczmarczyk, Marcin Mazur, Przemysław Spurek",2024-11-17T10:02:36Z,"Implicit Neural Representations (INRs) employ neural networks to approximate
discrete data as continuous functions. In the context of video data, such
models can be utilized to transform the coordinates of pixel locations along
with frame occurrence times (or indices) into RGB color values. Although INRs
facilitate effective compression, they are unsuitable for editing purposes. One
potential solution is to use a 3D Gaussian Splatting (3DGS) based model, such
as the Video Gaussian Representation (VGR), which is capable of encoding video
as a multitude of 3D Gaussians and is applicable for numerous video processing
operations, including editing. Nevertheless, in this case, the capacity for
modification is constrained to a limited set of basic transformations. To
address this issue, we introduce the Video Gaussian Splatting (VeGaS) model,
which enables realistic modifications of video data. To construct VeGaS, we
propose a novel family of Folded-Gaussian distributions designed to capture
nonlinear dynamics in a video stream and model consecutive frames by 2D
Gaussians obtained as respective conditional distributions. Our experiments
demonstrate that VeGaS outperforms state-of-the-art solutions in frame
reconstruction tasks and allows realistic modifications of video data. The code
is available at: https://github.com/gmum/VeGaS.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11024v1
"CCi-YOLOv8n: Enhanced Fire Detection with CARAFE and Context-Guided
  Modules",Kunwei Lv,2024-11-17T09:31:04Z,"Fire incidents in urban and forested areas pose serious threats,underscoring
the need for more effective detection technologies. To address these
challenges, we present CCi-YOLOv8n, an enhanced YOLOv8 model with targeted
improvements for detecting small fires and smoke. The model integrates the
CARAFE up-sampling operator and a context-guided module to reduce information
loss during up-sampling and down-sampling, thereby retaining richer feature
representations. Additionally, an inverted residual mobile block enhanced C2f
module captures small targets and fine smoke patterns, a critical improvement
over the original model's detection capacity.For validation, we introduce
Web-Fire, a dataset curated for fire and smoke detection across diverse
real-world scenarios. Experimental results indicate that CCi-YOLOv8n
outperforms YOLOv8n in detection precision, confirming its effectiveness for
robust fire detection tasks.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11011v1
EROAM: Event-based Camera Rotational Odometry and Mapping in Real-time,"Wanli Xing, Shijie Lin, Linhan Yang, Zeqing Zhang, Yanjun Du, Maolin Lei, Yipeng Pan, Jia Pan",2024-11-17T08:50:47Z,"This paper presents EROAM, a novel event-based rotational odometry and
mapping system that achieves real-time, accurate camera rotation estimation.
Unlike existing approaches that rely on event generation models or contrast
maximization, EROAM employs a spherical event representation by projecting
events onto a unit sphere and introduces Event Spherical Iterative Closest
Point (ES-ICP), a novel geometric optimization framework designed specifically
for event camera data. The spherical representation simplifies rotational
motion formulation while enabling continuous mapping for enhanced spatial
resolution. Combined with parallel point-to-line optimization, EROAM achieves
efficient computation without compromising accuracy. Extensive experiments on
both synthetic and real-world datasets show that EROAM significantly
outperforms state-of-the-art methods in terms of accuracy, robustness, and
computational efficiency. Our method maintains consistent performance under
challenging conditions, including high angular velocities and extended
sequences, where other methods often fail or show significant drift.
Additionally, EROAM produces high-quality panoramic reconstructions with
preserved fine structural details.","cs.CV, cs.RO",cs.CV,http://arxiv.org/abs/2411.11004v1
"Map-Free Trajectory Prediction with Map Distillation and Hierarchical
  Encoding","Xiaodong Liu, Yucheng Xing, Xin Wang",2024-11-17T04:50:44Z,"Reliable motion forecasting of surrounding agents is essential for ensuring
the safe operation of autonomous vehicles. Many existing trajectory prediction
methods rely heavily on high-definition (HD) maps as strong driving priors.
However, the availability and accuracy of these priors are not guaranteed due
to substantial costs to build, localization errors of vehicles, or ongoing road
constructions. In this paper, we introduce MFTP, a Map-Free Trajectory
Prediction method that offers several advantages. First, it eliminates the need
for HD maps during inference while still benefiting from map priors during
training via knowledge distillation. Second, we present a novel hierarchical
encoder that effectively extracts spatial-temporal agent features and
aggregates them into multiple trajectory queries. Additionally, we introduce an
iterative decoder that sequentially decodes trajectory queries to generate the
final predictions. Extensive experiments show that our approach achieves
state-of-the-art performance on the Argoverse dataset under the map-free
setting.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10961v1
Direct and Explicit 3D Generation from a Single Image,"Haoyu Wu, Meher Gitika Karumuri, Chuhang Zou, Seungbae Bang, Yuelong Li, Dimitris Samaras, Sunil Hadap",2024-11-17T03:14:50Z,"Current image-to-3D approaches suffer from high computational costs and lack
scalability for high-resolution outputs. In contrast, we introduce a novel
framework to directly generate explicit surface geometry and texture using
multi-view 2D depth and RGB images along with 3D Gaussian features using a
repurposed Stable Diffusion model. We introduce a depth branch into U-Net for
efficient and high quality multi-view, cross-domain generation and incorporate
epipolar attention into the latent-to-pixel decoder for pixel-level multi-view
consistency. By back-projecting the generated depth pixels into 3D space, we
create a structured 3D representation that can be either rendered via Gaussian
splatting or extracted to high-quality meshes, thereby leveraging additional
novel view synthesis loss to further improve our performance. Extensive
experiments demonstrate that our method surpasses existing baselines in
geometry and texture quality while achieving significantly faster generation
time.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10947v1
"Learn from Downstream and Be Yourself in Multimodal Large Language Model
  Fine-Tuning","Wenke Huang, Jian Liang, Zekun Shi, Didi Zhu, Guancheng Wan, He Li, Bo Du, Dacheng Tao, Mang Ye",2024-11-17T01:16:37Z,"Multimodal Large Language Model (MLLM) have demonstrated strong
generalization capabilities across diverse distributions and tasks, largely due
to extensive pre-training datasets. Fine-tuning MLLM has become a common
practice to improve performance on specific downstream tasks. However, during
fine-tuning, MLLM often faces the risk of forgetting knowledge acquired during
pre-training, which can result in a decline in generalization abilities. To
balance the trade-off between generalization and specialization, we propose
measuring the parameter importance for both pre-trained and fine-tuning
distributions, based on frozen pre-trained weight magnitude and accumulated
fine-tuning gradient values. We further apply an importance-aware weight
allocation strategy, selectively updating relatively important parameters for
downstream tasks. We conduct empirical evaluations on both image captioning and
visual question-answering tasks using various MLLM architectures. The
comprehensive experimental analysis demonstrates the effectiveness of the
proposed solution, highlighting the efficiency of the crucial modules in
enhancing downstream specialization performance while mitigating generalization
degradation in MLLM Fine-Tuning.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.10928v1
"LLM-assisted Physical Invariant Extraction for Cyber-Physical Systems
  Anomaly Detection","Danial Abshari, Chenglong Fu, Meera Sridhar",2024-11-17T00:09:04Z,"Modern industrial infrastructures rely heavily on Cyber-Physical Systems
(CPS), but these are vulnerable to cyber-attacks with potentially catastrophic
effects. To reduce these risks, anomaly detection methods based on physical
invariants have been developed. However, these methods often require
domain-specific expertise to manually define invariants, making them costly and
difficult to scale. To address this limitation, we propose a novel approach to
extract physical invariants from CPS testbeds for anomaly detection. Our
insight is that CPS design documentation often contains semantically rich
descriptions of physical procedures, which can profile inter-correlated
dynamics among system components. Leveraging the built-in physics and
engineering knowledge of recent generative AI models, we aim to automate this
traditionally manual process, improving scalability and reducing costs. This
work focuses on designing and optimizing a Retrieval-Augmented-Generation (RAG)
workflow with a customized prompting system tailored for CPS documentation,
enabling accurate extraction of semantic information and inference of physical
invariants from complex, multimodal content. Then, rather than directly
applying the inferred invariants for anomaly detection, we introduce an
innovative statistics-based learning approach that integrates these invariants
into the training dataset. This method addresses limitations such as
hallucination and concept drift, enhancing the reliability of the model. We
evaluate our approach on real-world public CPS security dataset which contains
86 data points and 58 attacking cases. The results show that our approach
achieves a high precision of 0.923, accurately detecting anomalies while
minimizing false alarms.","cs.CR, cs.AI",cs.CR,http://arxiv.org/abs/2411.10918v1
"BPO: Towards Balanced Preference Optimization between Knowledge Breadth
  and Depth in Alignment","Sizhe Wang, Yongqi Tong, Hengyuan Zhang, Dawei Li, Xin Zhang, Tianlong Chen",2024-11-16T23:53:27Z,"Reinforcement Learning with Human Feedback (RLHF) is the key to the success
of large language models (LLMs) in recent years. In this work, we first
introduce the concepts of knowledge breadth and knowledge depth, which measure
the comprehensiveness and depth of an LLM or knowledge source respectively. We
reveal that the imbalance in the number of prompts and responses can lead to a
potential disparity in breadth and depth learning within alignment tuning
datasets by showing that even a simple uniform method for balancing the number
of instructions and responses can lead to significant improvements. Building on
this, we further propose Balanced Preference Optimization (BPO), designed to
dynamically augment the knowledge depth of each sample. BPO is motivated by the
observation that the usefulness of knowledge varies across samples,
necessitating tailored learning of knowledge depth. To achieve this, we
introduce gradient-based clustering, estimating the knowledge informativeness
and usefulness of each augmented sample based on the model's optimization
direction. Our experimental results across various benchmarks demonstrate that
BPO outperforms other baseline methods in alignment tuning while maintaining
training efficiency. Furthermore, we conduct a detailed analysis of each
component of BPO, providing guidelines for future research in preference data
optimization.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10914v1
Planning for Tabletop Object Rearrangement,"Jiaming Hu, Jan Szczekulski, Sudhansh Peddabomma, Henrik I. Christensen",2024-11-16T21:58:26Z,"Finding an high-quality solution for the tabletop object rearrangement
planning is a challenging problem. Compared to determining a goal arrangement,
rearrangement planning is challenging due to the dependencies between objects
and the buffer capacity available to hold objects. Although orla* has proposed
an A* based searching strategy with lazy evaluation for the high-quality
solution, it is not scalable, with the success rate decreasing as the number of
objects increases. To overcome this limitation, we propose an enhanced A*-based
algorithm that improves state representation and employs incremental goal
attempts with lazy evaluation at each iteration. This approach aims to enhance
scalability while maintaining solution quality. Our evaluation demonstrates
that our algorithm can provide superior solutions compared to orla*, in a
shorter time, for both stationary and mobile robots.",cs.RO,cs.RO,http://arxiv.org/abs/2411.10899v1
On the Verification of Control Flow Attestation Evidence,"Adam Caulfield, Norrathep Rattanavipanon, Ivan De Oliveira Nunes",2024-11-16T18:24:11Z,"Remote run-time attestation methods, including Control Flow Attestation (CFA)
and Data Flow Attestation (DFA), have been proposed to generate precise
evidence of execution's control flow path (in CFA) and optionally execution
data inputs (in DFA) on a remote and potentially compromised embedded device,
hereby referred to as a Prover (Prv). Recent advances in run-time attestation
architectures are also able to guarantee that a remote Verifier (Vrf) reliably
receives this evidence from Prv, even when Prv's software state is fully
compromised. This, in theory, enables secure ""run-time auditing"" in addition to
best-effort attestation, i.e., it guarantees that Vrf can examine execution
evidence to identify previously unknown compromises as soon as they are
exploited, pinpoint their root cause(s), and remediate them. However, prior
work has for the most part focused on securely implementing Prv's root of trust
(responsible for generating authentic run-time evidence), leaving Vrf 's
perspective in this security service unexplored. In this work, we argue that
run-time attestation and auditing are only truly useful if Vrf can effectively
analyze received evidence. From this premise, we characterize different types
of evidence produced by existing run-time attestation/auditing architectures in
terms of Vrf 's ability to detect and remediate (previously unknown)
vulnerabilities. As a case study for practical uses of run-time evidence by
Vrf, we propose SABRE: a Security Analysis and Binary Repair Engine. SABRE
showcases how Vrf can systematically leverage run-time evidence to detect
control flow attacks, pinpoint corrupted control data and specific instructions
used to corrupt them, and leverage this evidence to automatically generate
binary patches to buffer overflow and use-after-free vulnerabilities without
source code knowledge.",cs.CR,cs.CR,http://arxiv.org/abs/2411.10855v1
NeuroNURBS: Learning Efficient Surface Representations for 3D Solids,"Jiajie Fan, Babak Gholami, Thomas Bäck, Hao Wang",2024-11-16T17:44:43Z,"Boundary Representation (B-Rep) is the de facto representation of 3D solids
in Computer-Aided Design (CAD). B-Rep solids are defined with a set of NURBS
(Non-Uniform Rational B-Splines) surfaces forming a closed volume. To represent
a surface, current works often employ the UV-grid approximation, i.e., sample
points uniformly on the surface. However, the UV-grid method is not efficient
in surface representation and sometimes lacks precision and regularity. In this
work, we propose NeuroNURBS, a representation learning method to directly
encode the parameters of NURBS surfaces. Our evaluation in solid generation and
segmentation tasks indicates that the NeuroNURBS performs comparably and, in
some cases, superior to UV-grids, but with a significantly improved efficiency:
for training the surface autoencoder, GPU consumption is reduced by 86.7%;
memory requirement drops by 79.9% for storing 3D solids. Moreover, adapting
BrepGen for solid generation with our NeuroNURBS improves the FID from 30.04 to
27.24, and resolves the undulating issue in generated surfaces.","cs.CV, cs.CE",cs.CV,http://arxiv.org/abs/2411.10848v1
"Stable Continual Reinforcement Learning via Diffusion-based Trajectory
  Replay","Feng Chen, Fuguang Han, Cong Guan, Lei Yuan, Zhilong Zhang, Yang Yu, Zongzhang Zhang",2024-11-16T14:03:23Z,"Given the inherent non-stationarity prevalent in real-world applications,
continual Reinforcement Learning (RL) aims to equip the agent with the
capability to address a series of sequentially presented decision-making tasks.
Within this problem setting, a pivotal challenge revolves around
\textit{catastrophic forgetting} issue, wherein the agent is prone to
effortlessly erode the decisional knowledge associated with past encountered
tasks when learning the new one. In recent progresses, the \textit{generative
replay} methods have showcased substantial potential by employing generative
models to replay data distribution of past tasks. Compared to storing the data
from past tasks directly, this category of methods circumvents the growing
storage overhead and possible data privacy concerns. However, constrained by
the expressive capacity of generative models, existing \textit{generative
replay} methods face challenges in faithfully reconstructing the data
distribution of past tasks, particularly in scenarios with a myriad of tasks or
high-dimensional data. Inspired by the success of diffusion models in various
generative tasks, this paper introduces a novel continual RL algorithm DISTR
(Diffusion-based Trajectory Replay) that employs a diffusion model to memorize
the high-return trajectory distribution of each encountered task and wakeups
these distributions during the policy learning on new tasks. Besides,
considering the impracticality of replaying all past data each time, a
prioritization mechanism is proposed to prioritize the trajectory replay of
pivotal tasks in our method. Empirical experiments on the popular continual RL
benchmark \texttt{Continual World} demonstrate that our proposed method obtains
a favorable balance between \textit{stability} and \textit{plasticity},
surpassing various existing continual RL baselines in average success rate.",cs.LG,cs.LG,http://arxiv.org/abs/2411.10809v1
Playing Language Game with LLMs Leads to Jailbreaking,"Yu Peng, Zewen Long, Fangming Dong, Congyi Li, Shu Wu, Kai Chen",2024-11-16T13:07:13Z,"The advent of large language models (LLMs) has spurred the development of
numerous jailbreak techniques aimed at circumventing their security defenses
against malicious attacks. An effective jailbreak approach is to identify a
domain where safety generalization fails, a phenomenon known as mismatched
generalization. In this paper, we introduce two novel jailbreak methods based
on mismatched generalization: natural language games and custom language games,
both of which effectively bypass the safety mechanisms of LLMs, with various
kinds and different variants, making them hard to defend and leading to high
attack rates. Natural language games involve the use of synthetic linguistic
constructs and the actions intertwined with these constructs, such as the Ubbi
Dubbi language. Building on this phenomenon, we propose the custom language
games method: by engaging with LLMs using a variety of custom rules, we
successfully execute jailbreak attacks across multiple LLM platforms. Extensive
experiments demonstrate the effectiveness of our methods, achieving success
rates of 93% on GPT-4o, 89% on GPT-4o-mini and 83% on Claude-3.5-Sonnet.
Furthermore, to investigate the generalizability of safety alignments, we
fine-tuned Llama-3.1-70B with the custom language games to achieve safety
alignment within our datasets and found that when interacting through other
language games, the fine-tuned models still failed to identify harmful content.
This finding indicates that the safety alignment knowledge embedded in LLMs
fails to generalize across different linguistic formats, thus opening new
avenues for future research in this area.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.12762v1
Going Beyond Conventional OOD Detection,Sudarshan Regmi,2024-11-16T13:04:52Z,"Out-of-distribution (OOD) detection is critical to ensure the safe deployment
of deep learning models in critical applications. Deep learning models can
often misidentify OOD samples as in-distribution (ID) samples. This
vulnerability worsens in the presence of spurious correlation in the training
set. Likewise, in fine-grained classification settings, detection of
fine-grained OOD samples becomes inherently challenging due to their high
similarity to ID samples. However, current research on OOD detection has
largely ignored these challenging scenarios, focusing instead on relatively
easier (conventional) cases. In this work, we present a unified Approach to
Spurious, fine-grained, and Conventional OOD Detection (ASCOOD). First, we
propose synthesizing virtual outliers from ID data by approximating the
destruction of invariant features. We identify invariant features with the
pixel attribution method using the model being learned. This approach
eliminates the burden of curating external OOD datasets. Then, we
simultaneously incentivize ID classification and predictive uncertainty towards
the virtual outliers leveraging standardized feature representation. Our
approach effectively mitigates the impact of spurious correlations and
encourages capturing fine-grained attributes. Extensive experiments across six
datasets demonstrate the merit of ASCOOD in spurious, fine-grained, and
conventional settings. The code is available at:
https://github.com/sudarshanregmi/ASCOOD/","cs.CV, cs.LG",cs.CV,http://arxiv.org/abs/2411.10794v1
"On Reductions and Representations of Learning Problems in Euclidean
  Spaces","Bogdan Chornomaz, Shay Moran, Tom Waknine",2024-11-16T12:09:37Z,"Many practical prediction algorithms represent inputs in Euclidean space and
replace the discrete 0/1 classification loss with a real-valued surrogate loss,
effectively reducing classification tasks to stochastic optimization. In this
paper, we investigate the expressivity of such reductions in terms of key
resources, including dimension and the role of randomness.
  We establish bounds on the minimum Euclidean dimension $D$ needed to reduce a
concept class with VC dimension $d$ to a Stochastic Convex Optimization (SCO)
problem in $\mathbb{R}^D$, formally addressing the intuitive interpretation of
the VC dimension as the number of parameters needed to learn the class. To
achieve this, we develop a generalization of the Borsuk-Ulam Theorem that
combines the classical topological approach with convexity considerations.
Perhaps surprisingly, we show that, in some cases, the number of parameters $D$
must be exponentially larger than the VC dimension $d$, even if the reduction
is only slightly non-trivial. We also present natural classification tasks that
can be represented in much smaller dimensions by leveraging randomness, as seen
in techniques like random initialization. This result resolves an open question
posed by Kamath, Montasser, and Srebro (COLT 2020).
  Our findings introduce new variants of \emph{dimension complexity} (also
known as \emph{sign-rank}), a well-studied parameter in learning and complexity
theory. Specifically, we define an approximate version of sign-rank and another
variant that captures the minimum dimension required for a reduction to SCO. We
also propose several open questions and directions for future research.","cs.LG, stat.ML, 68Q32",cs.LG,http://arxiv.org/abs/2411.10784v1
"$\text{S}^{3}$Mamba: Arbitrary-Scale Super-Resolution via Scaleable
  State Space Model","Peizhe Xia, Long Peng, Xin Di, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha",2024-11-16T11:13:02Z,"Arbitrary scale super-resolution (ASSR) aims to super-resolve low-resolution
images to high-resolution images at any scale using a single model, addressing
the limitations of traditional super-resolution methods that are restricted to
fixed-scale factors (e.g., $\times2$, $\times4$). The advent of Implicit Neural
Representations (INR) has brought forth a plethora of novel methodologies for
ASSR, which facilitate the reconstruction of original continuous signals by
modeling a continuous representation space for coordinates and pixel values,
thereby enabling arbitrary-scale super-resolution. Consequently, the primary
objective of ASSR is to construct a continuous representation space derived
from low-resolution inputs. However, existing methods, primarily based on CNNs
and Transformers, face significant challenges such as high computational
complexity and inadequate modeling of long-range dependencies, which hinder
their effectiveness in real-world applications. To overcome these limitations,
we propose a novel arbitrary-scale super-resolution method, called
$\text{S}^{3}$Mamba, to construct a scalable continuous representation space.
Specifically, we propose a Scalable State Space Model (SSSM) to modulate the
state transition matrix and the sampling matrix of step size during the
discretization process, achieving scalable and continuous representation
modeling with linear computational complexity. Additionally, we propose a novel
scale-aware self-attention mechanism to further enhance the network's ability
to perceive global important features at different scales, thereby building the
$\text{S}^{3}$Mamba to achieve superior arbitrary-scale super-resolution.
Extensive experiments on both synthetic and real-world benchmarks demonstrate
that our method achieves state-of-the-art performance and superior
generalization capabilities at arbitrary super-resolution scales.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11906v1
"Steam Turbine Anomaly Detection: An Unsupervised Learning Approach Using
  Enhanced Long Short-Term Memory Variational Autoencoder","Weiming Xu, Peng Zhang",2024-11-16T10:11:36Z,"As core thermal power generation equipment, steam turbines incur significant
expenses and adverse effects on operation when facing interruptions like
downtime, maintenance, and damage. Accurate anomaly detection is the
prerequisite for ensuring the safe and stable operation of steam turbines.
However, challenges in steam turbine anomaly detection, including inherent
anomalies, lack of temporal information analysis, and high-dimensional data
complexity, limit the effectiveness of existing methods. To address these
challenges, we proposed an Enhanced Long Short-Term Memory Variational
Autoencoder using Deep Advanced Features and Gaussian Mixture Model
(ELSTMVAE-DAF-GMM) for precise unsupervised anomaly detection in unlabeled
datasets. Specifically, LSTMVAE, integrating LSTM with VAE, was used to project
high-dimensional time-series data to a low-dimensional phase space. The Deep
Autoencoder-Local Outlier Factor (DAE-LOF) sample selection mechanism was used
to eliminate inherent anomalies during training, further improving the model's
precision and reliability. The novel deep advanced features (DAF) hybridize
latent embeddings and reconstruction discrepancies from the LSTMVAE model and
provide a more comprehensive data representation within a continuous and
structured phase space, significantly enhancing anomaly detection by
synergizing temporal dynamics with data pattern variations. These DAF were
incorporated into GMM to ensure robust and effective unsupervised anomaly
detection. We utilized real operating data from industry steam turbines and
conducted both comparison and ablation experiments, demonstrating superior
anomaly detection outcomes characterized by high accuracy and minimal false
alarm rates compared with existing methods.","cs.LG, eess.SP",cs.LG,http://arxiv.org/abs/2411.10765v1
"Chain-of-Programming (CoP) : Empowering Large Language Models for
  Geospatial Code Generation","Shuyang Hou, Haoyue Jiao, Zhangxiao Shen, Jianyuan Liang, Anqi Zhao, Xiaopu Zhang, Jianxun Wang, Huayi Wu",2024-11-16T09:20:35Z,"With the rapid growth of interdisciplinary demands for geospatial modeling
and the rise of large language models (LLMs), geospatial code generation
technology has seen significant advancements. However, existing LLMs often face
challenges in the geospatial code generation process due to incomplete or
unclear user requirements and insufficient knowledge of specific platform
syntax rules, leading to the generation of non-executable code, a phenomenon
known as ""code hallucination."" To address this issue, this paper proposes a
Chain of Programming (CoP) framework, which decomposes the code generation
process into five steps: requirement analysis, algorithm design, code
implementation, code debugging, and code annotation. The framework incorporates
a shared information pool, knowledge base retrieval, and user feedback
mechanisms, forming an end-to-end code generation flow from requirements to
code without the need for model fine-tuning. Based on a geospatial problem
classification framework and evaluation benchmarks, the CoP strategy
significantly improves the logical clarity, syntactical correctness, and
executability of the generated code, with improvements ranging from 3.0% to
48.8%. Comparative and ablation experiments further validate the superiority of
the CoP strategy over other optimization approaches and confirm the rationality
and necessity of its key components. Through case studies on building data
visualization and fire data analysis, this paper demonstrates the application
and effectiveness of CoP in various geospatial scenarios. The CoP framework
offers a systematic, step-by-step approach to LLM-based geospatial code
generation tasks, significantly enhancing code generation performance in
geospatial tasks and providing valuable insights for code generation in other
vertical domains.","cs.SE, cs.AI, cs.CL",cs.SE,http://arxiv.org/abs/2411.10753v1
"It Takes Two: Accurate Gait Recognition in the Wild via
  Cross-granularity Alignment","Jinkai Zheng, Xinchen Liu, Boyue Zhang, Chenggang Yan, Jiyong Zhang, Wu Liu, Yongdong Zhang",2024-11-16T08:54:27Z,"Existing studies for gait recognition primarily utilized sequences of either
binary silhouette or human parsing to encode the shapes and dynamics of persons
during walking. Silhouettes exhibit accurate segmentation quality and
robustness to environmental variations, but their low information entropy may
result in sub-optimal performance. In contrast, human parsing provides
fine-grained part segmentation with higher information entropy, but the
segmentation quality may deteriorate due to the complex environments. To
discover the advantages of silhouette and parsing and overcome their
limitations, this paper proposes a novel cross-granularity alignment gait
recognition method, named XGait, to unleash the power of gait representations
of different granularity. To achieve this goal, the XGait first contains two
branches of backbone encoders to map the silhouette sequences and the parsing
sequences into two latent spaces, respectively. Moreover, to explore the
complementary knowledge across the features of two representations, we design
the Global Cross-granularity Module (GCM) and the Part Cross-granularity Module
(PCM) after the two encoders. In particular, the GCM aims to enhance the
quality of parsing features by leveraging global features from silhouettes,
while the PCM aligns the dynamics of human parts between silhouette and parsing
features using the high information entropy in parsing sequences. In addition,
to effectively guide the alignment of two representations with different
granularity at the part level, an elaborate-designed learnable division
mechanism is proposed for the parsing features. Comprehensive experiments on
two large-scale gait datasets not only show the superior performance of XGait
with the Rank-1 accuracy of 80.5% on Gait3D and 88.3% CCPG but also reflect the
robustness of the learned features even under challenging conditions like
occlusions and cloth changes.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10742v1
HJ-Ky-0.1: an Evaluation Dataset for Kyrgyz Word Embeddings,"Anton Alekseev, Gulnara Kabaeva",2024-11-16T07:14:32Z,"One of the key tasks in modern applied computational linguistics is
constructing word vector representations (word embeddings), which are widely
used to address natural language processing tasks such as sentiment analysis,
information extraction, and more. To choose an appropriate method for
generating these word embeddings, quality assessment techniques are often
necessary. A standard approach involves calculating distances between vectors
for words with expert-assessed 'similarity'. This work introduces the first
'silver standard' dataset for such tasks in the Kyrgyz language, alongside
training corresponding models and validating the dataset's suitability through
quality evaluation metrics.",cs.CL,cs.CL,http://arxiv.org/abs/2411.10724v1
Multi Scale Graph Neural Network for Alzheimer's Disease,"Anya Chauhan, Ayush Noori, Zhaozhi Li, Yingnan He, Michelle M Li, Marinka Zitnik, Sudeshna Das",2024-11-16T06:48:14Z,"Alzheimer's disease (AD) is a complex, progressive neurodegenerative disorder
characterized by extracellular A\b{eta} plaques, neurofibrillary tau tangles,
glial activation, and neuronal degeneration, involving multiple cell types and
pathways. Current models often overlook the cellular context of these pathways.
To address this, we developed a multiscale graph neural network (GNN) model,
ALZ PINNACLE, using brain omics data from donors spanning the entire aging to
AD spectrum. ALZ PINNACLE is based on the PINNACLE GNN framework, which learns
context-aware protein, cell type, and tissue representations within a unified
latent space. ALZ PINNACLE was trained on 14,951 proteins, 206,850 protein
interactions, 7 cell types, and 48 cell subtypes or states. After pretraining,
we investigated the learned embedding of APOE, the largest genetic risk factor
for AD, across different cell types. Notably, APOE embeddings showed high
similarity in microglial, neuronal, and CD8 cells, suggesting a similar role of
APOE in these cell types. Fine tuning the model on AD risk genes revealed cell
type contexts predictive of the role of APOE in AD. Our results suggest that
ALZ PINNACLE may provide a valuable framework for uncovering novel insights
into AD neurobiology.","cs.LG, q-bio.NC, q-bio.QM",cs.LG,http://arxiv.org/abs/2411.10720v1
"Transforming Teacher Education in Developing Countries: The Role of
  Generative AI in Bridging Theory and Practice",Matthew Nyaaba,2024-11-16T06:46:09Z,"This study examines the transformative potential of Generative AI (GenAI) in
teacher education within developing countries, focusing on Ghana, where
challenges such as limited pedagogical modeling, performance-based assessments,
and practitioner-expertise gaps hinder progress. GenAI has the capacity to
address these issues by supporting content knowledge acquisition, a role that
currently dominates teacher education programs. By taking on this foundational
role, GenAI allows teacher educators to redirect their focus to other critical
areas, including pedagogical modeling, authentic assessments, and fostering
digital literacy and critical thinking. These roles are interconnected,
creating a ripple effect where pre-service teachers (PSTs) are better equipped
to enhance K-12 learning outcomes and align education with workforce needs. The
study emphasizes that GenAI's roles are multifaceted, directly addressing
resistance to change, improving resource accessibility, and supporting teacher
professional development. However, it cautions against misuse, which could
undermine critical thinking and creativity, essential skills nurtured through
traditional teaching methods. To ensure responsible and effective integration,
the study advocates a scaffolding approach to GenAI literacy. This includes
educating PSTs on its supportive role, training them in ethical use and prompt
engineering, and equipping them to critically assess AI-generated content for
biases and validity. The study concludes by recommending empirical research to
explore these roles further and develop practical steps for integrating GenAI
into teacher education systems responsibly and effectively.","cs.CY, J.4; J.5; K.4",cs.CY,http://arxiv.org/abs/2411.10718v2
EVT: Efficient View Transformation for Multi-Modal 3D Object Detection,"Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim",2024-11-16T06:11:10Z,"Multi-modal sensor fusion in bird's-eye-view (BEV) representation has become
the leading approach in 3D object detection. However, existing methods often
rely on depth estimators or transformer encoders for view transformation,
incurring substantial computational overhead. Furthermore, the lack of precise
geometric correspondence between 2D and 3D spaces leads to spatial and
ray-directional misalignments, restricting the effectiveness of BEV
representations. To address these challenges, we propose a novel 3D object
detector via efficient view transformation (EVT), which leverages a
well-structured BEV representation to enhance accuracy and efficiency. EVT
focuses on two main areas. First, it employs Adaptive Sampling and Adaptive
Projection (ASAP), using LiDAR guidance to generate 3D sampling points and
adaptive kernels. The generated points and kernels are then used to facilitate
the transformation of image features into BEV space and refine the BEV
features. Second, EVT includes an improved transformer-based detection
framework, which contains a group-wise query initialization method and an
enhanced query update framework. It is designed to effectively utilize the
obtained multi-modal BEV features within the transformer decoder. By leveraging
the geometric properties of object queries, this framework significantly
enhances detection performance, especially in a multi-layer transformer decoder
structure. EVT achieves state-of-the-art performance on the nuScenes test set
with real-time inference speed.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10715v2
"Hybrid Attention Model Using Feature Decomposition and Knowledge
  Distillation for Glucose Forecasting","Ebrahim Farahmand, Shovito Barua Soumma, Nooshin Taheri Chatrudi, Hassan Ghasemzadeh",2024-11-16T05:09:20Z,"The availability of continuous glucose monitors as over-the-counter
commodities have created a unique opportunity to monitor a person's blood
glucose levels, forecast blood glucose trajectories and provide automated
interventions to prevent devastating chronic complications that arise from poor
glucose control. However, forecasting blood glucose levels is challenging
because blood glucose changes consistently in response to food intake,
medication intake, physical activity, sleep, and stress. It is particularly
difficult to accurately predict BGL from multimodal and irregularly sampled
data and over long prediction horizons. Furthermore, these forecasting models
must operate in real-time on edge devices to provide in-the-moment
interventions. To address these challenges, we propose GlucoNet, an AI-powered
sensor system for continuously monitoring behavioral and physiological health
and robust forecasting of blood glucose patterns. GlucoNet devises a feature
decomposition-based transformer model that incorporates patients' behavioral
and physiological data and transforms sparse and irregular patient data (e.g.,
diet and medication intake data) into continuous features using a mathematical
model, facilitating better integration with the BGL data. Given the non-linear
and non-stationary nature of BG signals, we propose a decomposition method to
extract both low and high-frequency components from the BGL signals, thus
providing accurate forecasting. To reduce the computational complexity, we also
propose to employ knowledge distillation to compress the transformer model.
GlucoNet achieves a 60% improvement in RMSE and a 21% reduction in the number
of parameters, using data obtained involving 12 participants with T1-Diabetes.
These results underscore GlucoNet's potential as a compact and reliable tool
for real-world diabetes prevention and management.","cs.LG, eess.SP",cs.LG,http://arxiv.org/abs/2411.10703v1
"Diffusion-based Layer-wise Semantic Reconstruction for Unsupervised
  Out-of-Distribution Detection","Ying Yang, De Cheng, Chaowei Fang, Yubiao Wang, Changzhe Jiao, Lechao Cheng, Nannan Wang",2024-11-16T04:54:07Z,"Unsupervised out-of-distribution (OOD) detection aims to identify
out-of-domain data by learning only from unlabeled In-Distribution (ID)
training samples, which is crucial for developing a safe real-world machine
learning system. Current reconstruction-based methods provide a good
alternative approach by measuring the reconstruction error between the input
and its corresponding generative counterpart in the pixel/feature space.
However, such generative methods face a key dilemma: improving the
reconstruction power of the generative model while keeping a compact
representation of the ID data. To address this issue, we propose the
diffusion-based layer-wise semantic reconstruction approach for unsupervised
OOD detection. The innovation of our approach is that we leverage the diffusion
model's intrinsic data reconstruction ability to distinguish ID samples from
OOD samples in the latent feature space. Moreover, to set up a comprehensive
and discriminative feature representation, we devise a multi-layer semantic
feature extraction strategy. By distorting the extracted features with Gaussian
noise and applying the diffusion model for feature reconstruction, the
separation of ID and OOD samples is implemented according to the reconstruction
errors. Extensive experimental results on multiple benchmarks built upon
various datasets demonstrate that our method achieves state-of-the-art
performance in terms of detection accuracy and speed. Code is available at
<https://github.com/xbyym/DLSR>.","cs.CV, cs.LG, eess.IV",cs.CV,http://arxiv.org/abs/2411.10701v1
Multi-perspective Contrastive Logit Distillation,"Qi Wang, Jinjia Zhou",2024-11-16T04:08:41Z,"We propose a novel and efficient logit distillation method, Multi-perspective
Contrastive Logit Distillation (MCLD), which leverages contrastive learning to
distill logits from multiple perspectives in knowledge distillation. Recent
research on logit distillation has primarily focused on maximizing the
information learned from the teacher model's logits to enhance the performance
of the student model. To this end, we propose MCLD, which consists of three key
components: Instance-wise CLD, Sample-wise CLD, and Category-wise CLD. These
components are designed to facilitate the transfer of more information from the
teacher's logits to the student model. Comprehensive evaluations on image
classification tasks using CIFAR-100 and ImageNet, alongside representation
transferability assessments on STL-10 and Tiny-ImageNet, highlight the
significant advantages of our method. The knowledge distillation with our MCLD,
surpasses existing state-of-the-art methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10693v1
DiHuR: Diffusion-Guided Generalizable Human Reconstruction,"Jinnan Chen, Chen Li, Gim Hee Lee",2024-11-16T03:52:23Z,"We introduce DiHuR, a novel Diffusion-guided model for generalizable Human 3D
Reconstruction and view synthesis from sparse, minimally overlapping images.
While existing generalizable human radiance fields excel at novel view
synthesis, they often struggle with comprehensive 3D reconstruction. Similarly,
directly optimizing implicit Signed Distance Function (SDF) fields from
sparse-view images typically yields poor results due to limited overlap. To
enhance 3D reconstruction quality, we propose using learnable tokens associated
with SMPL vertices to aggregate sparse view features and then to guide SDF
prediction. These tokens learn a generalizable prior across different
identities in training datasets, leveraging the consistent projection of SMPL
vertices onto similar semantic areas across various human identities. This
consistency enables effective knowledge transfer to unseen identities during
inference. Recognizing SMPL's limitations in capturing clothing details, we
incorporate a diffusion model as an additional prior to fill in missing
information, particularly for complex clothing geometries. Our method
integrates two key priors in a coherent manner: the prior from generalizable
feed-forward models and the 2D diffusion prior, and it requires only multi-view
image training, without 3D supervision. DiHuR demonstrates superior performance
in both within-dataset and cross-dataset generalization settings, as validated
on THuman, ZJU-MoCap, and HuMMan datasets compared to existing methods.",cs.CV,cs.CV,http://arxiv.org/abs/2411.11903v1
"From Prototypes to General Distributions: An Efficient Curriculum for
  Masked Image Modeling","Jinhong Lin, Cheng-En Wu, Huanran Li, Jifan Zhang, Yu Hen Hu, Pedro Morgado",2024-11-16T03:21:06Z,"Masked Image Modeling (MIM) has emerged as a powerful self-supervised
learning paradigm for visual representation learning, enabling models to
acquire rich visual representations by predicting masked portions of images
from their visible regions. While this approach has shown promising results, we
hypothesize that its effectiveness may be limited by optimization challenges
during early training stages, where models are expected to learn complex image
distributions from partial observations before developing basic visual
processing capabilities. To address this limitation, we propose a
prototype-driven curriculum leagrning framework that structures the learning
process to progress from prototypical examples to more complex variations in
the dataset. Our approach introduces a temperature-based annealing scheme that
gradually expands the training distribution, enabling more stable and efficient
learning trajectories. Through extensive experiments on ImageNet-1K, we
demonstrate that our curriculum learning strategy significantly improves both
training efficiency and representation quality while requiring substantially
fewer training epochs compared to standard Masked Auto-Encoding. Our findings
suggest that carefully controlling the order of training examples plays a
crucial role in self-supervised visual learning, providing a practical solution
to the early-stage optimization challenges in MIM.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10685v1
"Exploring Feature-based Knowledge Distillation For Recommender System: A
  Frequency Perspective","Zhangchi Zhu, Wei Zhang",2024-11-16T02:41:12Z,"In this paper, we analyze the feature-based knowledge distillation for
recommendation from the frequency perspective. By defining knowledge as
different frequency components of the features, we theoretically demonstrate
that regular feature-based knowledge distillation is equivalent to equally
minimizing losses on all knowledge and further analyze how this equal loss
weight allocation method leads to important knowledge being overlooked. In
light of this, we propose to emphasize important knowledge by redistributing
knowledge weights. Furthermore, we propose FreqD, a lightweight knowledge
reweighting method, to avoid the computational cost of calculating losses on
each knowledge. Extensive experiments demonstrate that FreqD consistently and
significantly outperforms state-of-the-art knowledge distillation methods for
recommender systems. Our code is available at
\url{https://anonymous.4open.science/r/FreqKD/}","cs.IR, cs.AI, cs.LG",cs.IR,http://arxiv.org/abs/2411.10676v1
"Awaker2.5-VL: Stably Scaling MLLMs with Parameter-Efficient Mixture of
  Experts","Jinqiang Long, Yanqi Dai, Guoxing Yang, Hongpeng Lin, Nanyi Fei, Yizhao Gao, Zhiwu Lu",2024-11-16T02:10:14Z,"As the research of Multimodal Large Language Models (MLLMs) becomes popular,
an advancing MLLM model is typically required to handle various textual and
visual tasks (e.g., VQA, Detection, OCR, and ChartQA) simultaneously for
real-world applications. However, due to the significant differences in
representation and distribution among data from various tasks, simply mixing
data of all tasks together leads to the well-known``multi-task conflict"" issue,
resulting in performance degradation across various tasks. To address this
issue, we propose Awaker2.5-VL, a Mixture of Experts~(MoE) architecture
suitable for MLLM, which acquires the multi-task capabilities through multiple
sparsely activated experts. To speed up the training and inference of
Awaker2.5-VL, each expert in our model is devised as a low-rank adaptation
(LoRA) structure. Extensive experiments on multiple latest benchmarks
demonstrate the effectiveness of Awaker2.5-VL. The code and model weight are
released in our Project Page: https://github.com/MetabrainAGI/Awaker.",cs.CV,cs.CV,http://arxiv.org/abs/2411.10669v1
AutoIoT: Automated IoT Platform Using Large Language Models,"Ye Cheng, Minghui Xu, Yue Zhang, Kun Li, Ruoxi Wang, Lian Yang",2024-11-16T02:02:01Z,"IoT platforms, particularly smart home platforms providing significant
convenience to people's lives such as Apple HomeKit and Samsung SmartThings,
allow users to create automation rules through trigger-action programming.
However, some users may lack the necessary knowledge to formulate automation
rules, thus preventing them from fully benefiting from the conveniences offered
by smart home technology. To address this, smart home platforms provide
pre-defined automation policies based on the smart home devices registered by
the user. Nevertheless, these policies, being pre-generated and relatively
simple, fail to adequately cover the diverse needs of users. Furthermore,
conflicts may arise between automation rules, and integrating conflict
detection into the IoT platform increases the burden on developers. In this
paper, we propose AutoIoT, an automated IoT platform based on Large Language
Models (LLMs) and formal verification techniques, designed to achieve
end-to-end automation through device information extraction, LLM-based rule
generation, conflict detection, and avoidance. AutoIoT can help users generate
conflict-free automation rules and assist developers in generating codes for
conflict detection, thereby enhancing their experience. A code adapter has been
designed to separate logical reasoning from the syntactic details of code
generation, enabling LLMs to generate code for programming languages beyond
their training data. Finally, we evaluated the performance of AutoIoT and
presented a case study demonstrating how AutoIoT can integrate with existing
IoT platforms.",cs.CR,cs.CR,http://arxiv.org/abs/2411.10665v1
"Leveraging large language models for efficient representation learning
  for entity resolution","Xiaowei Xu, Bi T. Foua, Xingqiao Wang, Vivek Gunasekaran, John R. Talburt",2024-11-15T23:24:07Z,"In this paper, the authors propose TriBERTa, a supervised entity resolution
system that utilizes a pre-trained large language model and a triplet loss
function to learn representations for entity matching. The system consists of
two steps: first, name entity records are fed into a Sentence Bidirectional
Encoder Representations from Transformers (SBERT) model to generate vector
representations, which are then fine-tuned using contrastive learning based on
a triplet loss function. Fine-tuned representations are used as input for
entity matching tasks, and the results show that the proposed approach
outperforms state-of-the-art representations, including SBERT without
fine-tuning and conventional Term Frequency-Inverse Document Frequency
(TF-IDF), by a margin of 3 - 19%. Additionally, the representations generated
by TriBERTa demonstrated increased robustness, maintaining consistently higher
performance across a range of datasets. The authors also discussed the
importance of entity resolution in today's data-driven landscape and the
challenges that arise when identifying and reconciling duplicate data across
different sources. They also described the ER process, which involves several
crucial steps, including blocking, entity matching, and clustering.","cs.CL, cs.AI",cs.CL,http://arxiv.org/abs/2411.10629v1
D-Flow: Multi-modality Flow Matching for D-peptide Design,"Fang Wu, Tinson Xu, Shuting Jin, Xiangru Tang, Zerui Xu, James Zou, Brian Hie",2024-11-15T22:44:36Z,"Proteins play crucial roles in biological processes, with therapeutic
peptides emerging as promising pharmaceutical agents. They allow new
possibilities to leverage target binding sites that were previously
undruggable. While deep learning (DL) has advanced peptide discovery,
generating D-proteins composed of D-amino acids remains challenging due to the
scarcity of natural examples. This paper proposes D-Flow, a full-atom
flow-based framework for {de novo} D-peptide design. D-Flow is conditioned on
receptor binding and utilizes a comprehensive representation of peptide
structure, incorporating backbone frames, side-chain angles, and discrete amino
acid types. A mirror-image algorithm is implemented to address the lack of
training data for D-proteins, which converts L-receptors' chirality.
Furthermore, we enhance D-Flow's capacity by integrating large protein language
models (PLMs) with structural awareness through a lightweight structural
adapter. A two-stage training pipeline and a controlling toolkit also enable
D-Flow to transition from general protein design to targeted binder design
while preserving pretraining knowledge.
  Extensive experimental results on the PepMerge benchmark demonstrate D-Flow's
effectiveness, particularly in developing peptides with entire D-residues. This
approach represents a significant advancement in computational D-peptide
design, offering unique opportunities for bioorthogonal and stable molecular
tools and diagnostics. The code is available
in~\url{https://github.com/smiles724/PeptideDesign}.",cs.CE,cs.CE,http://arxiv.org/abs/2411.10618v1
"Validation of Tumbling Robot Dynamics with Posture Manipulation for
  Closed-Loop Heading Angle Control","Adarsh Salagame, Eric Sihite, Alireza Ramezani",2024-11-20T01:47:25Z,"Navigating rugged terrain and steep slopes is a challenge for mobile robots.
Conventional legged and wheeled systems struggle with these environments due to
limited traction and stability. Northeastern University's COBRA (Crater
Observing Bio-inspired Rolling Articulator), a novel multi-modal snake-like
robot, addresses these issues by combining traditional snake gaits for
locomotion on flat and inclined surfaces with a tumbling mode for controlled
descent on steep slopes. Through dynamic posture manipulation, COBRA can
modulate its heading angle and velocity during tumbling. This paper presents a
reduced-order cascade model for COBRA's tumbling locomotion and validates it
against a high-fidelity rigid-body simulation, presenting simulation results
that show that the model captures key system dynamics.","cs.RO, cs.SY, eess.SY",cs.RO,http://arxiv.org/abs/2411.12970v1
"Towards Unifying Feature Interaction Models for Click-Through Rate
  Prediction","Yu Kang, Junwei Pan, Jipeng Jin, Shudong Huang, Xiaofeng Gao, Lei Xiao",2024-11-19T12:04:02Z,"Modeling feature interactions plays a crucial role in accurately predicting
click-through rates (CTR) in advertising systems. To capture the intricate
patterns of interaction, many existing models employ matrix-factorization
techniques to represent features as lower-dimensional embedding vectors,
enabling the modeling of interactions as products between these embeddings. In
this paper, we propose a general framework called IPA to systematically unify
these models. Our framework comprises three key components: the Interaction
Function, which facilitates feature interaction; the Layer Pooling, which
constructs higher-level interaction layers; and the Layer Aggregator, which
combines the outputs of all layers to serve as input for the subsequent
classifier. We demonstrate that most existing models can be categorized within
our framework by making specific choices for these three components. Through
extensive experiments and a dimensional collapse analysis, we evaluate the
performance of these choices. Furthermore, by leveraging the most powerful
components within our framework, we introduce a novel model that achieves
competitive results compared to state-of-the-art CTR models. PFL gets
significant GMV lift during online A/B test in Tencent's advertising platform
and has been deployed as the production model in several primary scenarios.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12441v1
"Instrumentation of Software Systems with OpenTelemetry for Software
  Visualization","Malte Hansen, Wilhelm Hasselbring",2024-11-19T10:01:26Z,"As software systems grow in complexity, data and tools that provide valuable
insights for easier program comprehension become increasingly important.
OpenTelemetry has become a standard for the collection of monitoring data. In
this work we present our experiences with different ways how OpenTelemetry can
be leveraged to automatically instrument software systems for the purpose of
software visualization. Particularly, we explore automatic instrumentation with
the OpenTelemetry SDKs, and both application and unit test instrumentation with
the Java agent inspectIT Ocelot. The collected data is exported to our live
trace visualization tool ExplorViz.",cs.SE,cs.SE,http://arxiv.org/abs/2411.12380v1
"A computational model for inelastic behaviour and fracture of refractory
  industrial components under high-temperature conditions, application to slide
  gate plates","Lorenzo Fiore, Andrea Piccolroaz",2024-11-19T08:54:28Z,"This work aims to provide a computational model that can describe the complex
behaviour of refractory industrial components under working conditions. Special
attention is given to the asymmetric tension-compression behaviour and its
evolution in the full range of working temperatures. The model accounts for
inelastic flow in compression and brittle fracture behaviour in tension by
leveraging the continuum-mechanics theory of plasticity and phase-field
fracture damage. The model is implemented in the Finite Element open-source
platform FEniCS and is used to analyze the fracture phenomenon in the
refractory plate used in ladle slide gate systems to control the liquid steel
flow from the ladle to the tundish.","cs.CE, physics.class-ph",cs.CE,http://arxiv.org/abs/2411.12346v1
"User Experience Evaluation of Augmented Reality: A Systematic Literature
  Review","Stefan Graser, Felix Kirschenlohr, Stephan Böhm",2024-11-19T07:19:28Z,"Due to technological development, Augmented Reality (AR) can be applied in
different domains. However, innovative technologies refer to new interaction
paradigms, thus creating a new experience for the user. This so-called User
Experience (UX) is essential for developing and designing interactive products.
Moreover, UX must be measured to get insights into the user's perception and,
thus, to improve innovative technologies. We conducted a Systematic Literature
Review (SLR) to provide an overview of the current research concerning UX
evaluation of AR. In particular, we aim to identify (1) research referring to
UX evaluation of AR and (2) articles containing AR-specific UX models or
frameworks concerning the theoretical foundation. The SLR is a five-step
approach including five scopes. From a total of 498 records based on eight
search terms referring to two databases, 30 relevant articles were identified
and further analyzed. Results show that most approaches concerning UX
evaluation of AR are quantitative. In summary, five UX models/frameworks were
identified. Concerning the UX evaluation results of AR in Training and
Education, the UX was consistently positive. Negative aspects refer to errors
and deficiencies concerning the AR system and its functionality. No specific
metric for UX evaluation of AR in the field of Training and Education exists.
Only three AR-specific standardized UX questionnaires could be found. However,
the questionnaires do not refer to the field of Training and Education. Thus,
there is a lack of research in the field of UX evaluation of AR in Training and
Education.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12777v1
"Forward and Reverse Converters for the Moduli-Set
  $\{2^{2q+1},2^q+2^{q-1}\pm1\}$","Ghassem Jaberipur, Bardia Nadimi, R. Kazemi, Jeong-A Lee",2024-11-19T04:02:25Z,"Modulo-$(2^q + 2^{q-1} \pm 1)$ adders have recently been implemented using
the regular parallel prefix (RPP) architecture, matching the speed of the
widely used modulo-$(2^q \pm 1)$ RPP adders. Consequently, we introduce a new
moduli set $\tau^+ = \{2^{2q+1}, 2^q + 2^{q-1} \pm 1\}$, with over $(2^{q+2})
\times$ dynamic range and adder speeds comparable to the conventional $\tau =
\{2^q, 2^q \pm 1\}$ set. However, to fully leverage $\tau^+$ in residue number
system applications, a complete set of circuitries is necessary. This work
focuses on the design and implementation of the forward and reverse converters
for $\tau^+$. These converters consist of four and seven levels of carry-save
addition units, culminating in a final modulo-$(2^q + 2^{q-1} \pm 1)$ and
modulo-$(2^{2q+1} + 2^{2q-2} - 1)$ adder, respectively. Through analytical
evaluations and circuit simulations, we demonstrate that the overall
performance of a sequence of operations including residue generation --
including residue generation, $k$ additions, and reverse conversion -- using
$\tau^+$ surpasses that of $\tau$ when $k$ exceeds a certain practical
threshold.","cs.AR, eess.SP",cs.AR,http://arxiv.org/abs/2411.12213v1
Safe Navigation in Dynamic Environments using Density Functions,"Sriram S. K. S Narayanan, Joseph Moyalan, Umesh Vaidya",2024-11-19T03:49:57Z,"This work uses density functions for safe navigation in dynamic environments.
The dynamic environment consists of time-varying obstacles as well as
time-varying target sets. We propose an analytical construction of time-varying
density functions to solve these navigation problems. The proposed approach
leads to a time-varying feedback controller obtained as a positive gradient of
the density function. This paper's main contribution is providing convergence
proof using the analytically constructed density function for safe navigation
in the presence of a dynamic obstacle set and time-varying target set. The
results are the first of this kind developed for a system with integrator
dynamics and open up the possibility for application to systems with more
complex dynamics using methods based on control density function and inverse
kinematic-based control design. We present the application of the developed
approach for collision avoidance in multi-agent systems and robotic systems.
While the theoretical results are produced for first-order integrator systems,
we demonstrate how the framework can be applied for systems with non-trivial
dynamics, such as Dubin's car model and fully actuated Euler-Lagrange system
with robotics applications.","cs.RO, math.DS, math.OC",cs.RO,http://arxiv.org/abs/2411.12206v1
Sparser Training for On-Device Recommendation Systems,"Yunke Qu, Liang Qu, Tong Chen, Xiangyu Zhao, Jianxin Li, Hongzhi Yin",2024-11-19T03:48:48Z,"Recommender systems often rely on large embedding tables that map users and
items to dense vectors of uniform size, leading to substantial memory
consumption and inefficiencies. This is particularly problematic in
memory-constrained environments like mobile and Web of Things (WoT)
applications, where scalability and real-time performance are critical. Various
research efforts have sought to address these issues. Although embedding
pruning methods utilizing Dynamic Sparse Training (DST) stand out due to their
low training and inference costs, consistent sparsity, and end-to-end
differentiability, they face key challenges. Firstly, they typically
initializes the mask matrix, which is used to prune redundant parameters, with
random uniform sparse initialization. This strategy often results in suboptimal
performance as it creates unstructured and inefficient connections. Secondly,
they tend to favor the users/items sampled in the single batch immediately
before weight exploration when they reactivate pruned parameters with large
gradient magnitudes, which does not necessarily improve the overall
performance. Thirdly, while they use sparse weights during forward passes, they
still need to compute dense gradients during backward passes. In this paper, we
propose SparseRec, an lightweight embedding method based on DST, to address
these issues. Specifically, SparseRec initializes the mask matrix using
Nonnegative Matrix Factorization. It accumulates gradients to identify the
inactive parameters that can better improve the model performance after
activation. Furthermore, it avoids dense gradients during backpropagation by
sampling a subset of important vectors. Gradients are calculated only for
parameters in this subset, thus maintaining sparsity during training in both
forward and backward passes.",cs.IR,cs.IR,http://arxiv.org/abs/2411.12205v1
"A Software Platform for Testing Multi-Link Operation in Industrial Wi-Fi
  Networks","Matteo Rosani, Gianluca Cena, Dave Cavalcanti, Valerio Frascolla, Guido Marchetto, Stefano Scanzio",2024-11-18T21:43:22Z,"Multi-Link Operation (MLO) in Wi-Fi 7 is expected to tangibly boost
throughput while lowering transmission latency at the same time. This is very
relevant in industrial scenarios and makes MLO suitable, e.g., to support
seamless device mobility. Benefits depend on the ability of multi-link devices
to select at run-time the best link, among the available ones, in order to
maximize both communication performance and reliability.
  In this paper an experimental platform is proposed, with the aim of
leveraging commercial hardware and open source software, and easing prototyping
and evaluation of MLO techniques. The platform has been employed to analyze the
transmission quality of two pairs of non-overlapping channels, and in
particular to assess whether or not adequate diversity is provided, so that
those channels can be exploited to improve reliability. Results point out that
correlation between different links is, in most cases, limited, which makes MLO
a valuable approach.",cs.NI,cs.NI,http://arxiv.org/abs/2411.12077v1
"Coevolution of relationship-driven cooperation under recommendation
  protocol on multiplex networks","Hongyu Yue, Xiaojin Xiong, Minyu Feng, Attila Szolnoki",2024-11-19T11:53:26Z,"While traditional game models often simplify interactions among agents as
static, real-world social relationships are inherently dynamic, influenced by
both immediate payoffs and alternative information. Motivated by this fact, we
introduce a coevolutionary multiplex network model that incorporates the
concepts of a relationship threshold and a recommendation mechanism to explore
how the strength of relationships among agents interacts with their strategy
choices within the framework of weak prisoner's dilemma games. In the
relationship layer, the relationship strength between agents varies based on
interaction outcomes. In return, the strategy choice of agents in the game
layer is influenced by both payoffs and relationship indices, and agents can
interact with distant agents through a recommendation mechanism. Simulation of
various network topologies reveals that a higher average degree supports
cooperation, although increased randomness in interactions may inhibit its
formation. Interestingly, a higher threshold value of interaction quality is
detrimental, while the applied recommendation protocol can improve global
cooperation. The best results are obtained when the relative weight of payoff
is minimal and the individual fitness is dominated by the relationship indices
gained from the quality of links to neighbors. As a consequence, the changes in
the distribution of relationship indices are closely correlated with overall
levels of cooperation.","cs.SI, physics.soc-ph",cs.SI,http://arxiv.org/abs/2411.12436v1
Intelligent Usability Evaluation for Fashion Websites,"Asmaa Hakami, Raneem Alqarni, Asmaa Muqaibil, Nahed Alowidi",2024-11-18T15:42:16Z,"Websites have become increasingly important in people's lives, fulfilling a
wide range of needs across various domains such as shopping, education, news,
and booking. Among the most heavily used website categories are online shopping
platforms, whose usage has particularly increased during the COVID-19 pandemic,
as they eliminate time and geographical barriers, providing access to a broader
customer base. For these websites to effectively meet user needs and deliver a
positive experience, they must be well-designed and adhere to usability
principles. However, some existing shopping websites are poorly designed and do
not follow usability best practices, resulting in suboptimal user experiences.
Traditional manual website evaluation methods are time-consuming, and there is
a need for more intelligent, automated approaches, particularly those
leveraging machine learning techniques. This study aims to assist fashion
shopping website developers in improving the usability of their platforms by
providing an intelligent approach that can evaluate website usability. The
study employs two complementary approaches for the evaluation process. The
first model utilizes a Support Vector Machine (SVM) to assess websites based on
specific usability principles, while the second model is a Convolutional Neural
Network (CNN) that evaluates websites using features extracted from their
screenshot images. The datasets for this project were custom-built, comprising
a textual dataset for the SVM model and a screenshot dataset for the CNN model.
The results demonstrate that the SVM model achieved an impressive 99% accuracy,
while the CNN model attained 69% accuracy. These findings highlight the
potential of this intelligent approach to provide comprehensive, data-driven
insights for improving the usability of fashion shopping websites.",cs.HC,cs.HC,http://arxiv.org/abs/2411.12770v1
No-regret Exploration in Shuffle Private Reinforcement Learning,"Shaojie Bai, Mohammad Sadegh Talebi, Chengcheng Zhao, Peng Cheng, Jiming Chen",2024-11-18T15:24:11Z,"Differential privacy (DP) has recently been introduced into episodic
reinforcement learning (RL) to formally address user privacy concerns in
personalized services. Previous work mainly focuses on two trust models of DP:
the central model, where a central agent is responsible for protecting users'
sensitive data, and the (stronger) local model, where the protection occurs
directly on the user side. However, they either require a trusted central agent
or incur a significantly higher privacy cost, making it unsuitable for many
scenarios. This work introduces a trust model stronger than the central model
but with a lower privacy cost than the local model, leveraging the emerging
\emph{shuffle} model of privacy. We present the first generic algorithm for
episodic RL under the shuffle model, where a trusted shuffler randomly permutes
a batch of users' data before sending it to the central agent. We then
instantiate the algorithm using our proposed shuffle Privatizer, relying on a
shuffle private binary summation mechanism. Our analysis shows that the
algorithm achieves a near-optimal regret bound comparable to that of the
centralized model and significantly outperforms the local model in terms of
privacy cost.","cs.LG, cs.AI, cs.CR",cs.LG,http://arxiv.org/abs/2411.11647v1
Signaling and Social Learning in Swarms of Robots,"Leo Cazenille, Maxime Toquebiau, Nicolas Lobato-Dauzier, Alessia Loi, Loona Macabre, Nathanael Aubert-Kato, Anthony Genot, Nicolas Bredeche",2024-11-18T14:42:15Z,"This paper investigates the role of communication in improving coordination
within robot swarms, focusing on a paradigm where learning and execution occur
simultaneously in a decentralized manner. We highlight the role communication
can play in addressing the credit assignment problem (individual contribution
to the overall performance), and how it can be influenced by it. We propose a
taxonomy of existing and future works on communication, focusing on information
selection and physical abstraction as principal axes for classification: from
low-level lossless compression with raw signal extraction and processing to
high-level lossy compression with structured communication models. The paper
reviews current research from evolutionary robotics, multi-agent (deep)
reinforcement learning, language models, and biophysics models to outline the
challenges and opportunities of communication in a collective of robots that
continuously learn from one another through local message exchanges,
illustrating a form of social learning.","cs.RO, cs.AI, cs.LG, cs.MA",cs.RO,http://arxiv.org/abs/2411.11616v2
Performance evaluation of a ROS2 based Automated Driving System,"Jorin Kouril, Bernd Schäufele, Ilja Radusch, Bettina Schnor",2024-11-18T14:29:22Z,"Automated driving is currently a prominent area of scientific work. In the
future, highly automated driving and new Advanced Driver Assistance Systems
will become reality. While Advanced Driver Assistance Systems and automated
driving functions for certain domains are already commercially available,
ubiquitous automated driving in complex scenarios remains a subject of ongoing
research. Contrarily to single-purpose Electronic Control Units, the software
for automated driving is often executed on high performance PCs. The Robot
Operating System 2 (ROS2) is commonly used to connect components in an
automated driving system. Due to the time critical nature of automated driving
systems, the performance of the framework is especially important. In this
paper, a thorough performance evaluation of ROS2 is conducted, both in terms of
timeliness and error rate. The results show that ROS2 is a suitable framework
for automated driving systems.",cs.RO,cs.RO,http://arxiv.org/abs/2411.11607v2
OASIS: Open Agents Social Interaction Simulations on One Million Agents,"Ziyi Yang, Zaibin Zhang, Zirui Zheng, Yuxian Jiang, Ziyue Gan, Zhiyu Wang, Zijian Ling, Jinsong Chen, Martz Ma, Bowen Dong, Prateek Gupta, Shuyue Hu, Zhenfei Yin, Guohao Li, Xu Jia, Lijun Wang, Bernard Ghanem, Huchuan Lu, Wanli Ouyang, Yu Qiao, Philip Torr, Jing Shao",2024-11-18T13:57:35Z,"There has been a growing interest in enhancing rule-based agent-based models
(ABMs) for social media platforms (\emph{i.e.}, X, Reddit) with more realistic
large language model (LLM) agents, thereby allowing for a more nuanced study of
complex systems. As a result, several LLM-based ABMs have been proposed in the
past year. While they hold promise, each simulator is specifically designed to
study a particular scenario, making it time-consuming and resource-intensive to
explore other phenomena using the same ABM. Additionally, these models simulate
only a limited number of agents, whereas real-world social media platforms
involve millions of users. To this end, we propose OASIS, a generalizable and
scalable social media simulator. OASIS is designed based on real-world social
media platforms, incorporating dynamically updated environments (\emph{i.e.},
dynamic social networks and post information), diverse action spaces
(\emph{i.e.}, following, commenting), and recommendation systems (\emph{i.e.},
interest-based and hot-score-based). Additionally, OASIS supports large-scale
user simulations, capable of modeling up to one million users. With these
features, OASIS can be easily extended to different social media platforms to
study large-scale group phenomena and behaviors. We replicate various social
phenomena, including information spreading, group polarization, and herd
effects across X and Reddit platforms. Moreover, we provide observations of
social phenomena at different agent group scales. We observe that the larger
agent group scale leads to more enhanced group dynamics and more diverse and
helpful agents' opinions. These findings demonstrate OASIS's potential as a
powerful tool for studying complex systems in digital environments.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11581v1
Topology-aware Preemptive Scheduling for Co-located LLM Workloads,"Ping Zhang, Lei Su, Jinjie Yang, Xin Chen",2024-11-18T13:26:09Z,"Hosting diverse large language model workloads in a unified resource pool
through co-location is cost-effective. For example, long-running chat services
generally follow diurnal traffic patterns, which inspire co-location of batch
jobs to fulfill resource valleys between successive peaks, and thus to saturate
resource allocation in cluster-wide scope. These heterogeneous workloads often
have different business priorities, and therefore preemption can be leveraged
for resource elasticity. However, workloads often have distinct topology
preferences as well. The resources released by lower-priority instances may
fail to meet the requirements of high-priority online services which are
usually latency-sensitive. The root cause behind such mis-match is a lack of
topology awareness of resource scheduler, especially during preemption. To
bridge this gap, we develop a fine-grained topology-aware method for preemptive
scheduling of hybrid workloads. The method ensures that the resources freed by
preempted tasks adhere to the topological affinity needs of high-priority
preemptors in a guaranteed or best-effort manner. This dynamic alignment
significantly increases the efficiency of preemption and improves overall
scheduled performance for LLM workloads by $55\%$.","cs.DC, cs.AI",cs.DC,http://arxiv.org/abs/2411.11560v1
"A Pre-Trained Graph-Based Model for Adaptive Sequencing of Educational
  Documents","Jean Vassoyan, Anan Schütt, Jill-Jênn Vie, Arun-Balajiee Lekshmi-Narayanan, Elisabeth André, Nicolas Vayatis",2024-11-18T12:29:06Z,"Massive Open Online Courses (MOOCs) have greatly contributed to making
education more accessible. However, many MOOCs maintain a rigid,
one-size-fits-all structure that fails to address the diverse needs and
backgrounds of individual learners. Learning path personalization aims to
address this limitation, by tailoring sequences of educational content to
optimize individual student learning outcomes. Existing approaches, however,
often require either massive student interaction data or extensive expert
annotation, limiting their broad application. In this study, we introduce a
novel data-efficient framework for learning path personalization that operates
without expert annotation. Our method employs a flexible recommender system
pre-trained with reinforcement learning on a dataset of raw course materials.
Through experiments on semi-synthetic data, we show that this pre-training
stage substantially improves data-efficiency in a range of adaptive learning
scenarios featuring new educational materials. This opens up new perspectives
for the design of foundation models for adaptive learning.","cs.AI, cs.CY, cs.LG",cs.AI,http://arxiv.org/abs/2411.11520v1
"Structure learning with Temporal Gaussian Mixture for model-based
  Reinforcement Learning","Théophile Champion, Marek Grześ, Howard Bowman",2024-11-18T12:16:03Z,"Model-based reinforcement learning refers to a set of approaches capable of
sample-efficient decision making, which create an explicit model of the
environment. This model can subsequently be used for learning optimal policies.
In this paper, we propose a temporal Gaussian Mixture Model composed of a
perception model and a transition model. The perception model extracts discrete
(latent) states from continuous observations using a variational Gaussian
mixture likelihood. Importantly, our model constantly monitors the collected
data searching for new Gaussian components, i.e., the perception model performs
a form of structure learning (Smith et al., 2020; Friston et al., 2018; Neacsu
et al., 2022) as it learns the number of Gaussian components in the mixture.
Additionally, the transition model learns the temporal transition between
consecutive time steps by taking advantage of the Dirichlet-categorical
conjugacy. Both the perception and transition models are able to forget part of
the data points, while integrating the information they provide within the
prior, which ensure fast variational inference. Finally, decision making is
performed with a variant of Q-learning which is able to learn Q-values from
beliefs over states. Empirically, we have demonstrated the model's ability to
learn the structure of several mazes: the model discovered the number of states
and the transition probabilities between these states. Moreover, using its
learned Q-values, the agent was able to successfully navigate from the starting
position to the maze's exit.","cs.LG, cs.AI, stat.ML",cs.LG,http://arxiv.org/abs/2411.11511v1
"Search, Verify and Feedback: Towards Next Generation Post-training
  Paradigm of Foundation Models via Verifier Engineering","Xinyan Guan, Yanjiang Liu, Xinyu Lu, Boxi Cao, Ben He, Xianpei Han, Le Sun, Jie Lou, Bowen Yu, Yaojie Lu, Hongyu Lin",2024-11-18T12:04:52Z,"The evolution of machine learning has increasingly prioritized the
development of powerful models and more scalable supervision signals. However,
the emergence of foundation models presents significant challenges in providing
effective supervision signals necessary for further enhancing their
capabilities. Consequently, there is an urgent need to explore novel
supervision signals and technical approaches. In this paper, we propose
verifier engineering, a novel post-training paradigm specifically designed for
the era of foundation models. The core of verifier engineering involves
leveraging a suite of automated verifiers to perform verification tasks and
deliver meaningful feedback to foundation models. We systematically categorize
the verifier engineering process into three essential stages: search, verify,
and feedback, and provide a comprehensive review of state-of-the-art research
developments within each stage. We believe that verifier engineering
constitutes a fundamental pathway toward achieving Artificial General
Intelligence.","cs.AI, cs.CL, stat.ML",cs.AI,http://arxiv.org/abs/2411.11504v1
"Safe + Safe = Unsafe? Exploring How Safe Images Can Be Exploited to
  Jailbreak Large Vision-Language Models","Chenhang Cui, Gelei Deng, An Zhang, Jingnan Zheng, Yicong Li, Lianli Gao, Tianwei Zhang, Tat-Seng Chua",2024-11-18T11:58:07Z,"Recent advances in Large Vision-Language Models (LVLMs) have showcased strong
reasoning abilities across multiple modalities, achieving significant
breakthroughs in various real-world applications. Despite this great success,
the safety guardrail of LVLMs may not cover the unforeseen domains introduced
by the visual modality. Existing studies primarily focus on eliciting LVLMs to
generate harmful responses via carefully crafted image-based jailbreaks
designed to bypass alignment defenses. In this study, we reveal that a safe
image can be exploited to achieve the same jailbreak consequence when combined
with additional safe images and prompts. This stems from two fundamental
properties of LVLMs: universal reasoning capabilities and safety snowball
effect. Building on these insights, we propose Safety Snowball Agent (SSA), a
novel agent-based framework leveraging agents' autonomous and tool-using
abilities to jailbreak LVLMs. SSA operates through two principal stages: (1)
initial response generation, where tools generate or retrieve jailbreak images
based on potential harmful intents, and (2) harmful snowballing, where refined
subsequent prompts induce progressively harmful outputs. Our experiments
demonstrate that \ours can use nearly any image to induce LVLMs to produce
unsafe content, achieving high success jailbreaking rates against the latest
LVLMs. Unlike prior works that exploit alignment flaws, \ours leverages the
inherent properties of LVLMs, presenting a profound challenge for enforcing
safety in generative multimodal systems. Our code is avaliable at
\url{https://github.com/gzcch/Safety_Snowball_Agent}.",cs.CL,cs.CL,http://arxiv.org/abs/2411.11496v2
"Robust Markov Decision Processes: A Place Where AI and Formal Methods
  Meet","Marnix Suilen, Thom Badings, Eline M. Bovy, David Parker, Nils Jansen",2024-11-18T10:34:14Z,"Markov decision processes (MDPs) are a standard model for sequential
decision-making problems and are widely used across many scientific areas,
including formal methods and artificial intelligence (AI). MDPs do, however,
come with the restrictive assumption that the transition probabilities need to
be precisely known. Robust MDPs (RMDPs) overcome this assumption by instead
defining the transition probabilities to belong to some uncertainty set. We
present a gentle survey on RMDPs, providing a tutorial covering their
fundamentals. In particular, we discuss RMDP semantics and how to solve them by
extending standard MDP methods such as value iteration and policy iteration. We
also discuss how RMDPs relate to other models and how they are used in several
contexts, including reinforcement learning and abstraction techniques. We
conclude with some challenges for future work on RMDPs.","cs.AI, math.OC",cs.AI,http://arxiv.org/abs/2411.11451v1
Unveiling the Inflexibility of Adaptive Embedding in Traffic Forecasting,"Hongjun Wang, Jiyuan Chen, Lingyu Zhang, Renhe Jiang, Xuan Song",2024-11-18T10:30:34Z,"Spatiotemporal Graph Neural Networks (ST-GNNs) and Transformers have shown
significant promise in traffic forecasting by effectively modeling temporal and
spatial correlations. However, rapid urbanization in recent years has led to
dynamic shifts in traffic patterns and travel demand, posing major challenges
for accurate long-term traffic prediction. The generalization capability of
ST-GNNs in extended temporal scenarios and cross-city applications remains
largely unexplored. In this study, we evaluate state-of-the-art models on an
extended traffic benchmark and observe substantial performance degradation in
existing ST-GNNs over time, which we attribute to their limited inductive
capabilities. Our analysis reveals that this degradation stems from an
inability to adapt to evolving spatial relationships within urban environments.
To address this limitation, we reconsider the design of adaptive embeddings and
propose a Principal Component Analysis (PCA) embedding approach that enables
models to adapt to new scenarios without retraining. We incorporate PCA
embeddings into existing ST-GNN and Transformer architectures, achieving marked
improvements in performance. Notably, PCA embeddings allow for flexibility in
graph structures between training and testing, enabling models trained on one
city to perform zero-shot predictions on other cities. This adaptability
demonstrates the potential of PCA embeddings in enhancing the robustness and
generalization of spatiotemporal models.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11448v1
Implicit Regularization for Multi-label Feature Selection,"Dou El Kefel Mansouri, Khalid Benabdeslem, Seif-Eddine Benkabou",2024-11-18T10:08:05Z,"In this paper, we address the problem of feature selection in the context of
multi-label learning, by using a new estimator based on implicit regularization
and label embedding. Unlike the sparse feature selection methods that use a
penalized estimator with explicit regularization terms such as $l_{2,1}$-norm,
MCP or SCAD, we propose a simple alternative method via Hadamard product
parameterization. In order to guide the feature selection process, a latent
semantic of multi-label information method is adopted, as a label embedding.
Experimental results on some known benchmark datasets suggest that the proposed
estimator suffers much less from extra bias, and may lead to benign
overfitting.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11436v1
The GECo algorithm for Graph Neural Networks Explanation,"Salvatore Calderaro, Domenico Amato, Giosuè Lo Bosco, Riccardo Rizzo, Filippo Vella",2024-11-18T09:08:30Z,"Graph Neural Networks (GNNs) are powerful models that can manage complex data
sources and their interconnection links. One of GNNs' main drawbacks is their
lack of interpretability, which limits their application in sensitive fields.
In this paper, we introduce a new methodology involving graph communities to
address the interpretability of graph classification problems. The proposed
method, called GECo, exploits the idea that if a community is a subset of graph
nodes densely connected, this property should play a role in graph
classification. This is reasonable, especially if we consider the
message-passing mechanism, which is the basic mechanism of GNNs. GECo analyzes
the contribution to the classification result of the communities in the graph,
building a mask that highlights graph-relevant structures. GECo is tested for
Graph Convolutional Networks on six artificial and four real-world graph
datasets and is compared to the main explainability methods such as
PGMExplainer, PGExplainer, GNNExplainer, and SubgraphX using four different
metrics. The obtained results outperform the other methods for artificial graph
datasets and most real-world datasets.","cs.LG, cs.AI",cs.LG,http://arxiv.org/abs/2411.11391v1
"Multi-hop Differential Topology based Algorithms for Resilient Network
  of UAV Swarm","Huan Lin, Lianghui Ding",2024-11-18T07:23:55Z,"Unmanned aerial vehicle (UAV) swarm networks face severe challenges of
communication network split (CNS) issues caused by massive damage in hostile
environments. In this paper, we propose a new paradigm to restore network
connectivity by repositioning remaining UAVs based on damage information within
local topologies. Particularly, the locations of destroyed UAVs distributed in
gaps between disconnected sub-nets are considered for recovery trajectory
planning. Specifically, we construct the multi-hop differential sub-graph
(MDSG) to represent local damage-varying topologies. Based on this, we develop
two distinct algorithms to address CNS issues. The first approach leverages an
artificial potential field algorithm to calculate the recovery velocities via
MDSG, enabling simple deployment on low-intelligence UAVs. In the second
approach, we design an MDSG-based graph convolution framework to find the
recovery topology for high-intelligence swarms. As per the unique topology of
MDSG, we propose a novel bipartite graph convolution operation, enhanced with a
batch-processing mechanism to improve graph convolution efficiency. Simulation
results show that the proposed algorithms expedite the recovery with
significant margin while improving the spatial coverage and topology degree
uniformity after recovery.",cs.NI,cs.NI,http://arxiv.org/abs/2411.11342v1
Syllabus: Portable Curricula for Reinforcement Learning Agents,"Ryan Sullivan, Ryan Pégoud, Ameen Ur Rahmen, Xinchen Yang, Junyun Huang, Aayush Verma, Nistha Mitra, John P. Dickerson",2024-11-18T06:22:30Z,"Curriculum learning has been a quiet yet crucial component of many of the
high-profile successes of reinforcement learning. Despite this, none of the
major reinforcement learning libraries directly support curriculum learning or
include curriculum learning implementations. These methods can improve the
capabilities and robustness of RL agents, but often require significant,
complex changes to agent training code. We introduce Syllabus, a library for
training RL agents with curriculum learning, as a solution to this problem.
Syllabus provides a universal API for curriculum learning algorithms,
implementations of popular curriculum learning methods, and infrastructure for
easily integrating them with distributed training code written in nearly any RL
library. Syllabus provides a minimal API for each of the core components of
curriculum learning, dramatically simplifying the process of designing new
algorithms and applying existing algorithms to new environments. We demonstrate
that the same Syllabus code can be used to train agents written in multiple
different RL libraries on numerous domains. In doing so, we present the first
examples of curriculum learning in NetHack and Neural MMO, two of the premier
challenges for single-agent and multi-agent RL respectively, achieving strong
results compared to state of the art baselines.",cs.AI,cs.AI,http://arxiv.org/abs/2411.11318v1
"Establishing Minimum Elements for Effective Vulnerability Management in
  AI Software","Mohamad Fazelnia, Sara Moshtari, Mehdi Mirakhorli",2024-11-18T06:22:20Z,"In the rapidly evolving field of artificial intelligence (AI), the
identification, documentation, and mitigation of vulnerabilities are paramount
to ensuring robust and secure systems. This paper discusses the minimum
elements for AI vulnerability management and the establishment of an Artificial
Intelligence Vulnerability Database (AIVD). It presents standardized formats
and protocols for disclosing, analyzing, cataloging, and documenting AI
vulnerabilities. It discusses how such an AI incident database must extend
beyond the traditional scope of vulnerabilities by focusing on the unique
aspects of AI systems. Additionally, this paper highlights challenges and gaps
in AI Vulnerability Management, including the need for new severity scores,
weakness enumeration systems, and comprehensive mitigation strategies
specifically designed to address the multifaceted nature of AI vulnerabilities.",cs.CR,cs.CR,http://arxiv.org/abs/2411.11317v1
